// Generated by Futhark 0.26.0 (prerelease - include info below when reporting bugs).
// git: 7947116 (Mon Nov 17 10:29:28 2025 +0100)
// Compiled with GHC 9.6.7.

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wunused-const-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#pragma clang diagnostic ignored "-Wunused-but-set-variable"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wunused-const-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#define CL_TARGET_OPENCL_VERSION 120
#define CL_USE_DEPRECATED_OPENCL_1_2_APIS
#ifdef __APPLE__
#define CL_SILENCE_DEPRECATION
#include <OpenCL/cl.h>
#else
#include <CL/cl.h>
#endif

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *ctx);
void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_unified_memory(struct futhark_context_config *cfg, int flag);
void futhark_context_config_add_build_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_platform(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_select_device_interactively(struct futhark_context_config *cfg);
void futhark_context_config_list_devices(struct futhark_context_config *cfg);
const char *futhark_context_config_get_program(struct futhark_context_config *cfg);
void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_binary_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_binary_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_command_queue(struct futhark_context_config *cfg, cl_command_queue);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_i64_1d;
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0);
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, cl_mem data, int64_t dim0);
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data);
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0);
cl_mem futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
struct futhark_i8_1d;
struct futhark_i8_1d *futhark_new_i8_1d(struct futhark_context *ctx, const int8_t *data, int64_t dim0);
struct futhark_i8_1d *futhark_new_raw_i8_1d(struct futhark_context *ctx, cl_mem data, int64_t dim0);
int futhark_free_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr);
int futhark_values_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr, int8_t *data);
int futhark_index_i8_1d(struct futhark_context *ctx, int8_t *out, struct futhark_i8_1d *arr, int64_t i0);
cl_mem futhark_values_raw_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr);
const int64_t *futhark_shape_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr);

// Opaque values



// Entry points
int futhark_entry_main(struct futhark_context *ctx, struct futhark_i8_1d **out0, const int32_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i64_1d *in4);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
cl_command_queue futhark_context_get_command_queue(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
char *futhark_context_report(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_opencl
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
#define SCALAR_FUN_ATTR static inline
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

static void str_builder_str(struct str_builder *b, const char *s) {
  size_t needed = strlen(s);
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  strcpy(b->str+b->used, s);
  b->used += needed;
}

static void str_builder_char(struct str_builder *b, char c) {
  size_t needed = 1;
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  b->str[b->used] = c;
  b->str[b->used+1] = 0;
  b->used += needed;
}

static void str_builder_json_str(struct str_builder* sb, const char* s) {
  str_builder_char(sb, '"');
  for (int j = 0; s[j]; j++) {
    char c = s[j];
    switch (c) {
    case '\n':
      str_builder_str(sb, "\\n");
      break;
    case '"':
      str_builder_str(sb, "\\\"");
      break;
    default:
      str_builder_char(sb, c);
    }
  }
  str_builder_char(sb, '"');
}

static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// Assumes NULL-terminated.
static char *strconcat(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

static int64_t get_wall_time_ns(void) {
  return get_wall_time() * 1000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_MONOTONIC, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

static int64_t get_wall_time(void) {
  return get_wall_time_ns() / 1000;
}


#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
// Start of event_list.h

typedef int (*event_report_fn)(struct str_builder*, void*);

// A collection of key-value associations. Used to associate extra data with
// events.
struct kvs {
  // A buffer that contains all value data. Must be freed when the struct kvs is
  // no longer used.
  char *buf;

  // Size of buf in bytes.
  size_t buf_size;

  // Number of bytes used in buf.
  size_t buf_used;

  // Number of associations stored.
  size_t n;

  // Capacity of vals.
  size_t vals_capacity;

  // An array of keys.
  const char* *keys;

  // Indexes into 'buf' that contains the values as zero-terminated strings.
  size_t *vals;
};

static const size_t KVS_INIT_BUF_SIZE = 128;
static const size_t KVS_INIT_NUMKEYS = 8;

void kvs_init(struct kvs* kvs) {
  kvs->buf = malloc(KVS_INIT_BUF_SIZE);
  kvs->buf_size = KVS_INIT_BUF_SIZE;
  kvs->buf_used = 0;
  kvs->vals_capacity = KVS_INIT_NUMKEYS;
  kvs->keys = calloc(kvs->vals_capacity, sizeof(const char*));
  kvs->vals = calloc(kvs->vals_capacity, sizeof(size_t));
  kvs->n = 0;
}

struct kvs* kvs_new(void) {
  struct kvs *kvs = malloc(sizeof(struct kvs));
  kvs_init(kvs);
  return kvs;
}

void kvs_printf(struct kvs* kvs, const char* key, const char* fmt, ...) {
  va_list vl;
  va_start(vl, fmt);

  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, fmt, vl);

  while (kvs->buf_used+needed > kvs->buf_size) {
    kvs->buf_size *= 2;
    kvs->buf = realloc(kvs->buf, kvs->buf_size * sizeof(const char*));
  }

  if (kvs->n == kvs->vals_capacity) {
    kvs->vals_capacity *= 2;
    kvs->vals = realloc(kvs->vals, kvs->vals_capacity * sizeof(size_t));
    kvs->keys = realloc(kvs->keys, kvs->vals_capacity * sizeof(char*));
  }

  kvs->keys[kvs->n] = key;
  kvs->vals[kvs->n] = kvs->buf_used;
  kvs->buf_used += needed;

  va_start(vl, fmt); // Must re-init.
  vsnprintf(&kvs->buf[kvs->vals[kvs->n]], needed, fmt, vl);

  kvs->n++;
}

void kvs_free(struct kvs* kvs) {
  free(kvs->vals);
  free(kvs->keys);
  free(kvs->buf);
}

// Assumes all of the values are valid JSON objects.
void kvs_json(const struct kvs* kvs, struct str_builder *sb) {
  str_builder_char(sb, '{');
  for (size_t i = 0; i < kvs->n; i++) {
    if (i != 0) {
      str_builder_str(sb, ",");
    }
    str_builder_json_str(sb, kvs->keys[i]);
    str_builder_str(sb, ":");
    str_builder_str(sb, &kvs->buf[kvs->vals[i]]);
  }
  str_builder_char(sb, '}');
}

void kvs_log(const struct kvs* kvs, const char* prefix, FILE* f) {
  for (size_t i = 0; i < kvs->n; i++) {
    fprintf(f, "%s%s: %s\n",
            prefix,
            kvs->keys[i],
            &kvs->buf[kvs->vals[i]]);
  }
}

struct event {
  void* data;
  event_report_fn f;
  const char* name;
  const char *provenance;
  // Key-value information that is also to be printed.
  struct kvs *kvs;
};

struct event_list {
  struct event *events;
  int num_events;
  int capacity;
};

static void event_list_init(struct event_list *l) {
  l->capacity = 100;
  l->num_events = 0;
  l->events = calloc(l->capacity, sizeof(struct event));
}

static void event_list_free(struct event_list *l) {
  free(l->events);
}

static void add_event_to_list(struct event_list *l,
                              const char* name,
                              const char* provenance,
                              struct kvs *kvs,
                              void* data,
                              event_report_fn f) {
  if (l->num_events == l->capacity) {
    l->capacity *= 2;
    l->events = realloc(l->events, l->capacity * sizeof(struct event));
  }
  l->events[l->num_events].name = name;
  l->events[l->num_events].provenance =
    provenance ? provenance : "unknown";
  l->events[l->num_events].kvs = kvs;
  l->events[l->num_events].data = data;
  l->events[l->num_events].f = f;
  l->num_events++;
}

static int report_events_in_list(struct event_list *l,
                                 struct str_builder* sb) {
  int ret = 0;
  for (int i = 0; i < l->num_events; i++) {
    if (i != 0) {
      str_builder_str(sb, ",");
    }
    str_builder_str(sb, "{\"name\":");
    str_builder_json_str(sb, l->events[i].name);
    str_builder_str(sb, ",\"provenance\":");
    str_builder_json_str(sb, l->events[i].provenance);
    if (l->events[i].f(sb, l->events[i].data) != 0) {
      ret = 1;
      break;
    }

    str_builder_str(sb, ",\"details\":");
    if (l->events[i].kvs) {
      kvs_json(l->events[i].kvs, sb);
      kvs_free(l->events[i].kvs);
    } else {
      str_builder_str(sb, "{}");
    }

    str_builder(sb, "}");
  }
  event_list_free(l);
  event_list_init(l);
  return ret;
}

// End of event_list.h
#include <getopt.h>
#include <ctype.h>
#include <inttypes.h>
static const char *entry_point = "main";
// Start of values.h.

//// Text I/O

typedef int (*writer)(FILE*, const void*);
typedef int (*bin_reader)(void*);
typedef int (*str_reader)(const char *, void*);

struct array_reader {
  char* elems;
  int64_t n_elems_space;
  int64_t elem_size;
  int64_t n_elems_used;
  int64_t *shape;
  str_reader elem_reader;
};

static void skipspaces(FILE *f) {
  int c;
  do {
    c = getc(f);
  } while (isspace(c));

  if (c != EOF) {
    ungetc(c, f);
  }
}

static int constituent(char c) {
  return isalnum(c) || c == '.' || c == '-' || c == '+' || c == '_';
}

// Produces an empty token only on EOF.
static void next_token(FILE *f, char *buf, int bufsize) {
 start:
  skipspaces(f);

  int i = 0;
  while (i < bufsize) {
    int c = getc(f);
    buf[i] = (char)c;

    if (c == EOF) {
      buf[i] = 0;
      return;
    } else if (c == '-' && i == 1 && buf[0] == '-') {
      // Line comment, so skip to end of line and start over.
      for (; c != '\n' && c != EOF; c = getc(f));
      goto start;
    } else if (!constituent((char)c)) {
      if (i == 0) {
        // We permit single-character tokens that are not
        // constituents; this lets things like ']' and ',' be
        // tokens.
        buf[i+1] = 0;
        return;
      } else {
        ungetc(c, f);
        buf[i] = 0;
        return;
      }
    }

    i++;
  }

  buf[bufsize-1] = 0;
}

static int next_token_is(FILE *f, char *buf, int bufsize, const char* expected) {
  next_token(f, buf, bufsize);
  return strcmp(buf, expected) == 0;
}

static void remove_underscores(char *buf) {
  char *w = buf;

  for (char *r = buf; *r; r++) {
    if (*r != '_') {
      *w++ = *r;
    }
  }

  *w++ = 0;
}

static int read_str_elem(char *buf, struct array_reader *reader) {
  int ret;
  if (reader->n_elems_used == reader->n_elems_space) {
    reader->n_elems_space *= 2;
    reader->elems = (char*) realloc(reader->elems,
                                    (size_t)(reader->n_elems_space * reader->elem_size));
  }

  ret = reader->elem_reader(buf, reader->elems + reader->n_elems_used * reader->elem_size);

  if (ret == 0) {
    reader->n_elems_used++;
  }

  return ret;
}

static int read_str_array_elems(FILE *f,
                                char *buf, int bufsize,
                                struct array_reader *reader, int64_t dims) {
  int ret = 1;
  int expect_elem = 1;
  char *knows_dimsize = (char*) calloc((size_t)dims, sizeof(char));
  int cur_dim = (int)dims-1;
  int64_t *elems_read_in_dim = (int64_t*) calloc((size_t)dims, sizeof(int64_t));

  while (1) {
    next_token(f, buf, bufsize);
    if (strcmp(buf, "]") == 0) {
      expect_elem = 0;
      if (knows_dimsize[cur_dim]) {
        if (reader->shape[cur_dim] != elems_read_in_dim[cur_dim]) {
          ret = 1;
          break;
        }
      } else {
        knows_dimsize[cur_dim] = 1;
        reader->shape[cur_dim] = elems_read_in_dim[cur_dim];
      }
      if (cur_dim == 0) {
        ret = 0;
        break;
      } else {
        cur_dim--;
        elems_read_in_dim[cur_dim]++;
      }
    } else if (!expect_elem && strcmp(buf, ",") == 0) {
      expect_elem = 1;
    } else if (expect_elem) {
      if (strcmp(buf, "[") == 0) {
        if (cur_dim == dims - 1) {
          ret = 1;
          break;
        }
        cur_dim++;
        elems_read_in_dim[cur_dim] = 0;
      } else if (cur_dim == dims - 1) {
        ret = read_str_elem(buf, reader);
        if (ret != 0) {
          break;
        }
        expect_elem = 0;
        elems_read_in_dim[cur_dim]++;
      } else {
        ret = 1;
        break;
      }
    } else {
      ret = 1;
      break;
    }
  }

  free(knows_dimsize);
  free(elems_read_in_dim);
  return ret;
}

static int read_str_empty_array(FILE *f, char *buf, int bufsize,
                                const char *type_name, int64_t *shape, int64_t dims) {
  if (strlen(buf) == 0) {
    // EOF
    return 1;
  }

  if (strcmp(buf, "empty") != 0) {
    return 1;
  }

  if (!next_token_is(f, buf, bufsize, "(")) {
    return 1;
  }

  for (int i = 0; i < dims; i++) {
    if (!next_token_is(f, buf, bufsize, "[")) {
      return 1;
    }

    next_token(f, buf, bufsize);

    if (sscanf(buf, "%"SCNu64, (uint64_t*)&shape[i]) != 1) {
      return 1;
    }

    if (!next_token_is(f, buf, bufsize, "]")) {
      return 1;
    }
  }

  if (!next_token_is(f, buf, bufsize, type_name)) {
    return 1;
  }


  if (!next_token_is(f, buf, bufsize, ")")) {
    return 1;
  }

  // Check whether the array really is empty.
  for (int i = 0; i < dims; i++) {
    if (shape[i] == 0) {
      return 0;
    }
  }

  // Not an empty array!
  return 1;
}

static int read_str_array(FILE *f,
                          int64_t elem_size, str_reader elem_reader,
                          const char *type_name,
                          void **data, int64_t *shape, int64_t dims) {
  int ret;
  struct array_reader reader;
  char buf[100];

  int dims_seen;
  for (dims_seen = 0; dims_seen < dims; dims_seen++) {
    if (!next_token_is(f, buf, sizeof(buf), "[")) {
      break;
    }
  }

  if (dims_seen == 0) {
    return read_str_empty_array(f, buf, sizeof(buf), type_name, shape, dims);
  }

  if (dims_seen != dims) {
    return 1;
  }

  reader.shape = shape;
  reader.n_elems_used = 0;
  reader.elem_size = elem_size;
  reader.n_elems_space = 16;
  reader.elems = (char*) realloc(*data, (size_t)(elem_size*reader.n_elems_space));
  reader.elem_reader = elem_reader;

  ret = read_str_array_elems(f, buf, sizeof(buf), &reader, dims);

  *data = reader.elems;

  return ret;
}

#define READ_STR(MACRO, PTR, SUFFIX)                                   \
  remove_underscores(buf);                                              \
  int j;                                                                \
  if (sscanf(buf, "%"MACRO"%n", (PTR*)dest, &j) == 1) {                 \
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, SUFFIX) == 0);     \
  } else {                                                              \
    return 1;                                                           \
  }

static int read_str_i8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNi8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(int8_t*)dest = (int8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "i8") == 0);
  } else {
    return 1;
  }
}

static int read_str_u8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNu8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(uint8_t*)dest = (uint8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "u8") == 0);
  } else {
    return 1;
  }
}

static int read_str_i16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "i16");
}

static int read_str_u16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "u16");
}

static int read_str_i32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "i32");
}

static int read_str_u32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "u32");
}

static int read_str_i64(char *buf, void* dest) {
  READ_STR(SCNi64, int64_t, "i64");
}

static int read_str_u64(char *buf, void* dest) {
  // FIXME: This is not correct, as SCNu64 only permits decimal
  // literals.  However, SCNi64 does not handle very large numbers
  // correctly (it's really for signed numbers, so that's fair).
  READ_STR(SCNu64, uint64_t, "u64");
}

static int read_str_f16(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f16.nan") == 0) {
    *(uint16_t*)dest = float2halfbits(NAN);
    return 0;
  } else if (strcmp(buf, "f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(INFINITY);
    return 0;
  } else if (strcmp(buf, "-f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(-INFINITY);
    return 0;
  } else {
    int j;
    float x;
    if (sscanf(buf, "%f%n", &x, &j) == 1) {
      if (strcmp(buf+j, "") == 0 || strcmp(buf+j, "f16") == 0) {
        *(uint16_t*)dest = float2halfbits(x);
        return 0;
      }
    }
    return 1;
  }
}

static int read_str_f32(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f32.nan") == 0) {
    *(float*)dest = (float)NAN;
    return 0;
  } else if (strcmp(buf, "f32.inf") == 0) {
    *(float*)dest = (float)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f32.inf") == 0) {
    *(float*)dest = (float)-INFINITY;
    return 0;
  } else {
    READ_STR("f", float, "f32");
  }
}

static int read_str_f64(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f64.nan") == 0) {
    *(double*)dest = (double)NAN;
    return 0;
  } else if (strcmp(buf, "f64.inf") == 0) {
    *(double*)dest = (double)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f64.inf") == 0) {
    *(double*)dest = (double)-INFINITY;
    return 0;
  } else {
    READ_STR("lf", double, "f64");
  }
}

static int read_str_bool(char *buf, void* dest) {
  if (strcmp(buf, "true") == 0) {
    *(char*)dest = 1;
    return 0;
  } else if (strcmp(buf, "false") == 0) {
    *(char*)dest = 0;
    return 0;
  } else {
    return 1;
  }
}

static int write_str_i8(FILE *out, int8_t *src) {
  return fprintf(out, "%hhdi8", *src);
}

static int write_str_u8(FILE *out, uint8_t *src) {
  return fprintf(out, "%hhuu8", *src);
}

static int write_str_i16(FILE *out, int16_t *src) {
  return fprintf(out, "%hdi16", *src);
}

static int write_str_u16(FILE *out, uint16_t *src) {
  return fprintf(out, "%huu16", *src);
}

static int write_str_i32(FILE *out, int32_t *src) {
  return fprintf(out, "%di32", *src);
}

static int write_str_u32(FILE *out, uint32_t *src) {
  return fprintf(out, "%uu32", *src);
}

static int write_str_i64(FILE *out, int64_t *src) {
  return fprintf(out, "%"PRIi64"i64", *src);
}

static int write_str_u64(FILE *out, uint64_t *src) {
  return fprintf(out, "%"PRIu64"u64", *src);
}

static int write_str_f16(FILE *out, uint16_t *src) {
  float x = halfbits2float(*src);
  if (isnan(x)) {
    return fprintf(out, "f16.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f16.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f16.inf");
  } else {
    return fprintf(out, "%.*ff16", FLT_DIG, x);
  }
}

static int write_str_f32(FILE *out, float *src) {
  float x = *src;
  if (isnan(x)) {
    return fprintf(out, "f32.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f32.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f32.inf");
  } else {
    return fprintf(out, "%.*ff32", FLT_DIG, x);
  }
}

static int write_str_f64(FILE *out, double *src) {
  double x = *src;
  if (isnan(x)) {
    return fprintf(out, "f64.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f64.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f64.inf");
  } else {
    return fprintf(out, "%.*ff64", DBL_DIG, x);
  }
}

static int write_str_bool(FILE *out, void *src) {
  return fprintf(out, *(char*)src ? "true" : "false");
}

//// Binary I/O

#define BINARY_FORMAT_VERSION 2
#define IS_BIG_ENDIAN (!*(unsigned char *)&(uint16_t){1})

static void flip_bytes(size_t elem_size, unsigned char *elem) {
  for (size_t j=0; j<elem_size/2; j++) {
    unsigned char head = elem[j];
    size_t tail_index = elem_size-1-j;
    elem[j] = elem[tail_index];
    elem[tail_index] = head;
  }
}

// On Windows we need to explicitly set the file mode to not mangle
// newline characters.  On *nix there is no difference.
#ifdef _WIN32
#include <io.h>
#include <fcntl.h>
static void set_binary_mode(FILE *f) {
  setmode(fileno(f), O_BINARY);
}
#else
static void set_binary_mode(FILE *f) {
  (void)f;
}
#endif

static int read_byte(FILE *f, void* dest) {
  size_t num_elems_read = fread(dest, 1, 1, f);
  return num_elems_read == 1 ? 0 : 1;
}

//// Types

struct primtype_info_t {
  const char binname[4]; // Used for parsing binary data.
  const char* type_name; // Same name as in Futhark.
  const int64_t size; // in bytes
  const writer write_str; // Write in text format.
  const str_reader read_str; // Read in text format.
};

static const struct primtype_info_t i8_info =
  {.binname = "  i8", .type_name = "i8",   .size = 1,
   .write_str = (writer)write_str_i8, .read_str = (str_reader)read_str_i8};
static const struct primtype_info_t i16_info =
  {.binname = " i16", .type_name = "i16",  .size = 2,
   .write_str = (writer)write_str_i16, .read_str = (str_reader)read_str_i16};
static const struct primtype_info_t i32_info =
  {.binname = " i32", .type_name = "i32",  .size = 4,
   .write_str = (writer)write_str_i32, .read_str = (str_reader)read_str_i32};
static const struct primtype_info_t i64_info =
  {.binname = " i64", .type_name = "i64",  .size = 8,
   .write_str = (writer)write_str_i64, .read_str = (str_reader)read_str_i64};
static const struct primtype_info_t u8_info =
  {.binname = "  u8", .type_name = "u8",   .size = 1,
   .write_str = (writer)write_str_u8, .read_str = (str_reader)read_str_u8};
static const struct primtype_info_t u16_info =
  {.binname = " u16", .type_name = "u16",  .size = 2,
   .write_str = (writer)write_str_u16, .read_str = (str_reader)read_str_u16};
static const struct primtype_info_t u32_info =
  {.binname = " u32", .type_name = "u32",  .size = 4,
   .write_str = (writer)write_str_u32, .read_str = (str_reader)read_str_u32};
static const struct primtype_info_t u64_info =
  {.binname = " u64", .type_name = "u64",  .size = 8,
   .write_str = (writer)write_str_u64, .read_str = (str_reader)read_str_u64};
static const struct primtype_info_t f16_info =
  {.binname = " f16", .type_name = "f16",  .size = 2,
   .write_str = (writer)write_str_f16, .read_str = (str_reader)read_str_f16};
static const struct primtype_info_t f32_info =
  {.binname = " f32", .type_name = "f32",  .size = 4,
   .write_str = (writer)write_str_f32, .read_str = (str_reader)read_str_f32};
static const struct primtype_info_t f64_info =
  {.binname = " f64", .type_name = "f64",  .size = 8,
   .write_str = (writer)write_str_f64, .read_str = (str_reader)read_str_f64};
static const struct primtype_info_t bool_info =
  {.binname = "bool", .type_name = "bool", .size = 1,
   .write_str = (writer)write_str_bool, .read_str = (str_reader)read_str_bool};

static const struct primtype_info_t* primtypes[] = {
  &i8_info, &i16_info, &i32_info, &i64_info,
  &u8_info, &u16_info, &u32_info, &u64_info,
  &f16_info, &f32_info, &f64_info,
  &bool_info,
  NULL // NULL-terminated
};

// General value interface.  All endian business taken care of at
// lower layers.

static int read_is_binary(FILE *f) {
  skipspaces(f);
  int c = getc(f);
  if (c == 'b') {
    int8_t bin_version;
    int ret = read_byte(f, &bin_version);

    if (ret != 0) { futhark_panic(1, "binary-input: could not read version.\n"); }

    if (bin_version != BINARY_FORMAT_VERSION) {
      futhark_panic(1, "binary-input: File uses version %i, but I only understand version %i.\n",
            bin_version, BINARY_FORMAT_VERSION);
    }

    return 1;
  }
  ungetc(c, f);
  return 0;
}

static const struct primtype_info_t* read_bin_read_type_enum(FILE *f) {
  char read_binname[4];

  int num_matched = fscanf(f, "%4c", read_binname);
  if (num_matched != 1) { futhark_panic(1, "binary-input: Couldn't read element type.\n"); }

  const struct primtype_info_t **type = primtypes;

  for (; *type != NULL; type++) {
    // I compare the 4 characters manually instead of using strncmp because
    // this allows any value to be used, also NULL bytes
    if (memcmp(read_binname, (*type)->binname, 4) == 0) {
      return *type;
    }
  }
  futhark_panic(1, "binary-input: Did not recognize the type '%s'.\n", read_binname);
  return NULL;
}

static void read_bin_ensure_scalar(FILE *f, const struct primtype_info_t *expected_type) {
  int8_t bin_dims;
  int ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != 0) {
    futhark_panic(1, "binary-input: Expected scalar (0 dimensions), but got array with %i dimensions.\n",
          bin_dims);
  }

  const struct primtype_info_t *bin_type = read_bin_read_type_enum(f);
  if (bin_type != expected_type) {
    futhark_panic(1, "binary-input: Expected scalar of type %s but got scalar of type %s.\n",
          expected_type->type_name,
          bin_type->type_name);
  }
}

//// High-level interface

static int read_bin_array(FILE *f,
                          const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  int ret;

  int8_t bin_dims;
  ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != dims) {
    futhark_panic(1, "binary-input: Expected %i dimensions, but got array with %i dimensions.\n",
          dims, bin_dims);
  }

  const struct primtype_info_t *bin_primtype = read_bin_read_type_enum(f);
  if (expected_type != bin_primtype) {
    futhark_panic(1, "binary-input: Expected %iD-array with element type '%s' but got %iD-array with element type '%s'.\n",
          dims, expected_type->type_name, dims, bin_primtype->type_name);
  }

  int64_t elem_count = 1;
  for (int i=0; i<dims; i++) {
    int64_t bin_shape;
    ret = (int)fread(&bin_shape, sizeof(bin_shape), 1, f);
    if (ret != 1) {
      futhark_panic(1, "binary-input: Couldn't read size for dimension %i of array.\n", i);
    }
    if (IS_BIG_ENDIAN) {
      flip_bytes(sizeof(bin_shape), (unsigned char*) &bin_shape);
    }
    elem_count *= bin_shape;
    shape[i] = bin_shape;
  }

  int64_t elem_size = expected_type->size;
  void* tmp = realloc(*data, (size_t)(elem_count * elem_size));
  if (tmp == NULL) {
    futhark_panic(1, "binary-input: Failed to allocate array of size %i.\n",
          elem_count * elem_size);
  }
  *data = tmp;

  int64_t num_elems_read = (int64_t)fread(*data, (size_t)elem_size, (size_t)elem_count, f);
  if (num_elems_read != elem_count) {
    futhark_panic(1, "binary-input: tried to read %i elements of an array, but only got %i elements.\n",
          elem_count, num_elems_read);
  }

  // If we're on big endian platform we must change all multibyte elements
  // from using little endian to big endian
  if (IS_BIG_ENDIAN && elem_size != 1) {
    flip_bytes((size_t)elem_size, (unsigned char*) *data);
  }

  return 0;
}

static int read_array(FILE *f, const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  if (!read_is_binary(f)) {
    return read_str_array(f, expected_type->size, (str_reader)expected_type->read_str, expected_type->type_name, data, shape, dims);
  } else {
    return read_bin_array(f, expected_type, data, shape, dims);
  }
}

static int end_of_input(FILE *f) {
  skipspaces(f);
  char token[2];
  next_token(f, token, sizeof(token));
  if (strcmp(token, "") == 0) {
    return 0;
  } else {
    return 1;
  }
}

static int write_str_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  if (rank==0) {
    elem_type->write_str(out, (const void*)data);
  } else {
    int64_t len = (int64_t)shape[0];
    int64_t slice_size = 1;

    int64_t elem_size = elem_type->size;
    for (int8_t i = 1; i < rank; i++) {
      slice_size *= shape[i];
    }

    if (len*slice_size == 0) {
      fprintf(out, "empty(");
      for (int64_t i = 0; i < rank; i++) {
        fprintf(out, "[%"PRIi64"]", shape[i]);
      }
      fprintf(out, "%s", elem_type->type_name);
      fprintf(out, ")");
    } else if (rank==1) {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        elem_type->write_str(out, (const void*) (data + i * elem_size));
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    } else {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        write_str_array(out, elem_type, data + i * slice_size * elem_size, shape+1, rank-1);
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    }
  }
  return 0;
}

static int write_bin_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  int64_t num_elems = 1;
  for (int64_t i = 0; i < rank; i++) {
    num_elems *= shape[i];
  }

  fputc('b', out);
  fputc((char)BINARY_FORMAT_VERSION, out);
  fwrite(&rank, sizeof(int8_t), 1, out);
  fwrite(elem_type->binname, 4, 1, out);
  if (shape != NULL) {
    fwrite(shape, sizeof(int64_t), (size_t)rank, out);
  }

  if (IS_BIG_ENDIAN) {
    for (int64_t i = 0; i < num_elems; i++) {
      const unsigned char *elem = data+i*elem_type->size;
      for (int64_t j = 0; j < elem_type->size; j++) {
        fwrite(&elem[elem_type->size-j], 1, 1, out);
      }
    }
  } else {
    fwrite(data, (size_t)elem_type->size, (size_t)num_elems, out);
  }

  return 0;
}

static int write_array(FILE *out, int write_binary,
                       const struct primtype_info_t *elem_type,
                       const void *data,
                       const int64_t *shape,
                       const int8_t rank) {
  if (write_binary) {
    return write_bin_array(out, elem_type, data, shape, rank);
  } else {
    return write_str_array(out, elem_type, data, shape, rank);
  }
}

static int read_scalar(FILE *f,
                       const struct primtype_info_t *expected_type, void *dest) {
  if (!read_is_binary(f)) {
    char buf[100];
    next_token(f, buf, sizeof(buf));
    return expected_type->read_str(buf, dest);
  } else {
    read_bin_ensure_scalar(f, expected_type);
    size_t elem_size = (size_t)expected_type->size;
    size_t num_elems_read = fread(dest, elem_size, 1, f);
    if (IS_BIG_ENDIAN) {
      flip_bytes(elem_size, (unsigned char*) dest);
    }
    return num_elems_read == 1 ? 0 : 1;
  }
}

static int write_scalar(FILE *out, int write_binary, const struct primtype_info_t *type, void *src) {
  if (write_binary) {
    return write_bin_array(out, type, src, NULL, 0);
  } else {
    return type->write_str(out, src);
  }
}

// End of values.h.

// Start of server.h.

// Forward declarations of things that we technically don't know until
// the application header file is included, but which we need.
struct futhark_context_config;
struct futhark_context;
char *futhark_context_get_error(struct futhark_context *ctx);
int futhark_context_sync(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value);
int futhark_get_tuning_param_count(void);
const char* futhark_get_tuning_param_name(int i);
const char* futhark_get_tuning_param_class(int i);

typedef int (*restore_fn)(const void*, FILE *, struct futhark_context*, void*);
typedef void (*store_fn)(const void*, FILE *, struct futhark_context*, void*);
typedef int (*free_fn)(const void*, struct futhark_context*, void*);
typedef int (*project_fn)(struct futhark_context*, void*, const void*);
typedef int (*new_fn)(struct futhark_context*, void**, const void*[]);

struct field {
  const char *name;
  const struct type *type;
  project_fn project;
};

struct record {
  int num_fields;
  const struct field* fields;
  new_fn new;
};

struct type {
  const char *name;
  restore_fn restore;
  store_fn store;
  free_fn free;
  const void *aux;
  const struct record *record;
};

int free_scalar(const void *aux, struct futhark_context *ctx, void *p) {
  (void)aux;
  (void)ctx;
  (void)p;
  // Nothing to do.
  return 0;
}

#define DEF_SCALAR_TYPE(T)                                      \
  int restore_##T(const void *aux, FILE *f,                     \
                  struct futhark_context *ctx, void *p) {       \
    (void)aux;                                                  \
    (void)ctx;                                                  \
    return read_scalar(f, &T##_info, p);                        \
  }                                                             \
                                                                \
  void store_##T(const void *aux, FILE *f,                      \
                 struct futhark_context *ctx, void *p) {        \
    (void)aux;                                                  \
    (void)ctx;                                                  \
    write_scalar(f, 1, &T##_info, p);                           \
  }                                                             \
                                                                \
  struct type type_##T =                                        \
    { .name = #T,                                               \
      .restore = restore_##T,                                   \
      .store = store_##T,                                       \
      .free = free_scalar                                       \
    }                                                           \

DEF_SCALAR_TYPE(i8);
DEF_SCALAR_TYPE(i16);
DEF_SCALAR_TYPE(i32);
DEF_SCALAR_TYPE(i64);
DEF_SCALAR_TYPE(u8);
DEF_SCALAR_TYPE(u16);
DEF_SCALAR_TYPE(u32);
DEF_SCALAR_TYPE(u64);
DEF_SCALAR_TYPE(f16);
DEF_SCALAR_TYPE(f32);
DEF_SCALAR_TYPE(f64);
DEF_SCALAR_TYPE(bool);

struct value {
  const struct type *type;
  union {
    void *v_ptr;
    int8_t  v_i8;
    int16_t v_i16;
    int32_t v_i32;
    int64_t v_i64;

    uint8_t  v_u8;
    uint16_t v_u16;
    uint32_t v_u32;
    uint64_t v_u64;

    uint16_t v_f16;
    float v_f32;
    double v_f64;

    bool v_bool;
  } value;
};

void* value_ptr(struct value *v) {
  if (v->type == &type_i8) {
    return &v->value.v_i8;
  }
  if (v->type == &type_i16) {
    return &v->value.v_i16;
  }
  if (v->type == &type_i32) {
    return &v->value.v_i32;
  }
  if (v->type == &type_i64) {
    return &v->value.v_i64;
  }
  if (v->type == &type_u8) {
    return &v->value.v_u8;
  }
  if (v->type == &type_u16) {
    return &v->value.v_u16;
  }
  if (v->type == &type_u32) {
    return &v->value.v_u32;
  }
  if (v->type == &type_u64) {
    return &v->value.v_u64;
  }
  if (v->type == &type_f16) {
    return &v->value.v_f16;
  }
  if (v->type == &type_f32) {
    return &v->value.v_f32;
  }
  if (v->type == &type_f64) {
    return &v->value.v_f64;
  }
  if (v->type == &type_bool) {
    return &v->value.v_bool;
  }
  return &v->value.v_ptr;
}

struct variable {
  // NULL name indicates free slot.  Name is owned by this struct.
  char *name;
  struct value value;
};

typedef int (*entry_point_fn)(struct futhark_context*, void**, void**);

struct entry_point {
  const char *name;
  entry_point_fn f;
  const char** tuning_params;
  const struct type **out_types;
  bool *out_unique;
  const struct type **in_types;
  bool *in_unique;
};

int entry_num_ins(struct entry_point *e) {
  int count = 0;
  while (e->in_types[count]) {
    count++;
  }
  return count;
}

int entry_num_outs(struct entry_point *e) {
  int count = 0;
  while (e->out_types[count]) {
    count++;
  }
  return count;
}

struct futhark_prog {
  // Last entry point identified by NULL name.
  struct entry_point *entry_points;
  // Last type identified by NULL name.
  const struct type **types;
};

struct server_state {
  struct futhark_prog prog;
  struct futhark_context_config *cfg;
  struct futhark_context *ctx;
  int variables_capacity;
  struct variable *variables;
};

struct variable* get_variable(struct server_state *s,
                              const char *name) {
  for (int i = 0; i < s->variables_capacity; i++) {
    if (s->variables[i].name != NULL &&
        strcmp(s->variables[i].name, name) == 0) {
      return &s->variables[i];
    }
  }

  return NULL;
}

struct variable* create_variable(struct server_state *s,
                                 const char *name,
                                 const struct type *type) {
  int found = -1;
  for (int i = 0; i < s->variables_capacity; i++) {
    if (found == -1 && s->variables[i].name == NULL) {
      found = i;
    } else if (s->variables[i].name != NULL &&
               strcmp(s->variables[i].name, name) == 0) {
      return NULL;
    }
  }

  if (found != -1) {
    // Found a free spot.
    s->variables[found].name = strdup(name);
    s->variables[found].value.type = type;
    return &s->variables[found];
  }

  // Need to grow the buffer.
  found = s->variables_capacity;
  s->variables_capacity *= 2;
  s->variables = realloc(s->variables,
                         s->variables_capacity * sizeof(struct variable));

  s->variables[found].name = strdup(name);
  s->variables[found].value.type = type;

  for (int i = found+1; i < s->variables_capacity; i++) {
    s->variables[i].name = NULL;
  }

  return &s->variables[found];
}

void drop_variable(struct variable *v) {
  free(v->name);
  v->name = NULL;
}

int arg_exists(const char *args[], int i) {
  return args[i] != NULL;
}

const char* get_arg(const char *args[], int i) {
  if (!arg_exists(args, i)) {
    futhark_panic(1, "Insufficient command args.\n");
  }
  return args[i];
}

const struct type* get_type(struct server_state *s, const char *name) {
  for (int i = 0; s->prog.types[i]; i++) {
    if (strcmp(s->prog.types[i]->name, name) == 0) {
      return s->prog.types[i];
    }
  }

  futhark_panic(1, "Unknown type %s\n", name);
  return NULL;
}

struct entry_point* get_entry_point(struct server_state *s, const char *name) {
  for (int i = 0; s->prog.entry_points[i].name; i++) {
    if (strcmp(s->prog.entry_points[i].name, name) == 0) {
      return &s->prog.entry_points[i];
    }
  }

  return NULL;
}

// Print the command-done marker, indicating that we are ready for
// more input.
void ok(void) {
  printf("%%%%%% OK\n");
  fflush(stdout);
}

// Print the failure marker.  Output is now an error message until the
// next ok().
void failure(void) {
  printf("%%%%%% FAILURE\n");
}

void error_check(struct server_state *s, int err) {
  if (err != 0) {
    failure();
    char *error = futhark_context_get_error(s->ctx);
    if (error != NULL) {
      puts(error);
    }
    free(error);
  }
}

void cmd_call(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);

  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_outs = entry_num_outs(e);
  int num_ins = entry_num_ins(e);
  // +1 to avoid zero-size arrays, which is UB.
  void* outs[num_outs+1];
  void* ins[num_ins+1];

  for (int i = 0; i < num_ins; i++) {
    const char *in_name = get_arg(args, 1+num_outs+i);
    struct variable *v = get_variable(s, in_name);
    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", in_name);
      return;
    }
    if (v->value.type != e->in_types[i]) {
      failure();
      printf("Wrong input type.  Expected %s, got %s.\n",
             e->in_types[i]->name, v->value.type->name);
      return;
    }
    ins[i] = value_ptr(&v->value);
  }

  for (int i = 0; i < num_outs; i++) {
    const char *out_name = get_arg(args, 1+i);
    struct variable *v = create_variable(s, out_name, e->out_types[i]);
    if (v == NULL) {
      failure();
      printf("Variable already exists: %s\n", out_name);
      return;
    }
    outs[i] = value_ptr(&v->value);
  }

  int64_t t_start = get_wall_time();
  int err = e->f(s->ctx, outs, ins);
  err |= futhark_context_sync(s->ctx);
  int64_t t_end = get_wall_time();
  long long int elapsed_usec = t_end - t_start;
  printf("runtime: %lld\n", elapsed_usec);

  error_check(s, err);
  if (err != 0) {
    // Need to uncreate the output variables, which would otherwise be left
    // in an uninitialised state.
    for (int i = 0; i < num_outs; i++) {
      const char *out_name = get_arg(args, 1+i);
      struct variable *v = get_variable(s, out_name);
      if (v) {
        drop_variable(v);
      }
    }
  }
}

void cmd_restore(struct server_state *s, const char *args[]) {
  const char *fname = get_arg(args, 0);

  FILE *f = fopen(fname, "rb");
  if (f == NULL) {
    failure();
    printf("Failed to open %s: %s\n", fname, strerror(errno));
    return;
  }

  int bad = 0;
  int values = 0;
  for (int i = 1; arg_exists(args, i); i+=2, values++) {
    const char *vname = get_arg(args, i);
    const char *type = get_arg(args, i+1);

    const struct type *t = get_type(s, type);
    struct variable *v = create_variable(s, vname, t);

    if (v == NULL) {
      bad = 1;
      failure();
      printf("Variable already exists: %s\n", vname);
      break;
    }

    errno = 0;
    if (t->restore(t->aux, f, s->ctx, value_ptr(&v->value)) != 0) {
      bad = 1;
      failure();
      printf("Failed to restore variable %s.\n"
             "Possibly malformed data in %s (errno: %s)\n",
             vname, fname, strerror(errno));
      drop_variable(v);
      break;
    }
  }

  if (!bad && end_of_input(f) != 0) {
    failure();
    printf("Expected EOF after reading %d values from %s\n",
           values, fname);
  }

  fclose(f);

  if (!bad) {
    int err = futhark_context_sync(s->ctx);
    error_check(s, err);
  }
}

void cmd_store(struct server_state *s, const char *args[]) {
  const char *fname = get_arg(args, 0);

  FILE *f = fopen(fname, "wb");
  if (f == NULL) {
    failure();
    printf("Failed to open %s: %s\n", fname, strerror(errno));
  } else {
    for (int i = 1; arg_exists(args, i); i++) {
      const char *vname = get_arg(args, i);
      struct variable *v = get_variable(s, vname);

      if (v == NULL) {
        failure();
        printf("Unknown variable: %s\n", vname);
        return;
      }

      const struct type *t = v->value.type;
      t->store(t->aux, f, s->ctx, value_ptr(&v->value));
    }
    fclose(f);
  }
}

void cmd_free(struct server_state *s, const char *args[]) {
  for (int i = 0; arg_exists(args, i); i++) {
    const char *name = get_arg(args, i);
    struct variable *v = get_variable(s, name);

    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", name);
      return;
    }

    const struct type *t = v->value.type;

    int err = t->free(t->aux, s->ctx, value_ptr(&v->value));
    error_check(s, err);
    drop_variable(v);
  }
}

void cmd_rename(struct server_state *s, const char *args[]) {
  const char *oldname = get_arg(args, 0);
  const char *newname = get_arg(args, 1);
  struct variable *old = get_variable(s, oldname);
  struct variable *new = get_variable(s, newname);

  if (old == NULL) {
    failure();
    printf("Unknown variable: %s\n", oldname);
    return;
  }

  if (new != NULL) {
    failure();
    printf("Variable already exists: %s\n", newname);
    return;
  }

  free(old->name);
  old->name = strdup(newname);
}

void cmd_inputs(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_ins = entry_num_ins(e);
  for (int i = 0; i < num_ins; i++) {
    if (e->in_unique[i]) {
      putchar('*');
    }
    puts(e->in_types[i]->name);
  }
}

void cmd_outputs(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_outs = entry_num_outs(e);
  for (int i = 0; i < num_outs; i++) {
    if (e->out_unique[i]) {
      putchar('*');
    }
    puts(e->out_types[i]->name);
  }
}

void cmd_clear(struct server_state *s, const char *args[]) {
  (void)args;
  int err = 0;
  for (int i = 0; i < s->variables_capacity; i++) {
    struct variable *v = &s->variables[i];
    if (v->name != NULL) {
      err |= v->value.type->free(v->value.type->aux, s->ctx, value_ptr(&v->value));
      drop_variable(v);
    }
  }
  err |= futhark_context_clear_caches(s->ctx);
  error_check(s, err);
}

void cmd_pause_profiling(struct server_state *s, const char *args[]) {
  (void)args;
  futhark_context_pause_profiling(s->ctx);
}

void cmd_unpause_profiling(struct server_state *s, const char *args[]) {
  (void)args;
  futhark_context_unpause_profiling(s->ctx);
}

void cmd_report(struct server_state *s, const char *args[]) {
  (void)args;
  char *report = futhark_context_report(s->ctx);
  if (report) {
    puts(report);
  } else {
    failure();
    report = futhark_context_get_error(s->ctx);
    if (report) {
      puts(report);
    } else {
      puts("Failed to produce profiling report.\n");
    }
  }
  free(report);
}

void cmd_set_tuning_param(struct server_state *s, const char *args[]) {
  const char *param = get_arg(args, 0);
  const char *val_s = get_arg(args, 1);
  size_t val = atol(val_s);
  int err = futhark_context_config_set_tuning_param(s->cfg, param, val);

  error_check(s, err);

  if (err != 0) {
    printf("Failed to set tuning parameter %s to %ld\n", param, (long)val);
  }
}

void cmd_tuning_params(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  const char **params = e->tuning_params;
  for (int i = 0; params[i] != NULL; i++) {
    printf("%s\n", params[i]);
  }
}

void cmd_tuning_param_class(struct server_state *s, const char *args[]) {
  (void)s;
  const char *param = get_arg(args, 0);

  int n = futhark_get_tuning_param_count();

  for (int i = 0; i < n; i++) {
    if (strcmp(futhark_get_tuning_param_name(i), param) == 0) {
      printf("%s\n", futhark_get_tuning_param_class(i));
      return;
    }
  }

  failure();
  printf("Unknown tuning parameter: %s\n", param);
}

void cmd_fields(struct server_state *s, const char *args[]) {
  const char *type = get_arg(args, 0);
  const struct type *t = get_type(s, type);
  const struct record *r = t->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  for (int i = 0; i < r->num_fields; i++) {
    const struct field f = r->fields[i];
    printf("%s %s\n", f.name, f.type->name);
  }
}

void cmd_project(struct server_state *s, const char *args[]) {
  const char *to_name = get_arg(args, 0);
  const char *from_name = get_arg(args, 1);
  const char *field_name = get_arg(args, 2);

  struct variable *from = get_variable(s, from_name);

  if (from == NULL) {
    failure();
    printf("Unknown variable: %s\n", from_name);
    return;
  }

  const struct type *from_type = from->value.type;
  const struct record *r = from_type->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  const struct field *field = NULL;
  for (int i = 0; i < r->num_fields; i++) {
    if (strcmp(r->fields[i].name, field_name) == 0) {
      field = &r->fields[i];
      break;
    }
  }

  if (field == NULL) {
    failure();
    printf("No such field\n");
  }

  struct variable *to = create_variable(s, to_name, field->type);

  if (to == NULL) {
    failure();
    printf("Variable already exists: %s\n", to_name);
    return;
  }

  field->project(s->ctx, value_ptr(&to->value), from->value.value.v_ptr);
}

void cmd_new(struct server_state *s, const char *args[]) {
  const char *to_name = get_arg(args, 0);
  const char *type_name = get_arg(args, 1);
  const struct type *type = get_type(s, type_name);
  struct variable *to = create_variable(s, to_name, type);

  if (to == NULL) {
    failure();
    printf("Variable already exists: %s\n", to_name);
    return;
  }

  const struct record* r = type->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  int num_args = 0;
  for (int i = 2; arg_exists(args, i); i++) {
    num_args++;
  }

  if (num_args != r->num_fields) {
    failure();
    printf("%d fields expected but %d values provided.\n", num_args, r->num_fields);
    return;
  }

  const void** value_ptrs = alloca(num_args * sizeof(void*));

  for (int i = 0; i < num_args; i++) {
    struct variable* v = get_variable(s, args[2+i]);

    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", args[2+i]);
      return;
    }

    if (strcmp(v->value.type->name, r->fields[i].type->name) != 0) {
      failure();
      printf("Field %s mismatch: expected type %s, got %s\n",
             r->fields[i].name, r->fields[i].type->name, v->value.type->name);
      return;
    }

    value_ptrs[i] = value_ptr(&v->value);
  }

  r->new(s->ctx, value_ptr(&to->value), value_ptrs);
}

void cmd_entry_points(struct server_state *s, const char *args[]) {
  (void)args;
  for (int i = 0; s->prog.entry_points[i].name; i++) {
    puts(s->prog.entry_points[i].name);
  }
}

void cmd_types(struct server_state *s, const char *args[]) {
  (void)args;
  for (int i = 0; s->prog.types[i] != NULL; i++) {
    puts(s->prog.types[i]->name);
  }
}

char *next_word(char **line) {
  char *p = *line;

  while (isspace(*p)) {
    p++;
  }

  if (*p == 0) {
    return NULL;
  }

  if (*p == '"') {
    char *save = p+1;
    // Skip ahead till closing quote.
    p++;

    while (*p && *p != '"') {
      p++;
    }

    if (*p == '"') {
      *p = 0;
      *line = p+1;
      return save;
    } else {
      return NULL;
    }
  } else {
    char *save = p;
    // Skip ahead till next whitespace.

    while (*p && !isspace(*p)) {
      p++;
    }

    if (*p) {
      *p = 0;
      *line = p+1;
    } else {
      *line = p;
    }
    return save;
  }
}

void process_line(struct server_state *s, char *line) {
  int max_num_tokens = 1000;
  const char* tokens[max_num_tokens];
  int num_tokens = 0;

  while ((tokens[num_tokens] = next_word(&line)) != NULL) {
    num_tokens++;
    if (num_tokens == max_num_tokens) {
      futhark_panic(1, "Line too long.\n");
    }
  }

  const char *command = tokens[0];

  if (command == NULL) {
    failure();
    printf("Empty line\n");
  } else if (strcmp(command, "call") == 0) {
    cmd_call(s, tokens+1);
  } else if (strcmp(command, "restore") == 0) {
    cmd_restore(s, tokens+1);
  } else if (strcmp(command, "store") == 0) {
    cmd_store(s, tokens+1);
  } else if (strcmp(command, "free") == 0) {
    cmd_free(s, tokens+1);
  } else if (strcmp(command, "rename") == 0) {
    cmd_rename(s, tokens+1);
  } else if (strcmp(command, "inputs") == 0) {
    cmd_inputs(s, tokens+1);
  } else if (strcmp(command, "outputs") == 0) {
    cmd_outputs(s, tokens+1);
  } else if (strcmp(command, "clear") == 0) {
    cmd_clear(s, tokens+1);
  } else if (strcmp(command, "pause_profiling") == 0) {
    cmd_pause_profiling(s, tokens+1);
  } else if (strcmp(command, "unpause_profiling") == 0) {
    cmd_unpause_profiling(s, tokens+1);
  } else if (strcmp(command, "report") == 0) {
    cmd_report(s, tokens+1);
  } else if (strcmp(command, "set_tuning_param") == 0) {
    cmd_set_tuning_param(s, tokens+1);
  } else if (strcmp(command, "tuning_params") == 0) {
    cmd_tuning_params(s, tokens+1);
  } else if (strcmp(command, "tuning_param_class") == 0) {
    cmd_tuning_param_class(s, tokens+1);
  } else if (strcmp(command, "fields") == 0) {
    cmd_fields(s, tokens+1);
  } else if (strcmp(command, "new") == 0) {
    cmd_new(s, tokens+1);
  } else if (strcmp(command, "project") == 0) {
    cmd_project(s, tokens+1);
  } else if (strcmp(command, "entry_points") == 0) {
    cmd_entry_points(s, tokens+1);
  } else if (strcmp(command, "types") == 0) {
    cmd_types(s, tokens+1);
  } else {
    futhark_panic(1, "Unknown command: %s\n", command);
  }
}

void run_server(struct futhark_prog *prog,
                struct futhark_context_config *cfg,
                struct futhark_context *ctx) {
  char *line = NULL;
  size_t buflen = 0;
  ssize_t linelen;

  struct server_state s = {
    .cfg = cfg,
    .ctx = ctx,
    .variables_capacity = 100,
    .prog = *prog
  };

  s.variables = malloc(s.variables_capacity * sizeof(struct variable));

  for (int i = 0; i < s.variables_capacity; i++) {
    s.variables[i].name = NULL;
  }

  ok();
  while ((linelen = getline(&line, &buflen, stdin)) > 0) {
    process_line(&s, line);
    ok();
  }

  free(s.variables);
  free(line);
}

// The aux struct lets us write generic method implementations without
// code duplication.

typedef void* (*array_new_fn)(struct futhark_context *, const void*, const int64_t*);
typedef const int64_t* (*array_shape_fn)(struct futhark_context*, void*);
typedef int (*array_values_fn)(struct futhark_context*, void*, void*);
typedef int (*array_free_fn)(struct futhark_context*, void*);

struct array_aux {
  int rank;
  const struct primtype_info_t* info;
  const char *name;
  array_new_fn new;
  array_shape_fn shape;
  array_values_fn values;
  array_free_fn free;
};

int restore_array(const struct array_aux *aux, FILE *f,
                  struct futhark_context *ctx, void *p) {
  void *data = NULL;
  int64_t shape[aux->rank];
  if (read_array(f, aux->info, &data, shape, aux->rank) != 0) {
    return 1;
  }

  void *arr = aux->new(ctx, data, shape);
  if (arr == NULL) {
    return 1;
  }
  int err = futhark_context_sync(ctx);
  *(void**)p = arr;
  free(data);
  return err;
}

void store_array(const struct array_aux *aux, FILE *f,
                 struct futhark_context *ctx, void *p) {
  void *arr = *(void**)p;
  const int64_t *shape = aux->shape(ctx, arr);
  int64_t size = sizeof(aux->info->size);
  for (int i = 0; i < aux->rank; i++) {
    size *= shape[i];
  }
  int32_t *data = malloc(size);
  assert(aux->values(ctx, arr, data) == 0);
  assert(futhark_context_sync(ctx) == 0);
  assert(write_array(f, 1, aux->info, data, shape, aux->rank) == 0);
  free(data);
}

int free_array(const struct array_aux *aux,
               struct futhark_context *ctx, void *p) {
  void *arr = *(void**)p;
  return aux->free(ctx, arr);
}

typedef void* (*opaque_restore_fn)(struct futhark_context*, void*);
typedef int (*opaque_store_fn)(struct futhark_context*, const void*, void **, size_t *);
typedef int (*opaque_free_fn)(struct futhark_context*, void*);

struct opaque_aux {
  opaque_restore_fn restore;
  opaque_store_fn store;
  opaque_free_fn free;
};

int restore_opaque(const struct opaque_aux *aux, FILE *f,
                   struct futhark_context *ctx, void *p) {
  // We have a problem: we need to load data from 'f', since the
  // restore function takes a pointer, but we don't know how much we
  // need (and cannot possibly).  So we do something hacky: we read
  // *all* of the file, pass all of the data to the restore function
  // (which doesn't care if there's extra at the end), then we compute
  // how much space the the object actually takes in serialised form
  // and rewind the file to that position.  The only downside is more IO.
  size_t start = ftell(f);
  size_t size;
  char *bytes = fslurp_file(f, &size);
  void *obj = aux->restore(ctx, bytes);
  free(bytes);
  if (obj != NULL) {
    *(void**)p = obj;
    size_t obj_size;
    (void)aux->store(ctx, obj, NULL, &obj_size);
    fseek(f, start+obj_size, SEEK_SET);
    return 0;
  } else {
    fseek(f, start, SEEK_SET);
    return 1;
  }
}

void store_opaque(const struct opaque_aux *aux, FILE *f,
                  struct futhark_context *ctx, void *p) {
  void *obj = *(void**)p;
  size_t obj_size;
  void *data = NULL;
  (void)aux->store(ctx, obj, &data, &obj_size);
  assert(futhark_context_sync(ctx) == 0);
  fwrite(data, sizeof(char), obj_size, f);
  free(data);
}

int free_opaque(const struct opaque_aux *aux,
                struct futhark_context *ctx, void *p) {
  void *obj = *(void**)p;
  return aux->free(ctx, obj);
}

// End of server.h.

// Start of tuning.h.


int is_blank_line_or_comment(const char *s) {
  size_t i = strspn(s, " \t\n");
  return s[i] == '\0' || // Line is blank.
         strncmp(s + i, "--", 2) == 0; // Line is comment.
}

static char* load_tuning_file(const char *fname,
                              void *cfg,
                              int (*set_tuning_param)(void*, const char*, size_t)) {
  const int max_line_len = 1024;
  char* line = (char*) malloc(max_line_len);

  FILE *f = fopen(fname, "r");

  if (f == NULL) {
    snprintf(line, max_line_len, "Cannot open file: %s", strerror(errno));
    return line;
  }

  int lineno = 0;
  while (fgets(line, max_line_len, f) != NULL) {
    lineno++;
    if (is_blank_line_or_comment(line)) {
      continue;
    }
    char *eql = strstr(line, "=");
    if (eql) {
      *eql = 0;
      char *endptr;
      int value = strtol(eql+1, &endptr, 10);
      if (*endptr && *endptr != '\n') {
        snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
                 lineno);
        return line;
      }
      if (set_tuning_param(cfg, line, (size_t)value) != 0) {
        char* err = (char*) malloc(max_line_len + 50);
        snprintf(err, max_line_len + 50, "Unknown name '%s' on line %d.", line, lineno);
        free(line);
        return err;
      }
    } else {
      snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
               lineno);
      return line;
    }
  }

  free(line);

  return NULL;
}

// End of tuning.h.

const struct type type_ZMZNi64;
const struct type type_ZMZNi8;
void *futhark_new_i64_1d_wrap(struct futhark_context *ctx, const void *p, const int64_t *shape)
{
    return futhark_new_i64_1d(ctx, p, shape[0]);
}
const struct array_aux type_ZMZNi64_aux = {.name ="[]i64", .rank =1, .info =&i64_info, .new =(array_new_fn) futhark_new_i64_1d_wrap, .free =(array_free_fn) futhark_free_i64_1d, .shape =(array_shape_fn) futhark_shape_i64_1d, .values =(array_values_fn) futhark_values_i64_1d};
const struct type type_ZMZNi64 = {.name ="[]i64", .restore =(restore_fn) restore_array, .store =(store_fn) store_array, .free =(free_fn) free_array, .aux =&type_ZMZNi64_aux};
void *futhark_new_i8_1d_wrap(struct futhark_context *ctx, const void *p, const int64_t *shape)
{
    return futhark_new_i8_1d(ctx, p, shape[0]);
}
const struct array_aux type_ZMZNi8_aux = {.name ="[]i8", .rank =1, .info =&i8_info, .new =(array_new_fn) futhark_new_i8_1d_wrap, .free =(array_free_fn) futhark_free_i8_1d, .shape =(array_shape_fn) futhark_shape_i8_1d, .values =(array_values_fn) futhark_values_i8_1d};
const struct type type_ZMZNi8 = {.name ="[]i8", .restore =(restore_fn) restore_array, .store =(store_fn) store_array, .free =(free_fn) free_array, .aux =&type_ZMZNi8_aux};
const struct type *main_out_types[] = {&type_ZMZNi8, NULL};
bool main_out_unique[] = {false};
const struct type *main_in_types[] = {&type_i32, &type_i64, &type_ZMZNi64, &type_ZMZNi64, &type_ZMZNi64, NULL};
bool main_in_unique[] = {false, false, false, false, false};
const char *main_tuning_params[] = {"builtin#replicate_i8.tblock_size_23529", "main.segmap_num_tblocks_21520", "main.segmap_num_tblocks_21553", "main.segmap_num_tblocks_21578", "main.segmap_num_tblocks_21915", "main.segmap_num_tblocks_21968", "main.segmap_num_tblocks_21993", "main.segmap_num_tblocks_22026", "main.segmap_num_tblocks_22057", "main.segmap_num_tblocks_22092", "main.segmap_num_tblocks_22413", "main.segmap_num_tblocks_22440", "main.segmap_num_tblocks_22484", "main.segmap_num_tblocks_22511", "main.segmap_num_tblocks_22557", "main.segmap_num_tblocks_22584", "main.segmap_num_tblocks_22642", "main.segmap_tblock_size_21421", "main.segmap_tblock_size_21518", "main.segmap_tblock_size_21551", "main.segmap_tblock_size_21576", "main.segmap_tblock_size_21732", "main.segmap_tblock_size_21806", "main.segmap_tblock_size_21913", "main.segmap_tblock_size_21940", "main.segmap_tblock_size_21966", "main.segmap_tblock_size_21991", "main.segmap_tblock_size_22024", "main.segmap_tblock_size_22055", "main.segmap_tblock_size_22090", "main.segmap_tblock_size_22235", "main.segmap_tblock_size_22309", "main.segmap_tblock_size_22411", "main.segmap_tblock_size_22438", "main.segmap_tblock_size_22482", "main.segmap_tblock_size_22509", "main.segmap_tblock_size_22555", "main.segmap_tblock_size_22582", "main.segmap_tblock_size_22640", "main.segred_num_tblocks_21400", "main.segred_num_tblocks_21499", "main.segred_num_tblocks_21753", "main.segred_num_tblocks_22256", "main.segred_num_tblocks_23368", "main.segred_num_tblocks_23414", "main.segred_tblock_size_21398", "main.segred_tblock_size_21497", "main.segred_tblock_size_21751", "main.segred_tblock_size_22254", "main.segred_tblock_size_23370", "main.segred_tblock_size_23416", "main.segscan_num_tblocks_21510", "main.segscan_num_tblocks_22047", "main.segscan_tblock_size_21508", "main.segscan_tblock_size_22045", "main.suff_outer_par_0", "main.suff_outer_par_1", "main.tblock_size_23872", "main.tblock_size_23892", "main.tblock_size_23912", "main.tblock_size_24223", NULL};
int call_main(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_i8_1d * *out0 = outs[0];
    int32_t in0 = *(int32_t *) ins[0];
    int64_t in1 = *(int64_t *) ins[1];
    struct futhark_i64_1d * in2 = *(struct futhark_i64_1d * *) ins[2];
    struct futhark_i64_1d * in3 = *(struct futhark_i64_1d * *) ins[3];
    struct futhark_i64_1d * in4 = *(struct futhark_i64_1d * *) ins[4];
    
    return futhark_entry_main(ctx, out0, in0, in1, in2, in3, in4);
}
const struct type *types[] = {&type_i8, &type_i16, &type_i32, &type_i64, &type_u8, &type_u16, &type_u32, &type_u64, &type_f16, &type_f32, &type_f64, &type_bool, &type_ZMZNi64, &type_ZMZNi8, NULL};
struct entry_point entry_points[] = {{.name ="main", .f =call_main, .tuning_params =main_tuning_params, .in_types =main_in_types, .out_types =main_out_types, .in_unique =main_in_unique, .out_unique =main_out_unique}, {.name =NULL}};
struct futhark_prog prog = {.types =types, .entry_points =entry_points};
int parse_options(struct futhark_context_config *cfg, int argc, char *const argv[])
{
    int ch;
    static struct option long_options[] = {{"debugging", no_argument, NULL, 1}, {"log", no_argument, NULL, 2}, {"profile", no_argument, NULL, 3}, {"help", no_argument, NULL, 4}, {"print-params", no_argument, NULL, 5}, {"param", required_argument, NULL, 6}, {"tuning", required_argument, NULL, 7}, {"cache-file", required_argument, NULL, 8}, {"device", required_argument, NULL, 9}, {"default-thread-block-size", required_argument, NULL, 10}, {"default-grid-size", required_argument, NULL, 11}, {"default-group-size", required_argument, NULL, 12}, {"default-num-groups", required_argument, NULL, 13}, {"default-tile-size", required_argument, NULL, 14}, {"default-reg-tile-size", required_argument, NULL, 15}, {"default-registers", required_argument, NULL, 16}, {"default-cache", required_argument, NULL, 17}, {"default-threshold", required_argument, NULL, 18}, {"unified-memory", required_argument, NULL, 19}, {"platform", required_argument, NULL, 20}, {"dump-opencl", required_argument, NULL, 21}, {"load-opencl", required_argument, NULL, 22}, {"dump-opencl-binary", required_argument, NULL, 23}, {"load-opencl-binary", required_argument, NULL, 24}, {"build-option", required_argument, NULL, 25}, {"list-devices", no_argument, NULL, 26}, {0, 0, 0, 0}};
    static char *option_descriptions = "  -D/--debugging                  Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                        Print various low-overhead logging information while running.\n  -P/--profile                    Enable the collection of profiling information.\n  -h/--help                       Print help information and exit.\n  --print-params                  Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT              Set a tuning parameter to the given value.\n  --tuning FILE                   Read size=value assignments from the given file.\n  --cache-file FILE               Store program cache here.\n  -d/--device NAME                Use the first device whose name contains the given string.\n  --default-thread-block-size INT The default size of thread blocks that are launched.\n  --default-grid-size INT         The default number of thread blocks that are launched.\n  --default-group-size INT        Alias for --default-thread-block-size.\n  --default-num-groups INT        Alias for --default-num-thread-blocks.\n  --default-tile-size INT         The default tile size for two-dimensional tiling.\n  --default-reg-tile-size INT     The default register tile size for two-dimensional tiling.\n  --default-registers INT         The amount of register memory in bytes.\n  --default-cache INT             The amount of register memory in bytes.\n  --default-threshold INT         The default parallelism threshold.\n  --unified-memory INT            Whether to use unified memory\n  -p/--platform NAME              Use the first OpenCL platform whose name contains the given string.\n  --dump-opencl FILE              Dump the embedded OpenCL program to the indicated file.\n  --load-opencl FILE              Instead of using the embedded OpenCL program, load it from the indicated file.\n  --dump-opencl-binary FILE       Dump the compiled version of the embedded OpenCL program to the indicated file.\n  --load-opencl-binary FILE       Load an OpenCL binary from the indicated file.\n  --build-option OPT              Add an additional build option to the string passed to clBuildProgram().\n  --list-devices                  List all OpenCL devices and platforms available on the system.\n";
    
    while ((ch = getopt_long(argc, argv, ":DLPhd:p:", long_options, NULL)) != -1) {
        if (ch == 1 || ch == 'D')
            futhark_context_config_set_debugging(cfg, 1);
        if (ch == 2 || ch == 'L')
            futhark_context_config_set_logging(cfg, 1);
        if (ch == 3 || ch == 'P')
            futhark_context_config_set_profiling(cfg, 1);
        if (ch == 4 || ch == 'h') {
            printf("Usage: %s [OPTIONS]...\nOptions:\n\n%s\nFor more information, consult the Futhark User's Guide or the man pages.\n", fut_progname, option_descriptions);
            exit(0);
        }
        if (ch == 5) {
            int n = futhark_get_tuning_param_count();
            
            for (int i = 0; i < n; i++)
                printf("%s (%s)\n", futhark_get_tuning_param_name(i), futhark_get_tuning_param_class(i));
            exit(0);
        }
        if (ch == 6) {
            char *name = optarg;
            char *equals = strstr(optarg, "=");
            char *value_str = equals != NULL ? equals + 1 : optarg;
            int value = atoi(value_str);
            
            if (equals != NULL) {
                *equals = 0;
                if (futhark_context_config_set_tuning_param(cfg, name, value) != 0)
                    futhark_panic(1, "Unknown size: %s\n", name);
            } else
                futhark_panic(1, "Invalid argument for size option: %s\n", optarg);
        }
        if (ch == 7) {
            char *ret = load_tuning_file(optarg, cfg, (int (*)(void *, const char *, size_t)) futhark_context_config_set_tuning_param);
            
            if (ret != NULL)
                futhark_panic(1, "When loading tuning file '%s': %s\n", optarg, ret);
        }
        if (ch == 8)
            futhark_context_config_set_cache_file(cfg, optarg);
        if (ch == 9 || ch == 'd')
            futhark_context_config_set_device(cfg, optarg);
        if (ch == 10)
            futhark_context_config_set_default_thread_block_size(cfg, atoi(optarg));
        if (ch == 11)
            futhark_context_config_set_default_grid_size(cfg, atoi(optarg));
        if (ch == 12)
            futhark_context_config_set_default_group_size(cfg, atoi(optarg));
        if (ch == 13)
            futhark_context_config_set_default_num_groups(cfg, atoi(optarg));
        if (ch == 14)
            futhark_context_config_set_default_tile_size(cfg, atoi(optarg));
        if (ch == 15)
            futhark_context_config_set_default_reg_tile_size(cfg, atoi(optarg));
        if (ch == 16)
            futhark_context_config_set_default_registers(cfg, atoi(optarg));
        if (ch == 17)
            futhark_context_config_set_default_cache(cfg, atoi(optarg));
        if (ch == 18)
            futhark_context_config_set_default_threshold(cfg, atoi(optarg));
        if (ch == 19)
            futhark_context_config_set_unified_memory(cfg, atoi(optarg));
        if (ch == 20 || ch == 'p')
            futhark_context_config_set_platform(cfg, optarg);
        if (ch == 21) {
            const char *prog = futhark_context_config_get_program(cfg);
            
            if (dump_file(optarg, prog, strlen(prog)) != 0) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            exit(0);
        }
        if (ch == 22) {
            size_t n;
            const char *s = slurp_file(optarg, &n);
            
            if (s == NULL) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            futhark_context_config_set_program(cfg, s);
        }
        if (ch == 23) {
            futhark_context_config_dump_binary_to(cfg, optarg);
            entry_point = NULL;
        }
        if (ch == 24)
            futhark_context_config_load_binary_from(cfg, optarg);
        if (ch == 25)
            futhark_context_config_add_build_option(cfg, optarg);
        if (ch == 26) {
            futhark_context_config_list_devices(cfg);
            entry_point = NULL;
        }
        if (ch == ':')
            futhark_panic(-1, "Missing argument for option %s\n", argv[optind - 1]);
        if (ch == '?') {
            fprintf(stderr, "Usage: %s [OPTIONS]...\nOptions:\n\n%s\n", fut_progname, "  -D/--debugging                  Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                        Print various low-overhead logging information while running.\n  -P/--profile                    Enable the collection of profiling information.\n  -h/--help                       Print help information and exit.\n  --print-params                  Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT              Set a tuning parameter to the given value.\n  --tuning FILE                   Read size=value assignments from the given file.\n  --cache-file FILE               Store program cache here.\n  -d/--device NAME                Use the first device whose name contains the given string.\n  --default-thread-block-size INT The default size of thread blocks that are launched.\n  --default-grid-size INT         The default number of thread blocks that are launched.\n  --default-group-size INT        Alias for --default-thread-block-size.\n  --default-num-groups INT        Alias for --default-num-thread-blocks.\n  --default-tile-size INT         The default tile size for two-dimensional tiling.\n  --default-reg-tile-size INT     The default register tile size for two-dimensional tiling.\n  --default-registers INT         The amount of register memory in bytes.\n  --default-cache INT             The amount of register memory in bytes.\n  --default-threshold INT         The default parallelism threshold.\n  --unified-memory INT            Whether to use unified memory\n  -p/--platform NAME              Use the first OpenCL platform whose name contains the given string.\n  --dump-opencl FILE              Dump the embedded OpenCL program to the indicated file.\n  --load-opencl FILE              Instead of using the embedded OpenCL program, load it from the indicated file.\n  --dump-opencl-binary FILE       Dump the compiled version of the embedded OpenCL program to the indicated file.\n  --load-opencl-binary FILE       Load an OpenCL binary from the indicated file.\n  --build-option OPT              Add an additional build option to the string passed to clBuildProgram().\n  --list-devices                  List all OpenCL devices and platforms available on the system.\n");
            futhark_panic(1, "Unknown option: %s\n", argv[optind - 1]);
        }
    }
    return optind;
}
int main(int argc, char **argv)
{
    fut_progname = argv[0];
    
    struct futhark_context_config *cfg = futhark_context_config_new();
    
    assert(cfg != NULL);
    
    int parsed_options = parse_options(cfg, argc, argv);
    
    argc -= parsed_options;
    argv += parsed_options;
    if (argc != 0)
        futhark_panic(1, "Excess non-option: %s\n", argv[0]);
    
    struct futhark_context *ctx = futhark_context_new(cfg);
    
    assert(ctx != NULL);
    futhark_context_set_logging_file(ctx, stdout);
    
    char *error = futhark_context_get_error(ctx);
    
    if (error != NULL)
        futhark_panic(1, "Error during context initialisation:\n%s", error);
    if (entry_point != NULL)
        run_server(&prog, cfg, ctx);
    futhark_context_free(ctx);
    futhark_context_config_free(cfg);
}

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#define CL_TARGET_OPENCL_VERSION 120
#define CL_USE_DEPRECATED_OPENCL_1_2_APIS
#ifdef __APPLE__
#define CL_SILENCE_DEPRECATION
#include <OpenCL/cl.h>
#else
#include <CL/cl.h>
#endif


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

#ifndef M_PI
#define M_PI 3.141592653589793
#endif

SCALAR_FUN_ATTR int32_t fptobits_f32_i32(float x);
SCALAR_FUN_ATTR float bitstofp_i32_f32(int32_t x);

SCALAR_FUN_ATTR uint8_t   add8(uint8_t x, uint8_t y)   { return x + y; }
SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) { return x + y; }
SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) { return x + y; }
SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) { return x + y; }

SCALAR_FUN_ATTR uint8_t   sub8(uint8_t x, uint8_t y)   { return x - y; }
SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) { return x - y; }
SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) { return x - y; }
SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) { return x - y; }

SCALAR_FUN_ATTR uint8_t   mul8(uint8_t x, uint8_t y)   { return x * y; }
SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) { return x * y; }
SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) { return x * y; }
SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) { return x * y; }

#if defined(ISPC)

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i) { ys = y; }
  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i) { ys = y; }
  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i) { ys = y; }
  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i) { ys = y; }
  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i) { ys = y; }
  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i) { ys = y; }
  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i) { ys = y; }
  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i) { ys = y; }
  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i) { ys = y; }
  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i) { ys = y; }
  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i) { ys = y; }
  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i) { ys = y; }
  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i) { ys = y; }
  int8_t q = x / ys;
  int8_t r = x % ys;
  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i) { ys = y; }
  int16_t q = x / ys;
  int16_t r = x % ys;
  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i) { ys = y; }
  int32_t q = x / ys;
  int32_t r = x % ys;
  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i) { ys = y; }
  int64_t q = x / ys;
  int64_t r = x % ys;
  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) { return sdiv8(x + y - 1, y); }
SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) { return sdiv16(x + y - 1, y); }
SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) { return sdiv32(x + y - 1, y); }
SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) { return sdiv64(x + y - 1, y); }

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i) { ys = y; }
  int8_t r = x % ys;
  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i) { ys = y; }
  int16_t r = x % ys;
  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i) { ys = y; }
  int32_t r = x % ys;
  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i) { ys = y; }
  int64_t r = x % ys;
  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t   sdiv_safe8(int8_t x, int8_t y)   { return y == 0 ? 0 : sdiv8(x, y); }
SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) { return y == 0 ? 0 : sdiv16(x, y); }
SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) { return y == 0 ? 0 : sdiv32(x, y); }
SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) { return y == 0 ? 0 : sdiv64(x, y); }

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y)     { return sdiv_safe8(x + y - 1, y); }
SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) { return sdiv_safe16(x + y - 1, y); }
SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) { return sdiv_safe32(x + y - 1, y); }
SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) { return sdiv_safe64(x + y - 1, y); }

SCALAR_FUN_ATTR int8_t   smod_safe8(int8_t x, int8_t y)   { return y == 0 ? 0 : smod8(x, y); }
SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) { return y == 0 ? 0 : smod16(x, y); }
SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) { return y == 0 ? 0 : smod32(x, y); }
SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) { return y == 0 ? 0 : smod64(x, y); }

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i) { ys = y; }
  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i) { ys = y; }
  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i) { ys = y; }
  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i) { ys = y; }
  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i) { ys = y; }
  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i) { ys = y; }
  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i) { ys = y; }
  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i) { ys = y; }
  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i) { ys = y; }
  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t   udiv8(uint8_t x, uint8_t y)   { return x / y; }
SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) { return x / y; }
SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) { return x / y; }
SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) { return x / y; }

SCALAR_FUN_ATTR uint8_t   udiv_up8(uint8_t x, uint8_t y)   { return (x + y - 1) / y; }
SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) { return (x + y - 1) / y; }
SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) { return (x + y - 1) / y; }
SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) { return (x + y - 1) / y; }

SCALAR_FUN_ATTR uint8_t   umod8(uint8_t x, uint8_t y)   { return x % y; }
SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) { return x % y; }
SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) { return x % y; }
SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) { return x % y; }

SCALAR_FUN_ATTR uint8_t   udiv_safe8(uint8_t x, uint8_t y)   { return y == 0 ? 0 : x / y; }
SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) { return y == 0 ? 0 : x / y; }
SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) { return y == 0 ? 0 : x / y; }
SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) { return y == 0 ? 0 : x / y; }

SCALAR_FUN_ATTR uint8_t   udiv_up_safe8(uint8_t x, uint8_t y)   { return y == 0 ? 0 : (x + y - 1) / y; }
SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) { return y == 0 ? 0 : (x + y - 1) / y; }
SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) { return y == 0 ? 0 : (x + y - 1) / y; }
SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) { return y == 0 ? 0 : (x + y - 1) / y; }

SCALAR_FUN_ATTR uint8_t   umod_safe8(uint8_t x, uint8_t y)   { return y == 0 ? 0 : x % y; }
SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) { return y == 0 ? 0 : x % y; }
SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) { return y == 0 ? 0 : x % y; }
SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) { return y == 0 ? 0 : x % y; }

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;
  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;
  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;
  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;
  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t   sdiv_up8(int8_t x, int8_t y)   { return sdiv8(x + y - 1, y); }
SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) { return sdiv16(x + y - 1, y); }
SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) { return sdiv32(x + y - 1, y); }
SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) { return sdiv64(x + y - 1, y); }

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;
  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;
  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;
  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;
  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t   sdiv_safe8(int8_t x, int8_t y)   { return y == 0 ? 0 : sdiv8(x, y); }
SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) { return y == 0 ? 0 : sdiv16(x, y); }
SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) { return y == 0 ? 0 : sdiv32(x, y); }
SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) { return y == 0 ? 0 : sdiv64(x, y); }

SCALAR_FUN_ATTR int8_t   sdiv_up_safe8(int8_t x, int8_t y)   { return sdiv_safe8(x + y - 1, y);}
SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) { return sdiv_safe16(x + y - 1, y); }
SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) { return sdiv_safe32(x + y - 1, y); }
SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) { return sdiv_safe64(x + y - 1, y); }

SCALAR_FUN_ATTR int8_t   smod_safe8(int8_t x, int8_t y)   { return y == 0 ? 0 : smod8(x, y); }
SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) { return y == 0 ? 0 : smod16(x, y); }
SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) { return y == 0 ? 0 : smod32(x, y); }
SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) { return y == 0 ? 0 : smod64(x, y); }

SCALAR_FUN_ATTR int8_t   squot8(int8_t x, int8_t y)   { return x / y; }
SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) { return x / y; }
SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) { return x / y; }
SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) { return x / y; }

SCALAR_FUN_ATTR int8_t   srem8(int8_t x, int8_t y)   { return x % y; }
SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) { return x % y; }
SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) { return x % y; }
SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) { return x % y; }

SCALAR_FUN_ATTR int8_t   squot_safe8(int8_t x, int8_t y)   { return y == 0 ? 0 : x / y; }
SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) { return y == 0 ? 0 : x / y; }
SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) { return y == 0 ? 0 : x / y; }
SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) { return y == 0 ? 0 : x / y; }

SCALAR_FUN_ATTR int8_t   srem_safe8(int8_t x, int8_t y)   { return y == 0 ? 0 : x % y; }
SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) { return y == 0 ? 0 : x % y; }
SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) { return y == 0 ? 0 : x % y; }
SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) { return y == 0 ? 0 : x % y; }

#endif

SCALAR_FUN_ATTR int8_t   smin8(int8_t x, int8_t y)   { return x < y ? x : y; }
SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) { return x < y ? x : y; }
SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) { return x < y ? x : y; }
SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) { return x < y ? x : y; }

SCALAR_FUN_ATTR uint8_t   umin8(uint8_t x, uint8_t y)   { return x < y ? x : y; }
SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) { return x < y ? x : y; }
SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) { return x < y ? x : y; }
SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) { return x < y ? x : y; }

SCALAR_FUN_ATTR int8_t  smax8(int8_t x, int8_t y)    { return x < y ? y : x; }
SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) { return x < y ? y : x; }
SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) { return x < y ? y : x; }
SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) { return x < y ? y : x; }

SCALAR_FUN_ATTR uint8_t   umax8(uint8_t x, uint8_t y)   { return x < y ? y : x; }
SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) { return x < y ? y : x; }
SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) { return x < y ? y : x; }
SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) { return x < y ? y : x; }

SCALAR_FUN_ATTR uint8_t   shl8(uint8_t x, uint8_t y)   { return (uint8_t)(x << y); }
SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) { return (uint16_t)(x << y); }
SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) { return x << y; }
SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) { return x << y; }

SCALAR_FUN_ATTR uint8_t   lshr8(uint8_t x, uint8_t y)   { return x >> y; }
SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) { return x >> y; }
SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) { return x >> y; }
SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) { return x >> y; }

SCALAR_FUN_ATTR int8_t   ashr8(int8_t x, int8_t y)   { return x >> y; }
SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) { return x >> y; }
SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) { return x >> y; }
SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) { return x >> y; }

SCALAR_FUN_ATTR uint8_t   and8(uint8_t x, uint8_t y)   { return x & y; }
SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) { return x & y; }
SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) { return x & y; }
SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) { return x & y; }

SCALAR_FUN_ATTR uint8_t    or8(uint8_t x, uint8_t y)  { return x | y; }
SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) { return x | y; }
SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) { return x | y; }
SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) { return x | y; }

SCALAR_FUN_ATTR uint8_t   xor8(uint8_t x, uint8_t y)   { return x ^ y; }
SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) { return x ^ y; }
SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) { return x ^ y; }
SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) { return x ^ y; }

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y)    { return x < y; }
SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) { return x < y; }
SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) { return x < y; }
SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) { return x < y; }

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y)    { return x <= y; }
SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) { return x <= y; }
SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) { return x <= y; }
SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) { return x <= y; }

SCALAR_FUN_ATTR bool  slt8(int8_t x, int8_t y)   { return x < y; }
SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) { return x < y; }
SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) { return x < y; }
SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) { return x < y; }

SCALAR_FUN_ATTR bool  sle8(int8_t x, int8_t y)   { return x <= y; }
SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) { return x <= y; }
SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) { return x <= y; }
SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) { return x <= y; }

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;
  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;
  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;
  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;
  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool  itob_i8_bool(int8_t x)  { return x != 0; }
SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) { return x != 0; }
SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) { return x != 0; }
SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) { return x != 0; }

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x)   { return x; }
SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) { return x; }
SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) { return x; }
SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) { return x; }

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t   abs8(int8_t x)  { return (int8_t)abs(x); }
SCALAR_FUN_ATTR int16_t abs16(int16_t x) { return (int16_t)abs(x); }
SCALAR_FUN_ATTR int32_t abs32(int32_t x) { return abs(x); }
SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)

SCALAR_FUN_ATTR int32_t  futrts_popc8(int8_t x)  { return popcount(x); }
SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) { return popcount(x); }
SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) { return popcount(x); }
SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) { return popcount(x); }

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t  futrts_popc8(int8_t x)  { return __popc(zext_i8_i32(x)); }
SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) { return __popc(zext_i16_i32(x)); }
SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) { return __popc(x); }
SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) { return __popcll(x); }

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif defined(ISPC)
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t  futrts_clzz8(int8_t x)  { return clz(x); }
SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) { return clz(x); }
SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) { return clz(x); }
SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) { return clz(x); }

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t  futrts_clzz8(int8_t x)  { return __clz(zext_i8_i32(x)) - 24; }
SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) { return __clz(zext_i16_i32(x)) - 16; }
SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) { return __clz(x); }
SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) { return __clzll(x); }

#elif defined(ISPC)

SCALAR_FUN_ATTR int32_t  futrts_clzz8(int8_t x)  { return count_leading_zeros((int32_t)(uint8_t)x)-24; }
SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) { return count_leading_zeros((int32_t)(uint16_t)x)-16; }
SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) { return count_leading_zeros(x); }
SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) { return count_leading_zeros(x); }

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x)
{ return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24; }
SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x)
{ return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16; }
SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x)
{ return x == 0 ? 32 : __builtin_clz((uint32_t)x); }
SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x)
{ return x == 0 ? 64 : __builtin_clzll((uint64_t)x); }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1) ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1) ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1) ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1) ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif defined(ISPC)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) { return x == 0 ? 8 : count_trailing_zeros((int32_t)x); }
SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) { return x == 0 ? 16 : count_trailing_zeros((int32_t)x); }
SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) { return count_trailing_zeros(x); }
SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) { return count_trailing_zeros(x); }

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t  futrts_ctzz8(int8_t x)  { return x == 0 ? 8 : __builtin_ctz((uint32_t)x); }
SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) { return x == 0 ? 16 : __builtin_ctz((uint32_t)x); }
SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) { return x == 0 ? 32 : __builtin_ctz((uint32_t)x); }
SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) { return x == 0 ? 64 : __builtin_ctzll((uint64_t)x); }
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) { return x / y; }
SCALAR_FUN_ATTR float fadd32(float x, float y) { return x + y; }
SCALAR_FUN_ATTR float fsub32(float x, float y) { return x - y; }
SCALAR_FUN_ATTR float fmul32(float x, float y) { return x * y; }
SCALAR_FUN_ATTR bool cmplt32(float x, float y) { return x < y; }
SCALAR_FUN_ATTR bool cmple32(float x, float y) { return x <= y; }
SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x)  { return (float) x; }

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) { return (float) x; }
SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) { return (float) x; }
SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) { return (float) x; }
SCALAR_FUN_ATTR float  uitofp_i8_f32(uint8_t x)  { return (float) x; }
SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) { return (float) x; }
SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) { return (float) x; }
SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) { return (float) x; }

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x)          { return fabs(x); }
SCALAR_FUN_ATTR float fmax32(float x, float y) { return fmax(x, y); }
SCALAR_FUN_ATTR float fmin32(float x, float y) { return fmin(x, y); }
SCALAR_FUN_ATTR float fpow32(float x, float y) { return pow(x, y); }

#elif defined(ISPC)

SCALAR_FUN_ATTR float fabs32(float x) { return abs(x); }
SCALAR_FUN_ATTR float fmax32(float x, float y) { return isnan(x) ? y : isnan(y) ? x : max(x, y); }
SCALAR_FUN_ATTR float fmin32(float x, float y) { return isnan(x) ? y : isnan(y) ? x : min(x, y); }
SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = pow(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x)          { return fabsf(x); }
SCALAR_FUN_ATTR float fmax32(float x, float y) { return fmaxf(x, y); }
SCALAR_FUN_ATTR float fmin32(float x, float y) { return fminf(x, y); }
SCALAR_FUN_ATTR float fpow32(float x, float y) { return powf(x, y); }
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) { return isnan(x); }

#if defined(ISPC)

SCALAR_FUN_ATTR bool futrts_isinf32(float x) { return !isnan(x) && isnan(x - x); }

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) { return !isnan(x) && !futrts_isinf32(x); }

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) { return isinf(x); }

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) { return x != 0; }
SCALAR_FUN_ATTR float btof_bool_f32(bool x) { return x ? 1 : 0; }

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) { return log(x); }
SCALAR_FUN_ATTR float futrts_log2_32(float x) { return log2(x); }
SCALAR_FUN_ATTR float futrts_log10_32(float x) { return log10(x); }
SCALAR_FUN_ATTR float futrts_log1p_32(float x) { return log1p(x); }
SCALAR_FUN_ATTR float futrts_sqrt32(float x) { return sqrt(x); }
SCALAR_FUN_ATTR float futrts_rsqrt32(float x) { return rsqrt(x); }
SCALAR_FUN_ATTR float futrts_cbrt32(float x) { return cbrt(x); }
SCALAR_FUN_ATTR float futrts_exp32(float x) { return exp(x); }
SCALAR_FUN_ATTR float futrts_cos32(float x) { return cos(x); }
SCALAR_FUN_ATTR float futrts_cospi32(float x) { return cospi(x); }
SCALAR_FUN_ATTR float futrts_sin32(float x) { return sin(x); }
SCALAR_FUN_ATTR float futrts_sinpi32(float x) { return sinpi(x); }
SCALAR_FUN_ATTR float futrts_tan32(float x) { return tan(x); }
SCALAR_FUN_ATTR float futrts_tanpi32(float x) { return tanpi(x); }
SCALAR_FUN_ATTR float futrts_acos32(float x) { return acos(x); }
SCALAR_FUN_ATTR float futrts_acospi32(float x) { return acospi(x); }
SCALAR_FUN_ATTR float futrts_asin32(float x) { return asin(x); }
SCALAR_FUN_ATTR float futrts_asinpi32(float x) { return asinpi(x); }
SCALAR_FUN_ATTR float futrts_atan32(float x) { return atan(x); }
SCALAR_FUN_ATTR float futrts_atanpi32(float x) { return atanpi(x); }
SCALAR_FUN_ATTR float futrts_cosh32(float x) { return cosh(x); }
SCALAR_FUN_ATTR float futrts_sinh32(float x) { return sinh(x); }
SCALAR_FUN_ATTR float futrts_tanh32(float x) { return tanh(x); }
SCALAR_FUN_ATTR float futrts_acosh32(float x) { return acosh(x); }
SCALAR_FUN_ATTR float futrts_asinh32(float x) { return asinh(x); }
SCALAR_FUN_ATTR float futrts_atanh32(float x) { return atanh(x); }
SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) { return atan2(x, y); }
SCALAR_FUN_ATTR float futrts_atan2pi_32(float x, float y) { return atan2pi(x, y); }
SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) { return hypot(x, y); }
SCALAR_FUN_ATTR float futrts_gamma32(float x) { return tgamma(x); }
SCALAR_FUN_ATTR float futrts_lgamma32(float x) { return lgamma(x); }
SCALAR_FUN_ATTR float futrts_erf32(float x) { return erf(x); }
SCALAR_FUN_ATTR float futrts_erfc32(float x) { return erfc(x); }
SCALAR_FUN_ATTR float fmod32(float x, float y) { return fmod(x, y); }
SCALAR_FUN_ATTR float futrts_round32(float x) { return rint(x); }
SCALAR_FUN_ATTR float futrts_floor32(float x) { return floor(x); }
SCALAR_FUN_ATTR float futrts_ceil32(float x) { return ceil(x); }
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) { return nextafter(x, y); }
SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) { return mix(v0, v1, t); }
SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) { return ldexp(x, y); }
SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) { return copysign(x, y); }
SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) { return mad(a, b, c); }
SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) { return fma(a, b, c); }

#elif defined(ISPC)

SCALAR_FUN_ATTR float futrts_log32(float x) { return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x; }
SCALAR_FUN_ATTR float futrts_log2_32(float x) { return futrts_log32(x) / log(2.0f); }
SCALAR_FUN_ATTR float futrts_log10_32(float x) { return futrts_log32(x) / log(10.0f); }

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) { return sqrt(x); }
SCALAR_FUN_ATTR float futrts_rsqrt32(float x) { return 1/sqrt(x); }

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) { return exp(x); }
SCALAR_FUN_ATTR float futrts_cos32(float x) { return cos(x); }
SCALAR_FUN_ATTR float futrts_cospi32(float x) { return cos((float)M_PI*x); }
SCALAR_FUN_ATTR float futrts_sin32(float x) { return sin(x); }
SCALAR_FUN_ATTR float futrts_sinpi32(float x) { return sin(M_PI*x); }
SCALAR_FUN_ATTR float futrts_tan32(float x) { return tan(x); }
SCALAR_FUN_ATTR float futrts_tanpi32(float x) { return tan((float)M_PI*x); }
SCALAR_FUN_ATTR float futrts_acos32(float x) { return acos(x); }
SCALAR_FUN_ATTR float futrts_acospi32(float x) { return acos(x)/(float)M_PI; }
SCALAR_FUN_ATTR float futrts_asin32(float x) { return asin(x); }
SCALAR_FUN_ATTR float futrts_asinpi32(float x) { return asin(x)/(float)M_PI; }
SCALAR_FUN_ATTR float futrts_atan32(float x) { return atan(x); }
SCALAR_FUN_ATTR float futrts_atanpi32(float x) { return atan(x)/(float)M_PI; }
SCALAR_FUN_ATTR float futrts_cosh32(float x) { return (exp(x)+exp(-x)) / 2.0f; }
SCALAR_FUN_ATTR float futrts_sinh32(float x) { return (exp(x)-exp(-x)) / 2.0f; }
SCALAR_FUN_ATTR float futrts_tanh32(float x) { return futrts_sinh32(x)/futrts_cosh32(x); }

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if (futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if (futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if (futrts_isfinite32(f)) return log(f)/2.0f;
  return f;
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y)
{ return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y); }
SCALAR_FUN_ATTR float futrts_atan2pi_32(float x, float y)
{ return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y) / (float)M_PI; }

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) { return x - y * trunc(x/y); }
SCALAR_FUN_ATTR float futrts_round32(float x) { return round(x); }
SCALAR_FUN_ATTR float futrts_floor32(float x) { return floor(x); }
SCALAR_FUN_ATTR float futrts_ceil32(float x) { return ceil(x); }

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return x * pow((uniform float)2.0, (float)y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  int32_t xb = fptobits_f32_i32(x);
  int32_t yb = fptobits_f32_i32(y);
  return bitstofp_i32_f32((xb & ~(1<<31)) | (yb & (1<<31)));
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) { return logf(x); }
SCALAR_FUN_ATTR float futrts_log2_32(float x) { return log2f(x); }
SCALAR_FUN_ATTR float futrts_log10_32(float x) { return log10f(x); }
SCALAR_FUN_ATTR float futrts_log1p_32(float x) { return log1pf(x); }
SCALAR_FUN_ATTR float futrts_sqrt32(float x) { return sqrtf(x); }
SCALAR_FUN_ATTR float futrts_rsqrt32(float x) { return 1/sqrtf(x); }
SCALAR_FUN_ATTR float futrts_cbrt32(float x) { return cbrtf(x); }
SCALAR_FUN_ATTR float futrts_exp32(float x) { return expf(x); }
SCALAR_FUN_ATTR float futrts_cos32(float x) { return cosf(x); }

SCALAR_FUN_ATTR float futrts_cospi32(float x) {
#if defined(__CUDA_ARCH__)
  return cospif(x);
#else
  return cosf(((float)M_PI)*x);
#endif
}
SCALAR_FUN_ATTR float futrts_sin32(float x) { return sinf(x); }

SCALAR_FUN_ATTR float futrts_sinpi32(float x) {
#if defined(__CUDA_ARCH__)
  return sinpif(x);
#else
  return sinf((float)M_PI*x);
#endif
}

SCALAR_FUN_ATTR float futrts_tan32(float x) { return tanf(x); }
SCALAR_FUN_ATTR float futrts_tanpi32(float x) { return tanf((float)M_PI*x); }
SCALAR_FUN_ATTR float futrts_acos32(float x) { return acosf(x); }
SCALAR_FUN_ATTR float futrts_acospi32(float x) { return acosf(x)/(float)M_PI; }
SCALAR_FUN_ATTR float futrts_asin32(float x) { return asinf(x); }
SCALAR_FUN_ATTR float futrts_asinpi32(float x) { return asinf(x)/(float)M_PI; }
SCALAR_FUN_ATTR float futrts_atan32(float x) { return atanf(x); }
SCALAR_FUN_ATTR float futrts_atanpi32(float x) { return atanf(x)/(float)M_PI; }
SCALAR_FUN_ATTR float futrts_cosh32(float x) { return coshf(x); }
SCALAR_FUN_ATTR float futrts_sinh32(float x) { return sinhf(x); }
SCALAR_FUN_ATTR float futrts_tanh32(float x) { return tanhf(x); }
SCALAR_FUN_ATTR float futrts_acosh32(float x) { return acoshf(x); }
SCALAR_FUN_ATTR float futrts_asinh32(float x) { return asinhf(x); }
SCALAR_FUN_ATTR float futrts_atanh32(float x) { return atanhf(x); }
SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) { return atan2f(x, y); }
SCALAR_FUN_ATTR float futrts_atan2pi_32(float x, float y) { return atan2f(x, y) / (float)M_PI; }
SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) { return hypotf(x, y); }
SCALAR_FUN_ATTR float futrts_gamma32(float x) { return tgammaf(x); }
SCALAR_FUN_ATTR float futrts_lgamma32(float x) { return lgammaf(x); }
SCALAR_FUN_ATTR float futrts_erf32(float x) { return erff(x); }
SCALAR_FUN_ATTR float futrts_erfc32(float x) { return erfcf(x); }
SCALAR_FUN_ATTR float fmod32(float x, float y) { return fmodf(x, y); }
SCALAR_FUN_ATTR float futrts_round32(float x) { return rintf(x); }
SCALAR_FUN_ATTR float futrts_floor32(float x) { return floorf(x); }
SCALAR_FUN_ATTR float futrts_ceil32(float x) { return ceilf(x); }
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) { return nextafterf(x, y); }
SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) { return v0 + (v1 - v0) * t; }
SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) { return ldexpf(x, y); }
SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) { return copysignf(x, y); }
SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) { return a * b + c; }
SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) { return fmaf(a, b, c); }

#endif

#if defined(ISPC)

SCALAR_FUN_ATTR int32_t fptobits_f32_i32(float x) { return intbits(x); }
SCALAR_FUN_ATTR float bitstofp_i32_f32(int32_t x) { return floatbits(x); }
SCALAR_FUN_ATTR uniform int32_t fptobits_f32_i32(uniform float x) { return intbits(x); }
SCALAR_FUN_ATTR uniform float bitstofp_i32_f32(uniform int32_t x) { return floatbits(x); }

#else

SCALAR_FUN_ATTR int32_t fptobits_f32_i32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float bitstofp_i32_f32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double bitstofp_i64_f64(int64_t x);
SCALAR_FUN_ATTR int64_t fptobits_f64_i64(double x);

#if defined(ISPC)

SCALAR_FUN_ATTR bool futrts_isinf64(float x) { return !isnan(x) && isnan(x - x); }
SCALAR_FUN_ATTR bool futrts_isfinite64(float x) { return !isnan(x) && !futrts_isinf64(x); }
SCALAR_FUN_ATTR double fdiv64(double x, double y) { return x / y; }
SCALAR_FUN_ATTR double fadd64(double x, double y) { return x + y; }
SCALAR_FUN_ATTR double fsub64(double x, double y) { return x - y; }
SCALAR_FUN_ATTR double fmul64(double x, double y) { return x * y; }
SCALAR_FUN_ATTR bool cmplt64(double x, double y) { return x < y; }
SCALAR_FUN_ATTR bool cmple64(double x, double y) { return x <= y; }
SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) { return (double) x; }
SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) { return (double) x; }
SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) { return (double) x; }
SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) { return (double) x; }
SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) { return (double) x; }
SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) { return (double) x; }
SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) { return (double) x; }
SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) { return (double) x; }
SCALAR_FUN_ATTR double fabs64(double x) { return abs(x); }
SCALAR_FUN_ATTR double fmax64(double x, double y) { return isnan(x) ? y : isnan(y) ? x : max(x, y); }
SCALAR_FUN_ATTR double fmin64(double x, double y) { return isnan(x) ? y : isnan(y) ? x : min(x, y); }

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = pow(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}
SCALAR_FUN_ATTR double futrts_log64(double x) { return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x; }
SCALAR_FUN_ATTR double futrts_log2_64(double x) { return futrts_log64(x)/log(2.0d); }
SCALAR_FUN_ATTR double futrts_log10_64(double x) { return futrts_log64(x)/log(10.0d); }

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) { return sqrt(x); }
SCALAR_FUN_ATTR double futrts_rsqrt64(double x) { return 1/sqrt(x); }

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}
SCALAR_FUN_ATTR double futrts_exp64(double x) { return exp(x); }
SCALAR_FUN_ATTR double futrts_cos64(double x) { return cos(x); }
SCALAR_FUN_ATTR double futrts_cospi64(double x) { return cos(M_PI*x); }
SCALAR_FUN_ATTR double futrts_sin64(double x) { return sin(x); }
SCALAR_FUN_ATTR double futrts_sinpi64(double x) { return sin(M_PI*x); }
SCALAR_FUN_ATTR double futrts_tan64(double x) { return tan(x); }
SCALAR_FUN_ATTR double futrts_tanpi64(double x) { return tan(M_PI*x); }
SCALAR_FUN_ATTR double futrts_acos64(double x) { return acos(x); }
SCALAR_FUN_ATTR double futrts_acospi64(double x) { return acos(x)/M_PI; }
SCALAR_FUN_ATTR double futrts_asin64(double x) { return asin(x); }
SCALAR_FUN_ATTR double futrts_asinpi64(double x) { return asin(x)/M_PI; }
SCALAR_FUN_ATTR double futrts_atan64(double x) { return atan(x); }
SCALAR_FUN_ATTR double futrts_atanpi64(double x) { return atan(x)/M_PI; }
SCALAR_FUN_ATTR double futrts_cosh64(double x) { return (exp(x)+exp(-x)) / 2.0d; }
SCALAR_FUN_ATTR double futrts_sinh64(double x) { return (exp(x)-exp(-x)) / 2.0d; }
SCALAR_FUN_ATTR double futrts_tanh64(double x) { return futrts_sinh64(x)/futrts_cosh64(x); }

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;
}
SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) { return atan2(x, y); }

SCALAR_FUN_ATTR double futrts_atan2pi_64(double x, double y) { return atan2(x, y) / M_PI; }

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) { return a * b + c; }
SCALAR_FUN_ATTR double futrts_round64(double x) { return round(x); }
SCALAR_FUN_ATTR double futrts_ceil64(double x) { return ceil(x); }

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) { return floor(x); }
SCALAR_FUN_ATTR bool futrts_isnan64(double x) { return isnan(x); }

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) { return x != 0.0; }
SCALAR_FUN_ATTR double btof_bool_f64(bool x) { return x ? 1.0 : 0.0; }

SCALAR_FUN_ATTR int64_t fptobits_f64_i64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double bitstofp_i64_f64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR uniform int64_t fptobits_f64_i64(uniform double x) {
  return intbits(x);
}

SCALAR_FUN_ATTR uniform double bitstofp_i64_f64(uniform int64_t x) {
  return doublebits(x);
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return x * pow((uniform double)2.0, (double)y);
}

SCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {
  int64_t xb = fptobits_f64_i64(x);
  int64_t yb = fptobits_f64_i64(y);
  return bitstofp_i64_f64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) { return a * b + c; }
SCALAR_FUN_ATTR float fpconv_f32_f32(float x) { return (float) x; }
SCALAR_FUN_ATTR double fpconv_f32_f64(float x) { return (double) x; }
SCALAR_FUN_ATTR float fpconv_f64_f32(double x) { return (float) x; }
SCALAR_FUN_ATTR double fpconv_f64_f64(double x) { return (double) x; }

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) { return x / y; }
SCALAR_FUN_ATTR double fadd64(double x, double y) { return x + y; }
SCALAR_FUN_ATTR double fsub64(double x, double y) { return x - y; }
SCALAR_FUN_ATTR double fmul64(double x, double y) { return x * y; }
SCALAR_FUN_ATTR bool cmplt64(double x, double y) { return x < y; }
SCALAR_FUN_ATTR bool cmple64(double x, double y) { return x <= y; }
SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) { return (double) x; }
SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) { return (double) x; }
SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) { return (double) x; }
SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) { return (double) x; }
SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) { return (double) x; }
SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) { return (double) x; }
SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) { return (double) x; }
SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) { return (double) x; }
SCALAR_FUN_ATTR double fabs64(double x) { return fabs(x); }
SCALAR_FUN_ATTR double fmax64(double x, double y) { return fmax(x, y); }
SCALAR_FUN_ATTR double fmin64(double x, double y) { return fmin(x, y); }
SCALAR_FUN_ATTR double fpow64(double x, double y) { return pow(x, y); }
SCALAR_FUN_ATTR double futrts_log64(double x) { return log(x); }
SCALAR_FUN_ATTR double futrts_log2_64(double x) { return log2(x); }
SCALAR_FUN_ATTR double futrts_log10_64(double x) { return log10(x); }
SCALAR_FUN_ATTR double futrts_log1p_64(double x) { return log1p(x); }
SCALAR_FUN_ATTR double futrts_sqrt64(double x) { return sqrt(x); }
SCALAR_FUN_ATTR double futrts_rsqrt64(double x) { return 1/sqrt(x); }
SCALAR_FUN_ATTR double futrts_cbrt64(double x) { return cbrt(x); }
SCALAR_FUN_ATTR double futrts_exp64(double x) { return exp(x); }
SCALAR_FUN_ATTR double futrts_cos64(double x) { return cos(x); }

SCALAR_FUN_ATTR double futrts_cospi64(double x) {
#ifdef __OPENCL_VERSION__
  return cospi(x);
#elif defined(__CUDA_ARCH__)
  return cospi(x);
#else
  return cos(M_PI*x);
#endif
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_sinpi64(double x) {
#ifdef __OPENCL_VERSION__
  return sinpi(x);
#elif defined(__CUDA_ARCH__)
  return sinpi(x);
#else
  return sin(M_PI*x);
#endif
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_tanpi64(double x) {
#ifdef __OPENCL_VERSION__
  return tanpi(x);
#else
  return tan(M_PI*x);
#endif
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_acospi64(double x) {
#ifdef __OPENCL_VERSION__
  return acospi(x);
#else
  return acos(x) / M_PI;
#endif
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_asinpi64(double x) {
#ifdef __OPENCL_VERSION__
  return asinpi(x);
#else
  return asin(x) / M_PI;
#endif
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_atanpi64(double x) {
#ifdef __OPENCL_VERSION__
  return atanpi(x);
#else
  return atan(x) / M_PI;
#endif
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) { return cosh(x); }
SCALAR_FUN_ATTR double futrts_sinh64(double x) { return sinh(x); }
SCALAR_FUN_ATTR double futrts_tanh64(double x) { return tanh(x); }
SCALAR_FUN_ATTR double futrts_acosh64(double x) { return acosh(x); }
SCALAR_FUN_ATTR double futrts_asinh64(double x) { return asinh(x); }
SCALAR_FUN_ATTR double futrts_atanh64(double x) { return atanh(x); }
SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) { return atan2(x, y); }

SCALAR_FUN_ATTR double futrts_atan2pi_64(double x, double y) {
#ifdef __OPENCL_VERSION__
  return atan2pi(x, y);
#else
  return atan2(x, y) / M_PI;
#endif
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) { return hypot(x, y); }
SCALAR_FUN_ATTR double futrts_gamma64(double x) { return tgamma(x); }
SCALAR_FUN_ATTR double futrts_lgamma64(double x) { return lgamma(x); }
SCALAR_FUN_ATTR double futrts_erf64(double x) { return erf(x); }
SCALAR_FUN_ATTR double futrts_erfc64(double x) { return erfc(x); }
SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) { return fma(a, b, c); }
SCALAR_FUN_ATTR double futrts_round64(double x) { return rint(x); }
SCALAR_FUN_ATTR double futrts_ceil64(double x) { return ceil(x); }
SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) { return nextafter(x, y); }
SCALAR_FUN_ATTR double futrts_floor64(double x) { return floor(x); }
SCALAR_FUN_ATTR bool futrts_isnan64(double x) { return isnan(x); }
SCALAR_FUN_ATTR bool futrts_isinf64(double x) { return isinf(x); }

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) { return x != 0; }
SCALAR_FUN_ATTR double btof_bool_f64(bool x) { return x ? 1 : 0; }

SCALAR_FUN_ATTR int64_t fptobits_f64_i64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double bitstofp_i64_f64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) { return (float) x; }
SCALAR_FUN_ATTR double fpconv_f32_f64(float x) { return (double) x; }
SCALAR_FUN_ATTR float fpconv_f64_f32(double x) { return (float) x; }
SCALAR_FUN_ATTR double fpconv_f64_f64(double x) { return (double) x; }

#endif

#endif

#define futrts_cond_f16(x,y,z) ((x) ? (y) : (z))
#define futrts_cond_f32(x,y,z) ((x) ? (y) : (z))
#define futrts_cond_f64(x,y,z) ((x) ? (y) : (z))

#define futrts_cond_i8(x,y,z) ((x) ? (y) : (z))
#define futrts_cond_i16(x,y,z) ((x) ? (y) : (z))
#define futrts_cond_i32(x,y,z) ((x) ? (y) : (z))
#define futrts_cond_i64(x,y,z) ((x) ? (y) : (z))

#define futrts_cond_bool(x,y,z) ((x) ? (y) : (z))
#define futrts_cond_unit(x,y,z) ((x) ? (y) : (z))

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif defined(ISPC)
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.
SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) { return x + y; }
SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) { return x - y; }
SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) { return x * y; }
SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) { return x < y; }
SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) { return x <= y; }
SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) { return (f16) x; }
SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) { return (f16) x; }
SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) { return (f16) x; }
SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) { return (f16) x; }
SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) { return (f16) x; }
SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) { return (f16) x; }
SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) { return (f16) x; }
SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) { return (f16) x; }
SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) { return (int8_t) (float) x; }
SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) { return (int16_t) x; }
SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) { return (int32_t) x; }
SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) { return (int64_t) x; }
SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) { return (uint8_t) (float) x; }
SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) { return (uint16_t) x; }
SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) { return (uint32_t) x; }
SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) { return (uint64_t) x; }
SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) { return x != (f16)0; }
SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) { return x ? 1 : 0; }

#ifndef EMULATE_F16

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) { return isnan((float)x); }

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) { return fabs(x); }
SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) { return fmax(x, y); }
SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) { return fmin(x, y); }
SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) { return pow(x, y); }

#elif defined(ISPC)

SCALAR_FUN_ATTR f16 fabs16(f16 x) { return abs(x); }
SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) { return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y); }
SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) { return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y); }
SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) { return pow(x, y); }

#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) { return fabsf(x); }
SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) { return fmaxf(x, y); }
SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) { return fminf(x, y); }
SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) { return powf(x, y); }

#endif

#if defined(ISPC)
SCALAR_FUN_ATTR bool futrts_isinf16(float x) { return !futrts_isnan16(x) && futrts_isnan16(x - x); }
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) { return !futrts_isnan16(x) && !futrts_isinf16(x); }
#else
SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) { return isinf((float)x); }
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) { return log(x); }
SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) { return log2(x); }
SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) { return log10(x); }
SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) { return log1p(x); }
SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) { return sqrt(x); }
SCALAR_FUN_ATTR f16 futrts_rsqrt16(f16 x) { return rsqrt(x); }
SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) { return cbrt(x); }
SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) { return exp(x); }
SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) { return cos(x); }
SCALAR_FUN_ATTR f16 futrts_cospi16(f16 x) { return cospi(x); }
SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) { return sin(x); }
SCALAR_FUN_ATTR f16 futrts_sinpi16(f16 x) { return sinpi(x); }
SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) { return tan(x); }
SCALAR_FUN_ATTR f16 futrts_tanpi16(f16 x) { return tanpi(x); }
SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) { return acos(x); }
SCALAR_FUN_ATTR f16 futrts_acospi16(f16 x) { return acospi(x); }
SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) { return asin(x); }
SCALAR_FUN_ATTR f16 futrts_asinpi16(f16 x) { return asinpi(x); }
SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) { return atan(x); }
SCALAR_FUN_ATTR f16 futrts_atanpi16(f16 x) { return atanpi(x); }
SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) { return cosh(x); }
SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) { return sinh(x); }
SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) { return tanh(x); }
SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) { return acosh(x); }
SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) { return asinh(x); }
SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) { return atanh(x); }
SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) { return atan2(x, y); }
SCALAR_FUN_ATTR f16 futrts_atan2pi_16(f16 x, f16 y) { return atan2pi(x, y); }
SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) { return hypot(x, y); }
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) { return tgamma(x); }
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) { return lgamma(x); }
SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) { return erf(x); }
SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) { return erfc(x); }
SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) { return fmod(x, y); }
SCALAR_FUN_ATTR f16 futrts_round16(f16 x) { return rint(x); }
SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) { return floor(x); }
SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) { return ceil(x); }
SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) { return nextafter(x, y); }
SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) { return mix(v0, v1, t); }
SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) { return ldexp(x, y); }
SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) { return copysign(x, y); }
SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) { return mad(a, b, c); }
SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) { return fma(a, b, c); }

#elif defined(ISPC)

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) { return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x; }
SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) { return futrts_log16(x) / log(2.0f16); }
SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) { return futrts_log16(x) / log(10.0f16); }
SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}
SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) { return (float16)sqrt((float)x); }
SCALAR_FUN_ATTR f16 futrts_rsqrt16(f16 x) { return (float16)1/sqrt((float)x); }
SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) { return exp(x); }
SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) { return (float16)cos((float)x); }
SCALAR_FUN_ATTR f16 futrts_cospi16(f16 x) { return (float16)cos((float)M_PI*(float)x); }
SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) { return (float16)sin((float)x); }
SCALAR_FUN_ATTR f16 futrts_sinpi16(f16 x) { return (float16)sin((float)M_PI*(float)x); }
SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) { return (float16)tan((float)x); }
SCALAR_FUN_ATTR f16 futrts_tanpi16(f16 x) { return (float16)(tan((float)M_PI*(float)x)); }
SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) { return (float16)acos((float)x); }
SCALAR_FUN_ATTR f16 futrts_acospi16(f16 x) { return (float16)(acos((float)x)/(float)M_PI); }
SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) { return (float16)asin((float)x); }
SCALAR_FUN_ATTR f16 futrts_asinpi16(f16 x) { return (float16)(asin((float)x)/(float)M_PI); }
SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) { return (float16)atan((float)x); }
SCALAR_FUN_ATTR f16 futrts_atanpi16(f16 x) { return (float16)(atan((float)x)/(float)M_PI); }
SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) { return (exp(x)+exp(-x)) / 2.0f16; }
SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) { return (exp(x)-exp(-x)) / 2.0f16; }
SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) { return futrts_sinh16(x)/futrts_cosh16(x); }
SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}
SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}
SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}
SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) { return (float16)atan2((float)x, (float)y); }
SCALAR_FUN_ATTR f16 futrts_atan2pi_16(f16 x, f16 y) { return (float16)(atan2((float)x, (float)y)/(float)M_PI); }
SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) { return (float16)futrts_hypot32((float)x, (float)y); }

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}
SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) { return (f16)futrts_cbrt32((float)x); }
SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) { return (f16)futrts_erf32((float)x); }
SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) { return (f16)futrts_erfc32((float)x); }
SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) { return x - y * (float16)trunc((float) (x/y)); }
SCALAR_FUN_ATTR f16 futrts_round16(f16 x) { return (float16)round((float)x); }
SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) { return (float16)floor((float)x); }
SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) { return (float16)ceil((float)x); }
SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) { return (float16)futrts_nextafter32((float)x, (float) y); }
SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) { return v0 + (v1 - v0) * t; }
SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) { return futrts_ldexp32((float)x, y); }
SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) { return futrts_copysign32((float)x, y); }
SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) { return a * b + c; }
SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) { return a * b + c; }

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) { return hlog(x); }
SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) { return hlog2(x); }
SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) { return hlog10(x); }
SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) { return (f16)log1pf((float)x); }
SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) { return hsqrt(x); }
SCALAR_FUN_ATTR f16 futrts_rsqrt16(f16 x) { return hrsqrt(x); }
SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) { return cbrtf(x); }
SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) { return hexp(x); }
SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) { return hcos(x); }
SCALAR_FUN_ATTR f16 futrts_cospi16(f16 x) { return hcos((f16)M_PI*x); }
SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) { return hsin(x); }
SCALAR_FUN_ATTR f16 futrts_sinpi16(f16 x) { return hsin((f16)M_PI*x); }
SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) { return tanf(x); }
SCALAR_FUN_ATTR f16 futrts_tanpi16(f16 x) { return tanf((f16)M_PI*x); }
SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) { return acosf(x); }
SCALAR_FUN_ATTR f16 futrts_acospi16(f16 x) { return (f16)acosf(x)/(f16)M_PI; }
SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) { return asinf(x); }
SCALAR_FUN_ATTR f16 futrts_asinpi16(f16 x) { return (f16)asinf(x)/(f16)M_PI; }
SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) { return (f16)atanf(x); }
SCALAR_FUN_ATTR f16 futrts_atanpi16(f16 x) { return (f16)atanf(x)/(f16)M_PI; }
SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) { return coshf(x); }
SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) { return sinhf(x); }
SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) { return tanhf(x); }
SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) { return acoshf(x); }
SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) { return asinhf(x); }
SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) { return atanhf(x); }
SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) { return (f16)atan2f(x, y); }
SCALAR_FUN_ATTR f16 futrts_atan2pi_16(f16 x, f16 y) { return (f16)atan2f(x, y)/(f16)M_PI; }
SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) { return hypotf(x, y); }
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) { return tgammaf(x); }
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) { return lgammaf(x); }
SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) { return erff(x); }
SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) { return erfcf(x); }
SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) { return fmodf(x, y); }
SCALAR_FUN_ATTR f16 futrts_round16(f16 x) { return rintf(x); }
SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) { return hfloor(x); }
SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) { return hceil(x); }
SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) { return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y))); }
SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) { return v0 + (v1 - v0) * t; }
SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) { return futrts_ldexp32((float)x, y); }
SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) { return futrts_copysign32((float)x, y); }
SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) { return a * b + c; }
SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) { return fmaf(a, b, c); }

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t fptobits_f16_i16(f16 x) { return __half_as_ushort(x); }
SCALAR_FUN_ATTR f16 bitstofp_i16_f16(int16_t x) { return __ushort_as_half(x); }
#elif defined(ISPC)
SCALAR_FUN_ATTR int16_t fptobits_f16_i16(f16 x) { varying int16_t y = *((varying int16_t * uniform)&x); return y;
}
SCALAR_FUN_ATTR f16 bitstofp_i16_f16(int16_t x) { varying f16 y = *((varying f16 * uniform)&x); return y; }
#else
SCALAR_FUN_ATTR int16_t fptobits_f16_i16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 bitstofp_i16_f16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) { return fabs32(x); }
SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) { return fmax32(x, y); }
SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) { return fmin32(x, y); }
SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) { return fpow32(x, y); }
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) { return futrts_isnan32(x); }
SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) { return futrts_isinf32(x); }
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) { return futrts_log32(x); }
SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) { return futrts_log2_32(x); }
SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) { return futrts_log10_32(x); }
SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) { return futrts_log1p_32(x); }
SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) { return futrts_sqrt32(x); }
SCALAR_FUN_ATTR f16 futrts_rsqrt16(f16 x) { return futrts_rsqrt32(x); }
SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) { return futrts_cbrt32(x); }
SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) { return futrts_exp32(x); }
SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) { return futrts_cos32(x); }
SCALAR_FUN_ATTR f16 futrts_cospi16(f16 x) { return futrts_cospi32(x); }
SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) { return futrts_sin32(x); }
SCALAR_FUN_ATTR f16 futrts_sinpi16(f16 x) { return futrts_sinpi32(x); }
SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) { return futrts_tan32(x); }
SCALAR_FUN_ATTR f16 futrts_tanpi16(f16 x) { return futrts_tanpi32(x); }
SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) { return futrts_acos32(x); }
SCALAR_FUN_ATTR f16 futrts_acospi16(f16 x) { return futrts_acospi32(x); }
SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) { return futrts_asin32(x); }
SCALAR_FUN_ATTR f16 futrts_asinpi16(f16 x) { return futrts_asinpi32(x); }
SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) { return futrts_atan32(x); }
SCALAR_FUN_ATTR f16 futrts_atanpi16(f16 x) { return futrts_atanpi32(x); }
SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) { return futrts_cosh32(x); }
SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) { return futrts_sinh32(x); }
SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) { return futrts_tanh32(x); }
SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) { return futrts_acosh32(x); }
SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) { return futrts_asinh32(x); }
SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) { return futrts_atanh32(x); }
SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) { return futrts_atan2_32(x, y); }
SCALAR_FUN_ATTR f16 futrts_atan2pi_16(f16 x, f16 y) { return futrts_atan2pi_32(x, y); }
SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) { return futrts_hypot32(x, y); }
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) { return futrts_gamma32(x); }
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) { return futrts_lgamma32(x); }
SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) { return futrts_erf32(x); }
SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) { return futrts_erfc32(x); }
SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) { return fmod32(x, y); }
SCALAR_FUN_ATTR f16 futrts_round16(f16 x) { return futrts_round32(x); }
SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) { return futrts_floor32(x); }
SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) { return futrts_ceil32(x); }
SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) { return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y))); }
SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) { return futrts_lerp32(v0, v1, t); }
SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) { return futrts_ldexp32(x, y); }
SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) { return futrts_copysign32((float)x, y); }
SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) { return futrts_mad32(a, b, c); }
SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) { return futrts_fma32(a, b, c); }

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t fptobits_f16_i16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 bitstofp_i16_f16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else
SCALAR_FUN_ATTR int16_t fptobits_f16_i16(f16 x) { return (int16_t)float2halfbits(x); }
SCALAR_FUN_ATTR f16 bitstofp_i16_f16(int16_t x) { return halfbits2float((uint16_t)x); }
SCALAR_FUN_ATTR f16 fsignum16(f16 x) { return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0); }

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) { return x; }
SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) { return x; }
SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) { return (f16) x; }

#ifdef FUTHARK_F64_ENABLED
SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) { return (double) x; }
#if defined(ISPC)
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) { return (f16) ((float)x); }
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) { return (f16) x; }
#endif
#endif

// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Log that a copy has occurred. The provenance may be NULL, if we do not know
// where this came from.
static void log_copy(struct futhark_context* ctx,
                     const char *kind, const char *provenance,
                     int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]);

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t m, int64_t n);

static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]);

static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]);

static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]);

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      const char* provenance,
                      struct kvs *kvs,
                      void* data,
                      event_report_fn f);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    cl_mem mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device counters_mem_23456;
    struct memblock_device counters_mem_23560;
    struct memblock_device counters_mem_23724;
    struct memblock_device counters_mem_23821;
    struct memblock_device counters_mem_24078;
    struct memblock_device counters_mem_24172;
};
struct tuning_params {
    int dummy;
    int64_t *builtinzhreplicate_i32zitblock_sizze_23467;
    int64_t *builtinzhreplicate_i8zitblock_sizze_23529;
    int64_t *mainzisegmap_num_tblocks_21520;
    int64_t *mainzisegmap_num_tblocks_21553;
    int64_t *mainzisegmap_num_tblocks_21578;
    int64_t *mainzisegmap_num_tblocks_21915;
    int64_t *mainzisegmap_num_tblocks_21968;
    int64_t *mainzisegmap_num_tblocks_21993;
    int64_t *mainzisegmap_num_tblocks_22026;
    int64_t *mainzisegmap_num_tblocks_22057;
    int64_t *mainzisegmap_num_tblocks_22092;
    int64_t *mainzisegmap_num_tblocks_22413;
    int64_t *mainzisegmap_num_tblocks_22440;
    int64_t *mainzisegmap_num_tblocks_22484;
    int64_t *mainzisegmap_num_tblocks_22511;
    int64_t *mainzisegmap_num_tblocks_22557;
    int64_t *mainzisegmap_num_tblocks_22584;
    int64_t *mainzisegmap_num_tblocks_22642;
    int64_t *mainzisegmap_tblock_sizze_21421;
    int64_t *mainzisegmap_tblock_sizze_21518;
    int64_t *mainzisegmap_tblock_sizze_21551;
    int64_t *mainzisegmap_tblock_sizze_21576;
    int64_t *mainzisegmap_tblock_sizze_21732;
    int64_t *mainzisegmap_tblock_sizze_21806;
    int64_t *mainzisegmap_tblock_sizze_21913;
    int64_t *mainzisegmap_tblock_sizze_21940;
    int64_t *mainzisegmap_tblock_sizze_21966;
    int64_t *mainzisegmap_tblock_sizze_21991;
    int64_t *mainzisegmap_tblock_sizze_22024;
    int64_t *mainzisegmap_tblock_sizze_22055;
    int64_t *mainzisegmap_tblock_sizze_22090;
    int64_t *mainzisegmap_tblock_sizze_22235;
    int64_t *mainzisegmap_tblock_sizze_22309;
    int64_t *mainzisegmap_tblock_sizze_22411;
    int64_t *mainzisegmap_tblock_sizze_22438;
    int64_t *mainzisegmap_tblock_sizze_22482;
    int64_t *mainzisegmap_tblock_sizze_22509;
    int64_t *mainzisegmap_tblock_sizze_22555;
    int64_t *mainzisegmap_tblock_sizze_22582;
    int64_t *mainzisegmap_tblock_sizze_22640;
    int64_t *mainzisegred_num_tblocks_21400;
    int64_t *mainzisegred_num_tblocks_21499;
    int64_t *mainzisegred_num_tblocks_21753;
    int64_t *mainzisegred_num_tblocks_22256;
    int64_t *mainzisegred_num_tblocks_23368;
    int64_t *mainzisegred_num_tblocks_23414;
    int64_t *mainzisegred_tblock_sizze_21398;
    int64_t *mainzisegred_tblock_sizze_21497;
    int64_t *mainzisegred_tblock_sizze_21751;
    int64_t *mainzisegred_tblock_sizze_22254;
    int64_t *mainzisegred_tblock_sizze_23370;
    int64_t *mainzisegred_tblock_sizze_23416;
    int64_t *mainzisegscan_num_tblocks_21510;
    int64_t *mainzisegscan_num_tblocks_22047;
    int64_t *mainzisegscan_tblock_sizze_21508;
    int64_t *mainzisegscan_tblock_sizze_22045;
    int64_t *mainzisuff_outer_par_0;
    int64_t *mainzisuff_outer_par_1;
    int64_t *mainzitblock_sizze_23872;
    int64_t *mainzitblock_sizze_23892;
    int64_t *mainzitblock_sizze_23912;
    int64_t *mainzitblock_sizze_24223;
};
static const int num_tuning_params = 62;
static const char *tuning_param_names[] = {"builtin#replicate_i32.tblock_size_23467", "builtin#replicate_i8.tblock_size_23529", "main.segmap_num_tblocks_21520", "main.segmap_num_tblocks_21553", "main.segmap_num_tblocks_21578", "main.segmap_num_tblocks_21915", "main.segmap_num_tblocks_21968", "main.segmap_num_tblocks_21993", "main.segmap_num_tblocks_22026", "main.segmap_num_tblocks_22057", "main.segmap_num_tblocks_22092", "main.segmap_num_tblocks_22413", "main.segmap_num_tblocks_22440", "main.segmap_num_tblocks_22484", "main.segmap_num_tblocks_22511", "main.segmap_num_tblocks_22557", "main.segmap_num_tblocks_22584", "main.segmap_num_tblocks_22642", "main.segmap_tblock_size_21421", "main.segmap_tblock_size_21518", "main.segmap_tblock_size_21551", "main.segmap_tblock_size_21576", "main.segmap_tblock_size_21732", "main.segmap_tblock_size_21806", "main.segmap_tblock_size_21913", "main.segmap_tblock_size_21940", "main.segmap_tblock_size_21966", "main.segmap_tblock_size_21991", "main.segmap_tblock_size_22024", "main.segmap_tblock_size_22055", "main.segmap_tblock_size_22090", "main.segmap_tblock_size_22235", "main.segmap_tblock_size_22309", "main.segmap_tblock_size_22411", "main.segmap_tblock_size_22438", "main.segmap_tblock_size_22482", "main.segmap_tblock_size_22509", "main.segmap_tblock_size_22555", "main.segmap_tblock_size_22582", "main.segmap_tblock_size_22640", "main.segred_num_tblocks_21400", "main.segred_num_tblocks_21499", "main.segred_num_tblocks_21753", "main.segred_num_tblocks_22256", "main.segred_num_tblocks_23368", "main.segred_num_tblocks_23414", "main.segred_tblock_size_21398", "main.segred_tblock_size_21497", "main.segred_tblock_size_21751", "main.segred_tblock_size_22254", "main.segred_tblock_size_23370", "main.segred_tblock_size_23416", "main.segscan_num_tblocks_21510", "main.segscan_num_tblocks_22047", "main.segscan_tblock_size_21508", "main.segscan_tblock_size_22045", "main.suff_outer_par_0", "main.suff_outer_par_1", "main.tblock_size_23872", "main.tblock_size_23892", "main.tblock_size_23912", "main.tblock_size_24223", NULL};
static const char *tuning_param_vars[] = {"builtinzhreplicate_i32zitblock_sizze_23467", "builtinzhreplicate_i8zitblock_sizze_23529", "mainzisegmap_num_tblocks_21520", "mainzisegmap_num_tblocks_21553", "mainzisegmap_num_tblocks_21578", "mainzisegmap_num_tblocks_21915", "mainzisegmap_num_tblocks_21968", "mainzisegmap_num_tblocks_21993", "mainzisegmap_num_tblocks_22026", "mainzisegmap_num_tblocks_22057", "mainzisegmap_num_tblocks_22092", "mainzisegmap_num_tblocks_22413", "mainzisegmap_num_tblocks_22440", "mainzisegmap_num_tblocks_22484", "mainzisegmap_num_tblocks_22511", "mainzisegmap_num_tblocks_22557", "mainzisegmap_num_tblocks_22584", "mainzisegmap_num_tblocks_22642", "mainzisegmap_tblock_sizze_21421", "mainzisegmap_tblock_sizze_21518", "mainzisegmap_tblock_sizze_21551", "mainzisegmap_tblock_sizze_21576", "mainzisegmap_tblock_sizze_21732", "mainzisegmap_tblock_sizze_21806", "mainzisegmap_tblock_sizze_21913", "mainzisegmap_tblock_sizze_21940", "mainzisegmap_tblock_sizze_21966", "mainzisegmap_tblock_sizze_21991", "mainzisegmap_tblock_sizze_22024", "mainzisegmap_tblock_sizze_22055", "mainzisegmap_tblock_sizze_22090", "mainzisegmap_tblock_sizze_22235", "mainzisegmap_tblock_sizze_22309", "mainzisegmap_tblock_sizze_22411", "mainzisegmap_tblock_sizze_22438", "mainzisegmap_tblock_sizze_22482", "mainzisegmap_tblock_sizze_22509", "mainzisegmap_tblock_sizze_22555", "mainzisegmap_tblock_sizze_22582", "mainzisegmap_tblock_sizze_22640", "mainzisegred_num_tblocks_21400", "mainzisegred_num_tblocks_21499", "mainzisegred_num_tblocks_21753", "mainzisegred_num_tblocks_22256", "mainzisegred_num_tblocks_23368", "mainzisegred_num_tblocks_23414", "mainzisegred_tblock_sizze_21398", "mainzisegred_tblock_sizze_21497", "mainzisegred_tblock_sizze_21751", "mainzisegred_tblock_sizze_22254", "mainzisegred_tblock_sizze_23370", "mainzisegred_tblock_sizze_23416", "mainzisegscan_num_tblocks_21510", "mainzisegscan_num_tblocks_22047", "mainzisegscan_tblock_sizze_21508", "mainzisegscan_tblock_sizze_22045", "mainzisuff_outer_par_0", "mainzisuff_outer_par_1", "mainzitblock_sizze_23872", "mainzitblock_sizze_23892", "mainzitblock_sizze_23912", "mainzitblock_sizze_24223", NULL};
static const char *tuning_param_classes[] = {"thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(def, )", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", NULL};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static const int max_failure_args = 2;
static const int f64_required = 0;
static const char *gpu_program[] = {"#define FUTHARK_OPENCL\n// Start of prelude.cl\n\n#define SCALAR_FUN_ATTR static inline\n#define FUTHARK_FUN_ATTR static\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long int64_t;\n\ntypedef uchar uint8_t;\ntypedef ushort uint16_t;\ntypedef uint uint32_t;\ntypedef ulong uint64_t;\n\n#define get_tblock_id(d) get_group_id(d)\n#define get_num_tblocks(d) get_num_groups(d)\n\n// Clang-based OpenCL implementations need this for 'static' to work.\n#ifdef cl_clang_storage_class_specifiers\n#pragma OPENCL EXTENSION cl_clang_storage_class_specifiers : enable\n#endif\n#pragma OPENCL EXTENSION cl_khr_byte_addressable_store : enable\n\n#ifdef FUTHARK_F64_ENABLED\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#endif\n\n#pragma OPENCL EXTENSION cl_khr_int64_base_atomics : enable\n#pragma OPENCL EXTENSION cl_khr_int64_extended_atomics : enable\n\n// NVIDIAs OpenCL does not create device-wide memory fences (see #734), so we\n// use inline assembly if we detect we are on an NVIDIA GPU.\n#ifdef cl_nv_pragma_unroll\nstatic inline void mem_fence_global() {\n  asm(\"membar.gl;\");\n}\n#else\nstatic inline void mem_fence_global() {\n  mem_fence(CLK_LOCAL_MEM_FENCE | CLK_GLOBAL_MEM_FENCE);\n}\n#endif\nstatic inline void mem_fence_local() {\n  mem_fence(CLK_LOCAL_MEM_FENCE);\n}\n\nstatic inline void barrier_local() {\n  barrier(CLK_LOCAL_MEM_FENCE);\n}\n\n// Important for this to be int64_t so it has proper alignment for any type.\n#define SHARED_MEM_PARAM __local uint64_t* shared_mem,\n#define FUTHARK_KERNEL __kernel\n#define FUTHARK_KERNEL_SIZED(a,b,c) __attribute__((reqd_work_group_size(a, b, c))) __kernel\n\n// End of prelude.cl\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation th", "e rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x", "4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C",
                                    "00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, ", "24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x3660000", "0, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D000",
                                    "0, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10", "000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C", "000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330",
                                    "000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385", "C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x380", "2C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x381",
                                    "76000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x3", "82C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3", "840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x3",
                                    "8554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3", "869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0", "x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nSCALAR_FUN_ATTR uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nSCALAR_FUN_ATTR float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nSCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs =",
                                    " to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n// Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\n#ifndef M_PI\n#define M_PI 3.141592653589793\n#endif\n\nSCALAR_FUN_ATTR int32_t fptobits_f32_i32(float x);\nSCALAR_FUN_ATTR float bitstofp_i32_f32(int32_t x);\n\nSCALAR_FUN_ATTR uint8_t   add8(uint8_t x, uint8_t y)   { return x + y; }\nSCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) { return x + y; }\nSCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) { return x + y; }\nSCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) { return x + y; }\n\nSCALAR_FUN_ATTR uint8_t   sub8(uint8_t x, uint8_t y)   { return x - y; }\nSCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) { return x - y; }\nSCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) { return x - y; }\nSCALAR_FUN_ATTR uint64_t sub64(", "uint64_t x, uint64_t y) { return x - y; }\n\nSCALAR_FUN_ATTR uint8_t   mul8(uint8_t x, uint8_t y)   { return x * y; }\nSCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) { return x * y; }\nSCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) { return x * y; }\nSCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) { return x * y; }\n\n#if defined(ISPC)\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t", " x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == ",
                                    "0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  int8_t q = x / ys;\n  int8_t r = x % ys;\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i) { ys = y; }\n  int16_t q = x / ys;\n  int16_t r = x % ys;\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i) { ys = y; }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i) { ys = y; }\n  int64_t q = x / ys;\n  int64_t r = x % ys;\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) { return sdiv8(x + y - 1, y); }\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) { return sdiv16(x + y - 1, y); }\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) { return sdiv32(x + y - 1, y); }\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) { return sdiv64(x + y - 1, y); }\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  int8_t r = x % ys;\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i) { ys = y; }\n  int16_t r = x % ys;\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i) { ys = y; }\n  int32_t r = x % ys;\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i) { ys = y; }\n  int64_t r = x % ys;\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t   s", "div_safe8(int8_t x, int8_t y)   { return y == 0 ? 0 : sdiv8(x, y); }\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) { return y == 0 ? 0 : sdiv16(x, y); }\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) { return y == 0 ? 0 : sdiv32(x, y); }\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) { return y == 0 ? 0 : sdiv64(x, y); }\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y)     { return sdiv_safe8(x + y - 1, y); }\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) { return sdiv_safe16(x + y - 1, y); }\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) { return sdiv_safe32(x + y - 1, y); }\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) { return sdiv_safe64(x + y - 1, y); }\n\nSCALAR_FUN_ATTR int8_t   smod_safe8(int8_t x, int8_t y)   { return y == 0 ? 0 : smod8(x, y); }\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) { return y == 0 ? 0 : smod16(x, y); }\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) { return y == 0 ? 0 : smod32(x, y); }\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) { return y == 0 ? 0 : smod64(x, y); }\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x % ", "ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i) { ys = y; }\n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nSCALAR_FUN_ATTR uint8_t   udiv8(uint8_t x, uint8_t y)   { return x / y; }\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) { return x / y; }\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) { return x / y; }\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) { return x / y; }\n\nSCALAR_FUN_ATTR uint8_t   udiv_up8(uint8_t x, uint8_t y)   { return (x + y - 1) / y; }\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) { return (x + y - 1) / y; }\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) { return (x + y - 1) / y; }\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) { return (x + y - 1) / y; }\n\nSCALAR_FUN_ATTR uint8_t   umod8(uint8_t x, uint8_t y)   { return x % y; }\nSCAL",
                                    "AR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) { return x % y; }\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) { return x % y; }\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) { return x % y; }\n\nSCALAR_FUN_ATTR uint8_t   udiv_safe8(uint8_t x, uint8_t y)   { return y == 0 ? 0 : x / y; }\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) { return y == 0 ? 0 : x / y; }\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) { return y == 0 ? 0 : x / y; }\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) { return y == 0 ? 0 : x / y; }\n\nSCALAR_FUN_ATTR uint8_t   udiv_up_safe8(uint8_t x, uint8_t y)   { return y == 0 ? 0 : (x + y - 1) / y; }\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) { return y == 0 ? 0 : (x + y - 1) / y; }\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) { return y == 0 ? 0 : (x + y - 1) / y; }\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) { return y == 0 ? 0 : (x + y - 1) / y; }\n\nSCALAR_FUN_ATTR uint8_t   umod_safe8(uint8_t x, uint8_t y)   { return y == 0 ? 0 : x % y; }\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) { return y == 0 ? 0 : x % y; }\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) { return y == 0 ? 0 : x % y; }\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) { return y == 0 ? 0 : x % y; }\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t  ", " sdiv_up8(int8_t x, int8_t y)   { return sdiv8(x + y - 1, y); }\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) { return sdiv16(x + y - 1, y); }\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) { return sdiv32(x + y - 1, y); }\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) { return sdiv64(x + y - 1, y); }\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = x % y;\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t   sdiv_safe8(int8_t x, int8_t y)   { return y == 0 ? 0 : sdiv8(x, y); }\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) { return y == 0 ? 0 : sdiv16(x, y); }\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) { return y == 0 ? 0 : sdiv32(x, y); }\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) { return y == 0 ? 0 : sdiv64(x, y); }\n\nSCALAR_FUN_ATTR int8_t   sdiv_up_safe8(int8_t x, int8_t y)   { return sdiv_safe8(x + y - 1, y);}\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) { return sdiv_safe16(x + y - 1, y); }\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) { return sdiv_safe32(x + y - 1, y); }\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) { return sdiv_safe64(x + y - 1, y); }\n\nSCALAR_FUN_ATTR int8_t   smod_safe8(int8_t x, int8_t y)   { return y == 0 ? 0 : smod8(x, y); }\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) { return y == 0 ? 0 : smod16(x, y); }\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) { return y == 0 ? 0 : smod32(x, y); }\nSCALAR_", "FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) { return y == 0 ? 0 : smod64(x, y); }\n\nSCALAR_FUN_ATTR int8_t   squot8(int8_t x, int8_t y)   { return x / y; }\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) { return x / y; }\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) { return x / y; }\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) { return x / y; }\n\nSCALAR_FUN_ATTR int8_t   srem8(int8_t x, int8_t y)   { return x % y; }\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) { return x % y; }\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) { return x % y; }\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) { return x % y; }\n\nSCALAR_FUN_ATTR int8_t   squot_safe8(int8_t x, int8_t y)   { return y == 0 ? 0 : x / y; }\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) { return y == 0 ? 0 : x / y; }\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) { return y == 0 ? 0 : x / y; }\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) { return y == 0 ? 0 : x / y; }\n\nSCALAR_FUN_ATTR int8_t   srem_safe8(int8_t x, int8_t y)   { return y == 0 ? 0 : x % y; }\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) { return y == 0 ? 0 : x % y; }\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) { return y == 0 ? 0 : x % y; }\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) { return y == 0 ? 0 : x % y; }\n\n#endif\n\nSCALAR_FUN_ATTR int8_t   smin8(int8_t x, int8_t y)   { return x < y ? x : y; }\nSCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) { return x < y ? x : y; }\nSCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) { return x < y ? x : y; }\nSCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) { return x < y ? x : y; }\n\nSCALAR_FUN_ATTR uint8_t   umin8(uint8_t x, uint8_t y)   { return x < y ? x : y; }\nSCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) { return x < y ? x : y; }\nSCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) { return x < y ? x : y; }\nSCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uin",
                                    "t64_t y) { return x < y ? x : y; }\n\nSCALAR_FUN_ATTR int8_t  smax8(int8_t x, int8_t y)    { return x < y ? y : x; }\nSCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) { return x < y ? y : x; }\nSCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) { return x < y ? y : x; }\nSCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) { return x < y ? y : x; }\n\nSCALAR_FUN_ATTR uint8_t   umax8(uint8_t x, uint8_t y)   { return x < y ? y : x; }\nSCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) { return x < y ? y : x; }\nSCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) { return x < y ? y : x; }\nSCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) { return x < y ? y : x; }\n\nSCALAR_FUN_ATTR uint8_t   shl8(uint8_t x, uint8_t y)   { return (uint8_t)(x << y); }\nSCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) { return (uint16_t)(x << y); }\nSCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) { return x << y; }\nSCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) { return x << y; }\n\nSCALAR_FUN_ATTR uint8_t   lshr8(uint8_t x, uint8_t y)   { return x >> y; }\nSCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) { return x >> y; }\nSCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) { return x >> y; }\nSCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) { return x >> y; }\n\nSCALAR_FUN_ATTR int8_t   ashr8(int8_t x, int8_t y)   { return x >> y; }\nSCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) { return x >> y; }\nSCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) { return x >> y; }\nSCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) { return x >> y; }\n\nSCALAR_FUN_ATTR uint8_t   and8(uint8_t x, uint8_t y)   { return x & y; }\nSCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) { return x & y; }\nSCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) { return x & y; }\nSCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) { return x & y; }\n\nSCALAR_FUN_ATTR uint8_t    or8(uint8_t x, uint8_t y)  { return x | y; }\nSCALAR_FUN_ATTR uint16_t or16(uint16_t x, u", "int16_t y) { return x | y; }\nSCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) { return x | y; }\nSCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) { return x | y; }\n\nSCALAR_FUN_ATTR uint8_t   xor8(uint8_t x, uint8_t y)   { return x ^ y; }\nSCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) { return x ^ y; }\nSCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) { return x ^ y; }\nSCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) { return x ^ y; }\n\nSCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y)    { return x < y; }\nSCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) { return x < y; }\nSCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) { return x < y; }\nSCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) { return x < y; }\n\nSCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y)    { return x <= y; }\nSCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) { return x <= y; }\nSCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) { return x <= y; }\nSCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) { return x <= y; }\n\nSCALAR_FUN_ATTR bool  slt8(int8_t x, int8_t y)   { return x < y; }\nSCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) { return x < y; }\nSCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) { return x < y; }\nSCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) { return x < y; }\n\nSCALAR_FUN_ATTR bool  sle8(int8_t x, int8_t y)   { return x <= y; }\nSCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) { return x <= y; }\nSCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) { return x <= y; }\nSCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) { return x <= y; }\n\nSCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {\n  uin", "t32_t res = 1, rem = y;\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR bool  itob_i8_bool(int8_t x)  { return x != 0; }\nSCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) { return x != 0; }\nSCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) { return x != 0; }\nSCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) { return x != 0; }\n\nSCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x)   { return x; }\nSCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) { return x; }\nSCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) { return x; }\nSCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) { return x; }\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#def",
                                    "ine zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nSCALAR_FUN_ATTR int8_t   abs8(int8_t x)  { return (int8_t)abs(x); }\nSCALAR_FUN_ATTR int16_t abs16(int16_t x) { return (int16_t)abs(x); }\nSCALAR_FUN_ATTR int32_t abs32(int32_t x) { return abs(x); }\nSCALAR_FUN_ATTR int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VERSION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\n\nSCALAR_FUN_ATTR int32_t  futrts_popc8(int8_t x)  { return popcount(x); }\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) { return popcount(x); }\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) { return popcount(x); }\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) { return popcount(x); }\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t  futrts_popc8(int8_t x)  { return __popc(zext_i8_i32(x)); }\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) { return __popc(zext_i16_i32(x)); }\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) { return __popc(x); }\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) { return __popcll(x); }\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  u", "int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nSCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nSCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif defined(ISPC)\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh", " = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nSCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }\nSCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a)",
                                    " * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64", "_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t  futrts_clzz8(int8_t x)  { return clz(x); }\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) { return clz(x); }\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) { return clz(x); }\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) { return clz(x); }\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t  futrts_clzz8(int8_t x)  { return __clz(zext_i8_i32(x)) - 24; }\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) { return __clz(zext_i16_i32(x)) - 16; }\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) { return __clz(x); }\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) { return __clzll(x); }\n\n#elif defined(ISPC)\n\nSCALAR_FUN_ATTR int32_t  futrts_clzz8(int8_t x)  { return count_leading_zeros((int32_t)(uint8_t)x)-24; }\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) { return count_leading_zeros((int32_t)(uint16_t)x)-16; }\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) { return count_leading_zeros(x); }\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) { return count_leading_zeros(x); }\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x)\n{ return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24; }\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x)\n{ return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16; }\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x)\n{ return x == 0 ? 32 : __builtin_clz((uint32_t)x); }\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x)\n{ return x == 0 ? 64 : __builtin_clzll((uint64_t)x); }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1) ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1) ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && ", "(x & 1) == 0; i++, x >>= 1) ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1) ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1;\n}\n\n#elif defined(ISPC)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) { return x == 0 ? 8 : count_trailing_zeros((int32_t)x); }\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) { return x == 0 ? 16 : count_trailing_zeros((int32_t)x); }\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) { return count_trailing_zeros(x); }\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) { return count_trailing_zeros(x); }\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t  futrts_ctzz8(int8_t x)  { return x == 0 ? 8 : __builtin_ctz((uint32_t)x); }\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) { return x == 0 ? 16 : __builtin_ctz((uint32_t)x); }\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) { return x == 0 ? 32 : __builtin_ctz((uint32_t)x); }\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) { return x == 0 ? 64 : __builtin_ctzll((uint64_t)x); }\n#endif\n\nSCALAR_FUN_ATTR float fdiv32(float x, float y) { return x / y; }\nSCALAR_FUN_ATTR float fadd32(float x, float y) { return x + y; }\nSCALAR_FUN_ATTR float fsub32(float x, float y) { return x - y; }\nSCALAR_FUN_ATTR float fmul32(float x, float y) { return x * y; }\nSCALAR_FUN_ATTR bool cmplt32(float x, float y) { return x < y; }\nSCALAR_FUN_ATTR bool cmple32(float x, float y) { return x <= y; }\nSCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x)  { return (float) x; }\n\nSCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) { return",
                                    " (float) x; }\nSCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) { return (float) x; }\nSCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) { return (float) x; }\nSCALAR_FUN_ATTR float  uitofp_i8_f32(uint8_t x)  { return (float) x; }\nSCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) { return (float) x; }\nSCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) { return (float) x; }\nSCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) { return (float) x; }\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float fabs32(float x)          { return fabs(x); }\nSCALAR_FUN_ATTR float fmax32(float x, float y) { return fmax(x, y); }\nSCALAR_FUN_ATTR float fmin32(float x, float y) { return fmin(x, y); }\nSCALAR_FUN_ATTR float fpow32(float x, float y) { return pow(x, y); }\n\n#elif defined(ISPC)\n\nSCALAR_FUN_ATTR float fabs32(float x) { return abs(x); }\nSCALAR_FUN_ATTR float fmax32(float x, float y) { return isnan(x) ? y : isnan(y) ? x : max(x, y); }\nSCALAR_FUN_ATTR float fmin32(float x, float y) { return isnan(x) ? y : isnan(y) ? x : min(x, y); }\nSCALAR_FUN_ATTR float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = pow(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float fabs32(float x)          { return fabsf(x); }\nSCALAR_FUN_ATTR float fmax32(float x, float y) { return fmaxf(x, y); }\nSCALAR_FUN_ATTR float fmin32(float x, float y) { return fminf(x, y); }\nSCALAR_FUN_ATTR float fpow32(float x, float y) { return powf(x, y); }\n#endif\n\nSCALAR_FUN_ATTR bool futrts_isnan32(float x) { return isnan(x); }\n\n#if defined(ISPC)\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) { return !isnan(x) && isnan(x - x); }\n\nSCALAR_FUN_ATTR bool futrts_isfinite32(float x) { return !isnan(x) && !futrts_isinf32(x); }\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) { return isinf(x); }\n\n#endif\n\nSCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n", "  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  };\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f32_bool(float x) { return x != 0; }\nSCALAR_FUN_ATTR float btof_bool_f32(bool x) { return x ? 1 : 0; }\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float futrts_log32(float x) { return log(x); }\nSCALAR_FUN_ATTR float futrts_log2_32(float x) { return log2(x); }\nSCALAR_FUN_ATTR float futrts_log10_32(float x) { return log10(x); }\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) { return log1p(x); }\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) { return sqrt(x); }\nSCALAR_FUN_ATTR float futrts_rsqrt32(float x) { return rsqrt(x); }\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) { return cbrt(x); }\nSCALAR_FUN_ATTR float futrts_exp32(float x) { return exp(x); }\nSCALAR_FUN_ATTR float futrts_cos32(float x) { return cos(x); }\nSCALAR_FUN_ATTR float futrts_cospi32(float x) { return cospi(x); }\nSCALAR_FUN_ATTR float fut", "rts_sin32(float x) { return sin(x); }\nSCALAR_FUN_ATTR float futrts_sinpi32(float x) { return sinpi(x); }\nSCALAR_FUN_ATTR float futrts_tan32(float x) { return tan(x); }\nSCALAR_FUN_ATTR float futrts_tanpi32(float x) { return tanpi(x); }\nSCALAR_FUN_ATTR float futrts_acos32(float x) { return acos(x); }\nSCALAR_FUN_ATTR float futrts_acospi32(float x) { return acospi(x); }\nSCALAR_FUN_ATTR float futrts_asin32(float x) { return asin(x); }\nSCALAR_FUN_ATTR float futrts_asinpi32(float x) { return asinpi(x); }\nSCALAR_FUN_ATTR float futrts_atan32(float x) { return atan(x); }\nSCALAR_FUN_ATTR float futrts_atanpi32(float x) { return atanpi(x); }\nSCALAR_FUN_ATTR float futrts_cosh32(float x) { return cosh(x); }\nSCALAR_FUN_ATTR float futrts_sinh32(float x) { return sinh(x); }\nSCALAR_FUN_ATTR float futrts_tanh32(float x) { return tanh(x); }\nSCALAR_FUN_ATTR float futrts_acosh32(float x) { return acosh(x); }\nSCALAR_FUN_ATTR float futrts_asinh32(float x) { return asinh(x); }\nSCALAR_FUN_ATTR float futrts_atanh32(float x) { return atanh(x); }\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) { return atan2(x, y); }\nSCALAR_FUN_ATTR float futrts_atan2pi_32(float x, float y) { return atan2pi(x, y); }\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) { return hypot(x, y); }\nSCALAR_FUN_ATTR float futrts_gamma32(float x) { return tgamma(x); }\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) { return lgamma(x); }\nSCALAR_FUN_ATTR float futrts_erf32(float x) { return erf(x); }\nSCALAR_FUN_ATTR float futrts_erfc32(float x) { return erfc(x); }\nSCALAR_FUN_ATTR float fmod32(float x, float y) { return fmod(x, y); }\nSCALAR_FUN_ATTR float futrts_round32(float x) { return rint(x); }\nSCALAR_FUN_ATTR float futrts_floor32(float x) { return floor(x); }\nSCALAR_FUN_ATTR float futrts_ceil32(float x) { return ceil(x); }\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) { return nextafter(x, y); }\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) { return mix(v0, v1, t); }\nSCALAR_FUN_A",
                                    "TTR float futrts_ldexp32(float x, int32_t y) { return ldexp(x, y); }\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) { return copysign(x, y); }\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) { return mad(a, b, c); }\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) { return fma(a, b, c); }\n\n#elif defined(ISPC)\n\nSCALAR_FUN_ATTR float futrts_log32(float x) { return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x; }\nSCALAR_FUN_ATTR float futrts_log2_32(float x) { return futrts_log32(x) / log(2.0f); }\nSCALAR_FUN_ATTR float futrts_log10_32(float x) { return futrts_log32(x) / log(10.0f); }\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) { return sqrt(x); }\nSCALAR_FUN_ATTR float futrts_rsqrt32(float x) { return 1/sqrt(x); }\n\nextern \"C\" unmasked uniform float cbrtf(uniform float);\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) { return exp(x); }\nSCALAR_FUN_ATTR float futrts_cos32(float x) { return cos(x); }\nSCALAR_FUN_ATTR float futrts_cospi32(float x) { return cos((float)M_PI*x); }\nSCALAR_FUN_ATTR float futrts_sin32(float x) { return sin(x); }\nSCALAR_FUN_ATTR float futrts_sinpi32(float x) { return sin(M_PI*x); }\nSCALAR_FUN_ATTR float futrts_tan32(float x) { return tan(x); }\nSCALAR_FUN_ATTR float futrts_tanpi32(float x) { return tan((float)M_PI*x); }\nSCALAR_FUN_ATTR float futrts_acos32(float x) { return acos(x); }\nSCALAR_FUN_ATTR float futrts_acospi32(float x) { return acos(x)/(float)M_PI; }\nSCALAR_FUN_ATTR float futrts_asin32(float x) { return asin(x); }\nSCALAR_FUN_ATTR float futrts_asinpi32(float x) { return asin(x)/(float)M_PI; }\nSCALAR_FUN_ATTR float futrts_at", "an32(float x) { return atan(x); }\nSCALAR_FUN_ATTR float futrts_atanpi32(float x) { return atan(x)/(float)M_PI; }\nSCALAR_FUN_ATTR float futrts_cosh32(float x) { return (exp(x)+exp(-x)) / 2.0f; }\nSCALAR_FUN_ATTR float futrts_sinh32(float x) { return (exp(x)-exp(-x)) / 2.0f; }\nSCALAR_FUN_ATTR float futrts_tanh32(float x) { return futrts_sinh32(x)/futrts_cosh32(x); }\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if (futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if (futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if (futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y)\n{ return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y); }\nSCALAR_FUN_ATTR float futrts_atan2pi_32(float x, float y)\n{ return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y) / (float)M_PI; }\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;\n    else return x + y;\n  }\n\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgamm", "af(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) { return x - y * trunc(x/y); }\nSCALAR_FUN_ATTR float futrts_round32(float x) { return round(x); }\nSCALAR_FUN_ATTR float futrts_floor32(float x) { return floor(x); }\nSCALAR_FUN_ATTR float futrts_ceil32(float x) { return ceil(x); }\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return x * pow((uniform float)2.0, (float)y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  int32_t xb = fptobits_f32_i32(x);\n  int32_t yb = fptobits_f32_i32(y);\n  return bitstofp_i32_f32((xb & ~(1<<31)) | (yb & (1<<31)));\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float futrts_log32(float x) { return logf(x); }\nSCALAR_FUN_ATTR float futrts_log2_32(float x) { return log2f(x); }\nSCALAR_FUN_ATTR float futrts_log10_32(float x) { return log10f(x); }\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) { return log1pf(x)",
                                    "; }\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) { return sqrtf(x); }\nSCALAR_FUN_ATTR float futrts_rsqrt32(float x) { return 1/sqrtf(x); }\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) { return cbrtf(x); }\nSCALAR_FUN_ATTR float futrts_exp32(float x) { return expf(x); }\nSCALAR_FUN_ATTR float futrts_cos32(float x) { return cosf(x); }\n\nSCALAR_FUN_ATTR float futrts_cospi32(float x) {\n#if defined(__CUDA_ARCH__)\n  return cospif(x);\n#else\n  return cosf(((float)M_PI)*x);\n#endif\n}\nSCALAR_FUN_ATTR float futrts_sin32(float x) { return sinf(x); }\n\nSCALAR_FUN_ATTR float futrts_sinpi32(float x) {\n#if defined(__CUDA_ARCH__)\n  return sinpif(x);\n#else\n  return sinf((float)M_PI*x);\n#endif\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) { return tanf(x); }\nSCALAR_FUN_ATTR float futrts_tanpi32(float x) { return tanf((float)M_PI*x); }\nSCALAR_FUN_ATTR float futrts_acos32(float x) { return acosf(x); }\nSCALAR_FUN_ATTR float futrts_acospi32(float x) { return acosf(x)/(float)M_PI; }\nSCALAR_FUN_ATTR float futrts_asin32(float x) { return asinf(x); }\nSCALAR_FUN_ATTR float futrts_asinpi32(float x) { return asinf(x)/(float)M_PI; }\nSCALAR_FUN_ATTR float futrts_atan32(float x) { return atanf(x); }\nSCALAR_FUN_ATTR float futrts_atanpi32(float x) { return atanf(x)/(float)M_PI; }\nSCALAR_FUN_ATTR float futrts_cosh32(float x) { return coshf(x); }\nSCALAR_FUN_ATTR float futrts_sinh32(float x) { return sinhf(x); }\nSCALAR_FUN_ATTR float futrts_tanh32(float x) { return tanhf(x); }\nSCALAR_FUN_ATTR float futrts_acosh32(float x) { return acoshf(x); }\nSCALAR_FUN_ATTR float futrts_asinh32(float x) { return asinhf(x); }\nSCALAR_FUN_ATTR float futrts_atanh32(float x) { return atanhf(x); }\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) { return atan2f(x, y); }\nSCALAR_FUN_ATTR float futrts_atan2pi_32(float x, float y) { return atan2f(x, y) / (float)M_PI; }\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) { return hypotf(x, y); }\nSCALAR_FUN_ATTR float futrts_gamma32(float x) { return tgammaf(x); }\nSCALAR_FU", "N_ATTR float futrts_lgamma32(float x) { return lgammaf(x); }\nSCALAR_FUN_ATTR float futrts_erf32(float x) { return erff(x); }\nSCALAR_FUN_ATTR float futrts_erfc32(float x) { return erfcf(x); }\nSCALAR_FUN_ATTR float fmod32(float x, float y) { return fmodf(x, y); }\nSCALAR_FUN_ATTR float futrts_round32(float x) { return rintf(x); }\nSCALAR_FUN_ATTR float futrts_floor32(float x) { return floorf(x); }\nSCALAR_FUN_ATTR float futrts_ceil32(float x) { return ceilf(x); }\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) { return nextafterf(x, y); }\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) { return v0 + (v1 - v0) * t; }\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) { return ldexpf(x, y); }\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) { return copysignf(x, y); }\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) { return a * b + c; }\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) { return fmaf(a, b, c); }\n\n#endif\n\n#if defined(ISPC)\n\nSCALAR_FUN_ATTR int32_t fptobits_f32_i32(float x) { return intbits(x); }\nSCALAR_FUN_ATTR float bitstofp_i32_f32(int32_t x) { return floatbits(x); }\nSCALAR_FUN_ATTR uniform int32_t fptobits_f32_i32(uniform float x) { return intbits(x); }\nSCALAR_FUN_ATTR uniform float bitstofp_i32_f32(uniform int32_t x) { return floatbits(x); }\n\n#else\n\nSCALAR_FUN_ATTR int32_t fptobits_f32_i32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR float bitstofp_i32_f32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nSCALAR_FUN_ATTR float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double bitstofp_i64_f64(int64_t x);\nSCALAR_FUN_ATTR int64_t fptobits_f64_i64(double x);\n\n#if defined(ISPC)\n\nSCALAR_FUN_ATTR bool futrts_isinf64(float x) { return !isnan(x) && isnan(x - x); }\nSCALAR_FUN_ATTR bool futrts_isfinite64(fl", "oat x) { return !isnan(x) && !futrts_isinf64(x); }\nSCALAR_FUN_ATTR double fdiv64(double x, double y) { return x / y; }\nSCALAR_FUN_ATTR double fadd64(double x, double y) { return x + y; }\nSCALAR_FUN_ATTR double fsub64(double x, double y) { return x - y; }\nSCALAR_FUN_ATTR double fmul64(double x, double y) { return x * y; }\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) { return x < y; }\nSCALAR_FUN_ATTR bool cmple64(double x, double y) { return x <= y; }\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) { return (double) x; }\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) { return (double) x; }\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) { return (double) x; }\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) { return (double) x; }\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) { return (double) x; }\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) { return (double) x; }\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) { return (double) x; }\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) { return (double) x; }\nSCALAR_FUN_ATTR double fabs64(double x) { return abs(x); }\nSCALAR_FUN_ATTR double fmax64(double x, double y) { return isnan(x) ? y : isnan(y) ? x : max(x, y); }\nSCALAR_FUN_ATTR double fmin64(double x, double y) { return isnan(x) ? y : isnan(y) ? x : min(x, y); }\n\nSCALAR_FUN_ATTR double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = pow(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\nSCALAR_FUN_ATTR double futrts_log64(double x) { return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x; }\nSCALAR_FUN_ATTR double futrts_log2_64(double x) { return futrts_log64(x)/log(2.0d); }\nSCALAR_FUN_ATTR double futrts_log10_64(double x) { return futrts_log64(x)/log(10.0d); }\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN",
                                    "_ATTR double futrts_sqrt64(double x) { return sqrt(x); }\nSCALAR_FUN_ATTR double futrts_rsqrt64(double x) { return 1/sqrt(x); }\n\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\nSCALAR_FUN_ATTR double futrts_exp64(double x) { return exp(x); }\nSCALAR_FUN_ATTR double futrts_cos64(double x) { return cos(x); }\nSCALAR_FUN_ATTR double futrts_cospi64(double x) { return cos(M_PI*x); }\nSCALAR_FUN_ATTR double futrts_sin64(double x) { return sin(x); }\nSCALAR_FUN_ATTR double futrts_sinpi64(double x) { return sin(M_PI*x); }\nSCALAR_FUN_ATTR double futrts_tan64(double x) { return tan(x); }\nSCALAR_FUN_ATTR double futrts_tanpi64(double x) { return tan(M_PI*x); }\nSCALAR_FUN_ATTR double futrts_acos64(double x) { return acos(x); }\nSCALAR_FUN_ATTR double futrts_acospi64(double x) { return acos(x)/M_PI; }\nSCALAR_FUN_ATTR double futrts_asin64(double x) { return asin(x); }\nSCALAR_FUN_ATTR double futrts_asinpi64(double x) { return asin(x)/M_PI; }\nSCALAR_FUN_ATTR double futrts_atan64(double x) { return atan(x); }\nSCALAR_FUN_ATTR double futrts_atanpi64(double x) { return atan(x)/M_PI; }\nSCALAR_FUN_ATTR double futrts_cosh64(double x) { return (exp(x)+exp(-x)) / 2.0d; }\nSCALAR_FUN_ATTR double futrts_sinh64(double x) { return (exp(x)-exp(-x)) / 2.0d; }\nSCALAR_FUN_ATTR double futrts_tanh64(double x) { return futrts_sinh64(x)/futrts_cosh64(x); }\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n}\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) { return atan2(x, y); }\n\nSCALAR_FUN_ATTR double futrts_", "atan2pi_64(double x, double y) { return atan2(x, y) / M_PI; }\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) { return a * b + c; }\nSCALAR_FUN_ATTR double futrts_round64(double x) { return round(x); }\nSCALAR_FUN_ATTR double futrts_ceil64(double x) { return ceil(x); }\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nSCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) { return floor(x); }\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) { return isnan(x); }\n\nSCALAR_FUN_ATTR int8_t fptosi_f", "64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) { return x != 0.0; }\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) { return x ? 1.0 : 0.0; }\n\nSCALAR_FUN_ATTR int64_t fptobits_f64_i64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double bitstofp_i64_f64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i);\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uniform int64_t fptobits_f64_i64(uniform double x) {\n  return intbits(x);\n}\n\nSCALAR_FUN_ATTR uniform double bitstofp_i",
                                    "64_f64(uniform int64_t x) {\n  return doublebits(x);\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return x * pow((uniform double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {\n  int64_t xb = fptobits_f64_i64(x);\n  int64_t yb = fptobits_f64_i64(y);\n  return bitstofp_i64_f64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) { return a * b + c; }\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) { return (float) x; }\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) { return (double) x; }\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) { return (float) x; }\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) { return (double) x; }\n\n#else\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) { return x / y; }\nSCALAR_FUN_ATTR double fadd64(double x, double y) { return x + y; }\nSCALAR_FUN_ATTR double fsub64(double x, double y) { return x - y; }\nSCALAR_FUN_ATTR double fmul64(double x, double y) { return x * y; }\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) { return x < y; }\nSCALAR_FUN_ATTR bool cmple64(double x, double y) { return x <= y; }\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) { return (double) x; }\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) { return (double) x; }\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) { return (double) x; }\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) { return (double) x; }\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) { return (double) x; }\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) { return (double) x; }\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) { return (double) x; }\nSCALAR_FUN_", "ATTR double uitofp_i64_f64(uint64_t x) { return (double) x; }\nSCALAR_FUN_ATTR double fabs64(double x) { return fabs(x); }\nSCALAR_FUN_ATTR double fmax64(double x, double y) { return fmax(x, y); }\nSCALAR_FUN_ATTR double fmin64(double x, double y) { return fmin(x, y); }\nSCALAR_FUN_ATTR double fpow64(double x, double y) { return pow(x, y); }\nSCALAR_FUN_ATTR double futrts_log64(double x) { return log(x); }\nSCALAR_FUN_ATTR double futrts_log2_64(double x) { return log2(x); }\nSCALAR_FUN_ATTR double futrts_log10_64(double x) { return log10(x); }\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) { return log1p(x); }\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) { return sqrt(x); }\nSCALAR_FUN_ATTR double futrts_rsqrt64(double x) { return 1/sqrt(x); }\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) { return cbrt(x); }\nSCALAR_FUN_ATTR double futrts_exp64(double x) { return exp(x); }\nSCALAR_FUN_ATTR double futrts_cos64(double x) { return cos(x); }\n\nSCALAR_FUN_ATTR double futrts_cospi64(double x) {\n#ifdef __OPENCL_VERSION__\n  return cospi(x);\n#elif defined(__CUDA_ARCH__)\n  return cospi(x);\n#else\n  return cos(M_PI*x);\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sinpi64(double x) {\n#ifdef __OPENCL_VERSION__\n  return sinpi(x);\n#elif defined(__CUDA_ARCH__)\n  return sinpi(x);\n#else\n  return sin(M_PI*x);\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tanpi64(double x) {\n#ifdef __OPENCL_VERSION__\n  return tanpi(x);\n#else\n  return tan(M_PI*x);\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acospi64(double x) {\n#ifdef __OPENCL_VERSION__\n  return acospi(x);\n#else\n  return acos(x) / M_PI;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asinpi64(double x) {\n#ifdef __OPENCL_VERSION__\n  return asinpi(x);\n#else\n  return asin(x) / M_PI;\n#endif\n}\n\nSCALA", "R_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atanpi64(double x) {\n#ifdef __OPENCL_VERSION__\n  return atanpi(x);\n#else\n  return atan(x) / M_PI;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) { return cosh(x); }\nSCALAR_FUN_ATTR double futrts_sinh64(double x) { return sinh(x); }\nSCALAR_FUN_ATTR double futrts_tanh64(double x) { return tanh(x); }\nSCALAR_FUN_ATTR double futrts_acosh64(double x) { return acosh(x); }\nSCALAR_FUN_ATTR double futrts_asinh64(double x) { return asinh(x); }\nSCALAR_FUN_ATTR double futrts_atanh64(double x) { return atanh(x); }\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) { return atan2(x, y); }\n\nSCALAR_FUN_ATTR double futrts_atan2pi_64(double x, double y) {\n#ifdef __OPENCL_VERSION__\n  return atan2pi(x, y);\n#else\n  return atan2(x, y) / M_PI;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) { return hypot(x, y); }\nSCALAR_FUN_ATTR double futrts_gamma64(double x) { return tgamma(x); }\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) { return lgamma(x); }\nSCALAR_FUN_ATTR double futrts_erf64(double x) { return erf(x); }\nSCALAR_FUN_ATTR double futrts_erfc64(double x) { return erfc(x); }\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) { return fma(a, b, c); }\nSCALAR_FUN_ATTR double futrts_round64(double x) { return rint(x); }\nSCALAR_FUN_ATTR double futrts_ceil64(double x) { return ceil(x); }\nSCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) { return nextafter(x, y); }\nSCALAR_FUN_ATTR double futrts_floor64(double x) { return floor(x); }\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) { return isnan(x); }\nSCALAR_FUN_ATTR bool futrts_isinf64(double x) { return isinf(x); }\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {",
                                    "\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) { return x != 0; }\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) { return x ? 1 : 0; }\n\nSCALAR_FUN_ATTR int64_t fptobits_f64_i64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double bitstofp_i64_f64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VER", "SION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) { return (float) x; }\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) { return (double) x; }\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) { return (float) x; }\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) { return (double) x; }\n\n#endif\n\n#endif\n\n#define futrts_cond_f16(x,y,z) ((x) ? (y) : (z))\n#define futrts_cond_f32(x,y,z) ((x) ? (y) : (z))\n#define futrts_cond_f64(x,y,z) ((x) ? (y) : (z))\n\n#define futrts_cond_i8(x,y,z) ((x) ? (y) : (z))\n#define futrts_cond_i16(x,y,z) ((x) ? (y) : (z))\n#define futrts_cond_i32(x,y,z) ((x) ? (y) : (z))\n#define futrts_cond_i64(x,y,z) ((x) ? (y) : (z))\n\n#define futrts_cond_bool(x,y,z) ((x) ? (y) : (z))\n#define futrts_cond_unit(x,y,z) ((x) ? (y) : (z))\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif defined(ISPC)\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because half\n// precision versions are not available.\nSCALAR_FUN_A", "TTR f16 fadd16(f16 x, f16 y) { return x + y; }\nSCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) { return x - y; }\nSCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) { return x * y; }\nSCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) { return x < y; }\nSCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) { return x <= y; }\nSCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) { return (f16) x; }\nSCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) { return (f16) x; }\nSCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) { return (f16) x; }\nSCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) { return (f16) x; }\nSCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) { return (f16) x; }\nSCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) { return (f16) x; }\nSCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) { return (f16) x; }\nSCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) { return (f16) x; }\nSCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) { return (int8_t) (float) x; }\nSCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) { return (int16_t) x; }\nSCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) { return (int32_t) x; }\nSCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) { return (int64_t) x; }\nSCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) { return (uint8_t) (float) x; }\nSCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) { return (uint16_t) x; }\nSCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) { return (uint32_t) x; }\nSCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) { return (uint64_t) x; }\nSCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) { return x != (f16)0; }\nSCALAR_FUN_ATTR f16 btof_bool_f16(bool x) { return x ? 1 : 0; }\n\n#ifndef EMULATE_F16\n\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) { return isnan((float)x); }\n\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) { return fabs(x); }\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) { return fmax(x, y); }\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) { return fmin(x, y); }\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) { return pow(x, y); }\n\n#elif defined(ISPC)\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) { return abs(x); }\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f",
                                    "16 y) { return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y); }\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) { return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y); }\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) { return pow(x, y); }\n\n#else // Assuming CUDA.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) { return fabsf(x); }\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) { return fmaxf(x, y); }\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) { return fminf(x, y); }\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) { return powf(x, y); }\n\n#endif\n\n#if defined(ISPC)\nSCALAR_FUN_ATTR bool futrts_isinf16(float x) { return !futrts_isnan16(x) && futrts_isnan16(x - x); }\nSCALAR_FUN_ATTR bool futrts_isfinite16(float x) { return !futrts_isnan16(x) && !futrts_isinf16(x); }\n#else\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) { return isinf((float)x); }\n#endif\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) { return log(x); }\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) { return log2(x); }\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) { return log10(x); }\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) { return log1p(x); }\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) { return sqrt(x); }\nSCALAR_FUN_ATTR f16 futrts_rsqrt16(f16 x) { return rsqrt(x); }\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) { return cbrt(x); }\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) { return exp(x); }\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) { return cos(x); }\nSCALAR_FUN_ATTR f16 futrts_cospi16(f16 x) { return cospi(x); }\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) { return sin(x); }\nSCALAR_FUN_ATTR f16 futrts_sinpi16(f16 x) { return sinpi(x); }\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) { return tan(x); }\nSCALAR_FUN_ATTR f16 futrts_tanpi16(f16 x) { return tanpi(x); }\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) { return acos(x); }\nSCALAR_FUN_ATTR f16 futrts_acospi16(f16 x) { return acospi(x); }\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) { return asin(x); }\nSCALAR_FUN_ATTR f16 futrts_asinpi16(f16 x) { return asinpi(x); }\nSCALAR_FUN_ATTR f16 futr", "ts_atan16(f16 x) { return atan(x); }\nSCALAR_FUN_ATTR f16 futrts_atanpi16(f16 x) { return atanpi(x); }\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) { return cosh(x); }\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) { return sinh(x); }\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) { return tanh(x); }\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) { return acosh(x); }\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) { return asinh(x); }\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) { return atanh(x); }\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) { return atan2(x, y); }\nSCALAR_FUN_ATTR f16 futrts_atan2pi_16(f16 x, f16 y) { return atan2pi(x, y); }\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) { return hypot(x, y); }\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) { return tgamma(x); }\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) { return lgamma(x); }\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) { return erf(x); }\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) { return erfc(x); }\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) { return fmod(x, y); }\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) { return rint(x); }\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) { return floor(x); }\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) { return ceil(x); }\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) { return nextafter(x, y); }\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) { return mix(v0, v1, t); }\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) { return ldexp(x, y); }\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) { return copysign(x, y); }\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) { return mad(a, b, c); }\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) { return fma(a, b, c); }\n\n#elif defined(ISPC)\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) { return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x; }\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) { return futrts_log16(x) / log(2.0f16); }\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) { return futrts_log16(x) / log(10.0f16); }\nSCALAR_FUN_AT", "TR f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) { return (float16)sqrt((float)x); }\nSCALAR_FUN_ATTR f16 futrts_rsqrt16(f16 x) { return (float16)1/sqrt((float)x); }\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) { return exp(x); }\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) { return (float16)cos((float)x); }\nSCALAR_FUN_ATTR f16 futrts_cospi16(f16 x) { return (float16)cos((float)M_PI*(float)x); }\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) { return (float16)sin((float)x); }\nSCALAR_FUN_ATTR f16 futrts_sinpi16(f16 x) { return (float16)sin((float)M_PI*(float)x); }\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) { return (float16)tan((float)x); }\nSCALAR_FUN_ATTR f16 futrts_tanpi16(f16 x) { return (float16)(tan((float)M_PI*(float)x)); }\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) { return (float16)acos((float)x); }\nSCALAR_FUN_ATTR f16 futrts_acospi16(f16 x) { return (float16)(acos((float)x)/(float)M_PI); }\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) { return (float16)asin((float)x); }\nSCALAR_FUN_ATTR f16 futrts_asinpi16(f16 x) { return (float16)(asin((float)x)/(float)M_PI); }\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) { return (float16)atan((float)x); }\nSCALAR_FUN_ATTR f16 futrts_atanpi16(f16 x) { return (float16)(atan((float)x)/(float)M_PI); }\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) { return (exp(x)+exp(-x)) / 2.0f16; }\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) { return (exp(x)-exp(-x)) / 2.0f16; }\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) { return futrts_sinh16(x)/futrts_cosh16(x); }\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  float16 f = (1+",
                                    "x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) { return (float16)atan2((float)x, (float)y); }\nSCALAR_FUN_ATTR f16 futrts_atan2pi_16(f16 x, f16 y) { return (float16)(atan2((float)x, (float)y)/(float)M_PI); }\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) { return (float16)futrts_hypot32((float)x, (float)y); }\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) { return (f16)futrts_cbrt32((float)x); }\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) { return (f16)futrts_erf32((float)x); }\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) { return (f16)futrts_erfc32((float)x); }\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) { return x - y * (float16)trunc((float) (x/y)); }\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) { return (float16)round((float)x); }\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) { return (float16)floor((float)x); }\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) { return (float16)ceil((float)x); }\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) { return (float16)futrts_nextafter32((float)x, (float) y); }\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) { return v0 + (v1 - v0) * t; }\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) { return futrts_ldexp32((float)x, y); }\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) { return futrts_copysign32((float)x, y); }\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) { return a * b + c; }\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) { return a * b + c; }\n\n#else // A", "ssume CUDA.\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) { return hlog(x); }\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) { return hlog2(x); }\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) { return hlog10(x); }\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) { return (f16)log1pf((float)x); }\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) { return hsqrt(x); }\nSCALAR_FUN_ATTR f16 futrts_rsqrt16(f16 x) { return hrsqrt(x); }\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) { return cbrtf(x); }\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) { return hexp(x); }\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) { return hcos(x); }\nSCALAR_FUN_ATTR f16 futrts_cospi16(f16 x) { return hcos((f16)M_PI*x); }\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) { return hsin(x); }\nSCALAR_FUN_ATTR f16 futrts_sinpi16(f16 x) { return hsin((f16)M_PI*x); }\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) { return tanf(x); }\nSCALAR_FUN_ATTR f16 futrts_tanpi16(f16 x) { return tanf((f16)M_PI*x); }\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) { return acosf(x); }\nSCALAR_FUN_ATTR f16 futrts_acospi16(f16 x) { return (f16)acosf(x)/(f16)M_PI; }\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) { return asinf(x); }\nSCALAR_FUN_ATTR f16 futrts_asinpi16(f16 x) { return (f16)asinf(x)/(f16)M_PI; }\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) { return (f16)atanf(x); }\nSCALAR_FUN_ATTR f16 futrts_atanpi16(f16 x) { return (f16)atanf(x)/(f16)M_PI; }\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) { return coshf(x); }\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) { return sinhf(x); }\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) { return tanhf(x); }\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) { return acoshf(x); }\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) { return asinhf(x); }\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) { return atanhf(x); }\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) { return (f16)atan2f(x, y); }\nSCALAR_FUN_ATTR f16 futrts_atan2pi_16(f16 x, f16 y) { return (f16)atan2f(x, y)/(f16)M_PI; }\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) { return hypotf(x, y); }\nSCALAR_FUN_ATTR f16 futrts", "_gamma16(f16 x) { return tgammaf(x); }\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) { return lgammaf(x); }\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) { return erff(x); }\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) { return erfcf(x); }\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) { return fmodf(x, y); }\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) { return rintf(x); }\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) { return hfloor(x); }\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) { return hceil(x); }\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) { return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y))); }\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) { return v0 + (v1 - v0) * t; }\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) { return futrts_ldexp32((float)x, y); }\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) { return futrts_copysign32((float)x, y); }\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) { return a * b + c; }\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) { return fmaf(a, b, c); }\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nSCALAR_FUN_ATTR int16_t fptobits_f16_i16(f16 x) { return __half_as_ushort(x); }\nSCALAR_FUN_ATTR f16 bitstofp_i16_f16(int16_t x) { return __ushort_as_half(x); }\n#elif defined(ISPC)\nSCALAR_FUN_ATTR int16_t fptobits_f16_i16(f16 x) { varying int16_t y = *((varying int16_t * uniform)&x); return y;\n}\nSCALAR_FUN_ATTR f16 bitstofp_i16_f16(int16_t x) { varying f16 y = *((varying f16 * uniform)&x); return y; }\n#else\nSCALAR_FUN_ATTR int16_t fptobits_f16_i16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR f16 bitstofp_i16_f16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No native f16 - emulate.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) { return fabs32(x); }\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) { ret",
                                    "urn fmax32(x, y); }\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) { return fmin32(x, y); }\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) { return fpow32(x, y); }\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) { return futrts_isnan32(x); }\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) { return futrts_isinf32(x); }\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) { return futrts_log32(x); }\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) { return futrts_log2_32(x); }\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) { return futrts_log10_32(x); }\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) { return futrts_log1p_32(x); }\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) { return futrts_sqrt32(x); }\nSCALAR_FUN_ATTR f16 futrts_rsqrt16(f16 x) { return futrts_rsqrt32(x); }\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) { return futrts_cbrt32(x); }\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) { return futrts_exp32(x); }\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) { return futrts_cos32(x); }\nSCALAR_FUN_ATTR f16 futrts_cospi16(f16 x) { return futrts_cospi32(x); }\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) { return futrts_sin32(x); }\nSCALAR_FUN_ATTR f16 futrts_sinpi16(f16 x) { return futrts_sinpi32(x); }\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) { return futrts_tan32(x); }\nSCALAR_FUN_ATTR f16 futrts_tanpi16(f16 x) { return futrts_tanpi32(x); }\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) { return futrts_acos32(x); }\nSCALAR_FUN_ATTR f16 futrts_acospi16(f16 x) { return futrts_acospi32(x); }\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) { return futrts_asin32(x); }\nSCALAR_FUN_ATTR f16 futrts_asinpi16(f16 x) { return futrts_asinpi32(x); }\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) { return futrts_atan32(x); }\nSCALAR_FUN_ATTR f16 futrts_atanpi16(f16 x) { return futrts_atanpi32(x); }\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) { return futrts_cosh32(x); }\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) { return futrts_sinh32(x); }\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) { return futrts_tanh32(x); }\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) { return futrts_acosh32(x); }\n", "SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) { return futrts_asinh32(x); }\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) { return futrts_atanh32(x); }\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) { return futrts_atan2_32(x, y); }\nSCALAR_FUN_ATTR f16 futrts_atan2pi_16(f16 x, f16 y) { return futrts_atan2pi_32(x, y); }\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) { return futrts_hypot32(x, y); }\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) { return futrts_gamma32(x); }\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) { return futrts_lgamma32(x); }\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) { return futrts_erf32(x); }\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) { return futrts_erfc32(x); }\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) { return fmod32(x, y); }\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) { return futrts_round32(x); }\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) { return futrts_floor32(x); }\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) { return futrts_ceil32(x); }\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) { return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y))); }\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) { return futrts_lerp32(v0, v1, t); }\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) { return futrts_ldexp32(x, y); }\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) { return futrts_copysign32((float)x, y); }\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) { return futrts_mad32(a, b, c); }\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) { return futrts_fma32(a, b, c); }\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR int16_t fptobits_f16_i16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 bitstofp", "_i16_f16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\nSCALAR_FUN_ATTR int16_t fptobits_f16_i16(f16 x) { return (int16_t)float2halfbits(x); }\nSCALAR_FUN_ATTR f16 bitstofp_i16_f16(int16_t x) { return halfbits2float((uint16_t)x); }\nSCALAR_FUN_ATTR f16 fsignum16(f16 x) { return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0); }\n\n#endif\n\n#endif\n\nSCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) { return x; }\nSCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) { return x; }\nSCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) { return (f16) x; }\n\n#ifdef FUTHARK_F64_ENABLED\nSCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) { return (double) x; }\n#if defined(ISPC)\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) { return (f16) ((float)x); }\n#else\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) { return (f16) x; }\n#endif\n#endif\n\n// End of scalar_f16.h.\n// Start of atomics64.h\n\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volat",
                                    "ile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x);\n\n#ifdef FUTHARK_F64_ENABLED\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x);\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((unsigned long long*)p, x);\n#else\n  return atom_xchg(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((unsigned long long*)p, x);\n#else\n  return atom_xchg(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((unsigned long long*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n         ", "                                               int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((unsigned long long*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((unsigned long long*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((unsigned long long*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  double ret;\n  asm volatile(\"atom.global.add.f64 %0,[%1],%2;\":\"=d\"(ret):\"l\"(p),\"d\"(x):\"memory\");\n  return ret;\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f64)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f64(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  union {int64_t i; double f;} old;\n  union {int64_t i; double f;} ret;\n  old.f = x;\n  while (1) {\n    ret.i = atomic_xchg_i64_global((volatile __global int64_t*)p, (int64_t)0);\n    ret.f += old.f;\n    old.i = atomic_xchg_i64_global((volatile __global int64_t*)p, ret.i);\n    if (old.i == 0) {\n      break;\n    }\n  }\n  return ret.f;\n#endif\n}\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x) {\n#if defined(", "FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  union { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((long long*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((long long*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((long long*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return at",
                                    "omicMin((long long*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((unsigned long long*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((unsigned long long*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((unsigned long long*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((unsigned long long*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((unsigned long long*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((unsigned long long*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((unsigned long long*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_", "shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((unsigned long long*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((unsigned long long*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((unsigned long long*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\n// End of atomics64.h\n// Start of atomics.h\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                  int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                  int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t ", "x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x);\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                  int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                  int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __g",
                                    "lobal int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  float ret;\n  asm volatile(\"atom.global.add.f32 %0,[%1],%2;\":\"=f\"(ret):\"l\"(p),\"f\"(x):\"memory\");\n  return ret;\n#elif defined(__opencl_c_ext_fp32_global_atomic_add)\n  // use hardware-supported atomic addition on some Intel GPUs\n  return atomic_fetch_add_explicit((volatile __global atomic_float*)p,\n                                   x,\n                                   memory_order_relaxed);\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f32)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f32(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  float old = x;\n  float ret;\n  while ((old=atomic_xchg(p, ret=atomic_xchg(p, 0.0f)+old))!=0.0f);\n  return ret;\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_shared((volatile __local int32_t*)p, assumed.i, old", ".i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x)", ";\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// End of atomics.h\n// Start of atomics16.h\n\nSCALAR_FUN_ATTR int16_t atomic_cmpxchg_i16_global(volatile __global int16_t *p,\n                                                  int16_t cmp, int16_t val);\nSCALAR_FUN_ATTR int16_t atomic_cmpxchg_i16_shared(volatile __local int16_t *p,\n                                                  int16_t cmp, int16_t val);\nSCALAR_FUN_ATTR int16_t atomic_add_i16_global(volatile __global int16_t *p, int16_t x);\nSCALAR_FUN_ATTR int16_t atomic_add_i16_shared(volatile __local int16_t *p, int16_t x);\nSCALAR_FUN_ATTR f16 atomic_fadd_f16_global(volatile __global uint16_t *p, f16 x);\nSCALAR_FUN_ATTR f16 atomic_fadd_f16_shared(volatile __local uint16_t *p, f16 x);\nSCALAR_FUN_ATTR int16_t atomic_smax_i16_global(volatile __global int16_t *p, int16_t x);\nSCALAR_FUN_ATTR int16_t atomic_smax_i16_shared(volatile __local int16_t *p, int16_t x);\nS",
                                    "CALAR_FUN_ATTR int16_t atomic_smin_i16_global(volatile __global int16_t *p, int16_t x);\nSCALAR_FUN_ATTR int16_t atomic_smin_i16_shared(volatile __local int16_t *p, int16_t x);\nSCALAR_FUN_ATTR uint16_t atomic_umax_i16_global(volatile __global uint16_t *p, uint16_t x);\nSCALAR_FUN_ATTR uint16_t atomic_umax_i16_shared(volatile __local uint16_t *p, uint16_t x);\nSCALAR_FUN_ATTR uint16_t atomic_umin_i16_global(volatile __global uint16_t *p, uint16_t x);\nSCALAR_FUN_ATTR uint16_t atomic_umin_i16_shared(volatile __local uint16_t *p, uint16_t x);\nSCALAR_FUN_ATTR int16_t atomic_and_i16_global(volatile __global int16_t *p, int16_t x);\nSCALAR_FUN_ATTR int16_t atomic_and_i16_shared(volatile __local int16_t *p, int16_t x);\nSCALAR_FUN_ATTR int16_t atomic_or_i16_global(volatile __global int16_t *p, int16_t x);\nSCALAR_FUN_ATTR int16_t atomic_or_i16_shared(volatile __local int16_t *p, int16_t x);\nSCALAR_FUN_ATTR int16_t atomic_xor_i16_global(volatile __global int16_t *p, int16_t x);\nSCALAR_FUN_ATTR int16_t atomic_xor_i16_shared(volatile __local int16_t *p, int16_t x);\n\nSCALAR_FUN_ATTR int16_t atomic_cmpxchg_i16_global(volatile __global int16_t *p,\n                                                  int16_t cmp, int16_t val) {\n  int offset = ((uintptr_t)p >> 1 & 1);\n  volatile __global int32_t *p32 = (volatile __global int32_t*)((uintptr_t)p & ~0x3);\n\n  int shift = offset * 16;\n  int32_t mask = 0xffff << shift;\n  int32_t shifted_val = val << shift;\n  int32_t shifted_cmp = cmp << shift;\n\n  uint32_t old = shifted_cmp;\n  uint32_t upd = shifted_val;\n  uint32_t got;\n\n  while ((got=atomic_cmpxchg_i32_global(p32, old, upd)) != old) {\n    old = got;\n    upd = (old & ~mask) | shifted_val;\n  }\n\n  return old >> shift;\n}\n\nSCALAR_FUN_ATTR int16_t atomic_cmpxchg_i16_shared(volatile __local int16_t *p,\n                                                  int16_t cmp, int16_t val) {\n  int offset = ((uintptr_t)p >> 1 & 1);\n  volatile __local int32_t *p32 = (volatile __local int32_t*)((uintptr_t)p & ~0x3);\n\n ", " int shift = offset * 16;\n  int32_t mask = 0xffff << shift;\n  int32_t shifted_val = val << shift;\n  int32_t shifted_cmp = cmp << shift;\n\n  uint32_t old = shifted_cmp;\n  uint32_t upd = shifted_val;\n  uint32_t got;\n\n  while ((got=atomic_cmpxchg_i32_shared(p32, old, upd)) != old) {\n    old = got;\n    upd = (old & ~mask) | shifted_val;\n  }\n\n  return old >> shift;\n}\n\n// Convenience macro for arithmetic.\n#define DEFINE_16BIT_ATOMIC(name, T, op)                                \\\n  SCALAR_FUN_ATTR T                                                     \\\n  atomic_##name##_i16_global(volatile __global T *p, T val) {           \\\n    int offset = ((uintptr_t)p >> 1 & 1);                               \\\n    volatile __global int32_t *p32 = (volatile __global int32_t*)((uintptr_t)p & ~0x3); \\\n    int shift = offset * 16;                                            \\\n    int32_t mask = 0xffff << shift;                                     \\\n    int32_t old = 0;                                                    \\\n    int32_t upd = mask & (op(old >> shift, val) << shift);              \\\n    int32_t saw;                                                        \\\n    while ((saw=atomic_cmpxchg_i32_global(p32, old, upd)) != old) {     \\\n      old = saw;                                                        \\\n      upd = (old & ~mask) | ((op(old >> shift, val)) << shift);         \\\n    }                                                                   \\\n    return old >> shift;                                                \\\n  }                                                                     \\\n  SCALAR_FUN_ATTR T                                                     \\\n  atomic_##name##_i16_shared(volatile __local T *p, T val) {            \\\n    int offset = ((uintptr_t)p >> 1 & 1);                               \\\n    volatile __local int32_t *p32 = (volatile __local int32_t*)((uintptr_t)p & ~0x3); \\\n    int shift = offset * 16;                                            \\\n    int32_t ma", "sk = 0xffff << shift;                                     \\\n    int32_t old = 0;                                                    \\\n    int32_t upd = mask & ((op(old >> shift, val)) << shift);            \\\n    int32_t saw;                                                        \\\n    while ((saw=atomic_cmpxchg_i32_shared(p32, old, upd)) != old) {     \\\n      old = saw;                                                        \\\n      upd = (old & ~mask) | ((op(old >> shift, val)) << shift);         \\\n    }                                                                   \\\n    return old >> shift;                                                \\\n  }\n\nDEFINE_16BIT_ATOMIC(add, int16_t, add16);\nDEFINE_16BIT_ATOMIC(smax, int16_t, smax16);\nDEFINE_16BIT_ATOMIC(smin, int16_t, smin16);\nDEFINE_16BIT_ATOMIC(umax, uint16_t, umax16);\nDEFINE_16BIT_ATOMIC(umin, uint16_t, umin16);\n\nSCALAR_FUN_ATTR int16_t atomic_and_i16_global(volatile __global int16_t *p, int16_t val) {\n  volatile __global int32_t *p32 = (volatile __global int32_t*)((uintptr_t)p & ~0x3);\n  int shift = ((uintptr_t)p >> 1 & 1) * 16;\n  int32_t mask = 0xffff << shift;\n  return atomic_and_i32_global(p32, ~mask | (val<<shift)) >> shift;\n}\n\nSCALAR_FUN_ATTR int16_t atomic_and_i16_shared(volatile __local int16_t *p, int16_t val) {\n  volatile __local int32_t *p32 = (volatile __local int32_t*)((uintptr_t)p & ~0x3);\n  int shift = ((uintptr_t)p >> 1 & 1) * 16;\n  int32_t mask = 0xffff << shift;\n  return atomic_and_i32_shared(p32, ~mask | (val<<shift)) >> shift;\n}\n\nSCALAR_FUN_ATTR int16_t atomic_or_i16_global(volatile __global int16_t *p, int16_t val) {\n  volatile __global int32_t *p32 = (volatile __global int32_t*)((uintptr_t)p & ~0x3);\n  int shift = ((uintptr_t)p >> 1 & 1) * 16;\n  return atomic_or_i32_global(p32, (uint16_t)val<<shift) >> shift;\n}\n\nSCALAR_FUN_ATTR int16_t atomic_or_i16_shared(volatile __local int16_t *p, int16_t val) {\n  volatile __local int32_t *p32 = (volatile __local int32_t*)((uintptr_t)p & ~0x3);\n  int shif",
                                    "t = ((uintptr_t)p >> 1 & 1) * 16;\n  return atomic_or_i32_shared(p32, (uint16_t)val<<shift) >> shift;\n}\n\nSCALAR_FUN_ATTR int16_t atomic_xor_i16_global(volatile __global int16_t *p, int16_t val) {\n  volatile __global int32_t *p32 = (volatile __global int32_t*)((uintptr_t)p & ~0x3);\n  int shift = ((uintptr_t)p >> 1 & 1) * 16;\n  return atomic_xor_i32_global(p32, (uint16_t)val<<shift) >> shift;\n}\n\nSCALAR_FUN_ATTR int16_t atomic_xor_i16_shared(volatile __local int16_t *p, int16_t val) {\n  volatile __local int32_t *p32 = (volatile __local int32_t*)((uintptr_t)p & ~0x3);\n  int shift = ((uintptr_t)p >> 1 & 1) * 16;\n  return atomic_xor_i32_shared(p32, (uint16_t)val<<shift) >> shift;\n}\n\nSCALAR_FUN_ATTR f16 atomic_fadd_f16_global(volatile __global uint16_t *p, f16 val) {\n  int offset = ((uintptr_t)p >> 1 & 1);\n  volatile __global int32_t *p32 = (volatile __global int32_t*)((uintptr_t)p & ~0x3);\n  int shift = offset * 16;\n  int32_t mask = 0xffff << shift;\n  int32_t old = 0;\n  int32_t upd = mask & ((int32_t)fptobits_f16_i16(val) << shift);\n  int32_t saw;\n  while ((saw=atomic_cmpxchg_i32_global(p32, old, upd)) != old) {\n    old = saw;\n    upd = (old & ~mask) | (int32_t)fptobits_f16_i16(bitstofp_i16_f16((uint32_t)old >> shift) + val) << shift;\n  }\n  return bitstofp_i16_f16((uint32_t)old >> shift);\n}\n\nSCALAR_FUN_ATTR f16 atomic_fadd_f16_shared(volatile __local uint16_t *p, f16 val) {\n  int offset = ((uintptr_t)p >> 1 & 1);\n  volatile __local int32_t *p32 = (volatile __local int32_t*)((uintptr_t)p & ~0x3);\n  int shift = offset * 16;\n  int32_t mask = 0xffff << shift;\n  int32_t old = 0;\n  int32_t upd = mask & ((int32_t)fptobits_f16_i16(val) << shift);\n  int32_t saw;\n  while ((saw=atomic_cmpxchg_i32_shared(p32, old, upd)) != old) {\n    old = saw;\n    upd = (old & ~mask) | (int32_t)fptobits_f16_i16(bitstofp_i16_f16((uint32_t)old >> shift) + val) << shift;\n  }\n  return bitstofp_i16_f16((uint32_t)old >> shift);\n}\n\n// End of atomics16.h\n// Start of atomics8.h\n\nSCALAR_FUN_ATTR int8_t atomic_", "cmpxchg_i8_global(volatile __global int8_t *p,\n                                                int8_t cmp, int8_t val);\nSCALAR_FUN_ATTR int8_t atomic_cmpxchg_i8_shared(volatile __local int8_t *p,\n                                                int8_t cmp, int8_t val);\nSCALAR_FUN_ATTR int8_t atomic_add_i8_global(volatile __global int8_t *p, int8_t x);\nSCALAR_FUN_ATTR int8_t atomic_add_i8_shared(volatile __local int8_t *p, int8_t x);\nSCALAR_FUN_ATTR int8_t atomic_smax_i8_global(volatile __global int8_t *p, int8_t x);\nSCALAR_FUN_ATTR int8_t atomic_smax_i8_shared(volatile __local int8_t *p, int8_t x);\nSCALAR_FUN_ATTR int8_t atomic_smin_i8_global(volatile __global int8_t *p, int8_t x);\nSCALAR_FUN_ATTR int8_t atomic_smin_i8_shared(volatile __local int8_t *p, int8_t x);\nSCALAR_FUN_ATTR uint8_t atomic_umax_i8_global(volatile __global uint8_t *p, uint8_t x);\nSCALAR_FUN_ATTR uint8_t atomic_umax_i8_shared(volatile __local uint8_t *p, uint8_t x);\nSCALAR_FUN_ATTR uint8_t atomic_umin_i8_global(volatile __global uint8_t *p, uint8_t x);\nSCALAR_FUN_ATTR uint8_t atomic_umin_i8_shared(volatile __local uint8_t *p, uint8_t x);\nSCALAR_FUN_ATTR int8_t atomic_and_i8_global(volatile __global int8_t *p, int8_t x);\nSCALAR_FUN_ATTR int8_t atomic_and_i8_shared(volatile __local int8_t *p, int8_t x);\nSCALAR_FUN_ATTR int8_t atomic_or_i8_global(volatile __global int8_t *p, int8_t x);\nSCALAR_FUN_ATTR int8_t atomic_or_i8_shared(volatile __local int8_t *p, int8_t x);\nSCALAR_FUN_ATTR int8_t atomic_xor_i8_global(volatile __global int8_t *p, int8_t x);\nSCALAR_FUN_ATTR int8_t atomic_xor_i8_shared(volatile __local int8_t *p, int8_t x);\n\nSCALAR_FUN_ATTR int8_t atomic_cmpxchg_i8_global(volatile __global int8_t *p,\n                                                int8_t cmp, int8_t val) {\n  int offset = ((uintptr_t)p & 3);\n  volatile __global int32_t *p32 = (volatile __global int32_t*)((uintptr_t)p & ~0x3);\n\n  int shift = offset * 8;\n  int32_t mask = 0xff << shift;\n  int32_t shifted_val = val << shift;\n  int32", "_t shifted_cmp = cmp << shift;\n\n  uint32_t old = shifted_cmp;\n  uint32_t upd = shifted_val;\n  uint32_t got;\n\n  while ((got=atomic_cmpxchg_i32_global(p32, old, upd)) != old) {\n    old = got;\n    upd = (old & ~mask) | shifted_val;\n  }\n\n  return old >> shift;\n}\n\nSCALAR_FUN_ATTR int8_t atomic_cmpxchg_i8_shared(volatile __local int8_t *p,\n                                                int8_t cmp, int8_t val) {\n  int offset = ((uintptr_t)p >> 1 & 3);\n  volatile __local int32_t *p32 = (volatile __local int32_t*)((uintptr_t)p & ~0x3);\n\n  int shift = offset * 8;\n  int32_t mask = 0xff << shift;\n  int32_t shifted_val = val << shift;\n  int32_t shifted_cmp = cmp << shift;\n\n  uint32_t old = shifted_cmp;\n  uint32_t upd = shifted_val;\n  uint32_t got;\n\n  while ((got=atomic_cmpxchg_i32_shared(p32, old, upd)) != old) {\n    old = got;\n    upd = (old & ~mask) | shifted_val;\n  }\n\n  return old >> shift;\n}\n\n// Convenience macro for arithmetic.\n#define DEFINE_8BIT_ATOMIC(name, T, op)                                 \\\n  SCALAR_FUN_ATTR T                                                     \\\n  atomic_##name##_i8_global(volatile __global T *p, T val) {            \\\n    int offset = ((uintptr_t)p & 3);                                    \\\n    volatile __global int32_t *p32 = (volatile __global int32_t*)((uintptr_t)p & ~0x3); \\\n    int shift = offset * 8;                                             \\\n    int32_t mask = 0xff << shift;                                       \\\n    int32_t old = 0;                                                    \\\n    int32_t upd = mask & (op(old >> shift, val) << shift);              \\\n    int32_t saw;                                                        \\\n    while ((saw=atomic_cmpxchg_i32_global(p32, old, upd)) != old) {     \\\n      old = saw;                                                        \\\n      upd = (old & ~mask) | ((op(old >> shift, val)) << shift);         \\\n    }                                                                   \\\n    return ol",
                                    "d >> shift;                                                \\\n  }                                                                     \\\n  SCALAR_FUN_ATTR T                                                     \\\n  atomic_##name##_i8_shared(volatile __local T *p, T val) {             \\\n    int offset = ((uintptr_t)p & 3);                                    \\\n    volatile __local int32_t *p32 = (volatile __local int32_t*)((uintptr_t)p & ~0x3); \\\n    int shift = offset * 8;                                             \\\n    int32_t mask = 0xff << shift;                                       \\\n    int32_t old = 0;                                                    \\\n    int32_t upd = mask & ((op(old >> shift, val)) << shift);            \\\n    int32_t saw;                                                        \\\n    while ((saw=atomic_cmpxchg_i32_shared(p32, old, upd)) != old) {     \\\n      old = saw;                                                        \\\n      upd = (old & ~mask) | ((op(old >> shift, val)) << shift);         \\\n    }                                                                   \\\n    return old >> shift;                                                \\\n  }\n\nDEFINE_8BIT_ATOMIC(add, int8_t, add8);\nDEFINE_8BIT_ATOMIC(smax, int8_t, smax8);\nDEFINE_8BIT_ATOMIC(smin, int8_t, smin8);\nDEFINE_8BIT_ATOMIC(umax, uint8_t, umax8);\nDEFINE_8BIT_ATOMIC(umin, uint8_t, umin8);\n\nSCALAR_FUN_ATTR int8_t atomic_and_i8_global(volatile __global int8_t *p, int8_t val) {\n  volatile __global int32_t *p32 = (volatile __global int32_t*)((uintptr_t)p & ~0x3);\n  int shift = ((uintptr_t)p & 3) * 8;\n  int32_t mask = 0xff << shift;\n  return atomic_and_i32_global(p32, ~mask | (val<<shift)) >> shift;\n}\n\nSCALAR_FUN_ATTR int8_t atomic_and_i8_shared(volatile __local int8_t *p, int8_t val) {\n  volatile __local int32_t *p32 = (volatile __local int32_t*)((uintptr_t)p & ~0x3);\n  int shift = ((uintptr_t)p & 3) * 8;\n  int32_t mask = 0xff << shift;\n  return atomic_and_i32_shared(p32, ~mask | (val<<", "shift)) >> shift;\n}\n\nSCALAR_FUN_ATTR int8_t atomic_or_i8_global(volatile __global int8_t *p, int8_t val) {\n  volatile __global int32_t *p32 = (volatile __global int32_t*)((uintptr_t)p & ~0x3);\n  int shift = ((uintptr_t)p & 3) * 8;\n  return atomic_or_i32_global(p32, (uint8_t)val<<shift) >> shift;\n}\n\nSCALAR_FUN_ATTR int8_t atomic_or_i8_shared(volatile __local int8_t *p, int8_t val) {\n  volatile __local int32_t *p32 = (volatile __local int32_t*)((uintptr_t)p & ~0x3);\n  int shift = ((uintptr_t)p & 3) * 8;\n  return atomic_or_i32_shared(p32, (uint8_t)val<<shift) >> shift;\n}\n\nSCALAR_FUN_ATTR int8_t atomic_xor_i8_global(volatile __global int8_t *p, int8_t val) {\n  volatile __global int32_t *p32 = (volatile __global int32_t*)((uintptr_t)p & ~0x3);\n  int shift = ((uintptr_t)p & 3) * 8;\n  return atomic_xor_i32_global(p32, (uint8_t)val<<shift) >> shift;\n}\n\nSCALAR_FUN_ATTR int8_t atomic_xor_i8_shared(volatile __local int8_t *p, int8_t val) {\n  volatile __local int32_t *p32 = (volatile __local int32_t*)((uintptr_t)p & ~0x3);\n  int shift = ((uintptr_t)p & 3) * 8;\n  return atomic_xor_i32_shared(p32, (uint8_t)val<<shift) >> shift;\n}\n\n// End of atomics8.h\n// Start of transpose.cl\n\n#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME(SHARED_MEM_PARAM                              \\\n                          __global ELEM_TYPE *dst_mem,                  \\\n                          int64_t dst_offset,                           \\\n                          __global ELEM_TYPE *src_mem,                  \\\n                          int64_t src_offset,                           \\\n                          int32_t num_arrays,                           \\\n                          int32_t x_elems,                              \\\n                          int32_t y_elems,                              \\\n                          int32_t mulx,                                 \\\n    ", "                      int32_t muly,                                 \\\n                          int32_t repeat_1,                             \\\n                          int32_t repeat_2) {                           \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      if (tblock_id_2 >= num_arrays) { break; }                         \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = global_id_0;                                    \\\n      int32_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }               ",
                                    "                                              \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_height(SHARED_MEM_PARAM                 \\\n                                                __global ELEM_TY", "PE *dst_mem, \\\n                                                int64_t dst_offset,     \\\n                                                __global ELEM_TYPE *src_mem, \\\n                                                int64_t src_offset,     \\\n                                                int32_t num_arrays,     \\\n                                                int32_t x_elems,        \\\n                                                int32_t y_elems,        \\\n                                                int32_t mulx,           \\\n                                                int32_t muly,           \\\n                                                int32_t repeat_1,       \\\n                                                int32_t repeat_2) {     \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      if (tblock_id_2 >= num_arrays) { break; }                         \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index =                                                 \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(0) +                                               \\\n        get_local_id(1)%mulx * TR_BLOCK_DIM;            ", "                \\\n      int32_t y_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;      \\\n      y_index =                                                         \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(1) +                                               \\\n        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_width(SHARED_MEM_PARAM ",
                                    "                 \\\n                                      __global ELEM_TYPE *dst_mem,      \\\n                                      int64_t dst_offset,               \\\n                                      __global ELEM_TYPE *src_mem,      \\\n                                      int64_t src_offset,               \\\n                                      int32_t num_arrays,               \\\n                                      int32_t x_elems,                  \\\n                                      int32_t y_elems,                  \\\n                                      int32_t mulx,                     \\\n                                      int32_t muly,                     \\\n                                      int32_t repeat_1,                 \\\n                                      int32_t repeat_2) {               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      if (tblock_id_2 >= num_arrays) { break; }                         \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \\\n      int32_t y_index =                                                 \\\n        tblock_id_1 * TR_BLOCK_DIM * muly +           ", "                  \\\n        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM * muly +                     \\\n        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \\\n      y_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;      \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_num_tblocks(2) * get_local_size(2);            \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_num_tblocks(1) * get_local_size(1);              \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \\\nvoid map_transpose_##NAME##_small(SHARED_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,  ", "                 \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int32_t num_arrays,                   \\\n                                  int32_t x_elems,                      \\\n                                  int32_t y_elems,                      \\\n                                  int32_t mulx,                         \\\n                                  int32_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \\\n      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \\\n      int32_t y_index = global_id_0%y_elems;                            \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      int32_t index_out = x_index * y_elems + y_index;                  \\\n      if (global_id_0 < x_elems * y_elems *",
                                    " num_arrays) {               \\\n        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME##_large(SHARED_MEM_PARAM                      \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int64_t num_arrays,                   \\\n                                  int64_t x_elems,                      \\\n                                  int64_t y_elems,                      \\\n                                  int64_t mulx,                         \\\n                                  int64_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;             \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0); ", "                                  \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      if (tblock_id_2 >= num_arrays) { break; }                         \\\n      int64_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int64_t odata_offset = dst_offset + our_array_offset;             \\\n      int64_t idata_offset = src_offset + our_array_offset;             \\\n      int64_t x_index = global_id_0;                                    \\\n      int64_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                              ", "            \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n\nGEN_TRANSPOSE_KERNELS(1b, uint8_t)\nGEN_TRANSPOSE_KERNELS(2b, uint16_t)\nGEN_TRANSPOSE_KERNELS(4b, uint32_t)\nGEN_TRANSPOSE_KERNELS(8b, uint64_t)\n\n// End of transpose.cl\n// Start of copy.cl\n\n#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \\\nFUTHARK_KERNEL void lmad_copy_##NAME(SHARED_MEM_PARAM                   \\\n                               __global ELEM_TYPE *dst_mem,             \\\n                               int64_t dst_offset,                      \\\n                               __global ELEM_TYPE *src_mem,             \\\n                               int64_t src_offset,                      \\\n                               int64_t n,                               \\\n                               int r,                                   \\\n              ",
                                    "                 int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \\\n                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \\\n                               int64_t shape2, int64_t dst_stride2, int64_t src_stride2, \\\n                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \\\n                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \\\n                               int64_t shape5, int64_t dst_stride5, int64_t src_stride5, \\\n                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \\\n                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \\\n  int64_t gtid = get_global_id(0);                                      \\\n  int64_t remainder = gtid;                                             \\\n                                                                        \\\n  if (gtid >= n) {                                                      \\\n    return;                                                             \\\n  }                                                                     \\\n                                                                        \\\n  if (r > 0) {                                                          \\\n    int64_t i = remainder % shape0;                                     \\\n    dst_offset += i * dst_stride0;                                      \\\n    src_offset += i * src_stride0;                                      \\\n    remainder /= shape0;                                                \\\n  }                                                                     \\\n  if (r > 1) {                                                          \\\n    int64_t i = remainder % shape1;                                     \\\n    dst_offset += i * dst_stride1;                                      \\\n    src_offset += i * src_stride1;                                      \\\n    remainder /= shape1;  ", "                                              \\\n  }                                                                     \\\n  if (r > 2) {                                                          \\\n    int64_t i = remainder % shape2;                                     \\\n    dst_offset += i * dst_stride2;                                      \\\n    src_offset += i * src_stride2;                                      \\\n    remainder /= shape2;                                                \\\n  }                                                                     \\\n  if (r > 3) {                                                          \\\n    int64_t i = remainder % shape3;                                     \\\n    dst_offset += i * dst_stride3;                                      \\\n    src_offset += i * src_stride3;                                      \\\n    remainder /= shape3;                                                \\\n  }                                                                     \\\n  if (r > 4) {                                                          \\\n    int64_t i = remainder % shape4;                                     \\\n    dst_offset += i * dst_stride4;                                      \\\n    src_offset += i * src_stride4;                                      \\\n    remainder /= shape4;                                                \\\n  }                                                                     \\\n  if (r > 5) {                                                          \\\n    int64_t i = remainder % shape5;                                     \\\n    dst_offset += i * dst_stride5;                                      \\\n    src_offset += i * src_stride5;                                      \\\n    remainder /= shape5;                                                \\\n  }                                                                     \\\n  if (r > 6) {                                                          \\\n    int64_t i = remainder % ", "shape6;                                     \\\n    dst_offset += i * dst_stride6;                                      \\\n    src_offset += i * src_stride6;                                      \\\n    remainder /= shape6;                                                \\\n  }                                                                     \\\n  if (r > 7) {                                                          \\\n    int64_t i = remainder % shape7;                                     \\\n    dst_offset += i * dst_stride7;                                      \\\n    src_offset += i * src_stride7;                                      \\\n    remainder /= shape7;                                                \\\n  }                                                                     \\\n                                                                        \\\n  dst_mem[dst_offset] = src_mem[src_offset];                            \\\n}\n\nGEN_COPY_KERNEL(1b, uint8_t)\nGEN_COPY_KERNEL(2b, uint16_t)\nGEN_COPY_KERNEL(4b, uint32_t)\nGEN_COPY_KERNEL(8b, uint64_t)\n\n// End of copy.cl\n\n\n\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i32zireplicate_23463(__local uint64_t *shared_mem_aligned, int64_t num_elems_23459, int32_t val_23460, int64_t replicate_n_23462, int64_t virt_num_tblocks_23468, int64_t num_tblocks_23469, __global unsigned char *mem_23458)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    int32_t replicate_ltid_23464;\n    int32_t tblock_sizze_23466;\n    int32_t replicate_gid_23465;\n    int32_t replicate_gtid_23463;\n    int32_t phys_tblock_id_23470;\n    int32_t iterations_23471;\n    \n    replicate_ltid_23464 = get_local_id(0);\n    tblock_sizze_23466 = get_local_size(0);\n    replicate_gid_23465 = get_tblock_id(0);\n    replicate_gtid_23463 = replicate_gid_23465 * tblock_sizze_23466 + replicate_ltid_23464;\n    phys_tblock_id_23470 = get_tblock_id(0);\n    iterations_23471 = sdiv_up32(sext_i64_i32(virt_num_tblocks_23468) - phys_tblock_id_23470, sext_i",
                                    "64_i32(num_tblocks_23469));\n    for (int32_t i_23472 = 0; i_23472 < iterations_23471; i_23472++) {\n        int32_t virt_tblock_id_23473;\n        int64_t global_tid_23474;\n        int64_t slice_23476;\n        int64_t rep_i_23475;\n        int64_t remnant_23477;\n        \n        virt_tblock_id_23473 = phys_tblock_id_23470 + i_23472 * sext_i64_i32(num_tblocks_23469);\n        global_tid_23474 = sext_i32_i64(virt_tblock_id_23473) * sext_i32_i64(tblock_sizze_23466) + sext_i32_i64(replicate_ltid_23464);\n        slice_23476 = num_elems_23459;\n        rep_i_23475 = global_tid_23474;\n        remnant_23477 = global_tid_23474 - rep_i_23475;\n        if (slt64(global_tid_23474, replicate_n_23462)) {\n            ((__global int32_t *) mem_23458)[rep_i_23475] = val_23460;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i8zireplicate_23525(__local uint64_t *shared_mem_aligned, int64_t num_elems_23521, int8_t val_23522, int64_t replicate_n_23524, int64_t virt_num_tblocks_23530, int64_t num_tblocks_23531, __global unsigned char *mem_23520)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    int32_t replicate_ltid_23526;\n    int32_t tblock_sizze_23528;\n    int32_t replicate_gid_23527;\n    int32_t replicate_gtid_23525;\n    int32_t phys_tblock_id_23532;\n    int32_t iterations_23533;\n    \n    replicate_ltid_23526 = get_local_id(0);\n    tblock_sizze_23528 = get_local_size(0);\n    replicate_gid_23527 = get_tblock_id(0);\n    replicate_gtid_23525 = replicate_gid_23527 * tblock_sizze_23528 + replicate_ltid_23526;\n    phys_tblock_id_23532 = get_tblock_id(0);\n    iterations_23533 = sdiv_up32(sext_i64_i32(virt_num_tblocks_23530) - phys_tblock_id_23532, sext_i64_i32(num_tblocks_23531));\n    for (int32_t i_23534 = 0; i_23534 < iterations_23533; i_23534++) {\n        int32_t virt_tblock_id_23535;\n        int64_t global_tid_23536;\n        int64_t slice_23538;\n        ", "int64_t rep_i_23537;\n        int64_t remnant_23539;\n        \n        virt_tblock_id_23535 = phys_tblock_id_23532 + i_23534 * sext_i64_i32(num_tblocks_23531);\n        global_tid_23536 = sext_i32_i64(virt_tblock_id_23535) * sext_i32_i64(tblock_sizze_23528) + sext_i32_i64(replicate_ltid_23526);\n        slice_23538 = num_elems_23521;\n        rep_i_23537 = global_tid_23536;\n        remnant_23539 = global_tid_23536 - rep_i_23537;\n        if (slt64(global_tid_23536, replicate_n_23524)) {\n            ((__global int8_t *) mem_23520)[rep_i_23537] = val_23522;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(mainzigpuseq_23546_dim1, 1, 1)\nvoid mainzigpuseq_23546(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t i_16715, __global unsigned char *cQ_mem_23046, __global unsigned char *mem_23061)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23548;\n    int32_t tblock_sizze_23551;\n    int32_t wave_sizze_23550;\n    int32_t block_id_23549;\n    int32_t global_tid_23547;\n    int64_t tid_23546;\n    int64_t loopres_22810;\n    \n    local_tid_23548 = get_local_id(0);\n    tblock_sizze_23551 = get_local_size(0);\n    wave_sizze_23550 = LOCKSTEP_WIDTH;\n    block_id_23549 = get_tblock_id(0);\n    global_tid_23547 = block_id_23549 * tblock_sizze_23551 + local_tid_23548;\n    tid_23546 = sext_i32_i64(global_tid_23547);\n    // main.fut:53:34-70\n    loopres_22810 = ((__global int64_t *) cQ_mem_23046)[i_16715];\n    ((__global int64_t *) mem_23061)[(int64_t) 0] = loopres_22810;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(mainzigpuseq_23553_dim1, 1, 1)\nvoid mainzigpuseq_23553(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659", ", __global unsigned char *mem_23061, __global unsigned char *mem_23105, __global unsigned char *mem_23106)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23555;\n    int32_t tblock_sizze_23558;\n    int32_t wave_sizze_23557;\n    int32_t block_id_23556;\n    int32_t global_tid_23554;\n    int64_t tid_23553;\n    int64_t loopres_22812;\n    bool x_22813;\n    bool y_22816;\n    bool bounds_check_22820;\n    bool index_certs_22824;\n    \n    local_tid_23555 = get_local_id(0);\n    tblock_sizze_23558 = get_local_size(0);\n    wave_sizze_23557 = LOCKSTEP_WIDTH;\n    block_id_23556 = get_tblock_id(0);\n    global_tid_23554 = block_id_23556 * tblock_sizze_23558 + local_tid_23555;\n    tid_23553 = sext_i32_i64(global_tid_23554);\n    loopres_22812 = ((__global int64_t *) mem_23061)[(int64_t) 0];\n    // definitions.fut:97:30-42\n    x_22813 = sle64((int64_t) 0, loopres_22812);\n    // definitions.fut:97:30-42\n    y_22816 = slt64(loopres_22812, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n    // definitions.fut:97:30-42\n    bounds_check_22820 = x_22813 && y_22816;\n    // definitions.fut:97:30-42\n    if (!bounds_check_22820) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {\n                global_failure_args[0] = (int64_t) loopres_22812;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                ;\n            }\n            return;\n        }\n    }\n    ((__global bool *) mem_23105)[(int64_t) 0] = bounds_check_22820;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(mainzigpuseq_23614_dim1, 1, 1)\nvoid mainzigpuseq_23614(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, unsigned char cond_20775_bits",
                                    ", __global unsigned char *mem_23061, __global unsigned char *mem_23105, __global unsigned char *mem_23110)\n{\n    bool cond_20775 = cond_20775_bits;\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23616;\n    int32_t tblock_sizze_23619;\n    int32_t wave_sizze_23618;\n    int32_t block_id_23617;\n    int32_t global_tid_23615;\n    int64_t tid_23614;\n    bool bounds_check_22827;\n    bool protect_assert_disj_22828;\n    int64_t loopres_22831;\n    bool index_certs_22832;\n    \n    local_tid_23616 = get_local_id(0);\n    tblock_sizze_23619 = get_local_size(0);\n    wave_sizze_23618 = LOCKSTEP_WIDTH;\n    block_id_23617 = get_tblock_id(0);\n    global_tid_23615 = block_id_23617 * tblock_sizze_23619 + local_tid_23616;\n    tid_23614 = sext_i32_i64(global_tid_23615);\n    bounds_check_22827 = ((__global bool *) mem_23105)[(int64_t) 0];\n    protect_assert_disj_22828 = cond_20775 || bounds_check_22827;\n    loopres_22831 = ((__global int64_t *) mem_23061)[(int64_t) 0];\n    // definitions.fut:132:43-53\n    if (!protect_assert_disj_22828) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 2) == -1) {\n                global_failure_args[0] = (int64_t) loopres_22831;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                ;\n            }\n            return;\n        }\n    }\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(mainzigpuseq_23623_dim1, 1, 1)\nvoid mainzigpuseq_23623(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int8_t u64_res_21014, int64_t measurement_count_21197, __global unsigned char *mem_23052, __global unsigned char *mem_23053, __global unsigned char *mem_23061, __", "global unsigned char *mem_23108, __global unsigned char *mem_23211, __global unsigned char *mem_23212, __global unsigned char *mem_23213, __global unsigned char *mem_23214, __global unsigned char *mem_23215)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23625;\n    int32_t tblock_sizze_23628;\n    int32_t wave_sizze_23627;\n    int32_t block_id_23626;\n    int32_t global_tid_23624;\n    int64_t tid_23623;\n    int64_t defunc_0_f_res_22834;\n    bool x_22839;\n    bool y_22842;\n    bool bounds_check_22846;\n    bool index_certs_22850;\n    int8_t zt_rhs_22853;\n    int8_t zp_rhs_22856;\n    int64_t tmp_22863;\n    int64_t loopres_22867;\n    int64_t zeze_rhs_22868;\n    \n    local_tid_23625 = get_local_id(0);\n    tblock_sizze_23628 = get_local_size(0);\n    wave_sizze_23627 = LOCKSTEP_WIDTH;\n    block_id_23626 = get_tblock_id(0);\n    global_tid_23624 = block_id_23626 * tblock_sizze_23628 + local_tid_23625;\n    tid_23623 = sext_i32_i64(global_tid_23624);\n    defunc_0_f_res_22834 = ((__global int64_t *) mem_23108)[(int64_t) 0];\n    // definitions.fut:25:43-52\n    x_22839 = sle64((int64_t) 0, defunc_0_f_res_22834);\n    // definitions.fut:25:43-52\n    y_22842 = slt64(defunc_0_f_res_22834, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n    // definitions.fut:25:43-52\n    bounds_check_22846 = x_22839 && y_22842;\n    // definitions.fut:25:43-52\n    if (!bounds_check_22846) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 3) == -1) {\n                global_failure_args[0] = (int64_t) defunc_0_f_res_22834;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                ;\n            }\n            return;\n        }\n    }\n    // definitions.fut:89:58-103:37\n    zt_rhs_22853 = ((__global int8_t *) mem_23052)[defunc_0_f_res_22834 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unu", "m_qubitsZRz20U1z7dUzg_16659 + arg_16658];\n    // definitions.fut:26:41-61\n    zp_rhs_22856 = mul8((int8_t) 2, zt_rhs_22853);\n    // definitions.fut:108:35-38\n    tmp_22863 = sub64(defunc_0_f_res_22834, num_qubits_14547);\n    loopres_22867 = ((__global int64_t *) mem_23061)[(int64_t) 0];\n    // definitions.fut:117:31-34\n    zeze_rhs_22868 = add64(num_qubits_14547, loopres_22867);\n    ((__global int64_t *) mem_23211)[(int64_t) 0] = defunc_0_f_res_22834;\n    ((__global int8_t *) mem_23213)[(int64_t) 0] = zp_rhs_22856;\n    ((__global int64_t *) mem_23214)[(int64_t) 0] = tmp_22863;\n    ((__global int64_t *) mem_23215)[(int64_t) 0] = zeze_rhs_22868;\n    ((__global int8_t *) mem_23053)[measurement_count_21197] = u64_res_21014;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(mainzigpuseq_24069_dim1, 1, 1)\nvoid mainzigpuseq_24069(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, __global unsigned char *mem_23052, __global unsigned char *mem_23128)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24071;\n    int32_t tblock_sizze_24074;\n    int32_t wave_sizze_24073;\n    int32_t block_id_24072;\n    int32_t global_tid_24070;\n    int64_t tid_24069;\n    int8_t zt_rhs_22873;\n    int8_t zp_lhs_22876;\n    \n    local_tid_24071 = get_local_id(0);\n    tblock_sizze_24074 = get_local_size(0);\n    wave_sizze_24073 = LOCKSTEP_WIDTH;\n    block_id_24072 = get_tblock_id(0);\n    global_tid_24070 = block_id_24072 * tblock_sizze_24074 + local_tid_24071;\n    tid_24069 = sext_i32_i64(global_tid_24070);\n    // definitions.fut:89:58-133:67\n    zt_rhs_22873 = ((__global int8_t *) mem_23052)[arg_16658 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + arg_16658];\n    // definitions.fut:26:16-36\n    zp_lhs_22876 = mul8((int8_t) 2, zt_rhs_22873);\n    ((__global i",
                                    "nt8_t *) mem_23128)[(int64_t) 0] = zp_lhs_22876;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(mainzigpuseq_24253_dim1, 1, 1)\nvoid mainzigpuseq_24253(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t measurement_count_21197, __global unsigned char *mem_23052, __global unsigned char *mem_23053)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24255;\n    int32_t tblock_sizze_24258;\n    int32_t wave_sizze_24257;\n    int32_t block_id_24256;\n    int32_t global_tid_24254;\n    int64_t tid_24253;\n    int8_t tmp_22880;\n    \n    local_tid_24255 = get_local_id(0);\n    tblock_sizze_24258 = get_local_size(0);\n    wave_sizze_24257 = LOCKSTEP_WIDTH;\n    block_id_24256 = get_tblock_id(0);\n    global_tid_24254 = block_id_24256 * tblock_sizze_24258 + local_tid_24255;\n    tid_24253 = sext_i32_i64(global_tid_24254);\n    // main.fut:7:78-11:83\n    tmp_22880 = ((__global int8_t *) mem_23052)[arg_16658 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + arg_16658];\n    ((__global int8_t *) mem_23053)[measurement_count_21197] = tmp_22880;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(mainzigpuseq_24261_dim1, 1, 1)\nvoid mainzigpuseq_24261(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, __global unsigned char *mem_23061, __global unsigned char *mem_23092, __global unsigned char *mem_23093, __global unsigned char *mem_23094, __global unsigned char *mem_23095, __global unsigned char *mem_23096)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n  ", "  int32_t local_tid_24263;\n    int32_t tblock_sizze_24266;\n    int32_t wave_sizze_24265;\n    int32_t block_id_24264;\n    int32_t global_tid_24262;\n    int64_t tid_24261;\n    int64_t loopres_22885;\n    int64_t tmp_22886;\n    bool y_22893;\n    bool x_22896;\n    bool bounds_check_22900;\n    bool index_certs_22904;\n    bool y_22907;\n    bool x_22910;\n    bool bounds_check_22914;\n    bool index_certs_22918;\n    \n    local_tid_24263 = get_local_id(0);\n    tblock_sizze_24266 = get_local_size(0);\n    wave_sizze_24265 = LOCKSTEP_WIDTH;\n    block_id_24264 = get_tblock_id(0);\n    global_tid_24262 = block_id_24264 * tblock_sizze_24266 + local_tid_24263;\n    tid_24261 = sext_i32_i64(global_tid_24262);\n    loopres_22885 = ((__global int64_t *) mem_23061)[(int64_t) 0];\n    // definitions.fut:64:53-56\n    tmp_22886 = add64(num_qubits_14547, loopres_22885);\n    // definitions.fut:64:17-69\n    ((__global int64_t *) mem_23092)[(int64_t) 0] = arg_16658;\n    ((__global int64_t *) mem_23092)[(int64_t) 1] = loopres_22885;\n    ((__global int64_t *) mem_23092)[(int64_t) 2] = tmp_22886;\n    // definitions.fut:69:22-38\n    y_22893 = slt64(tmp_22886, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n    // definitions.fut:69:22-38\n    x_22896 = sle64((int64_t) 0, tmp_22886);\n    // definitions.fut:69:22-38\n    bounds_check_22900 = y_22893 && x_22896;\n    // definitions.fut:69:22-38\n    if (!bounds_check_22900) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 25) == -1) {\n                global_failure_args[0] = (int64_t) tmp_22886;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                ;\n            }\n            return;\n        }\n    }\n    // definitions.fut:68:22-34\n    y_22907 = slt64(loopres_22885, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n    // definitions.fut:68:22-34\n    x_22910 = sle64((int64_t) 0, loopres_22885);\n    // definitions.fut:68:22-34", "\n    bounds_check_22914 = y_22907 && x_22910;\n    // definitions.fut:68:22-34\n    if (!bounds_check_22914) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 26) == -1) {\n                global_failure_args[0] = (int64_t) loopres_22885;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                ;\n            }\n            return;\n        }\n    }\n    ((__global int64_t *) mem_23093)[(int64_t) 0] = tmp_22886;\n    for (int64_t i_0 = 0; i_0 < (int64_t) 3; i_0++) {\n        ((__global int64_t *) mem_23094)[i_0] = ((__global int64_t *) mem_23092)[i_0];\n    }\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(mainzigpuseq_24295_dim1, 1, 1)\nvoid mainzigpuseq_24295(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, __global unsigned char *mem_23061, __global unsigned char *mem_23079, __global unsigned char *mem_23080, __global unsigned char *mem_23081, __global unsigned char *mem_23082, __global unsigned char *mem_23083)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24297;\n    int32_t tblock_sizze_24300;\n    int32_t wave_sizze_24299;\n    int32_t block_id_24298;\n    int32_t global_tid_24296;\n    int64_t tid_24295;\n    int64_t loopres_22922;\n    int64_t tmp_22923;\n    bool y_22929;\n    bool x_22932;\n    bool bounds_check_22936;\n    bool index_certs_22940;\n    bool y_22943;\n    bool x_22946;\n    bool bounds_check_22950;\n    bool index_certs_22954;\n    \n    local_tid_24297 = get_local_id(0);\n    tblock_sizze_24300 = get_local_size(0);\n    wave_sizze_24299 = LOCKSTEP_WIDTH;\n    block_id_24298 = get_tblock_id(0);\n    global_tid_24296 = block_id_24298 * tblock_sizze_24300 + ",
                                    "local_tid_24297;\n    tid_24295 = sext_i32_i64(global_tid_24296);\n    loopres_22922 = ((__global int64_t *) mem_23061)[(int64_t) 0];\n    // definitions.fut:78:45-48\n    tmp_22923 = add64(num_qubits_14547, loopres_22922);\n    // definitions.fut:78:17-61\n    ((__global int64_t *) mem_23079)[(int64_t) 0] = arg_16658;\n    ((__global int64_t *) mem_23079)[(int64_t) 1] = tmp_22923;\n    // definitions.fut:83:22-38\n    y_22929 = slt64(tmp_22923, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n    // definitions.fut:83:22-38\n    x_22932 = sle64((int64_t) 0, tmp_22923);\n    // definitions.fut:83:22-38\n    bounds_check_22936 = y_22929 && x_22932;\n    // definitions.fut:83:22-38\n    if (!bounds_check_22936) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 28) == -1) {\n                global_failure_args[0] = (int64_t) tmp_22923;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                ;\n            }\n            return;\n        }\n    }\n    // definitions.fut:82:22-34\n    y_22943 = slt64(loopres_22922, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n    // definitions.fut:82:22-34\n    x_22946 = sle64((int64_t) 0, loopres_22922);\n    // definitions.fut:82:22-34\n    bounds_check_22950 = y_22943 && x_22946;\n    // definitions.fut:82:22-34\n    if (!bounds_check_22950) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 29) == -1) {\n                global_failure_args[0] = (int64_t) loopres_22922;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                ;\n            }\n            return;\n        }\n    }\n    ((__global int64_t *) mem_23080)[(int64_t) 0] = tmp_22923;\n    for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n        ((__global int64_t *) mem_23081)[i_0] = ((__global int64_t *) mem_23079)[i_0];\n    }\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_S", "IZED(mainzigpuseq_24329_dim1, 1, 1)\nvoid mainzigpuseq_24329(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t i_16715, __global unsigned char *tQ_mem_23047, __global unsigned char *mem_23061, __global unsigned char *mem_23062, __global unsigned char *mem_23063, __global unsigned char *mem_23064, __global unsigned char *mem_23065, __global unsigned char *mem_23066, __global unsigned char *mem_23067, __global unsigned char *mem_23068, __global unsigned char *mem_23069, __global unsigned char *mem_23070)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24331;\n    int32_t tblock_sizze_24334;\n    int32_t wave_sizze_24333;\n    int32_t block_id_24332;\n    int32_t global_tid_24330;\n    int64_t tid_24329;\n    int64_t loopres_22958;\n    int64_t loopres_22960;\n    int64_t tmp_22961;\n    bool y_22968;\n    bool x_22971;\n    bool bounds_check_22975;\n    bool index_certs_22979;\n    bool y_22982;\n    bool x_22985;\n    bool bounds_check_22989;\n    bool index_certs_22993;\n    int64_t zzib_22996;\n    bool y_22999;\n    bool x_23002;\n    bool bounds_check_23006;\n    bool index_certs_23010;\n    bool y_23013;\n    bool x_23016;\n    bool bounds_check_23020;\n    bool index_certs_23024;\n    \n    local_tid_24331 = get_local_id(0);\n    tblock_sizze_24334 = get_local_size(0);\n    wave_sizze_24333 = LOCKSTEP_WIDTH;\n    block_id_24332 = get_tblock_id(0);\n    global_tid_24330 = block_id_24332 * tblock_sizze_24334 + local_tid_24331;\n    tid_24329 = sext_i32_i64(global_tid_24330);\n    // main.fut:53:34-70\n    loopres_22958 = ((__global int64_t *) tQ_mem_23047)[i_16715];\n    loopres_22960 = ((__global int64_t *) mem_23061)[(int64_t) 0];\n    // definitions.fut:47:37-40\n    tmp_22961", " = add64(num_qubits_14547, loopres_22960);\n    // definitions.fut:46:5-48:18\n    ((__global int64_t *) mem_23062)[(int64_t) 0] = arg_16658;\n    ((__global int64_t *) mem_23062)[(int64_t) 1] = loopres_22958;\n    ((__global int64_t *) mem_23062)[(int64_t) 2] = tmp_22961;\n    // definitions.fut:55:22-34\n    y_22968 = slt64(loopres_22958, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n    // definitions.fut:55:22-34\n    x_22971 = sle64((int64_t) 0, loopres_22958);\n    // definitions.fut:55:22-34\n    bounds_check_22975 = y_22968 && x_22971;\n    // definitions.fut:55:22-34\n    if (!bounds_check_22975) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 31) == -1) {\n                global_failure_args[0] = (int64_t) loopres_22958;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                ;\n            }\n            return;\n        }\n    }\n    // definitions.fut:54:22-34\n    y_22982 = slt64(loopres_22960, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n    // definitions.fut:54:22-34\n    x_22985 = sle64((int64_t) 0, loopres_22960);\n    // definitions.fut:54:22-34\n    bounds_check_22989 = y_22982 && x_22985;\n    // definitions.fut:54:22-34\n    if (!bounds_check_22989) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 32) == -1) {\n                global_failure_args[0] = (int64_t) loopres_22960;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                ;\n            }\n            return;\n        }\n    }\n    // definitions.fut:53:34-37\n    zzib_22996 = add64(num_qubits_14547, loopres_22958);\n    // definitions.fut:53:22-38\n    y_22999 = slt64(zzib_22996, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n    // definitions.fut:53:22-38\n    x_23002 = sle64((int64_t) 0, zzib_22996);\n    // definitions.fut:53:22-38\n    bounds_check_23006 ",
                                    "= y_22999 && x_23002;\n    // definitions.fut:53:22-38\n    if (!bounds_check_23006) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 33) == -1) {\n                global_failure_args[0] = (int64_t) zzib_22996;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                ;\n            }\n            return;\n        }\n    }\n    // definitions.fut:52:22-38\n    y_23013 = slt64(tmp_22961, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n    // definitions.fut:52:22-38\n    x_23016 = sle64((int64_t) 0, tmp_22961);\n    // definitions.fut:52:22-38\n    bounds_check_23020 = y_23013 && x_23016;\n    // definitions.fut:52:22-38\n    if (!bounds_check_23020) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 34) == -1) {\n                global_failure_args[0] = (int64_t) tmp_22961;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                ;\n            }\n            return;\n        }\n    }\n    ((__global int64_t *) mem_23063)[(int64_t) 0] = loopres_22958;\n    ((__global int64_t *) mem_23064)[(int64_t) 0] = tmp_22961;\n    for (int64_t i_0 = 0; i_0 < (int64_t) 3; i_0++) {\n        ((__global int64_t *) mem_23065)[i_0] = ((__global int64_t *) mem_23062)[i_0];\n    }\n    ((__global int64_t *) mem_23068)[(int64_t) 0] = zzib_22996;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid mainzireplicate_23868(__local uint64_t *shared_mem_aligned, int64_t arg_16658, int64_t m_20840, int64_t replicate_n_23867, int64_t virt_num_tblocks_23873, int64_t num_tblocks_23874, __global unsigned char *mem_23223, __global unsigned char *mem_23246)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    int32_t replicate_ltid_23869;\n    int32_t tblock_sizze_23871;\n    int32_t replicate_gid_23870;\n    int32_t replicate_gtid_23868;\n    int32_t phys_tblock_id_23875;\n    int3", "2_t iterations_23876;\n    \n    replicate_ltid_23869 = get_local_id(0);\n    tblock_sizze_23871 = get_local_size(0);\n    replicate_gid_23870 = get_tblock_id(0);\n    replicate_gtid_23868 = replicate_gid_23870 * tblock_sizze_23871 + replicate_ltid_23869;\n    phys_tblock_id_23875 = get_tblock_id(0);\n    iterations_23876 = sdiv_up32(sext_i64_i32(virt_num_tblocks_23873) - phys_tblock_id_23875, sext_i64_i32(num_tblocks_23874));\n    for (int32_t i_23877 = 0; i_23877 < iterations_23876; i_23877++) {\n        int32_t virt_tblock_id_23878;\n        int64_t global_tid_23879;\n        int64_t slice_23882;\n        int64_t slice_23883;\n        int64_t rep_i_23880;\n        int64_t remnant_23884;\n        int64_t rep_i_23881;\n        int64_t remnant_23885;\n        \n        virt_tblock_id_23878 = phys_tblock_id_23875 + i_23877 * sext_i64_i32(num_tblocks_23874);\n        global_tid_23879 = sext_i32_i64(virt_tblock_id_23878) * sext_i32_i64(tblock_sizze_23871) + sext_i32_i64(replicate_ltid_23869);\n        slice_23882 = m_20840;\n        slice_23883 = arg_16658 * slice_23882;\n        rep_i_23880 = squot64(global_tid_23879, slice_23882);\n        remnant_23884 = global_tid_23879 - rep_i_23880 * slice_23882;\n        rep_i_23881 = remnant_23884;\n        remnant_23885 = remnant_23884 - rep_i_23881;\n        if (slt64(global_tid_23879, replicate_n_23867)) {\n            int64_t tmp_23886 = ((__global int64_t *) mem_23223)[rep_i_23881];\n            \n            ((__global int64_t *) mem_23246)[rep_i_23880 * m_20840 + rep_i_23881] = tmp_23886;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid mainzireplicate_23888(__local uint64_t *shared_mem_aligned, int64_t arg_16658, int64_t m_20840, int64_t replicate_n_23887, int64_t virt_num_tblocks_23893, int64_t num_tblocks_23894, __global unsigned char *mem_23223, __global unsigned char *mem_23246)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n  ", "  int32_t replicate_ltid_23889;\n    int32_t tblock_sizze_23891;\n    int32_t replicate_gid_23890;\n    int32_t replicate_gtid_23888;\n    int32_t phys_tblock_id_23895;\n    int32_t iterations_23896;\n    \n    replicate_ltid_23889 = get_local_id(0);\n    tblock_sizze_23891 = get_local_size(0);\n    replicate_gid_23890 = get_tblock_id(0);\n    replicate_gtid_23888 = replicate_gid_23890 * tblock_sizze_23891 + replicate_ltid_23889;\n    phys_tblock_id_23895 = get_tblock_id(0);\n    iterations_23896 = sdiv_up32(sext_i64_i32(virt_num_tblocks_23893) - phys_tblock_id_23895, sext_i64_i32(num_tblocks_23894));\n    for (int32_t i_23897 = 0; i_23897 < iterations_23896; i_23897++) {\n        int32_t virt_tblock_id_23898;\n        int64_t global_tid_23899;\n        int64_t slice_23902;\n        int64_t slice_23903;\n        int64_t rep_i_23900;\n        int64_t remnant_23904;\n        int64_t rep_i_23901;\n        int64_t remnant_23905;\n        \n        virt_tblock_id_23898 = phys_tblock_id_23895 + i_23897 * sext_i64_i32(num_tblocks_23894);\n        global_tid_23899 = sext_i32_i64(virt_tblock_id_23898) * sext_i32_i64(tblock_sizze_23891) + sext_i32_i64(replicate_ltid_23889);\n        slice_23902 = m_20840;\n        slice_23903 = slice_23902;\n        rep_i_23900 = squot64(global_tid_23899, slice_23902);\n        remnant_23904 = global_tid_23899 - rep_i_23900 * slice_23902;\n        rep_i_23901 = remnant_23904;\n        remnant_23905 = remnant_23904 - rep_i_23901;\n        if (slt64(global_tid_23899, replicate_n_23887)) {\n            int64_t tmp_23906 = ((__global int64_t *) mem_23223)[rep_i_23901];\n            \n            ((__global int64_t *) mem_23246)[m_20840 * arg_16658 + (rep_i_23900 * m_20840 + rep_i_23901)] = tmp_23906;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid mainzireplicate_23908(__local uint64_t *shared_mem_aligned, int64_t m_20840, int64_t replicate_n_23907, int64_t virt_num_tblocks_23913, int64_t num_tblocks_2",
                                    "3914, __global unsigned char *mem_23237, __global unsigned char *mem_23243)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    int32_t replicate_ltid_23909;\n    int32_t tblock_sizze_23911;\n    int32_t replicate_gid_23910;\n    int32_t replicate_gtid_23908;\n    int32_t phys_tblock_id_23915;\n    int32_t iterations_23916;\n    \n    replicate_ltid_23909 = get_local_id(0);\n    tblock_sizze_23911 = get_local_size(0);\n    replicate_gid_23910 = get_tblock_id(0);\n    replicate_gtid_23908 = replicate_gid_23910 * tblock_sizze_23911 + replicate_ltid_23909;\n    phys_tblock_id_23915 = get_tblock_id(0);\n    iterations_23916 = sdiv_up32(sext_i64_i32(virt_num_tblocks_23913) - phys_tblock_id_23915, sext_i64_i32(num_tblocks_23914));\n    for (int32_t i_23917 = 0; i_23917 < iterations_23916; i_23917++) {\n        int32_t virt_tblock_id_23918;\n        int64_t global_tid_23919;\n        int64_t slice_23922;\n        int64_t slice_23923;\n        int64_t rep_i_23920;\n        int64_t remnant_23924;\n        int64_t rep_i_23921;\n        int64_t remnant_23925;\n        \n        virt_tblock_id_23918 = phys_tblock_id_23915 + i_23917 * sext_i64_i32(num_tblocks_23914);\n        global_tid_23919 = sext_i32_i64(virt_tblock_id_23918) * sext_i32_i64(tblock_sizze_23911) + sext_i32_i64(replicate_ltid_23909);\n        slice_23922 = m_20840;\n        slice_23923 = slice_23922;\n        rep_i_23920 = squot64(global_tid_23919, slice_23922);\n        remnant_23924 = global_tid_23919 - rep_i_23920 * slice_23922;\n        rep_i_23921 = remnant_23924;\n        remnant_23925 = remnant_23924 - rep_i_23921;\n        if (slt64(global_tid_23919, replicate_n_23907)) {\n            int8_t tmp_23926 = ((__global int8_t *) mem_23237)[rep_i_23921];\n            \n            ((__global int8_t *) mem_23243)[rep_i_23920 * m_20840 + rep_i_23921] = tmp_23926;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid mainzireplicate_24", "219(__local uint64_t *shared_mem_aligned, int64_t m_21071, int64_t replicate_n_24218, int64_t virt_num_tblocks_24224, int64_t num_tblocks_24225, __global unsigned char *mem_23143, __global unsigned char *mem_23144)\n{\n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    int32_t replicate_ltid_24220;\n    int32_t tblock_sizze_24222;\n    int32_t replicate_gid_24221;\n    int32_t replicate_gtid_24219;\n    int32_t phys_tblock_id_24226;\n    int32_t iterations_24227;\n    \n    replicate_ltid_24220 = get_local_id(0);\n    tblock_sizze_24222 = get_local_size(0);\n    replicate_gid_24221 = get_tblock_id(0);\n    replicate_gtid_24219 = replicate_gid_24221 * tblock_sizze_24222 + replicate_ltid_24220;\n    phys_tblock_id_24226 = get_tblock_id(0);\n    iterations_24227 = sdiv_up32(sext_i64_i32(virt_num_tblocks_24224) - phys_tblock_id_24226, sext_i64_i32(num_tblocks_24225));\n    for (int32_t i_24228 = 0; i_24228 < iterations_24227; i_24228++) {\n        int32_t virt_tblock_id_24229;\n        int64_t global_tid_24230;\n        int64_t slice_24233;\n        int64_t slice_24234;\n        int64_t rep_i_24231;\n        int64_t remnant_24235;\n        int64_t rep_i_24232;\n        int64_t remnant_24236;\n        \n        virt_tblock_id_24229 = phys_tblock_id_24226 + i_24228 * sext_i64_i32(num_tblocks_24225);\n        global_tid_24230 = sext_i32_i64(virt_tblock_id_24229) * sext_i32_i64(tblock_sizze_24222) + sext_i32_i64(replicate_ltid_24220);\n        slice_24233 = m_21071;\n        slice_24234 = slice_24233;\n        rep_i_24231 = squot64(global_tid_24230, slice_24233);\n        remnant_24235 = global_tid_24230 - rep_i_24231 * slice_24233;\n        rep_i_24232 = remnant_24235;\n        remnant_24236 = remnant_24235 - rep_i_24232;\n        if (slt64(global_tid_24230, replicate_n_24218)) {\n            int8_t tmp_24237 = ((__global int8_t *) mem_23143)[rep_i_24232];\n            \n            ((__global int8_t *) mem_23144)[rep_i_24231 * m_21071 + rep_i_24232] = tmp_24237;\n      ", "  }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(mainziscan_stage1_21514_dim1, 1, 1)\nvoid mainziscan_stage1_21514(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int32_t num_threads_23631, __global unsigned char *mem_23052, __global unsigned char *mem_23061, __global unsigned char *mem_23211, __global unsigned char *mem_23219, __global unsigned char *mem_23221)\n{\n    #define segscan_tblock_sizze_21509 (mainziscan_stage1_21514zisegscan_tblock_sizze_21509)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local unsigned char *scan_arr_mem_23637_backing_0 = &shared_mem[0];\n    const int64_t scan_arr_mem_23637_backing_0_offset = 0 + (smax64((int64_t) 1, (int64_t) 8 * segscan_tblock_sizze_21509) + srem64((int64_t) 8 - srem64(smax64((int64_t) 1, (int64_t) 8 * segscan_tblock_sizze_21509), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_23633;\n    int32_t tblock_sizze_23636;\n    int32_t wave_sizze_23635;\n    int32_t block_id_23634;\n    int32_t global_tid_23632;\n    int64_t phys_tid_21514;\n    __local unsigned char *scan_arr_mem_23637;\n    int64_t eta_p_20827;\n    int64_t eta_p_20828;\n    \n    local_tid_23633 = get_local_id(0);\n    tblock_sizze_23636 = get_local_size(0);\n    wave_sizze_23635 = LOCKSTEP_WIDTH;\n    block_id_23634 = get_tblock_id(0);\n    global_tid_23632 = block_id_23634 * tblock_sizze_23636 + local_tid_23633;\n    phys_tid_21514 = sext_i32_i64(global_tid_23632);\n    scan_arr_mem_23637 = (__local unsigned char *) scan_arr_mem_",
                                    "23637_backing_0;\n    eta_p_20827 = (int64_t) 0;\n    for (int64_t j_23639 = 0; j_23639 < sdiv_up64(arg_16658, sext_i32_i64(num_threads_23631)); j_23639++) {\n        int64_t chunk_offset_23640;\n        int64_t flat_idx_23641;\n        int64_t gtid_21513;\n        int64_t defunc_0_op_res_20829;\n        int64_t eta_p_23642;\n        int64_t eta_p_23643;\n        int64_t eta_p_23645;\n        int64_t eta_p_23646;\n        bool ltid_in_bounds_23648;\n        int32_t skip_threads_23649;\n        int32_t skip_threads_23651;\n        bool no_carry_in_23653;\n        bool crosses_segment_23655;\n        bool should_load_carry_23656;\n        \n        chunk_offset_23640 = segscan_tblock_sizze_21509 * j_23639 + sext_i32_i64(block_id_23634) * (segscan_tblock_sizze_21509 * sdiv_up64(arg_16658, sext_i32_i64(num_threads_23631)));\n        flat_idx_23641 = chunk_offset_23640 + sext_i32_i64(local_tid_23633);\n        gtid_21513 = flat_idx_23641;\n        // threads in bounds read input\n        if (slt64(gtid_21513, arg_16658)) {\n            int64_t defunc_0_f_res_22837;\n            bool cond_20813;\n            bool cond_20814;\n            bool lifted_lambda_res_20815;\n            int64_t defunc_0_f_res_20826;\n            \n            defunc_0_f_res_22837 = ((__global int64_t *) mem_23211)[(int64_t) 0];\n            // definitions.fut:100:43-70\n            cond_20813 = gtid_21513 == defunc_0_f_res_22837;\n            // definitions.fut:100:43-70\n            cond_20814 = !cond_20813;\n            // definitions.fut:100:43-70\n            if (cond_20814) {\n                int64_t loopres_22836;\n                bool y_20817;\n                bool index_certs_20819;\n                bool x_20820;\n                bool y_20821;\n                bool bounds_check_20822;\n                bool index_certs_20823;\n                int8_t zeze_lhs_20824;\n                bool lifted_lambda_res_t_res_20825;\n                \n                loopres_22836 = ((__global int64_t *) mem_23061)[(int64_t) 0];\n                // d", "efinitions.fut:100:53-62\n                y_20817 = slt64(gtid_21513, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n                // definitions.fut:100:53-62\n                if (!y_20817) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 4) == -1) {\n                            global_failure_args[0] = (int64_t) gtid_21513;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                // definitions.fut:100:53-65\n                x_20820 = sle64((int64_t) 0, loopres_22836);\n                // definitions.fut:100:53-65\n                y_20821 = slt64(loopres_22836, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n                // definitions.fut:100:53-65\n                bounds_check_20822 = x_20820 && y_20821;\n                // definitions.fut:100:53-65\n                if (!bounds_check_20822) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 5) == -1) {\n                            global_failure_args[0] = (int64_t) loopres_22836;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                // definitions.fut:100:29-85\n                zeze_lhs_20824 = ((__global int8_t *) mem_23052)[gtid_21513 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + loopres_22836];\n                // definitions.fut:100:66-70\n                lifted_lambda_res_t_res_20825 = zeze_lhs_20824 == (int8_t) 1;\n                lifted_lamb", "da_res_20815 = lifted_lambda_res_t_res_20825;\n            } else {\n                lifted_lambda_res_20815 = 0;\n            }\n            // definitions.fut:100:29-85\n            defunc_0_f_res_20826 = btoi_bool_i64(lifted_lambda_res_20815);\n            // write to-scan values to parameters\n            eta_p_20828 = defunc_0_f_res_20826;\n            // write mapped values results to global memory\n            ((__global int64_t *) mem_23221)[gtid_21513] = defunc_0_f_res_20826;\n        }\n        // do one intra-group scan operation\n        // maybe restore some to-scan values to parameters, or read neutral\n        if (!slt64(gtid_21513, arg_16658)) {\n            eta_p_20828 = (int64_t) 0;\n        }\n        // combine with carry and write to shared memory\n        // definitions.fut:100:29-85\n        defunc_0_op_res_20829 = add64(eta_p_20827, eta_p_20828);\n        ((__local int64_t *) scan_arr_mem_23637)[sext_i32_i64(local_tid_23633)] = defunc_0_op_res_20829;\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_in_bounds_23648 = slt64(sext_i32_i64(local_tid_23633), segscan_tblock_sizze_21509);\n        // read input for in-block scan\n        if (ltid_in_bounds_23648) {\n            eta_p_23643 = ((volatile __local int64_t *) scan_arr_mem_23637)[sext_i32_i64(local_tid_23633)];\n            if ((local_tid_23633 - squot32(local_tid_23633, 32) * 32) == 0) {\n                eta_p_23642 = eta_p_23643;\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        skip_threads_23649 = 1;\n        while (slt32(skip_threads_23649, 32)) {\n            bool thread_active_23650 = sle32(skip_threads_23649, local_tid_23633 - squot32(local_tid_23633, 32) * 32) && ltid_in_bounds_23648;\n            \n            if (thread_active_23650) {\n                // read operands\n                eta_p_23642 = ((volatile __local int64_t *) scan_arr_mem_23637)[sext_i32_i64(",
                                    "local_tid_23633) - sext_i32_i64(skip_threads_23649)];\n            }\n            // perform operation\n            if (thread_active_23650) {\n                int64_t defunc_0_op_res_23644;\n                \n                // definitions.fut:100:29-85\n                defunc_0_op_res_23644 = add64(eta_p_23642, eta_p_23643);\n                eta_p_23642 = defunc_0_op_res_23644;\n            }\n            if (sle32(wave_sizze_23635, skip_threads_23649)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_23650) {\n                // write result\n                ((volatile __local int64_t *) scan_arr_mem_23637)[sext_i32_i64(local_tid_23633)] = eta_p_23642;\n                eta_p_23643 = eta_p_23642;\n            }\n            if (sle32(wave_sizze_23635, skip_threads_23649)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_23649 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // last thread of block 'i' writes its result to offset 'i'\n        if ((local_tid_23633 - squot32(local_tid_23633, 32) * 32) == 31 && ltid_in_bounds_23648) {\n            ((volatile __local int64_t *) scan_arr_mem_23637)[sext_i32_i64(squot32(local_tid_23633, 32))] = eta_p_23642;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n        // read input for in-block scan\n        if (squot32(local_tid_23633, 32) == 0 && ltid_in_bounds_23648) {\n            eta_p_23646 = ((volatile __local int64_t *) scan_arr_mem_23637)[sext_i32_i64(local_tid_23633)];\n            if ((local_tid_23633 - squot32(local_tid_23633, 32) * 32) == 0) {\n                eta_p_23645 = eta_p_23646;\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        skip_threads_23651 = 1;\n        while (slt32(skip_threads_23651, 32)) {\n            bool thread_active_23652 = sle32(skip_threads_23651, local_tid_23633 - squot32(local_tid_23633, 32) ", "* 32) && (squot32(local_tid_23633, 32) == 0 && ltid_in_bounds_23648);\n            \n            if (thread_active_23652) {\n                // read operands\n                eta_p_23645 = ((volatile __local int64_t *) scan_arr_mem_23637)[sext_i32_i64(local_tid_23633) - sext_i32_i64(skip_threads_23651)];\n            }\n            // perform operation\n            if (thread_active_23652) {\n                int64_t defunc_0_op_res_23647;\n                \n                // definitions.fut:100:29-85\n                defunc_0_op_res_23647 = add64(eta_p_23645, eta_p_23646);\n                eta_p_23645 = defunc_0_op_res_23647;\n            }\n            if (sle32(wave_sizze_23635, skip_threads_23651)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_23652) {\n                // write result\n                ((volatile __local int64_t *) scan_arr_mem_23637)[sext_i32_i64(local_tid_23633)] = eta_p_23645;\n                eta_p_23646 = eta_p_23645;\n            }\n            if (sle32(wave_sizze_23635, skip_threads_23651)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_23651 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        no_carry_in_23653 = squot32(local_tid_23633, 32) == 0 || !ltid_in_bounds_23648;\n        // carry-in for every block except the first\n        // read operands\n        if (!no_carry_in_23653) {\n            eta_p_23643 = eta_p_23642;\n            eta_p_23642 = ((__local int64_t *) scan_arr_mem_23637)[sext_i32_i64(squot32(local_tid_23633, 32)) - (int64_t) 1];\n        }\n        // perform operation\n        if (!no_carry_in_23653) {\n            int64_t defunc_0_op_res_23644;\n            \n            // definitions.fut:100:29-85\n            defunc_0_op_res_23644 = add64(eta_p_23642, eta_p_23643);\n            eta_p_23642 = defunc_0_op_res_23644;\n        }\n        // write final result\n        if (!no_carry_in_23653) {\n            ((__local int64_t *) scan_arr_mem_23637)[sext_i32_i64", "(local_tid_23633)] = eta_p_23642;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // restore correct values for first block\n        if (squot32(local_tid_23633, 32) == 0 && ltid_in_bounds_23648) {\n            ((__local int64_t *) scan_arr_mem_23637)[sext_i32_i64(local_tid_23633)] = eta_p_23643;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // threads in bounds write partial scan result\n        if (slt64(gtid_21513, arg_16658)) {\n            int64_t tmp_23654 = ((__local int64_t *) scan_arr_mem_23637)[sext_i32_i64(local_tid_23633)];\n            \n            ((__global int64_t *) mem_23219)[gtid_21513] = tmp_23654;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // first thread reads last element as carry-in for next iteration\n        crosses_segment_23655 = 0;\n        should_load_carry_23656 = local_tid_23633 == 0 && !crosses_segment_23655;\n        if (should_load_carry_23656) {\n            eta_p_20827 = ((__local int64_t *) scan_arr_mem_23637)[segscan_tblock_sizze_21509 - (int64_t) 1];\n        }\n        if (!should_load_carry_23656) {\n            eta_p_20827 = (int64_t) 0;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef segscan_tblock_sizze_21509\n}\nFUTHARK_KERNEL_SIZED(mainziscan_stage1_22051_dim1, 1, 1)\nvoid mainziscan_stage1_22051(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int32_t num_threads_23994, __global unsigned char *mem_23052, __global unsigned char *mem_23061, __global unsigned char *mem_23119, __global unsigned char *mem_23122, __global unsigned char *mem_23124)\n{\n    #define segscan_tblock_sizze_22046 (mainziscan_stage1_22051zisegscan_tblock_sizze_22046)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local unsigned char *scan_arr_mem_24000_b",
                                    "acking_0 = &shared_mem[0];\n    const int64_t scan_arr_mem_24000_backing_0_offset = 0 + (smax64((int64_t) 1, (int64_t) 8 * segscan_tblock_sizze_22046) + srem64((int64_t) 8 - srem64(smax64((int64_t) 1, (int64_t) 8 * segscan_tblock_sizze_22046), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_23996;\n    int32_t tblock_sizze_23999;\n    int32_t wave_sizze_23998;\n    int32_t block_id_23997;\n    int32_t global_tid_23995;\n    int64_t phys_tid_22051;\n    __local unsigned char *scan_arr_mem_24000;\n    int64_t eta_p_21054;\n    int64_t eta_p_21055;\n    \n    local_tid_23996 = get_local_id(0);\n    tblock_sizze_23999 = get_local_size(0);\n    wave_sizze_23998 = LOCKSTEP_WIDTH;\n    block_id_23997 = get_tblock_id(0);\n    global_tid_23995 = block_id_23997 * tblock_sizze_23999 + local_tid_23996;\n    phys_tid_22051 = sext_i32_i64(global_tid_23995);\n    scan_arr_mem_24000 = (__local unsigned char *) scan_arr_mem_24000_backing_0;\n    eta_p_21054 = (int64_t) 0;\n    for (int64_t j_24002 = 0; j_24002 < sdiv_up64(num_qubits_14547, sext_i32_i64(num_threads_23994)); j_24002++) {\n        int64_t chunk_offset_24003;\n        int64_t flat_idx_24004;\n        int64_t gtid_22050;\n        int64_t defunc_0_op_res_21056;\n        int64_t eta_p_24005;\n        int64_t eta_p_24006;\n        int64_t eta_p_24008;\n        int64_t eta_p_24009;\n        bool ltid_in_bounds_24011;\n        int32_t skip_threads_24012;\n        int32_t skip_threads_24014;\n        bool no_carry_in_24016;\n        bool crosses_segment_24018;\n        bool should_load_carry_24019;\n        \n        chunk_offset_24003 = segscan_tblock_sizze_22046 * j_24002 + sext_i32_i64(block_id_23997) * (segscan_tblock_sizze_22046 * sdiv_up64(num_qubits_14547, sext_i32_i64(num_threads_23994)));\n        flat_idx_24004 = chu", "nk_offset_24003 + sext_i32_i64(local_tid_23996);\n        gtid_22050 = flat_idx_24004;\n        // threads in bounds read input\n        if (slt64(gtid_22050, num_qubits_14547)) {\n            bool y_21046;\n            bool index_certs_21048;\n            int64_t loopres_22872;\n            int8_t zeze_lhs_21049;\n            bool lifted_lambda_res_21050;\n            int64_t defunc_0_f_res_21051;\n            int64_t tmp_21052;\n            int64_t mem_23117[(int64_t) 2];\n            \n            // definitions.fut:132:43-50\n            y_21046 = slt64(gtid_22050, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            // definitions.fut:132:43-50\n            if (!y_21046) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 15) == -1) {\n                        global_failure_args[0] = (int64_t) gtid_22050;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            loopres_22872 = ((__global int64_t *) mem_23061)[(int64_t) 0];\n            // definitions.fut:132:29-67\n            zeze_lhs_21049 = ((__global int8_t *) mem_23052)[gtid_22050 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + loopres_22872];\n            // definitions.fut:132:54-58\n            lifted_lambda_res_21050 = zeze_lhs_21049 == (int8_t) 1;\n            // definitions.fut:132:29-67\n            defunc_0_f_res_21051 = btoi_bool_i64(lifted_lambda_res_21050);\n            // definitions.fut:28:38-41\n            tmp_21052 = add64(num_qubits_14547, gtid_22050);\n            // definitions.fut:28:12-52\n            mem_23117[(int64_t) 0] = gtid_22050;\n            mem_23117[(int64_t) 1] = tmp_21052;\n            // write to-scan values to parameters\n            eta_p_21055 = defunc_0_f_res_21051;\n            // write ", "mapped values results to global memory\n            for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                ((__global int64_t *) mem_23122)[gtid_22050 * (int64_t) 2 + i_0] = mem_23117[i_0];\n            }\n            ((__global int64_t *) mem_23124)[gtid_22050] = defunc_0_f_res_21051;\n        }\n        // do one intra-group scan operation\n        // maybe restore some to-scan values to parameters, or read neutral\n        if (!slt64(gtid_22050, num_qubits_14547)) {\n            eta_p_21055 = (int64_t) 0;\n        }\n        // combine with carry and write to shared memory\n        // definitions.fut:132:29-67\n        defunc_0_op_res_21056 = add64(eta_p_21054, eta_p_21055);\n        ((__local int64_t *) scan_arr_mem_24000)[sext_i32_i64(local_tid_23996)] = defunc_0_op_res_21056;\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_in_bounds_24011 = slt64(sext_i32_i64(local_tid_23996), segscan_tblock_sizze_22046);\n        // read input for in-block scan\n        if (ltid_in_bounds_24011) {\n            eta_p_24006 = ((volatile __local int64_t *) scan_arr_mem_24000)[sext_i32_i64(local_tid_23996)];\n            if ((local_tid_23996 - squot32(local_tid_23996, 32) * 32) == 0) {\n                eta_p_24005 = eta_p_24006;\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        skip_threads_24012 = 1;\n        while (slt32(skip_threads_24012, 32)) {\n            bool thread_active_24013 = sle32(skip_threads_24012, local_tid_23996 - squot32(local_tid_23996, 32) * 32) && ltid_in_bounds_24011;\n            \n            if (thread_active_24013) {\n                // read operands\n                eta_p_24005 = ((volatile __local int64_t *) scan_arr_mem_24000)[sext_i32_i64(local_tid_23996) - sext_i32_i64(skip_threads_24012)];\n            }\n            // perform operation\n            if (thread_active_24013) {\n                int64_t defunc_0_op_res",
                                    "_24007;\n                \n                // definitions.fut:132:29-67\n                defunc_0_op_res_24007 = add64(eta_p_24005, eta_p_24006);\n                eta_p_24005 = defunc_0_op_res_24007;\n            }\n            if (sle32(wave_sizze_23998, skip_threads_24012)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_24013) {\n                // write result\n                ((volatile __local int64_t *) scan_arr_mem_24000)[sext_i32_i64(local_tid_23996)] = eta_p_24005;\n                eta_p_24006 = eta_p_24005;\n            }\n            if (sle32(wave_sizze_23998, skip_threads_24012)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_24012 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // last thread of block 'i' writes its result to offset 'i'\n        if ((local_tid_23996 - squot32(local_tid_23996, 32) * 32) == 31 && ltid_in_bounds_24011) {\n            ((volatile __local int64_t *) scan_arr_mem_24000)[sext_i32_i64(squot32(local_tid_23996, 32))] = eta_p_24005;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n        // read input for in-block scan\n        if (squot32(local_tid_23996, 32) == 0 && ltid_in_bounds_24011) {\n            eta_p_24009 = ((volatile __local int64_t *) scan_arr_mem_24000)[sext_i32_i64(local_tid_23996)];\n            if ((local_tid_23996 - squot32(local_tid_23996, 32) * 32) == 0) {\n                eta_p_24008 = eta_p_24009;\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        skip_threads_24014 = 1;\n        while (slt32(skip_threads_24014, 32)) {\n            bool thread_active_24015 = sle32(skip_threads_24014, local_tid_23996 - squot32(local_tid_23996, 32) * 32) && (squot32(local_tid_23996, 32) == 0 && ltid_in_bounds_24011);\n            \n            if (thread_active_24015) {\n                // read operands\n                eta_p_24", "008 = ((volatile __local int64_t *) scan_arr_mem_24000)[sext_i32_i64(local_tid_23996) - sext_i32_i64(skip_threads_24014)];\n            }\n            // perform operation\n            if (thread_active_24015) {\n                int64_t defunc_0_op_res_24010;\n                \n                // definitions.fut:132:29-67\n                defunc_0_op_res_24010 = add64(eta_p_24008, eta_p_24009);\n                eta_p_24008 = defunc_0_op_res_24010;\n            }\n            if (sle32(wave_sizze_23998, skip_threads_24014)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_24015) {\n                // write result\n                ((volatile __local int64_t *) scan_arr_mem_24000)[sext_i32_i64(local_tid_23996)] = eta_p_24008;\n                eta_p_24009 = eta_p_24008;\n            }\n            if (sle32(wave_sizze_23998, skip_threads_24014)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_24014 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        no_carry_in_24016 = squot32(local_tid_23996, 32) == 0 || !ltid_in_bounds_24011;\n        // carry-in for every block except the first\n        // read operands\n        if (!no_carry_in_24016) {\n            eta_p_24006 = eta_p_24005;\n            eta_p_24005 = ((__local int64_t *) scan_arr_mem_24000)[sext_i32_i64(squot32(local_tid_23996, 32)) - (int64_t) 1];\n        }\n        // perform operation\n        if (!no_carry_in_24016) {\n            int64_t defunc_0_op_res_24007;\n            \n            // definitions.fut:132:29-67\n            defunc_0_op_res_24007 = add64(eta_p_24005, eta_p_24006);\n            eta_p_24005 = defunc_0_op_res_24007;\n        }\n        // write final result\n        if (!no_carry_in_24016) {\n            ((__local int64_t *) scan_arr_mem_24000)[sext_i32_i64(local_tid_23996)] = eta_p_24005;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // restore correct values for first block\n        if (squot32(local_tid_23996, 32) == 0 &", "& ltid_in_bounds_24011) {\n            ((__local int64_t *) scan_arr_mem_24000)[sext_i32_i64(local_tid_23996)] = eta_p_24006;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // threads in bounds write partial scan result\n        if (slt64(gtid_22050, num_qubits_14547)) {\n            int64_t tmp_24017 = ((__local int64_t *) scan_arr_mem_24000)[sext_i32_i64(local_tid_23996)];\n            \n            ((__global int64_t *) mem_23119)[gtid_22050] = tmp_24017;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // first thread reads last element as carry-in for next iteration\n        crosses_segment_24018 = 0;\n        should_load_carry_24019 = local_tid_23996 == 0 && !crosses_segment_24018;\n        if (should_load_carry_24019) {\n            eta_p_21054 = ((__local int64_t *) scan_arr_mem_24000)[segscan_tblock_sizze_22046 - (int64_t) 1];\n        }\n        if (!should_load_carry_24019) {\n            eta_p_21054 = (int64_t) 0;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef segscan_tblock_sizze_22046\n}\nFUTHARK_KERNEL\nvoid mainziscan_stage2_21514(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t arg_16658, int64_t stage1_num_tblocks_23630, int32_t num_threads_23631, __global unsigned char *mem_23219)\n{\n    #define segscan_tblock_sizze_21509 (mainziscan_stage2_21514zisegscan_tblock_sizze_21509)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local unsigned char *scan_arr_mem_23662_backing_0 = &shared_mem[0];\n    const int64_t scan_arr_mem_23662_backing_0_offset = 0 + (smax64((int64_t) 1, (int64_t) 8 * stage1_num_tblocks_23630) + srem64((int64_t) 8 - srem64(smax64((int64_t) 1, (int64_t) 8 * stage1_num_tblocks_23630), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23658;\n    int32_t tblock_sizze_23661;\n    int32_t wave_sizze_23660;\n    int32_t block_id_23659;\n    int32_t global_tid",
                                    "_23657;\n    int64_t phys_tid_21514;\n    __local unsigned char *scan_arr_mem_23662;\n    int64_t flat_idx_23664;\n    int64_t gtid_21513;\n    int64_t eta_p_20827;\n    int64_t eta_p_20828;\n    int64_t eta_p_23666;\n    int64_t eta_p_23667;\n    bool ltid_in_bounds_23669;\n    int32_t skip_threads_23670;\n    int32_t skip_threads_23672;\n    bool no_carry_in_23674;\n    \n    local_tid_23658 = get_local_id(0);\n    tblock_sizze_23661 = get_local_size(0);\n    wave_sizze_23660 = LOCKSTEP_WIDTH;\n    block_id_23659 = get_tblock_id(0);\n    global_tid_23657 = block_id_23659 * tblock_sizze_23661 + local_tid_23658;\n    phys_tid_21514 = sext_i32_i64(global_tid_23657);\n    scan_arr_mem_23662 = (__local unsigned char *) scan_arr_mem_23662_backing_0;\n    flat_idx_23664 = (sext_i32_i64(local_tid_23658) + (int64_t) 1) * (segscan_tblock_sizze_21509 * sdiv_up64(arg_16658, sext_i32_i64(num_threads_23631))) - (int64_t) 1;\n    gtid_21513 = flat_idx_23664;\n    // threads in bound read carries; others get neutral element\n    if (slt64(gtid_21513, arg_16658)) {\n        int64_t tmp_23665 = ((__global int64_t *) mem_23219)[gtid_21513];\n        \n        ((__local int64_t *) scan_arr_mem_23662)[sext_i32_i64(local_tid_23658)] = tmp_23665;\n    } else {\n        ((__local int64_t *) scan_arr_mem_23662)[sext_i32_i64(local_tid_23658)] = (int64_t) 0;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_in_bounds_23669 = slt64(sext_i32_i64(local_tid_23658), stage1_num_tblocks_23630);\n    // read input for in-block scan\n    if (ltid_in_bounds_23669) {\n        eta_p_20828 = ((volatile __local int64_t *) scan_arr_mem_23662)[sext_i32_i64(local_tid_23658)];\n        if ((local_tid_23658 - squot32(local_tid_23658, 32) * 32) == 0) {\n            eta_p_20827 = eta_p_20828;\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    skip_threads_23670 = 1;\n    while (slt32(skip_threads_23670, 32)) {\n        bool thread_active_23671 = sle32(skip_threads_23670, local_tid_23658 - squot32(local_tid_23658, 32) * 32) && ", "ltid_in_bounds_23669;\n        \n        if (thread_active_23671) {\n            // read operands\n            eta_p_20827 = ((volatile __local int64_t *) scan_arr_mem_23662)[sext_i32_i64(local_tid_23658) - sext_i32_i64(skip_threads_23670)];\n        }\n        // perform operation\n        if (thread_active_23671) {\n            int64_t defunc_0_op_res_20829;\n            \n            // definitions.fut:100:29-85\n            defunc_0_op_res_20829 = add64(eta_p_20827, eta_p_20828);\n            eta_p_20827 = defunc_0_op_res_20829;\n        }\n        if (sle32(wave_sizze_23660, skip_threads_23670)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        if (thread_active_23671) {\n            // write result\n            ((volatile __local int64_t *) scan_arr_mem_23662)[sext_i32_i64(local_tid_23658)] = eta_p_20827;\n            eta_p_20828 = eta_p_20827;\n        }\n        if (sle32(wave_sizze_23660, skip_threads_23670)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        skip_threads_23670 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    if ((local_tid_23658 - squot32(local_tid_23658, 32) * 32) == 31 && ltid_in_bounds_23669) {\n        ((volatile __local int64_t *) scan_arr_mem_23662)[sext_i32_i64(squot32(local_tid_23658, 32))] = eta_p_20827;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    // read input for in-block scan\n    if (squot32(local_tid_23658, 32) == 0 && ltid_in_bounds_23669) {\n        eta_p_23667 = ((volatile __local int64_t *) scan_arr_mem_23662)[sext_i32_i64(local_tid_23658)];\n        if ((local_tid_23658 - squot32(local_tid_23658, 32) * 32) == 0) {\n            eta_p_23666 = eta_p_23667;\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    skip_threads_23672 = 1;\n    while (slt32(skip_threads_23672, 32)) {\n        bool thread_active_23673 = sle32(skip_threads_23672, local_tid_23658 - squot", "32(local_tid_23658, 32) * 32) && (squot32(local_tid_23658, 32) == 0 && ltid_in_bounds_23669);\n        \n        if (thread_active_23673) {\n            // read operands\n            eta_p_23666 = ((volatile __local int64_t *) scan_arr_mem_23662)[sext_i32_i64(local_tid_23658) - sext_i32_i64(skip_threads_23672)];\n        }\n        // perform operation\n        if (thread_active_23673) {\n            int64_t defunc_0_op_res_23668;\n            \n            // definitions.fut:100:29-85\n            defunc_0_op_res_23668 = add64(eta_p_23666, eta_p_23667);\n            eta_p_23666 = defunc_0_op_res_23668;\n        }\n        if (sle32(wave_sizze_23660, skip_threads_23672)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        if (thread_active_23673) {\n            // write result\n            ((volatile __local int64_t *) scan_arr_mem_23662)[sext_i32_i64(local_tid_23658)] = eta_p_23666;\n            eta_p_23667 = eta_p_23666;\n        }\n        if (sle32(wave_sizze_23660, skip_threads_23672)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        skip_threads_23672 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_23674 = squot32(local_tid_23658, 32) == 0 || !ltid_in_bounds_23669;\n    // carry-in for every block except the first\n    // read operands\n    if (!no_carry_in_23674) {\n        eta_p_20828 = eta_p_20827;\n        eta_p_20827 = ((__local int64_t *) scan_arr_mem_23662)[sext_i32_i64(squot32(local_tid_23658, 32)) - (int64_t) 1];\n    }\n    // perform operation\n    if (!no_carry_in_23674) {\n        int64_t defunc_0_op_res_20829;\n        \n        // definitions.fut:100:29-85\n        defunc_0_op_res_20829 = add64(eta_p_20827, eta_p_20828);\n        eta_p_20827 = defunc_0_op_res_20829;\n    }\n    // write final result\n    if (!no_carry_in_23674) {\n        ((__local int64_t *) scan_arr_mem_23662)[sext_i32_i64(local_tid_23658)] = eta_p_20827;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    if (squot32(local_tid_23658, 32)",
                                    " == 0 && ltid_in_bounds_23669) {\n        ((__local int64_t *) scan_arr_mem_23662)[sext_i32_i64(local_tid_23658)] = eta_p_20828;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // threads in bounds write scanned carries\n    if (slt64(gtid_21513, arg_16658)) {\n        int64_t tmp_23675 = ((__local int64_t *) scan_arr_mem_23662)[sext_i32_i64(local_tid_23658)];\n        \n        ((__global int64_t *) mem_23219)[gtid_21513] = tmp_23675;\n    }\n    \n  error_1:\n    return;\n    #undef segscan_tblock_sizze_21509\n}\nFUTHARK_KERNEL\nvoid mainziscan_stage2_22051(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t num_qubits_14547, int64_t stage1_num_tblocks_23993, int32_t num_threads_23994, __global unsigned char *mem_23119)\n{\n    #define segscan_tblock_sizze_22046 (mainziscan_stage2_22051zisegscan_tblock_sizze_22046)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local unsigned char *scan_arr_mem_24025_backing_0 = &shared_mem[0];\n    const int64_t scan_arr_mem_24025_backing_0_offset = 0 + (smax64((int64_t) 1, (int64_t) 8 * stage1_num_tblocks_23993) + srem64((int64_t) 8 - srem64(smax64((int64_t) 1, (int64_t) 8 * stage1_num_tblocks_23993), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24021;\n    int32_t tblock_sizze_24024;\n    int32_t wave_sizze_24023;\n    int32_t block_id_24022;\n    int32_t global_tid_24020;\n    int64_t phys_tid_22051;\n    __local unsigned char *scan_arr_mem_24025;\n    int64_t flat_idx_24027;\n    int64_t gtid_22050;\n    int64_t eta_p_21054;\n    int64_t eta_p_21055;\n    int64_t eta_p_24029;\n    int64_t eta_p_24030;\n    bool ltid_in_bounds_24032;\n    int32_t skip_threads_24033;\n    int32_t skip_threads_24035;\n    bool no_carry_in_24037;\n    \n    local_tid_24021 = get_local_id(0);\n    tblock_sizze_24024 = get_local_size(0);\n    wave_sizze_24023 = LOCKSTEP_WIDTH;\n    block_id_24022 = get_tblock_id(0);\n    global_tid_24020 = block_i", "d_24022 * tblock_sizze_24024 + local_tid_24021;\n    phys_tid_22051 = sext_i32_i64(global_tid_24020);\n    scan_arr_mem_24025 = (__local unsigned char *) scan_arr_mem_24025_backing_0;\n    flat_idx_24027 = (sext_i32_i64(local_tid_24021) + (int64_t) 1) * (segscan_tblock_sizze_22046 * sdiv_up64(num_qubits_14547, sext_i32_i64(num_threads_23994))) - (int64_t) 1;\n    gtid_22050 = flat_idx_24027;\n    // threads in bound read carries; others get neutral element\n    if (slt64(gtid_22050, num_qubits_14547)) {\n        int64_t tmp_24028 = ((__global int64_t *) mem_23119)[gtid_22050];\n        \n        ((__local int64_t *) scan_arr_mem_24025)[sext_i32_i64(local_tid_24021)] = tmp_24028;\n    } else {\n        ((__local int64_t *) scan_arr_mem_24025)[sext_i32_i64(local_tid_24021)] = (int64_t) 0;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_in_bounds_24032 = slt64(sext_i32_i64(local_tid_24021), stage1_num_tblocks_23993);\n    // read input for in-block scan\n    if (ltid_in_bounds_24032) {\n        eta_p_21055 = ((volatile __local int64_t *) scan_arr_mem_24025)[sext_i32_i64(local_tid_24021)];\n        if ((local_tid_24021 - squot32(local_tid_24021, 32) * 32) == 0) {\n            eta_p_21054 = eta_p_21055;\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    skip_threads_24033 = 1;\n    while (slt32(skip_threads_24033, 32)) {\n        bool thread_active_24034 = sle32(skip_threads_24033, local_tid_24021 - squot32(local_tid_24021, 32) * 32) && ltid_in_bounds_24032;\n        \n        if (thread_active_24034) {\n            // read operands\n            eta_p_21054 = ((volatile __local int64_t *) scan_arr_mem_24025)[sext_i32_i64(local_tid_24021) - sext_i32_i64(skip_threads_24033)];\n        }\n        // perform operation\n        if (thread_active_24034) {\n            int64_t defunc_0_op_res_21056;\n            \n            // definitions.fut:132:29-67\n            defunc_0_op_res_21056 = add64(eta_p_21054, eta_p_21055);\n            eta_p_21054 = defunc_0_op_res_21056;\n        }\n   ", "     if (sle32(wave_sizze_24023, skip_threads_24033)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        if (thread_active_24034) {\n            // write result\n            ((volatile __local int64_t *) scan_arr_mem_24025)[sext_i32_i64(local_tid_24021)] = eta_p_21054;\n            eta_p_21055 = eta_p_21054;\n        }\n        if (sle32(wave_sizze_24023, skip_threads_24033)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        skip_threads_24033 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    if ((local_tid_24021 - squot32(local_tid_24021, 32) * 32) == 31 && ltid_in_bounds_24032) {\n        ((volatile __local int64_t *) scan_arr_mem_24025)[sext_i32_i64(squot32(local_tid_24021, 32))] = eta_p_21054;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    // read input for in-block scan\n    if (squot32(local_tid_24021, 32) == 0 && ltid_in_bounds_24032) {\n        eta_p_24030 = ((volatile __local int64_t *) scan_arr_mem_24025)[sext_i32_i64(local_tid_24021)];\n        if ((local_tid_24021 - squot32(local_tid_24021, 32) * 32) == 0) {\n            eta_p_24029 = eta_p_24030;\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    skip_threads_24035 = 1;\n    while (slt32(skip_threads_24035, 32)) {\n        bool thread_active_24036 = sle32(skip_threads_24035, local_tid_24021 - squot32(local_tid_24021, 32) * 32) && (squot32(local_tid_24021, 32) == 0 && ltid_in_bounds_24032);\n        \n        if (thread_active_24036) {\n            // read operands\n            eta_p_24029 = ((volatile __local int64_t *) scan_arr_mem_24025)[sext_i32_i64(local_tid_24021) - sext_i32_i64(skip_threads_24035)];\n        }\n        // perform operation\n        if (thread_active_24036) {\n            int64_t defunc_0_op_res_24031;\n            \n            // definitions.fut:132:29-67\n            defunc_0_op_res_24031 = add64(eta_p_24029, eta_",
                                    "p_24030);\n            eta_p_24029 = defunc_0_op_res_24031;\n        }\n        if (sle32(wave_sizze_24023, skip_threads_24035)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        if (thread_active_24036) {\n            // write result\n            ((volatile __local int64_t *) scan_arr_mem_24025)[sext_i32_i64(local_tid_24021)] = eta_p_24029;\n            eta_p_24030 = eta_p_24029;\n        }\n        if (sle32(wave_sizze_24023, skip_threads_24035)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        skip_threads_24035 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_24037 = squot32(local_tid_24021, 32) == 0 || !ltid_in_bounds_24032;\n    // carry-in for every block except the first\n    // read operands\n    if (!no_carry_in_24037) {\n        eta_p_21055 = eta_p_21054;\n        eta_p_21054 = ((__local int64_t *) scan_arr_mem_24025)[sext_i32_i64(squot32(local_tid_24021, 32)) - (int64_t) 1];\n    }\n    // perform operation\n    if (!no_carry_in_24037) {\n        int64_t defunc_0_op_res_21056;\n        \n        // definitions.fut:132:29-67\n        defunc_0_op_res_21056 = add64(eta_p_21054, eta_p_21055);\n        eta_p_21054 = defunc_0_op_res_21056;\n    }\n    // write final result\n    if (!no_carry_in_24037) {\n        ((__local int64_t *) scan_arr_mem_24025)[sext_i32_i64(local_tid_24021)] = eta_p_21054;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    if (squot32(local_tid_24021, 32) == 0 && ltid_in_bounds_24032) {\n        ((__local int64_t *) scan_arr_mem_24025)[sext_i32_i64(local_tid_24021)] = eta_p_21055;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // threads in bounds write scanned carries\n    if (slt64(gtid_22050, num_qubits_14547)) {\n        int64_t tmp_24038 = ((__local int64_t *) scan_arr_mem_24025)[sext_i32_i64(local_tid_24021)];\n        \n        ((__global int64_t *) mem_23119)[gtid_22050] = tmp_24038;\n    }\n    \n  error_1:\n    return;\n    #undef segscan_tblock_sizze_22046\n}\nFUTHARK_KERNEL_SIZED(mainzis", "can_stage3_21514_dim1, 1, 1)\nvoid mainziscan_stage3_21514(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t arg_16658, int64_t num_tblocks_21511, int32_t num_threads_23631, int32_t required_groups_23676, __global unsigned char *mem_23219)\n{\n    #define segscan_tblock_sizze_21509 (mainziscan_stage3_21514zisegscan_tblock_sizze_21509)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23678;\n    int32_t tblock_sizze_23681;\n    int32_t wave_sizze_23680;\n    int32_t block_id_23679;\n    int32_t global_tid_23677;\n    int64_t phys_tid_21514;\n    int32_t phys_tblock_id_23682;\n    int32_t iterations_23683;\n    \n    local_tid_23678 = get_local_id(0);\n    tblock_sizze_23681 = get_local_size(0);\n    wave_sizze_23680 = LOCKSTEP_WIDTH;\n    block_id_23679 = get_tblock_id(0);\n    global_tid_23677 = block_id_23679 * tblock_sizze_23681 + local_tid_23678;\n    phys_tid_21514 = sext_i32_i64(global_tid_23677);\n    phys_tblock_id_23682 = get_tblock_id(0);\n    iterations_23683 = sdiv_up32(required_groups_23676 - phys_tblock_id_23682, sext_i64_i32(num_tblocks_21511));\n    for (int32_t i_23684 = 0; i_23684 < iterations_23683; i_23684++) {\n        int32_t virt_tblock_id_23685;\n        int64_t flat_idx_23686;\n        int64_t gtid_21513;\n        int64_t orig_group_23687;\n        int64_t carry_in_flat_idx_23688;\n        \n        virt_tblock_id_23685 = phys_tblock_id_23682 + i_23684 * sext_i64_i32(num_tblocks_21511);\n        flat_idx_23686 = sext_i32_i64(virt_tblock_id_23685) * segscan_tblock_sizze_21509 + sext_i32_i64(local_tid_23678);\n        gtid_21513 = flat_idx_23686;\n        orig_group_23687 = squot64(flat_idx_23686, segscan_tblock_sizze_21509 * sdiv_up64(arg_16658, sext_i32_i64(num_threads_23631)));\n        carry_in_flat_idx_23688 = orig_group_23687 * (segscan_tblock_sizze_21509 * sdiv_up64(arg_16658, sext_i32_i64(num_threads_23631))) - (int64_t) 1;", "\n        if (slt64(gtid_21513, arg_16658)) {\n            if (!(orig_group_23687 == (int64_t) 0 || flat_idx_23686 == (orig_group_23687 + (int64_t) 1) * (segscan_tblock_sizze_21509 * sdiv_up64(arg_16658, sext_i32_i64(num_threads_23631))) - (int64_t) 1)) {\n                int64_t eta_p_20827;\n                int64_t eta_p_20828;\n                int64_t defunc_0_op_res_20829;\n                \n                eta_p_20827 = ((__global int64_t *) mem_23219)[carry_in_flat_idx_23688];\n                eta_p_20828 = ((__global int64_t *) mem_23219)[gtid_21513];\n                // definitions.fut:100:29-85\n                defunc_0_op_res_20829 = add64(eta_p_20827, eta_p_20828);\n                eta_p_20827 = defunc_0_op_res_20829;\n                ((__global int64_t *) mem_23219)[gtid_21513] = eta_p_20827;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segscan_tblock_sizze_21509\n}\nFUTHARK_KERNEL_SIZED(mainziscan_stage3_22051_dim1, 1, 1)\nvoid mainziscan_stage3_22051(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t num_qubits_14547, int64_t num_tblocks_22048, int32_t num_threads_23994, int32_t required_groups_24039, __global unsigned char *mem_23119)\n{\n    #define segscan_tblock_sizze_22046 (mainziscan_stage3_22051zisegscan_tblock_sizze_22046)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24041;\n    int32_t tblock_sizze_24044;\n    int32_t wave_sizze_24043;\n    int32_t block_id_24042;\n    int32_t global_tid_24040;\n    int64_t phys_tid_22051;\n    int32_t phys_tblock_id_24045;\n    int32_t iterations_24046;\n    \n    local_tid_24041 = get_local_id(0);\n    tblock_sizze_24044 = get_local_size(0);\n    wave_sizze_24043 = LOCKSTEP_WIDTH;\n    block_id_24042 = get_tblock_id(0);\n    global_tid_24040 = block_id_24042 * tblock_sizze_24044 + local_tid_24041;\n    phys_t",
                                    "id_22051 = sext_i32_i64(global_tid_24040);\n    phys_tblock_id_24045 = get_tblock_id(0);\n    iterations_24046 = sdiv_up32(required_groups_24039 - phys_tblock_id_24045, sext_i64_i32(num_tblocks_22048));\n    for (int32_t i_24047 = 0; i_24047 < iterations_24046; i_24047++) {\n        int32_t virt_tblock_id_24048;\n        int64_t flat_idx_24049;\n        int64_t gtid_22050;\n        int64_t orig_group_24050;\n        int64_t carry_in_flat_idx_24051;\n        \n        virt_tblock_id_24048 = phys_tblock_id_24045 + i_24047 * sext_i64_i32(num_tblocks_22048);\n        flat_idx_24049 = sext_i32_i64(virt_tblock_id_24048) * segscan_tblock_sizze_22046 + sext_i32_i64(local_tid_24041);\n        gtid_22050 = flat_idx_24049;\n        orig_group_24050 = squot64(flat_idx_24049, segscan_tblock_sizze_22046 * sdiv_up64(num_qubits_14547, sext_i32_i64(num_threads_23994)));\n        carry_in_flat_idx_24051 = orig_group_24050 * (segscan_tblock_sizze_22046 * sdiv_up64(num_qubits_14547, sext_i32_i64(num_threads_23994))) - (int64_t) 1;\n        if (slt64(gtid_22050, num_qubits_14547)) {\n            if (!(orig_group_24050 == (int64_t) 0 || flat_idx_24049 == (orig_group_24050 + (int64_t) 1) * (segscan_tblock_sizze_22046 * sdiv_up64(num_qubits_14547, sext_i32_i64(num_threads_23994))) - (int64_t) 1)) {\n                int64_t eta_p_21054;\n                int64_t eta_p_21055;\n                int64_t defunc_0_op_res_21056;\n                \n                eta_p_21054 = ((__global int64_t *) mem_23119)[carry_in_flat_idx_24051];\n                eta_p_21055 = ((__global int64_t *) mem_23119)[gtid_22050];\n                // definitions.fut:132:29-67\n                defunc_0_op_res_21056 = add64(eta_p_21054, eta_p_21055);\n                eta_p_21054 = defunc_0_op_res_21056;\n                ((__global int64_t *) mem_23119)[gtid_22050] = eta_p_21054;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segscan_tblock_sizze_22046\n}\nFUTHARK_KER", "NEL_SIZED(mainzisegmap_21484_dim1, 1, 1)\nvoid mainzisegmap_21484(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, __global unsigned char *mem_23052)\n{\n    #define segmap_tblock_sizze_21479 (mainzisegmap_21484zisegmap_tblock_sizze_21479)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23511;\n    int32_t tblock_sizze_23514;\n    int32_t wave_sizze_23513;\n    int32_t block_id_23512;\n    int32_t global_tid_23510;\n    int64_t phys_tid_21484;\n    int64_t global_tid_23515;\n    int64_t slice_23516;\n    int64_t slice_23517;\n    int64_t gtid_21482;\n    int64_t remnant_23518;\n    int64_t gtid_21483;\n    int64_t remnant_23519;\n    \n    local_tid_23511 = get_local_id(0);\n    tblock_sizze_23514 = get_local_size(0);\n    wave_sizze_23513 = LOCKSTEP_WIDTH;\n    block_id_23512 = get_tblock_id(0);\n    global_tid_23510 = block_id_23512 * tblock_sizze_23514 + local_tid_23511;\n    phys_tid_21484 = sext_i32_i64(global_tid_23510);\n    global_tid_23515 = sext_i32_i64(block_id_23512) * segmap_tblock_sizze_21479 + sext_i32_i64(local_tid_23511);\n    slice_23516 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n    slice_23517 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 * slice_23516;\n    gtid_21482 = squot64(global_tid_23515, slice_23516);\n    remnant_23518 = global_tid_23515 - gtid_21482 * slice_23516;\n    gtid_21483 = remnant_23518;\n    remnant_23519 = remnant_23518 - gtid_21483;\n    if (slt64(gtid_21482, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659) && slt64(gtid_21483, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) {\n        bool index_primexp_22795;\n        bool cond_21488;\n        bool x_21489;\n        bool y_21490;\n        bool cond_21491;\n        int8_t lifted_lambda_res_21492;\n      ", "  \n        index_primexp_22795 = gtid_21482 == arg_16658;\n        // definitions.fut:35:29-41:35\n        cond_21488 = gtid_21483 == arg_16658;\n        // definitions.fut:34:6-41:35\n        x_21489 = !cond_21488;\n        // definitions.fut:34:6-41:35\n        y_21490 = x_21489 && index_primexp_22795;\n        // definitions.fut:34:6-41:35\n        cond_21491 = cond_21488 || y_21490;\n        // definitions.fut:35:29-41:35\n        if (cond_21491) {\n            lifted_lambda_res_21492 = (int8_t) 0;\n        } else {\n            bool cond_21493;\n            int8_t lifted_lambda_res_f_res_21494;\n            \n            // definitions.fut:38:34-41:35\n            cond_21493 = gtid_21482 == gtid_21483;\n            // definitions.fut:34:6-41:35\n            lifted_lambda_res_f_res_21494 = btoi_bool_i8(cond_21493);\n            lifted_lambda_res_21492 = lifted_lambda_res_f_res_21494;\n        }\n        ((__global int8_t *) mem_23052)[gtid_21482 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_21483] = lifted_lambda_res_21492;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_21479\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21539_dim1, 1, 1)\nvoid mainzisegmap_21539(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t arg_16658, int64_t m_20840, int64_t num_tblocks_21535, int32_t virt_num_tblocks_23706, __global unsigned char *mem_23219, __global unsigned char *mem_23221, __global unsigned char *mem_23223)\n{\n    #define segmap_tblock_sizze_21534 (mainzisegmap_21539zisegmap_tblock_sizze_21534)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23708;\n    int32_t tblock_sizze_23711;\n    int32_t wave_sizze_23710;\n    int32_t block_id_23709;\n    int32_t global_tid_23707;\n    int64_t phys_tid_21539;\n    int32_t phys_tblock_id_23712;\n    int32_t iterations_23713;\n    \n    local_tid_23708 = get_local_id(0);\n    tblock_siz",
                                    "ze_23711 = get_local_size(0);\n    wave_sizze_23710 = LOCKSTEP_WIDTH;\n    block_id_23709 = get_tblock_id(0);\n    global_tid_23707 = block_id_23709 * tblock_sizze_23711 + local_tid_23708;\n    phys_tid_21539 = sext_i32_i64(global_tid_23707);\n    phys_tblock_id_23712 = get_tblock_id(0);\n    iterations_23713 = sdiv_up32(virt_num_tblocks_23706 - phys_tblock_id_23712, sext_i64_i32(num_tblocks_21535));\n    for (int32_t i_23714 = 0; i_23714 < iterations_23713; i_23714++) {\n        int32_t virt_tblock_id_23715;\n        int64_t global_tid_23716;\n        int64_t slice_23717;\n        int64_t gtid_21538;\n        int64_t remnant_23718;\n        \n        virt_tblock_id_23715 = phys_tblock_id_23712 + i_23714 * sext_i64_i32(num_tblocks_21535);\n        global_tid_23716 = sext_i32_i64(virt_tblock_id_23715) * segmap_tblock_sizze_21534 + sext_i32_i64(local_tid_23708);\n        slice_23717 = arg_16658;\n        gtid_21538 = global_tid_23716;\n        remnant_23718 = global_tid_23716 - gtid_21538;\n        if (slt64(gtid_21538, arg_16658)) {\n            int64_t eta_p_21540;\n            bool cond_21544;\n            int64_t lifted_lambda_res_21545;\n            \n            eta_p_21540 = ((__global int64_t *) mem_23221)[gtid_21538];\n            // definitions.fut:100:29-85\n            cond_21544 = eta_p_21540 == (int64_t) 1;\n            // definitions.fut:100:29-85\n            if (cond_21544) {\n                int64_t eta_p_21541;\n                int64_t lifted_lambda_res_t_res_21546;\n                \n                eta_p_21541 = ((__global int64_t *) mem_23219)[gtid_21538];\n                // definitions.fut:100:29-85\n                lifted_lambda_res_t_res_21546 = sub64(eta_p_21541, (int64_t) 1);\n                lifted_lambda_res_21545 = lifted_lambda_res_t_res_21546;\n            } else {\n                lifted_lambda_res_21545 = (int64_t) -1;\n            }\n            // definitions.fut:100:29-85\n            // UpdateAcc\n            if (sle64((int64_t) 0, lifted_lambda_res_21545) && slt64(lift", "ed_lambda_res_21545, m_20840)) {\n                ((__global int64_t *) mem_23223)[lifted_lambda_res_21545] = gtid_21538;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_21534\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21567_dim1, 1, 1)\nvoid mainzisegmap_21567(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t num_qubits_14547, int64_t num_tblocks_21563, int32_t virt_num_tblocks_23691, __global unsigned char *mem_23210)\n{\n    #define segmap_tblock_sizze_21562 (mainzisegmap_21567zisegmap_tblock_sizze_21562)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23693;\n    int32_t tblock_sizze_23696;\n    int32_t wave_sizze_23695;\n    int32_t block_id_23694;\n    int32_t global_tid_23692;\n    int64_t phys_tid_21567;\n    int32_t phys_tblock_id_23697;\n    int32_t iterations_23698;\n    \n    local_tid_23693 = get_local_id(0);\n    tblock_sizze_23696 = get_local_size(0);\n    wave_sizze_23695 = LOCKSTEP_WIDTH;\n    block_id_23694 = get_tblock_id(0);\n    global_tid_23692 = block_id_23694 * tblock_sizze_23696 + local_tid_23693;\n    phys_tid_21567 = sext_i32_i64(global_tid_23692);\n    phys_tblock_id_23697 = get_tblock_id(0);\n    iterations_23698 = sdiv_up32(virt_num_tblocks_23691 - phys_tblock_id_23697, sext_i64_i32(num_tblocks_21563));\n    for (int32_t i_23699 = 0; i_23699 < iterations_23698; i_23699++) {\n        int32_t virt_tblock_id_23700;\n        int64_t global_tid_23701;\n        int64_t slice_23702;\n        int64_t gtid_21566;\n        int64_t remnant_23703;\n        \n        virt_tblock_id_23700 = phys_tblock_id_23697 + i_23699 * sext_i64_i32(num_tblocks_21563);\n        global_tid_23701 = sext_i32_i64(virt_tblock_id_23700) * segmap_tblock_sizze_21562 + sext_i32_i64(local_tid_23693);\n        slice_23702 = num_qubits_14547;\n        gtid_21566 = glob", "al_tid_23701;\n        remnant_23703 = global_tid_23701 - gtid_21566;\n        if (slt64(gtid_21566, num_qubits_14547)) {\n            int64_t tmp_21569;\n            int64_t mem_23200[(int64_t) 2];\n            \n            // definitions.fut:28:38-41\n            tmp_21569 = add64(num_qubits_14547, gtid_21566);\n            // definitions.fut:28:12-52\n            mem_23200[(int64_t) 0] = gtid_21566;\n            mem_23200[(int64_t) 1] = tmp_21569;\n            // definitions.fut:28:12-52\n            for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                ((__global int64_t *) mem_23210)[gtid_21566 + i_0 * num_qubits_14547] = mem_23200[i_0];\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_21562\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21651_dim1, 1, 1)\nvoid mainzisegmap_21651(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t m_20840, int64_t num_tblocks_21646, int64_t num_threads_23359, int64_t ctx_23400, int32_t virt_num_tblocks_23757, __global unsigned char *mem_23052, __global unsigned char *mem_23211, __global unsigned char *mem_23213, __global unsigned char *mem_23223, __global unsigned char *mem_23251, __global unsigned char *mem_23290, __global unsigned char *mem_23301, __global unsigned char *color_23357)\n{\n    #define segmap_tblock_sizze_21645 (mainzisegmap_21651zisegmap_tblock_sizze_21645)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_23759;\n    int32_t tb",
                                    "lock_sizze_23762;\n    int32_t wave_sizze_23761;\n    int32_t block_id_23760;\n    int32_t global_tid_23758;\n    int64_t phys_tid_21651;\n    int32_t phys_tblock_id_23763;\n    int32_t iterations_23764;\n    \n    local_tid_23759 = get_local_id(0);\n    tblock_sizze_23762 = get_local_size(0);\n    wave_sizze_23761 = LOCKSTEP_WIDTH;\n    block_id_23760 = get_tblock_id(0);\n    global_tid_23758 = block_id_23760 * tblock_sizze_23762 + local_tid_23759;\n    phys_tid_21651 = sext_i32_i64(global_tid_23758);\n    phys_tblock_id_23763 = get_tblock_id(0);\n    iterations_23764 = sdiv_up32(virt_num_tblocks_23757 - phys_tblock_id_23763, sext_i64_i32(num_tblocks_21646));\n    for (int32_t i_23765 = 0; i_23765 < iterations_23764; i_23765++) {\n        int32_t virt_tblock_id_23766;\n        int64_t global_tid_23767;\n        int64_t slice_23768;\n        int64_t gtid_21650;\n        int64_t remnant_23769;\n        \n        virt_tblock_id_23766 = phys_tblock_id_23763 + i_23765 * sext_i64_i32(num_tblocks_21646);\n        global_tid_23767 = sext_i32_i64(virt_tblock_id_23766) * segmap_tblock_sizze_21645 + sext_i32_i64(local_tid_23759);\n        slice_23768 = m_20840;\n        gtid_21650 = global_tid_23767;\n        remnant_23769 = global_tid_23767 - gtid_21650;\n        if (slt64(gtid_21650, m_20840)) {\n            int64_t eta_p_21652;\n            bool x_21653;\n            bool y_21654;\n            bool bounds_check_21655;\n            bool index_certs_21656;\n            int64_t defunc_0_f_res_22858;\n            int8_t zp_rhs_22859;\n            int8_t mem_23259[(int64_t) 2];\n            int8_t defunc_0_f_res_21657;\n            int8_t redout_22797;\n            int8_t zt_rhs_21699;\n            int8_t zp_lhs_21700;\n            int8_t zp_lhs_21701;\n            int8_t zv_lhs_21702;\n            int8_t res_21703;\n            bool cond_21704;\n            bool cond_neg_21705;\n            int8_t v_21706;\n            int64_t mem_23273[(int64_t) 1];\n            int8_t mem_23277[(int64_t) 1];\n            int64_t tmp_offs_2", "3775;\n            int64_t tmp_offs_23776;\n            \n            eta_p_21652 = ((__global int64_t *) mem_23223)[gtid_21650];\n            // definitions.fut:25:73-82\n            x_21653 = sle64((int64_t) 0, eta_p_21652);\n            // definitions.fut:25:73-82\n            y_21654 = slt64(eta_p_21652, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            // definitions.fut:25:73-82\n            bounds_check_21655 = x_21653 && y_21654;\n            // definitions.fut:25:73-82\n            if (!bounds_check_21655) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 7) == -1) {\n                        global_failure_args[0] = (int64_t) eta_p_21652;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            defunc_0_f_res_22858 = ((__global int64_t *) mem_23211)[(int64_t) 0];\n            zp_rhs_22859 = ((__global int8_t *) mem_23213)[(int64_t) 0];\n            // definitions.fut:29:12-98\n            // definitions.fut:25:17-29:98\n            redout_22797 = (int8_t) 0;\n            for (int64_t i_22799 = 0; i_22799 < num_qubits_14547; i_22799++) {\n                int64_t g_arg3_21660;\n                bool x_21661;\n                bool y_21662;\n                bool bounds_check_21663;\n                bool index_certs_21664;\n                bool y_21667;\n                bool index_certs_21669;\n                int8_t g_arg3_21665;\n                int8_t g_arg2_21670;\n                int8_t g_arg1_21671;\n                int8_t g_arg0_21672;\n                bool cond_21673;\n                bool cond_t_res_21674;\n                bool x_21675;\n                int8_t g_res_21676;\n                int8_t tmp_21693;\n                int8_t tmp_21694;\n                int8_t defunc_0_op_res_21698;\n     ", "           int8_t redout_tmp_23770;\n                \n                // definitions.fut:25:85-88\n                g_arg3_21660 = add64(num_qubits_14547, i_22799);\n                // definitions.fut:25:73-89\n                x_21661 = sle64((int64_t) 0, g_arg3_21660);\n                // definitions.fut:25:73-89\n                y_21662 = slt64(g_arg3_21660, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n                // definitions.fut:25:73-89\n                bounds_check_21663 = x_21661 && y_21662;\n                // definitions.fut:25:73-89\n                if (!bounds_check_21663) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 8) == -1) {\n                            global_failure_args[0] = (int64_t) g_arg3_21660;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                // definitions.fut:25:60-72\n                y_21667 = slt64(i_22799, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n                // definitions.fut:25:60-72\n                if (!y_21667) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 9) == -1) {\n                            global_failure_args[0] = (int64_t) i_22799;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                // definitions.fut:25:17-98\n                g_arg3_21665 = ((__global int8_t *) mem_23052)[eta_p_21652 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + g",
                                    "_arg3_21660];\n                // definitions.fut:25:17-98\n                g_arg2_21670 = ((__global int8_t *) mem_23052)[eta_p_21652 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + i_22799];\n                // definitions.fut:25:17-98\n                g_arg1_21671 = ((__global int8_t *) mem_23052)[defunc_0_f_res_22858 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + g_arg3_21660];\n                // definitions.fut:25:17-98\n                g_arg0_21672 = ((__global int8_t *) mem_23052)[defunc_0_f_res_22858 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + i_22799];\n                // definitions.fut:12:3-20:9\n                cond_21673 = g_arg0_21672 == g_arg2_21670;\n                // definitions.fut:12:21-25\n                cond_t_res_21674 = g_arg0_21672 == (int8_t) 0;\n                // definitions.fut:25:28-89\n                x_21675 = cond_21673 && cond_t_res_21674;\n                // definitions.fut:12:3-20:9\n                if (x_21675) {\n                    g_res_21676 = (int8_t) 0;\n                } else {\n                    bool cond_t_res_21677;\n                    bool x_21678;\n                    int8_t g_res_f_res_21679;\n                    \n                    // definitions.fut:14:26-30\n                    cond_t_res_21677 = g_arg0_21672 == (int8_t) 1;\n                    // definitions.fut:25:28-89\n                    x_21678 = cond_21673 && cond_t_res_21677;\n                    // definitions.fut:14:8-20:9\n                    if (x_21678) {\n                        int8_t g_res_f_res_t_res_21680;\n                        \n                        // definitions.fut:15:11-15\n                        g_res_f_res_t_res_21680 = sub8(g_arg3_21665, g_arg1_21671);\n                        g_res_f_res_21679 = g_res_f_res_t_res_21680;\n                    } else {\n                        bool cond_t_res_21681;\n                        bool x_21682;\n                        int8_t g_res_f_res_f_res_21683;\n   ", "                     \n                        // definitions.fut:16:25-29\n                        cond_t_res_21681 = g_arg2_21670 == (int8_t) 0;\n                        // definitions.fut:25:28-89\n                        x_21682 = cond_t_res_21677 && cond_t_res_21681;\n                        // definitions.fut:16:8-20:9\n                        if (x_21682) {\n                            int8_t zm_lhs_21684;\n                            int8_t zt_rhs_21685;\n                            int8_t g_res_f_res_f_res_t_res_21686;\n                            \n                            // definitions.fut:17:16-20\n                            zm_lhs_21684 = mul8((int8_t) 2, g_arg1_21671);\n                            // definitions.fut:17:21-24\n                            zt_rhs_21685 = sub8(zm_lhs_21684, (int8_t) 1);\n                            // definitions.fut:17:11-24\n                            g_res_f_res_f_res_t_res_21686 = mul8(g_arg3_21665, zt_rhs_21685);\n                            g_res_f_res_f_res_21683 = g_res_f_res_f_res_t_res_21686;\n                        } else {\n                            bool cond_t_res_21687;\n                            bool x_21688;\n                            int8_t g_res_f_res_f_res_f_res_21689;\n                            \n                            // definitions.fut:18:25-29\n                            cond_t_res_21687 = g_arg2_21670 == (int8_t) 1;\n                            // definitions.fut:25:28-89\n                            x_21688 = cond_t_res_21674 && cond_t_res_21687;\n                            // definitions.fut:18:8-20:9\n                            if (x_21688) {\n                                int8_t zm_rhs_21690;\n                                int8_t zt_rhs_21691;\n                                int8_t g_res_f_res_f_res_f_res_t_res_21692;\n                                \n                                // definitions.fut:19:20-24\n                                zm_rhs_21690 = mul8((int8_t) 2, g_arg3_21665);\n           ", "                     // definitions.fut:19:16-24\n                                zt_rhs_21691 = sub8((int8_t) 1, zm_rhs_21690);\n                                // definitions.fut:19:11-24\n                                g_res_f_res_f_res_f_res_t_res_21692 = mul8(g_arg1_21671, zt_rhs_21691);\n                                g_res_f_res_f_res_f_res_21689 = g_res_f_res_f_res_f_res_t_res_21692;\n                            } else {\n                                g_res_f_res_f_res_f_res_21689 = (int8_t) 0;\n                            }\n                            g_res_f_res_f_res_21683 = g_res_f_res_f_res_f_res_21689;\n                        }\n                        g_res_f_res_21679 = g_res_f_res_f_res_21683;\n                    }\n                    g_res_21676 = g_res_f_res_21679;\n                }\n                // definitions.fut:29:37-51\n                tmp_21693 = g_arg2_21670 ^ g_arg0_21672;\n                // definitions.fut:29:70-88\n                tmp_21694 = g_arg3_21665 ^ g_arg1_21671;\n                // definitions.fut:29:12-98\n                mem_23259[(int64_t) 0] = tmp_21693;\n                mem_23259[(int64_t) 1] = tmp_21694;\n                // definitions.fut:25:110-113\n                defunc_0_op_res_21698 = add8(g_res_21676, redout_22797);\n                for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                    ((__global int8_t *) mem_23251)[phys_tid_21651 + i_22799 * ctx_23400 + i_0 * num_threads_23359] = mem_23259[i_0];\n                }\n                redout_tmp_23770 = defunc_0_op_res_21698;\n                redout_22797 = redout_tmp_23770;\n            }\n            defunc_0_f_res_21657 = redout_22797;\n            // definitions.fut:89:58-103:37\n            zt_rhs_21699 = ((__global int8_t *) mem_23052)[eta_p_21652 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + arg_16658];\n            // definitions.fut:26:16-36\n            zp_lhs_21700 = mul8((int8_t) 2, zt_rhs_21699);\n            // definitions.fut:26:37-61\n",
                                    "            zp_lhs_21701 = add8(zp_lhs_21700, zp_rhs_22859);\n            // definitions.fut:26:62-71\n            zv_lhs_21702 = add8(defunc_0_f_res_21657, zp_lhs_21701);\n            // definitions.fut:26:73-76\n            res_21703 = smod8(zv_lhs_21702, (int8_t) 4);\n            // definitions.fut:27:11-36\n            cond_21704 = res_21703 == (int8_t) 0;\n            // definitions.fut:89:58-103:37\n            cond_neg_21705 = !cond_21704;\n            // definitions.fut:89:58-103:37\n            v_21706 = btoi_bool_i8(cond_neg_21705);\n            // definitions.fut:89:58-103:37\n            for (int64_t nest_i_23772 = 0; nest_i_23772 < arg_16658; nest_i_23772++) {\n                ((__global int64_t *) mem_23301)[gtid_21650 + nest_i_23772 * m_20840] = eta_p_21652;\n            }\n            // definitions.fut:89:58-103:37\n            // definitions.fut:89:58-103:37\n            for (int64_t i_0 = 0; i_0 < num_qubits_14547; i_0++) {\n                for (int64_t i_1 = 0; i_1 < (int64_t) 2; i_1++) {\n                    ((__global int8_t *) color_23357)[phys_tid_21651 + (i_0 * (num_threads_23359 * (int64_t) 2) + i_1 * num_threads_23359)] = ((__global int8_t *) mem_23251)[phys_tid_21651 + (i_0 * ctx_23400 + i_1 * num_threads_23359)];\n                }\n            }\n            // definitions.fut:89:58-103:37\n            // definitions.fut:89:58-103:37\n            for (int64_t nest_i_23773 = 0; nest_i_23773 < (int64_t) 1; nest_i_23773++) {\n                mem_23273[nest_i_23773] = eta_p_21652;\n            }\n            // definitions.fut:89:58-103:37\n            // definitions.fut:89:58-103:37\n            for (int64_t nest_i_23774 = 0; nest_i_23774 < (int64_t) 1; nest_i_23774++) {\n                mem_23277[nest_i_23774] = v_21706;\n            }\n            // definitions.fut:23:79-104:29\n            tmp_offs_23775 = (int64_t) 0;\n            if (!((gtid_21650 + m_20840 * tmp_offs_23775) == gtid_21650)) {\n                // definitions.fut:23:79-104:29\n                for (int64_", "t i_0 = 0; i_0 < arg_16658; i_0++) {\n                    ((__global int64_t *) mem_23301)[gtid_21650 + m_20840 * tmp_offs_23775 + i_0 * m_20840] = ((__global int64_t *) mem_23301)[gtid_21650 + i_0 * m_20840];\n                }\n            }\n            tmp_offs_23775 += arg_16658;\n            // definitions.fut:23:79-104:29\n            for (int64_t i_0 = 0; i_0 < (int64_t) 1; i_0++) {\n                ((__global int64_t *) mem_23301)[gtid_21650 + m_20840 * tmp_offs_23775 + i_0 * m_20840] = mem_23273[i_0];\n            }\n            tmp_offs_23775 += (int64_t) 1;\n            // definitions.fut:23:79-104:29\n            tmp_offs_23776 = (int64_t) 0;\n            // definitions.fut:23:79-104:29\n            for (int64_t i_0 = 0; i_0 < arg_16658; i_0++) {\n                ((__global int8_t *) mem_23290)[gtid_21650 + m_20840 * tmp_offs_23776 + i_0 * m_20840] = ((__global int8_t *) color_23357)[phys_tid_21651 + i_0 * num_threads_23359];\n            }\n            tmp_offs_23776 += arg_16658;\n            // definitions.fut:23:79-104:29\n            for (int64_t i_0 = 0; i_0 < (int64_t) 1; i_0++) {\n                ((__global int8_t *) mem_23290)[gtid_21650 + m_20840 * tmp_offs_23776 + i_0 * m_20840] = mem_23277[i_0];\n            }\n            tmp_offs_23776 += (int64_t) 1;\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_21645\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21821_dim1, 1, 1)\nvoid mainzisegmap_21821(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t m_20840, __global unsigned char *mem_23223, __global unsigned char *mem_23226)\n{\n    #define segmap_tblock_sizze_21817 (mainzisegmap_21821zisegmap_tblock_si", "zze_21817)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23779;\n    int32_t tblock_sizze_23782;\n    int32_t wave_sizze_23781;\n    int32_t block_id_23780;\n    int32_t global_tid_23778;\n    int64_t phys_tid_21821;\n    int64_t global_tid_23783;\n    int64_t slice_23784;\n    int64_t gtid_21820;\n    int64_t remnant_23785;\n    \n    local_tid_23779 = get_local_id(0);\n    tblock_sizze_23782 = get_local_size(0);\n    wave_sizze_23781 = LOCKSTEP_WIDTH;\n    block_id_23780 = get_tblock_id(0);\n    global_tid_23778 = block_id_23780 * tblock_sizze_23782 + local_tid_23779;\n    phys_tid_21821 = sext_i32_i64(global_tid_23778);\n    global_tid_23783 = sext_i32_i64(block_id_23780) * segmap_tblock_sizze_21817 + sext_i32_i64(local_tid_23779);\n    slice_23784 = m_20840;\n    gtid_21820 = global_tid_23783;\n    remnant_23785 = global_tid_23783 - gtid_21820;\n    if (slt64(gtid_21820, m_20840)) {\n        int64_t eta_p_21822;\n        bool x_21823;\n        bool y_21824;\n        bool bounds_check_21825;\n        bool index_certs_21826;\n        \n        eta_p_21822 = ((__global int64_t *) mem_23223)[gtid_21820];\n        // definitions.fut:25:73-82\n        x_21823 = sle64((int64_t) 0, eta_p_21822);\n        // definitions.fut:25:73-82\n        y_21824 = slt64(eta_p_21822, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n        // definitions.fut:25:73-82\n        bounds_check_21825 = x_21823 && y_21824;\n        // definitions.fut:25:73-82\n        if (!bounds_check_21825) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 10) == -1) {\n                    global_failure_args[0] = (int64_t) eta_p_21822;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                    ;\n                }\n                return;\n            }\n        }\n    }\n    \n  error_0:\n    return",
                                    ";\n    #undef segmap_tblock_sizze_21817\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21884_dim1, 1, 1)\nvoid mainzisegmap_21884(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t m_20840, __global unsigned char *mem_23052, __global unsigned char *mem_23213, __global unsigned char *mem_23223, __global unsigned char *mem_23226, __global unsigned char *mem_23237)\n{\n    #define segmap_tblock_sizze_21880 (mainzisegmap_21884zisegmap_tblock_sizze_21880)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23860;\n    int32_t tblock_sizze_23863;\n    int32_t wave_sizze_23862;\n    int32_t block_id_23861;\n    int32_t global_tid_23859;\n    int64_t phys_tid_21884;\n    int64_t global_tid_23864;\n    int64_t slice_23865;\n    int64_t gtid_21883;\n    int64_t remnant_23866;\n    \n    local_tid_23860 = get_local_id(0);\n    tblock_sizze_23863 = get_local_size(0);\n    wave_sizze_23862 = LOCKSTEP_WIDTH;\n    block_id_23861 = get_tblock_id(0);\n    global_tid_23859 = block_id_23861 * tblock_sizze_23863 + local_tid_23860;\n    phys_tid_21884 = sext_i32_i64(global_tid_23859);\n    global_tid_23864 = sext_i32_i64(block_id_23861) * segmap_tblock_sizze_21880 + sext_i32_i64(local_tid_23860);\n    slice_23865 = m_20840;\n    gtid_21883 = global_tid_23864;\n    remnant_23866 = global_tid_23864 - gtid_21883;\n    if (slt64(gtid_21883, m_20840)) {\n        int8_t zp_rhs_22861;\n        int64_t eta_p_21885;\n        bool index_certs_21886;\n        int8_t defunc_0_f_res_21887;\n        int8_t zt_rhs_21888;\n        int8_t zp_lhs_21889;\n        int8_t zp_lhs_21890;\n        int8_t zv_lhs_21891;\n        int8_t res_21892;\n        bool cond_21893;\n        bool cond_neg_21894;\n        int8_t v_21895;\n        \n        zp_rhs_22861 = ((__global int8_t *) mem_23213)[(int64_t) 0];\n        eta_p_21885 = ((__g", "lobal int64_t *) mem_23223)[gtid_21883];\n        index_certs_21886 = 0;\n        defunc_0_f_res_21887 = ((__global int8_t *) mem_23237)[gtid_21883];\n        // definitions.fut:89:58-103:37\n        zt_rhs_21888 = ((__global int8_t *) mem_23052)[eta_p_21885 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + arg_16658];\n        // definitions.fut:26:16-36\n        zp_lhs_21889 = mul8((int8_t) 2, zt_rhs_21888);\n        // definitions.fut:26:37-61\n        zp_lhs_21890 = add8(zp_lhs_21889, zp_rhs_22861);\n        // definitions.fut:26:62-71\n        zv_lhs_21891 = add8(defunc_0_f_res_21887, zp_lhs_21890);\n        // definitions.fut:26:73-76\n        res_21892 = smod8(zv_lhs_21891, (int8_t) 4);\n        // definitions.fut:27:11-36\n        cond_21893 = res_21892 == (int8_t) 0;\n        // definitions.fut:89:58-103:37\n        cond_neg_21894 = !cond_21893;\n        // definitions.fut:89:58-103:37\n        v_21895 = btoi_bool_i8(cond_neg_21894);\n        ((__global int8_t *) mem_23237)[gtid_21883] = v_21895;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_21880\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21931_dim1, 1, 1)\nvoid mainzisegmap_21931(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t num_qubits_14547, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t m_20840, int64_t dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20858, int64_t num_tblocks_21927, int64_t ext_23303, int64_t ext_23304, int32_t virt_num_tblocks_23931, __global unsigned char *mem_23052, __global unsigned char *mem_23210, __global unsigned char *ext_mem_23302, __global unsigned char *ext_mem_23305)\n{\n    #define segmap_tblock_sizze_21926 (mainzisegmap_21931zisegmap_tblock_sizze_21926)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23933;\n    int32_t tblock_sizze", "_23936;\n    int32_t wave_sizze_23935;\n    int32_t block_id_23934;\n    int32_t global_tid_23932;\n    int64_t phys_tid_21931;\n    int32_t phys_tblock_id_23937;\n    int32_t iterations_23938;\n    \n    local_tid_23933 = get_local_id(0);\n    tblock_sizze_23936 = get_local_size(0);\n    wave_sizze_23935 = LOCKSTEP_WIDTH;\n    block_id_23934 = get_tblock_id(0);\n    global_tid_23932 = block_id_23934 * tblock_sizze_23936 + local_tid_23933;\n    phys_tid_21931 = sext_i32_i64(global_tid_23932);\n    phys_tblock_id_23937 = get_tblock_id(0);\n    iterations_23938 = sdiv_up32(virt_num_tblocks_23931 - phys_tblock_id_23937, sext_i64_i32(num_tblocks_21927));\n    for (int32_t i_23939 = 0; i_23939 < iterations_23938; i_23939++) {\n        int32_t virt_tblock_id_23940;\n        int64_t global_tid_23941;\n        int64_t slice_23942;\n        int64_t gtid_21930;\n        int64_t remnant_23943;\n        \n        virt_tblock_id_23940 = phys_tblock_id_23937 + i_23939 * sext_i64_i32(num_tblocks_21927);\n        global_tid_23941 = sext_i32_i64(virt_tblock_id_23940) * segmap_tblock_sizze_21926 + sext_i32_i64(local_tid_23933);\n        slice_23942 = dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20858;\n        gtid_21930 = global_tid_23941;\n        remnant_23943 = global_tid_23941 - gtid_21930;\n        if (slt64(gtid_21930, dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20858)) {\n            int64_t new_index_22670;\n            int64_t binop_y_22672;\n            int64_t new_index_22673;\n            int64_t v_21933;\n            bool index_concat_cmp_22683;\n            int64_t index_concat_branch_22687;\n            int8_t v_21935;\n            \n            new_index_22670 = squot64(gtid_21930, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            binop_y_22672 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 * new_index_22670;\n            new_index_22673 = gtid_21930 - binop_y_22672;\n            v_21933 =",
                                    " ((__global int64_t *) ext_mem_23302)[new_index_22670 + new_index_22673 * m_20840];\n            index_concat_cmp_22683 = sle64(arg_16658, new_index_22673);\n            if (index_concat_cmp_22683) {\n                index_concat_branch_22687 = arg_16658;\n            } else {\n                int64_t new_index_22785;\n                int64_t binop_y_22787;\n                int64_t new_index_22788;\n                int64_t index_concat_22686;\n                \n                new_index_22785 = squot64(new_index_22673, (int64_t) 2);\n                binop_y_22787 = (int64_t) 2 * new_index_22785;\n                new_index_22788 = new_index_22673 - binop_y_22787;\n                index_concat_22686 = ((__global int64_t *) mem_23210)[new_index_22785 + new_index_22788 * num_qubits_14547];\n                index_concat_branch_22687 = index_concat_22686;\n            }\n            v_21935 = ((__global int8_t *) ext_mem_23305)[new_index_22670 * ext_23304 + new_index_22673 * ext_23303];\n            // definitions.fut:106:22-72\n            // UpdateAcc\n            if ((sle64((int64_t) 0, v_21933) && slt64(v_21933, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) && (sle64((int64_t) 0, index_concat_branch_22687) && slt64(index_concat_branch_22687, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659))) {\n                ((__global int8_t *) mem_23052)[v_21933 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + index_concat_branch_22687] = v_21935;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_21926\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21956_dim1, 1, 1)\nvoid mainzisegmap_21956(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, __global unsigned char *mem_23052, __global unsigned char *mem_23211, __global unsigned char *mem_23308)\n{\n    #define segmap_tblock_", "sizze_21952 (mainzisegmap_21956zisegmap_tblock_sizze_21952)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23946;\n    int32_t tblock_sizze_23949;\n    int32_t wave_sizze_23948;\n    int32_t block_id_23947;\n    int32_t global_tid_23945;\n    int64_t phys_tid_21956;\n    int64_t global_tid_23950;\n    int64_t slice_23951;\n    int64_t gtid_21955;\n    int64_t remnant_23952;\n    \n    local_tid_23946 = get_local_id(0);\n    tblock_sizze_23949 = get_local_size(0);\n    wave_sizze_23948 = LOCKSTEP_WIDTH;\n    block_id_23947 = get_tblock_id(0);\n    global_tid_23945 = block_id_23947 * tblock_sizze_23949 + local_tid_23946;\n    phys_tid_21956 = sext_i32_i64(global_tid_23945);\n    global_tid_23950 = sext_i32_i64(block_id_23947) * segmap_tblock_sizze_21952 + sext_i32_i64(local_tid_23946);\n    slice_23951 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n    gtid_21955 = global_tid_23950;\n    remnant_23952 = global_tid_23950 - gtid_21955;\n    if (slt64(gtid_21955, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) {\n        int64_t defunc_0_f_res_22865;\n        int8_t lifted_lambda_res_21962;\n        \n        defunc_0_f_res_22865 = ((__global int64_t *) mem_23211)[(int64_t) 0];\n        // definitions.fut:109:21-58\n        lifted_lambda_res_21962 = ((__global int8_t *) mem_23052)[defunc_0_f_res_22865 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_21955];\n        ((__global int8_t *) mem_23308)[gtid_21955] = lifted_lambda_res_21962;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_21952\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21983_dim1, 1, 1)\nvoid mainzisegmap_21983(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t num_tblocks_21979, int32_t virt_num_tblocks_23953, __global unsigned char *mem_23052, __gl", "obal unsigned char *mem_23214, __global unsigned char *mem_23308)\n{\n    #define segmap_tblock_sizze_21978 (mainzisegmap_21983zisegmap_tblock_sizze_21978)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23955;\n    int32_t tblock_sizze_23958;\n    int32_t wave_sizze_23957;\n    int32_t block_id_23956;\n    int32_t global_tid_23954;\n    int64_t phys_tid_21983;\n    int32_t phys_tblock_id_23959;\n    int32_t iterations_23960;\n    \n    local_tid_23955 = get_local_id(0);\n    tblock_sizze_23958 = get_local_size(0);\n    wave_sizze_23957 = LOCKSTEP_WIDTH;\n    block_id_23956 = get_tblock_id(0);\n    global_tid_23954 = block_id_23956 * tblock_sizze_23958 + local_tid_23955;\n    phys_tid_21983 = sext_i32_i64(global_tid_23954);\n    phys_tblock_id_23959 = get_tblock_id(0);\n    iterations_23960 = sdiv_up32(virt_num_tblocks_23953 - phys_tblock_id_23959, sext_i64_i32(num_tblocks_21979));\n    for (int32_t i_23961 = 0; i_23961 < iterations_23960; i_23961++) {\n        int32_t virt_tblock_id_23962;\n        int64_t global_tid_23963;\n        int64_t slice_23964;\n        int64_t gtid_21982;\n        int64_t remnant_23965;\n        \n        virt_tblock_id_23962 = phys_tblock_id_23959 + i_23961 * sext_i64_i32(num_tblocks_21979);\n        global_tid_23963 = sext_i32_i64(virt_tblock_id_23962) * segmap_tblock_sizze_21978 + sext_i32_i64(local_tid_23955);\n        slice_23964 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n        gtid_21982 = global_tid_23963;\n        remnant_23965 = global_tid_23963 - gtid_21982;\n        if (slt64(gtid_21982, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) {\n            int64_t tmp_22866;\n            int8_t v_21986;\n            \n            tmp_22866 = ((__global int64_t *) mem_23214)[(int64_t) 0];\n            v_21986 = ((__global int8_t *) mem_23308)[gtid_21982];\n            // definitions.fut:110:22-45\n            ",
                                    "// UpdateAcc\n            if ((sle64((int64_t) 0, tmp_22866) && slt64(tmp_22866, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) && (sle64((int64_t) 0, gtid_21982) && slt64(gtid_21982, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659))) {\n                ((__global int8_t *) mem_23052)[tmp_22866 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_21982] = v_21986;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_21978\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22012_dim1, 1, 1)\nvoid mainzisegmap_22012(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t num_qubits_14547, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int8_t u64_res_21014, int64_t num_tblocks_22008, int32_t virt_num_tblocks_23966, __global unsigned char *mem_23052, __global unsigned char *mem_23211, __global unsigned char *mem_23215)\n{\n    #define segmap_tblock_sizze_22007 (mainzisegmap_22012zisegmap_tblock_sizze_22007)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23968;\n    int32_t tblock_sizze_23971;\n    int32_t wave_sizze_23970;\n    int32_t block_id_23969;\n    int32_t global_tid_23967;\n    int64_t phys_tid_22012;\n    int32_t phys_tblock_id_23972;\n    int32_t iterations_23973;\n    \n    local_tid_23968 = get_local_id(0);\n    tblock_sizze_23971 = get_local_size(0);\n    wave_sizze_23970 = LOCKSTEP_WIDTH;\n    block_id_23969 = get_tblock_id(0);\n    global_tid_23967 = block_id_23969 * tblock_sizze_23971 + local_tid_23968;\n    phys_tid_22012 = sext_i32_i64(global_tid_23967);\n    phys_tblock_id_23972 = get_tblock_id(0);\n    iterations_23973 = sdiv_up32(virt_num_tblocks_23966 - phys_tblock_id_23972, sext_i64_i32(num_tblocks_22008));\n    for (int32_t i_23974 = 0; i_23974 < iterations_23973; i_2", "3974++) {\n        int32_t virt_tblock_id_23975;\n        int64_t global_tid_23976;\n        int64_t slice_23977;\n        int64_t gtid_22011;\n        int64_t remnant_23978;\n        \n        virt_tblock_id_23975 = phys_tblock_id_23972 + i_23974 * sext_i64_i32(num_tblocks_22008);\n        global_tid_23976 = sext_i32_i64(virt_tblock_id_23975) * segmap_tblock_sizze_22007 + sext_i32_i64(local_tid_23968);\n        slice_23977 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n        gtid_22011 = global_tid_23976;\n        remnant_23978 = global_tid_23976 - gtid_22011;\n        if (slt64(gtid_22011, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) {\n            int64_t defunc_0_f_res_22870;\n            int64_t zeze_rhs_22871;\n            bool cond_22015;\n            int8_t lifted_lambda_res_22016;\n            \n            defunc_0_f_res_22870 = ((__global int64_t *) mem_23211)[(int64_t) 0];\n            zeze_rhs_22871 = ((__global int64_t *) mem_23215)[(int64_t) 0];\n            // definitions.fut:117:20-122:26\n            cond_22015 = gtid_22011 == zeze_rhs_22871;\n            // definitions.fut:117:20-122:26\n            if (cond_22015) {\n                lifted_lambda_res_22016 = (int8_t) 1;\n            } else {\n                int64_t zeze_rhs_22017;\n                bool cond_22018;\n                int8_t lifted_lambda_res_f_res_22019;\n                \n                // definitions.fut:120:31-34\n                zeze_rhs_22017 = mul64((int64_t) 2, num_qubits_14547);\n                // definitions.fut:120:20-122:26\n                cond_22018 = gtid_22011 == zeze_rhs_22017;\n                // definitions.fut:120:20-122:26\n                if (cond_22018) {\n                    lifted_lambda_res_f_res_22019 = u64_res_21014;\n                } else {\n                    lifted_lambda_res_f_res_22019 = (int8_t) 0;\n                }\n                lifted_lambda_res_22016 = lifted_lambda_res_f_res_22019;\n            }\n            // definitions.fut:124:22-", "45\n            // UpdateAcc\n            if ((sle64((int64_t) 0, defunc_0_f_res_22870) && slt64(defunc_0_f_res_22870, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) && (sle64((int64_t) 0, gtid_22011) && slt64(gtid_22011, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659))) {\n                ((__global int8_t *) mem_23052)[defunc_0_f_res_22870 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_22011] = lifted_lambda_res_22016;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22007\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22040_dim1, 1, 1)\nvoid mainzisegmap_22040(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t num_tblocks_22036, int32_t virt_num_tblocks_23979, __global unsigned char *mem_23052)\n{\n    #define segmap_tblock_sizze_22035 (mainzisegmap_22040zisegmap_tblock_sizze_22035)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23981;\n    int32_t tblock_sizze_23984;\n    int32_t wave_sizze_23983;\n    int32_t block_id_23982;\n    int32_t global_tid_23980;\n    int64_t phys_tid_22040;\n    int32_t phys_tblock_id_23985;\n    int32_t iterations_23986;\n    \n    local_tid_23981 = get_local_id(0);\n    tblock_sizze_23984 = get_local_size(0);\n    wave_sizze_23983 = LOCKSTEP_WIDTH;\n    block_id_23982 = get_tblock_id(0);\n    global_tid_23980 = block_id_23982 * tblock_sizze_23984 + local_tid_23981;\n    phys_tid_22040 = sext_i32_i64(global_tid_23980);\n    phys_tblock_id_23985 = get_tblock_id(0);\n    iterations_23986 = sdiv_up32(virt_num_tblocks_23979 - phys_tblock_id_23985, sext_i64_i32(num_tblocks_22036));\n    for (int32_t i_23987 = 0; i_23987 < iterations_23986; i_23987++) {\n        int32_t virt_tblo",
                                    "ck_id_23988;\n        int64_t global_tid_23989;\n        int64_t slice_23990;\n        int64_t gtid_22039;\n        int64_t remnant_23991;\n        \n        virt_tblock_id_23988 = phys_tblock_id_23985 + i_23987 * sext_i64_i32(num_tblocks_22036);\n        global_tid_23989 = sext_i32_i64(virt_tblock_id_23988) * segmap_tblock_sizze_22035 + sext_i32_i64(local_tid_23981);\n        slice_23990 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n        gtid_22039 = global_tid_23989;\n        remnant_23991 = global_tid_23989 - gtid_22039;\n        if (slt64(gtid_22039, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) {\n            // definitions.fut:130:22-47\n            // UpdateAcc\n            if ((sle64((int64_t) 0, arg_16658) && slt64(arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) && (sle64((int64_t) 0, gtid_22039) && slt64(gtid_22039, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659))) {\n                ((__global int8_t *) mem_23052)[arg_16658 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_22039] = (int8_t) 0;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22035\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22076_dim1, 1, 1)\nvoid mainzisegmap_22076(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t num_qubits_14547, int64_t m_21071, int64_t num_tblocks_22072, int32_t virt_num_tblocks_24053, __global unsigned char *mem_23119, __global unsigned char *mem_23124, __global unsigned char *mem_23126)\n{\n    #define segmap_tblock_sizze_22071 (mainzisegmap_22076zisegmap_tblock_sizze_22071)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24055;\n    int32_t tblock_sizze_24058;\n    int32_t wave_sizze_24057;\n    int32_t block_id_24056;\n    int32_t global", "_tid_24054;\n    int64_t phys_tid_22076;\n    int32_t phys_tblock_id_24059;\n    int32_t iterations_24060;\n    \n    local_tid_24055 = get_local_id(0);\n    tblock_sizze_24058 = get_local_size(0);\n    wave_sizze_24057 = LOCKSTEP_WIDTH;\n    block_id_24056 = get_tblock_id(0);\n    global_tid_24054 = block_id_24056 * tblock_sizze_24058 + local_tid_24055;\n    phys_tid_22076 = sext_i32_i64(global_tid_24054);\n    phys_tblock_id_24059 = get_tblock_id(0);\n    iterations_24060 = sdiv_up32(virt_num_tblocks_24053 - phys_tblock_id_24059, sext_i64_i32(num_tblocks_22072));\n    for (int32_t i_24061 = 0; i_24061 < iterations_24060; i_24061++) {\n        int32_t virt_tblock_id_24062;\n        int64_t global_tid_24063;\n        int64_t slice_24064;\n        int64_t gtid_22075;\n        int64_t remnant_24065;\n        \n        virt_tblock_id_24062 = phys_tblock_id_24059 + i_24061 * sext_i64_i32(num_tblocks_22072);\n        global_tid_24063 = sext_i32_i64(virt_tblock_id_24062) * segmap_tblock_sizze_22071 + sext_i32_i64(local_tid_24055);\n        slice_24064 = num_qubits_14547;\n        gtid_22075 = global_tid_24063;\n        remnant_24065 = global_tid_24063 - gtid_22075;\n        if (slt64(gtid_22075, num_qubits_14547)) {\n            int64_t eta_p_22077;\n            bool cond_22081;\n            int64_t lifted_lambda_res_22082;\n            \n            eta_p_22077 = ((__global int64_t *) mem_23124)[gtid_22075];\n            // definitions.fut:132:29-67\n            cond_22081 = eta_p_22077 == (int64_t) 1;\n            // definitions.fut:132:29-67\n            if (cond_22081) {\n                int64_t eta_p_22078;\n                int64_t lifted_lambda_res_t_res_22083;\n                \n                eta_p_22078 = ((__global int64_t *) mem_23119)[gtid_22075];\n                // definitions.fut:132:29-67\n                lifted_lambda_res_t_res_22083 = sub64(eta_p_22078, (int64_t) 1);\n                lifted_lambda_res_22082 = lifted_lambda_res_t_res_22083;\n            } else {\n                lifted_lambda_res", "_22082 = (int64_t) -1;\n            }\n            // definitions.fut:132:29-67\n            // UpdateAcc\n            if (sle64((int64_t) 0, lifted_lambda_res_22082) && slt64(lifted_lambda_res_22082, m_21071)) {\n                ((__global int64_t *) mem_23126)[lifted_lambda_res_22082] = gtid_22075;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22071\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22162_dim1, 1, 1)\nvoid mainzisegmap_22162(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t m_21071, int64_t num_tblocks_22158, int64_t num_threads_23405, int64_t ctx_23447, int32_t virt_num_tblocks_24111, __global unsigned char *mem_23052, __global unsigned char *mem_23126, __global unsigned char *mem_23128, __global unsigned char *mem_23156, __global unsigned char *mem_23159, __global unsigned char *mem_23189, __global unsigned char *color_23358)\n{\n    #define segmap_tblock_sizze_22157 (mainzisegmap_22162zisegmap_tblock_sizze_22157)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24113;\n    int32_t tblock_sizze_24116;\n    int32_t wave_sizze_24115;\n    int32_t block_id_24114;\n    int32_t global_tid_24112;\n    int64_t phys_tid_22162;\n    int32_t phys_tblock_id_24117;\n    int32_t iterations_24118;\n    \n    local_tid_24113 = get_local_id(0);\n    tblock_sizze_24116 = get_local_size(0);\n    wave_sizze_24115 = LOCKSTEP_WIDTH;\n    block_id_24114 = get_tblock_id(0);\n    global_tid_24112 = blo",
                                    "ck_id_24114 * tblock_sizze_24116 + local_tid_24113;\n    phys_tid_22162 = sext_i32_i64(global_tid_24112);\n    phys_tblock_id_24117 = get_tblock_id(0);\n    iterations_24118 = sdiv_up32(virt_num_tblocks_24111 - phys_tblock_id_24117, sext_i64_i32(num_tblocks_22158));\n    for (int32_t i_24119 = 0; i_24119 < iterations_24118; i_24119++) {\n        int32_t virt_tblock_id_24120;\n        int64_t global_tid_24121;\n        int64_t slice_24122;\n        int64_t gtid_22161;\n        int64_t remnant_24123;\n        \n        virt_tblock_id_24120 = phys_tblock_id_24117 + i_24119 * sext_i64_i32(num_tblocks_22158);\n        global_tid_24121 = sext_i32_i64(virt_tblock_id_24120) * segmap_tblock_sizze_22157 + sext_i32_i64(local_tid_24113);\n        slice_24122 = m_21071;\n        gtid_22161 = global_tid_24121;\n        remnant_24123 = global_tid_24121 - gtid_22161;\n        if (slt64(gtid_22161, m_21071)) {\n            int64_t eta_p_22163;\n            int64_t rowsum_arg2_22164;\n            bool x_22165;\n            bool y_22166;\n            bool bounds_check_22167;\n            bool index_certs_22168;\n            int8_t zp_lhs_22878;\n            int8_t mem_23167[(int64_t) 2];\n            int8_t defunc_0_f_res_22169;\n            int8_t redout_22802;\n            int8_t zt_rhs_22211;\n            int8_t zp_rhs_22212;\n            int8_t zp_lhs_22213;\n            int8_t zv_lhs_22214;\n            int8_t res_22215;\n            bool cond_22216;\n            bool cond_neg_22217;\n            int8_t v_22218;\n            int8_t mem_23178[(int64_t) 1];\n            int64_t tmp_offs_24127;\n            \n            eta_p_22163 = ((__global int64_t *) mem_23126)[gtid_22161];\n            // definitions.fut:133:64-67\n            rowsum_arg2_22164 = add64(num_qubits_14547, eta_p_22163);\n            // definitions.fut:25:43-52\n            x_22165 = sle64((int64_t) 0, rowsum_arg2_22164);\n            // definitions.fut:25:43-52\n            y_22166 = slt64(rowsum_arg2_22164, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz", "20U1z7dUzg_16659);\n            // definitions.fut:25:43-52\n            bounds_check_22167 = x_22165 && y_22166;\n            // definitions.fut:25:43-52\n            if (!bounds_check_22167) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 17) == -1) {\n                        global_failure_args[0] = (int64_t) rowsum_arg2_22164;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            zp_lhs_22878 = ((__global int8_t *) mem_23128)[(int64_t) 0];\n            // definitions.fut:29:12-98\n            // definitions.fut:25:17-29:98\n            redout_22802 = (int8_t) 0;\n            for (int64_t i_22804 = 0; i_22804 < num_qubits_14547; i_22804++) {\n                int64_t g_arg3_22172;\n                bool x_22173;\n                bool y_22174;\n                bool bounds_check_22175;\n                bool index_certs_22176;\n                bool y_22179;\n                bool index_certs_22181;\n                int8_t g_arg3_22177;\n                int8_t g_arg2_22182;\n                int8_t g_arg1_22183;\n                int8_t g_arg0_22184;\n                bool cond_22185;\n                bool cond_t_res_22186;\n                bool x_22187;\n                int8_t g_res_22188;\n                int8_t tmp_22205;\n                int8_t tmp_22206;\n                int8_t defunc_0_op_res_22210;\n                int8_t redout_tmp_24124;\n                \n                // definitions.fut:25:85-88\n                g_arg3_22172 = add64(num_qubits_14547, i_22804);\n                // definitions.fut:25:73-89\n                x_22173 = sle64((int64_t) 0, g_arg3_22172);\n                // definitions.fut:25:73-89\n                y_22174 = slt64(g_arg3_22172, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n   ", "             // definitions.fut:25:73-89\n                bounds_check_22175 = x_22173 && y_22174;\n                // definitions.fut:25:73-89\n                if (!bounds_check_22175) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 18) == -1) {\n                            global_failure_args[0] = (int64_t) g_arg3_22172;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                // definitions.fut:25:60-72\n                y_22179 = slt64(i_22804, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n                // definitions.fut:25:60-72\n                if (!y_22179) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 19) == -1) {\n                            global_failure_args[0] = (int64_t) i_22804;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                // definitions.fut:25:17-98\n                g_arg3_22177 = ((__global int8_t *) mem_23052)[arg_16658 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + g_arg3_22172];\n                // definitions.fut:25:17-98\n                g_arg2_22182 = ((__global int8_t *) mem_23052)[arg_16658 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + i_22804];\n                // definitions.fut:25:17-98\n                g_arg1_22183 = ((__global int8_t *) mem_23156)[rowsum_arg2_22164 + g_arg3_22172 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659];\n        ",
                                    "        // definitions.fut:25:17-98\n                g_arg0_22184 = ((__global int8_t *) mem_23156)[rowsum_arg2_22164 + i_22804 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659];\n                // definitions.fut:12:3-20:9\n                cond_22185 = g_arg0_22184 == g_arg2_22182;\n                // definitions.fut:12:21-25\n                cond_t_res_22186 = g_arg0_22184 == (int8_t) 0;\n                // definitions.fut:25:28-89\n                x_22187 = cond_22185 && cond_t_res_22186;\n                // definitions.fut:12:3-20:9\n                if (x_22187) {\n                    g_res_22188 = (int8_t) 0;\n                } else {\n                    bool cond_t_res_22189;\n                    bool x_22190;\n                    int8_t g_res_f_res_22191;\n                    \n                    // definitions.fut:14:26-30\n                    cond_t_res_22189 = g_arg0_22184 == (int8_t) 1;\n                    // definitions.fut:25:28-89\n                    x_22190 = cond_22185 && cond_t_res_22189;\n                    // definitions.fut:14:8-20:9\n                    if (x_22190) {\n                        int8_t g_res_f_res_t_res_22192;\n                        \n                        // definitions.fut:15:11-15\n                        g_res_f_res_t_res_22192 = sub8(g_arg3_22177, g_arg1_22183);\n                        g_res_f_res_22191 = g_res_f_res_t_res_22192;\n                    } else {\n                        bool cond_t_res_22193;\n                        bool x_22194;\n                        int8_t g_res_f_res_f_res_22195;\n                        \n                        // definitions.fut:16:25-29\n                        cond_t_res_22193 = g_arg2_22182 == (int8_t) 0;\n                        // definitions.fut:25:28-89\n                        x_22194 = cond_t_res_22189 && cond_t_res_22193;\n                        // definitions.fut:16:8-20:9\n                        if (x_22194) {\n                            int8_t zm_lhs_22196;\n                       ", "     int8_t zt_rhs_22197;\n                            int8_t g_res_f_res_f_res_t_res_22198;\n                            \n                            // definitions.fut:17:16-20\n                            zm_lhs_22196 = mul8((int8_t) 2, g_arg1_22183);\n                            // definitions.fut:17:21-24\n                            zt_rhs_22197 = sub8(zm_lhs_22196, (int8_t) 1);\n                            // definitions.fut:17:11-24\n                            g_res_f_res_f_res_t_res_22198 = mul8(g_arg3_22177, zt_rhs_22197);\n                            g_res_f_res_f_res_22195 = g_res_f_res_f_res_t_res_22198;\n                        } else {\n                            bool cond_t_res_22199;\n                            bool x_22200;\n                            int8_t g_res_f_res_f_res_f_res_22201;\n                            \n                            // definitions.fut:18:25-29\n                            cond_t_res_22199 = g_arg2_22182 == (int8_t) 1;\n                            // definitions.fut:25:28-89\n                            x_22200 = cond_t_res_22186 && cond_t_res_22199;\n                            // definitions.fut:18:8-20:9\n                            if (x_22200) {\n                                int8_t zm_rhs_22202;\n                                int8_t zt_rhs_22203;\n                                int8_t g_res_f_res_f_res_f_res_t_res_22204;\n                                \n                                // definitions.fut:19:20-24\n                                zm_rhs_22202 = mul8((int8_t) 2, g_arg3_22177);\n                                // definitions.fut:19:16-24\n                                zt_rhs_22203 = sub8((int8_t) 1, zm_rhs_22202);\n                                // definitions.fut:19:11-24\n                                g_res_f_res_f_res_f_res_t_res_22204 = mul8(g_arg1_22183, zt_rhs_22203);\n                                g_res_f_res_f_res_f_res_22201 = g_res_f_res_f_res_f_res_t_res_22204;\n                            } else {\n   ", "                             g_res_f_res_f_res_f_res_22201 = (int8_t) 0;\n                            }\n                            g_res_f_res_f_res_22195 = g_res_f_res_f_res_f_res_22201;\n                        }\n                        g_res_f_res_22191 = g_res_f_res_f_res_22195;\n                    }\n                    g_res_22188 = g_res_f_res_22191;\n                }\n                // definitions.fut:29:37-51\n                tmp_22205 = g_arg2_22182 ^ g_arg0_22184;\n                // definitions.fut:29:70-88\n                tmp_22206 = g_arg3_22177 ^ g_arg1_22183;\n                // definitions.fut:29:12-98\n                mem_23167[(int64_t) 0] = tmp_22205;\n                mem_23167[(int64_t) 1] = tmp_22206;\n                // definitions.fut:25:110-113\n                defunc_0_op_res_22210 = add8(g_res_22188, redout_22802);\n                for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                    ((__global int8_t *) mem_23159)[phys_tid_22162 + i_22804 * ctx_23447 + i_0 * num_threads_23405] = mem_23167[i_0];\n                }\n                redout_tmp_24124 = defunc_0_op_res_22210;\n                redout_22802 = redout_tmp_24124;\n            }\n            defunc_0_f_res_22169 = redout_22802;\n            // definitions.fut:89:58-133:67\n            zt_rhs_22211 = ((__global int8_t *) mem_23052)[rowsum_arg2_22164 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + arg_16658];\n            // definitions.fut:26:41-61\n            zp_rhs_22212 = mul8((int8_t) 2, zt_rhs_22211);\n            // definitions.fut:26:37-61\n            zp_lhs_22213 = add8(zp_rhs_22212, zp_lhs_22878);\n            // definitions.fut:26:62-71\n            zv_lhs_22214 = add8(defunc_0_f_res_22169, zp_lhs_22213);\n            // definitions.fut:26:73-76\n            res_22215 = smod8(zv_lhs_22214, (int8_t) 4);\n            // definitions.fut:27:11-36\n            cond_22216 = res_22215 == (int8_t) 0;\n            // definitions.fut:89:58-133:67\n            cond_neg_22217",
                                    " = !cond_22216;\n            // definitions.fut:89:58-133:67\n            v_22218 = btoi_bool_i8(cond_neg_22217);\n            // definitions.fut:89:58-133:67\n            // definitions.fut:89:58-133:67\n            for (int64_t i_0 = 0; i_0 < num_qubits_14547; i_0++) {\n                for (int64_t i_1 = 0; i_1 < (int64_t) 2; i_1++) {\n                    ((__global int8_t *) color_23358)[phys_tid_22162 + (i_0 * (num_threads_23405 * (int64_t) 2) + i_1 * num_threads_23405)] = ((__global int8_t *) mem_23159)[phys_tid_22162 + (i_0 * ctx_23447 + i_1 * num_threads_23405)];\n                }\n            }\n            // definitions.fut:89:58-133:67\n            // definitions.fut:89:58-133:67\n            for (int64_t nest_i_24126 = 0; nest_i_24126 < (int64_t) 1; nest_i_24126++) {\n                mem_23178[nest_i_24126] = v_22218;\n            }\n            // definitions.fut:23:79-133:82\n            tmp_offs_24127 = (int64_t) 0;\n            // definitions.fut:23:79-133:82\n            for (int64_t i_0 = 0; i_0 < arg_16658; i_0++) {\n                ((__global int8_t *) mem_23189)[gtid_22161 + m_21071 * tmp_offs_24127 + i_0 * m_21071] = ((__global int8_t *) color_23358)[phys_tid_22162 + i_0 * num_threads_23405];\n            }\n            tmp_offs_24127 += arg_16658;\n            // definitions.fut:23:79-133:82\n            for (int64_t i_0 = 0; i_0 < (int64_t) 1; i_0++) {\n                ((__global int8_t *) mem_23189)[gtid_22161 + m_21071 * tmp_offs_24127 + i_0 * m_21071] = mem_23178[i_0];\n            }\n            tmp_offs_24127 += (int64_t) 1;\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22157\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22326_dim1, 1, 1)\nvoid mainzisegmap_22326(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option,", " __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t m_21071, __global unsigned char *mem_23126, __global unsigned char *mem_23131, __global unsigned char *mem_23132)\n{\n    #define segmap_tblock_sizze_22321 (mainzisegmap_22326zisegmap_tblock_sizze_22321)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24130;\n    int32_t tblock_sizze_24133;\n    int32_t wave_sizze_24132;\n    int32_t block_id_24131;\n    int32_t global_tid_24129;\n    int64_t phys_tid_22326;\n    int64_t global_tid_24134;\n    int64_t slice_24135;\n    int64_t gtid_22325;\n    int64_t remnant_24136;\n    \n    local_tid_24130 = get_local_id(0);\n    tblock_sizze_24133 = get_local_size(0);\n    wave_sizze_24132 = LOCKSTEP_WIDTH;\n    block_id_24131 = get_tblock_id(0);\n    global_tid_24129 = block_id_24131 * tblock_sizze_24133 + local_tid_24130;\n    phys_tid_22326 = sext_i32_i64(global_tid_24129);\n    global_tid_24134 = sext_i32_i64(block_id_24131) * segmap_tblock_sizze_22321 + sext_i32_i64(local_tid_24130);\n    slice_24135 = m_21071;\n    gtid_22325 = global_tid_24134;\n    remnant_24136 = global_tid_24134 - gtid_22325;\n    if (slt64(gtid_22325, m_21071)) {\n        int64_t eta_p_22327;\n        int64_t rowsum_arg2_22328;\n        bool x_22329;\n        bool y_22330;\n        bool bounds_check_22331;\n        bool index_certs_22332;\n        \n        eta_p_22327 = ((__global int64_t *) mem_23126)[gtid_22325];\n        // definitions.fut:133:64-67\n        rowsum_arg2_22328 = add64(num_qubits_14547, eta_p_22327);\n        // definitions.fut:25:43-52\n        x_22329 = sle64((int64_t) 0, rowsum_arg2_22328);\n        // definitions.fut:25:43-52\n        y_22330 = slt64(rowsum_arg2_22328, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n        // definitions.fut:25:43-52\n        bounds_check_22331 = x_22", "329 && y_22330;\n        // definitions.fut:25:43-52\n        if (!bounds_check_22331) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 20) == -1) {\n                    global_failure_args[0] = (int64_t) rowsum_arg2_22328;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                    ;\n                }\n                return;\n            }\n        }\n        ((__global int64_t *) mem_23131)[gtid_22325] = rowsum_arg2_22328;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22321\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22390_dim1, 1, 1)\nvoid mainzisegmap_22390(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t m_21071, __global unsigned char *mem_23052, __global unsigned char *mem_23128, __global unsigned char *mem_23131, __global unsigned char *mem_23132, __global unsigned char *mem_23143)\n{\n    #define segmap_tblock_sizze_22386 (mainzisegmap_22390zisegmap_tblock_sizze_22386)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24211;\n    int32_t tblock_sizze_24214;\n    int32_t wave_sizze_24213;\n    int32_t block_id_24212;\n    int32_t global_tid_24210;\n    int64_t phys_tid_22390;\n    int64_t global_tid_24215;\n    int64_t slice_24216;\n    int64_t gtid_22389;\n    int64_t remnant_24217;\n    \n    local_tid_24211 = get_local_id(0);\n    tblock_sizze_24214 = get_local_size(0);\n    wave_sizze_24213 = LOCKSTEP_WIDTH;\n    block_id_24212 = get_tblock_id(0);\n    global_tid_24210 = block_id_24212 * tblock_sizze_24214 + local_tid_24211;\n    phys_tid_22390 = sext_i32_i64(global_tid_24210);\n    global_tid_24215 = sext_i32_i64(block_id_24212) * segmap_tblock_sizze_22386 + sext_i32_i64(local_tid_24211);\n    slice_24216 = m_21071;\n    gtid",
                                    "_22389 = global_tid_24215;\n    remnant_24217 = global_tid_24215 - gtid_22389;\n    if (slt64(gtid_22389, m_21071)) {\n        int8_t zp_lhs_22879;\n        int64_t rowsum_arg2_22391;\n        bool index_certs_22392;\n        int8_t defunc_0_f_res_22393;\n        int8_t zt_rhs_22394;\n        int8_t zp_rhs_22395;\n        int8_t zp_lhs_22396;\n        int8_t zv_lhs_22397;\n        int8_t res_22398;\n        bool cond_22399;\n        bool cond_neg_22400;\n        int8_t v_22401;\n        \n        zp_lhs_22879 = ((__global int8_t *) mem_23128)[(int64_t) 0];\n        rowsum_arg2_22391 = ((__global int64_t *) mem_23131)[gtid_22389];\n        index_certs_22392 = 0;\n        defunc_0_f_res_22393 = ((__global int8_t *) mem_23143)[gtid_22389];\n        // definitions.fut:89:58-133:67\n        zt_rhs_22394 = ((__global int8_t *) mem_23052)[rowsum_arg2_22391 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + arg_16658];\n        // definitions.fut:26:41-61\n        zp_rhs_22395 = mul8((int8_t) 2, zt_rhs_22394);\n        // definitions.fut:26:37-61\n        zp_lhs_22396 = add8(zp_rhs_22395, zp_lhs_22879);\n        // definitions.fut:26:62-71\n        zv_lhs_22397 = add8(defunc_0_f_res_22393, zp_lhs_22396);\n        // definitions.fut:26:73-76\n        res_22398 = smod8(zv_lhs_22397, (int8_t) 4);\n        // definitions.fut:27:11-36\n        cond_22399 = res_22398 == (int8_t) 0;\n        // definitions.fut:89:58-133:67\n        cond_neg_22400 = !cond_22399;\n        // definitions.fut:89:58-133:67\n        v_22401 = btoi_bool_i8(cond_neg_22400);\n        ((__global int8_t *) mem_23143)[gtid_22389] = v_22401;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22386\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22429_dim1, 1, 1)\nvoid mainzisegmap_22429(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t dzlz7bUZLztZRz20Udz2081Uz2083Uz2082Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1", "ZRz7dUzg_21089, int64_t num_tblocks_22425, int64_t ext_23190, int64_t ext_23191, int32_t virt_num_tblocks_24240, __global unsigned char *mem_23052, __global unsigned char *mem_23122, __global unsigned char *ext_mem_23192)\n{\n    #define segmap_tblock_sizze_22424 (mainzisegmap_22429zisegmap_tblock_sizze_22424)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24242;\n    int32_t tblock_sizze_24245;\n    int32_t wave_sizze_24244;\n    int32_t block_id_24243;\n    int32_t global_tid_24241;\n    int64_t phys_tid_22429;\n    int32_t phys_tblock_id_24246;\n    int32_t iterations_24247;\n    \n    local_tid_24242 = get_local_id(0);\n    tblock_sizze_24245 = get_local_size(0);\n    wave_sizze_24244 = LOCKSTEP_WIDTH;\n    block_id_24243 = get_tblock_id(0);\n    global_tid_24241 = block_id_24243 * tblock_sizze_24245 + local_tid_24242;\n    phys_tid_22429 = sext_i32_i64(global_tid_24241);\n    phys_tblock_id_24246 = get_tblock_id(0);\n    iterations_24247 = sdiv_up32(virt_num_tblocks_24240 - phys_tblock_id_24246, sext_i64_i32(num_tblocks_22425));\n    for (int32_t i_24248 = 0; i_24248 < iterations_24247; i_24248++) {\n        int32_t virt_tblock_id_24249;\n        int64_t global_tid_24250;\n        int64_t slice_24251;\n        int64_t gtid_22428;\n        int64_t remnant_24252;\n        \n        virt_tblock_id_24249 = phys_tblock_id_24246 + i_24248 * sext_i64_i32(num_tblocks_22425);\n        global_tid_24250 = sext_i32_i64(virt_tblock_id_24249) * segmap_tblock_sizze_22424 + sext_i32_i64(local_tid_24242);\n        slice_24251 = dzlz7bUZLztZRz20Udz2081Uz2083Uz2082Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_21089;\n        gtid_22428 = global_tid_24250;\n        remnant_24252 = global_tid_24250 - gtid_22428;\n        if (slt64(gtid_22428, dzlz7bUZLztZRz20Udz2081Uz2083Uz2082Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_21089)) {\n            int64_t binop_x_22702;\n            int6", "4_t binop_y_22703;\n            int64_t new_index_22704;\n            bool index_concat_cmp_22710;\n            int64_t index_concat_branch_22714;\n            int8_t v_22433;\n            \n            binop_x_22702 = squot64(gtid_22428, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            binop_y_22703 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 * binop_x_22702;\n            new_index_22704 = gtid_22428 - binop_y_22703;\n            index_concat_cmp_22710 = sle64(arg_16658, new_index_22704);\n            if (index_concat_cmp_22710) {\n                index_concat_branch_22714 = arg_16658;\n            } else {\n                int64_t new_index_22789;\n                int64_t binop_y_22791;\n                int64_t new_index_22792;\n                int64_t index_concat_22713;\n                \n                new_index_22789 = squot64(new_index_22704, (int64_t) 2);\n                binop_y_22791 = (int64_t) 2 * new_index_22789;\n                new_index_22792 = new_index_22704 - binop_y_22791;\n                index_concat_22713 = ((__global int64_t *) mem_23122)[new_index_22789 * (int64_t) 2 + new_index_22792];\n                index_concat_branch_22714 = index_concat_22713;\n            }\n            v_22433 = ((__global int8_t *) ext_mem_23192)[binop_x_22702 * ext_23191 + new_index_22704 * ext_23190];\n            // definitions.fut:134:22-70\n            // UpdateAcc\n            if ((sle64((int64_t) 0, arg_16658) && slt64(arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) && (sle64((int64_t) 0, index_concat_branch_22714) && slt64(index_concat_branch_22714, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659))) {\n                ((__global int8_t *) mem_23052)[arg_16658 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + index_concat_branch_22714] = v_22433;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #und",
                                    "ef segmap_tblock_sizze_22424\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22467_dim1, 1, 1)\nvoid mainzisegmap_22467(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t num_tblocks_22463, int32_t virt_num_tblocks_24267, __global unsigned char *mem_23052, __global unsigned char *mem_23061, __global unsigned char *mem_23093, __global unsigned char *mem_23103)\n{\n    #define segmap_tblock_sizze_22462 (mainzisegmap_22467zisegmap_tblock_sizze_22462)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24269;\n    int32_t tblock_sizze_24272;\n    int32_t wave_sizze_24271;\n    int32_t block_id_24270;\n    int32_t global_tid_24268;\n    int64_t phys_tid_22467;\n    int32_t phys_tblock_id_24273;\n    int32_t iterations_24274;\n    \n    local_tid_24269 = get_local_id(0);\n    tblock_sizze_24272 = get_local_size(0);\n    wave_sizze_24271 = LOCKSTEP_WIDTH;\n    block_id_24270 = get_tblock_id(0);\n    global_tid_24268 = block_id_24270 * tblock_sizze_24272 + local_tid_24269;\n    phys_tid_22467 = sext_i32_i64(global_tid_24268);\n    phys_tblock_id_24273 = get_tblock_id(0);\n    iterations_24274 = sdiv_up32(virt_num_tblocks_24267 - phys_tblock_id_24273, sext_i64_i32(num_tblocks_22463));\n    for (int32_t i_24275 = 0; i_24275 < iterations_24274; i_24275++) {\n        int32_t virt_tblock_id_24276;\n        int64_t global_tid_24277;\n        int64_t slice_24278;\n        int64_t gtid_22466;\n        int64_t remnant_24279;\n        \n        virt_tblock_id_24276 = phys_tblock_id_24273 + i_24275 * sext_i64_i32(num_tblocks_22463);\n        global_tid_", "24277 = sext_i32_i64(virt_tblock_id_24276) * segmap_tblock_sizze_22462 + sext_i32_i64(local_tid_24269);\n        slice_24278 = arg_16658;\n        gtid_22466 = global_tid_24277;\n        remnant_24279 = global_tid_24277 - gtid_22466;\n        if (slt64(gtid_22466, arg_16658)) {\n            bool y_22470;\n            bool index_certs_22472;\n            int64_t loopres_22920;\n            int64_t tmp_22921;\n            int8_t ri_22473;\n            int8_t xia_22474;\n            int8_t zzia_22475;\n            int8_t zc_rhs_22476;\n            int8_t tmp_22477;\n            int8_t mem_23101[(int64_t) 3];\n            \n            // definitions.fut:67:21-30\n            y_22470 = slt64(gtid_22466, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            // definitions.fut:67:21-30\n            if (!y_22470) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 27) == -1) {\n                        global_failure_args[0] = (int64_t) gtid_22466;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            loopres_22920 = ((__global int64_t *) mem_23061)[(int64_t) 0];\n            tmp_22921 = ((__global int64_t *) mem_23093)[(int64_t) 0];\n            // definitions.fut:66:5-72:18\n            ri_22473 = ((__global int8_t *) mem_23052)[gtid_22466 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + arg_16658];\n            // definitions.fut:66:5-72:18\n            xia_22474 = ((__global int8_t *) mem_23052)[gtid_22466 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + loopres_22920];\n            // definitions.fut:66:5-72:18\n            zzia_22475 = ((__global int8_t *) mem_23052)[gtid_22466 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + tmp_22921];\n        ", "    // definitions.fut:70:25-30\n            zc_rhs_22476 = mul8(xia_22474, zzia_22475);\n            // definitions.fut:70:19-30\n            tmp_22477 = ri_22473 ^ zc_rhs_22476;\n            // definitions.fut:66:5-72:18\n            // definitions.fut:66:5-72:18\n            mem_23101[(int64_t) 0] = tmp_22477;\n            mem_23101[(int64_t) 1] = zzia_22475;\n            mem_23101[(int64_t) 2] = xia_22474;\n            // definitions.fut:64:17-72:18\n            for (int64_t i_0 = 0; i_0 < (int64_t) 3; i_0++) {\n                ((__global int8_t *) mem_23103)[gtid_22466 * (int64_t) 3 + i_0] = mem_23101[i_0];\n            }\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22462\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22500_dim1, 1, 1)\nvoid mainzisegmap_22500(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027, int64_t num_tblocks_22496, int32_t virt_num_tblocks_24280, __global unsigned char *mem_23052, __global unsigned char *mem_23094, __global unsigned char *mem_23103)\n{\n    #define segmap_tblock_sizze_22495 (mainzisegmap_22500zisegmap_tblock_sizze_22495)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24282;\n    int32_t tblock_sizze_24285;\n    int32_t wave_sizze_24284;\n    int32_t block_id_24283;\n    int32_t global_tid_24281;\n    int64_t phys_tid_22500;\n    int32_t phys_tblock_id_24286;\n    int32_t iterations_24287;\n    \n    local_tid_24282 = get_local_id(0);\n    tblock_sizze_24285 = get_local_size(0);\n    wave_sizze_24284 = LOCKSTEP_WIDTH;\n    block_id_24283 = get_tblock_id(0);\n    global_tid_24281 = block_id",
                                    "_24283 * tblock_sizze_24285 + local_tid_24282;\n    phys_tid_22500 = sext_i32_i64(global_tid_24281);\n    phys_tblock_id_24286 = get_tblock_id(0);\n    iterations_24287 = sdiv_up32(virt_num_tblocks_24280 - phys_tblock_id_24286, sext_i64_i32(num_tblocks_22496));\n    for (int32_t i_24288 = 0; i_24288 < iterations_24287; i_24288++) {\n        int32_t virt_tblock_id_24289;\n        int64_t global_tid_24290;\n        int64_t slice_24291;\n        int64_t gtid_22499;\n        int64_t remnant_24292;\n        \n        virt_tblock_id_24289 = phys_tblock_id_24286 + i_24288 * sext_i64_i32(num_tblocks_22496);\n        global_tid_24290 = sext_i32_i64(virt_tblock_id_24289) * segmap_tblock_sizze_22495 + sext_i32_i64(local_tid_24282);\n        slice_24291 = dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027;\n        gtid_22499 = global_tid_24290;\n        remnant_24292 = global_tid_24290 - gtid_22499;\n        if (slt64(gtid_22499, dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027)) {\n            int64_t new_index_22731;\n            int64_t binop_y_22737;\n            int64_t new_index_22738;\n            int64_t v_22503;\n            int8_t v_22504;\n            \n            new_index_22731 = squot64(gtid_22499, (int64_t) 3);\n            binop_y_22737 = (int64_t) 3 * new_index_22731;\n            new_index_22738 = gtid_22499 - binop_y_22737;\n            v_22503 = ((__global int64_t *) mem_23094)[new_index_22738];\n            v_22504 = ((__global int8_t *) mem_23103)[new_index_22731 * (int64_t) 3 + new_index_22738];\n            // definitions.fut:74:6-38\n            // UpdateAcc\n            if ((sle64((int64_t) 0, new_index_22731) && slt64(new_index_22731, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) && (sle64((int64_t) 0, v_22503) && slt64(v_22503, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659))) {\n                ((__global int8_t *) mem_23052)[new_index_22731 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + v_22503] = v_22504;\n            }\n        }\n        barri", "er(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22495\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22539_dim1, 1, 1)\nvoid mainzisegmap_22539(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t num_tblocks_22535, int32_t virt_num_tblocks_24301, __global unsigned char *mem_23052, __global unsigned char *mem_23061, __global unsigned char *mem_23080, __global unsigned char *mem_23090)\n{\n    #define segmap_tblock_sizze_22534 (mainzisegmap_22539zisegmap_tblock_sizze_22534)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24303;\n    int32_t tblock_sizze_24306;\n    int32_t wave_sizze_24305;\n    int32_t block_id_24304;\n    int32_t global_tid_24302;\n    int64_t phys_tid_22539;\n    int32_t phys_tblock_id_24307;\n    int32_t iterations_24308;\n    \n    local_tid_24303 = get_local_id(0);\n    tblock_sizze_24306 = get_local_size(0);\n    wave_sizze_24305 = LOCKSTEP_WIDTH;\n    block_id_24304 = get_tblock_id(0);\n    global_tid_24302 = block_id_24304 * tblock_sizze_24306 + local_tid_24303;\n    phys_tid_22539 = sext_i32_i64(global_tid_24302);\n    phys_tblock_id_24307 = get_tblock_id(0);\n    iterations_24308 = sdiv_up32(virt_num_tblocks_24301 - phys_tblock_id_24307, sext_i64_i32(num_tblocks_22535));\n    for (int32_t i_24309 = 0; i_24309 < iterations_24308; i_24309++) {\n        int32_t virt_tblock_id_24310;\n        int64_t global_tid_24311;\n        int64_t slice_24312;\n        int64_t gtid_22538;\n        int64_t remnant_24313;\n        \n        virt_tblock_id_243", "10 = phys_tblock_id_24307 + i_24309 * sext_i64_i32(num_tblocks_22535);\n        global_tid_24311 = sext_i32_i64(virt_tblock_id_24310) * segmap_tblock_sizze_22534 + sext_i32_i64(local_tid_24303);\n        slice_24312 = arg_16658;\n        gtid_22538 = global_tid_24311;\n        remnant_24313 = global_tid_24311 - gtid_22538;\n        if (slt64(gtid_22538, arg_16658)) {\n            bool y_22542;\n            bool index_certs_22544;\n            int64_t loopres_22956;\n            int64_t tmp_22957;\n            int8_t ri_22545;\n            int8_t xia_22546;\n            int8_t zzia_22547;\n            int8_t zc_rhs_22548;\n            int8_t tmp_22549;\n            int8_t tmp_22550;\n            int8_t mem_23088[(int64_t) 2];\n            \n            // definitions.fut:81:21-30\n            y_22542 = slt64(gtid_22538, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            // definitions.fut:81:21-30\n            if (!y_22542) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 30) == -1) {\n                        global_failure_args[0] = (int64_t) gtid_22538;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            loopres_22956 = ((__global int64_t *) mem_23061)[(int64_t) 0];\n            tmp_22957 = ((__global int64_t *) mem_23080)[(int64_t) 0];\n            // definitions.fut:80:5-85:18\n            ri_22545 = ((__global int8_t *) mem_23052)[gtid_22538 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + arg_16658];\n            // definitions.fut:80:5-85:18\n            xia_22546 = ((__global int8_t *) mem_23052)[gtid_22538 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + loopres_22956];\n            // definitions.fut:80:5-85:18\n            zzia_22547 = ((__global ",
                                    "int8_t *) mem_23052)[gtid_22538 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + tmp_22957];\n            // definitions.fut:84:25-30\n            zc_rhs_22548 = mul8(xia_22546, zzia_22547);\n            // definitions.fut:84:19-30\n            tmp_22549 = ri_22545 ^ zc_rhs_22548;\n            // definitions.fut:84:36-41\n            tmp_22550 = xia_22546 ^ zzia_22547;\n            // definitions.fut:80:5-85:18\n            // definitions.fut:80:5-85:18\n            mem_23088[(int64_t) 0] = tmp_22549;\n            mem_23088[(int64_t) 1] = tmp_22550;\n            // definitions.fut:78:17-85:18\n            for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                ((__global int8_t *) mem_23090)[gtid_22538 * (int64_t) 2 + i_0] = mem_23088[i_0];\n            }\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22534\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22573_dim1, 1, 1)\nvoid mainzisegmap_22573(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t dzlz7bUZLztZRz20Utmpz20U2z7dUzg_17080, int64_t num_tblocks_22569, int32_t virt_num_tblocks_24314, __global unsigned char *mem_23052, __global unsigned char *mem_23081, __global unsigned char *mem_23090)\n{\n    #define segmap_tblock_sizze_22568 (mainzisegmap_22573zisegmap_tblock_sizze_22568)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24316;\n    int32_t tblock_sizze_24319;\n    int32_t wave_sizze_24318;\n    int32_t block_id_24317;\n    int32_t global_tid_24315;\n    int64_t phys_tid_22573;\n    int32_t phys_tblock_id_24320;\n    int32_t iterations_24321;\n    \n    local_tid_24316 = get_local_i", "d(0);\n    tblock_sizze_24319 = get_local_size(0);\n    wave_sizze_24318 = LOCKSTEP_WIDTH;\n    block_id_24317 = get_tblock_id(0);\n    global_tid_24315 = block_id_24317 * tblock_sizze_24319 + local_tid_24316;\n    phys_tid_22573 = sext_i32_i64(global_tid_24315);\n    phys_tblock_id_24320 = get_tblock_id(0);\n    iterations_24321 = sdiv_up32(virt_num_tblocks_24314 - phys_tblock_id_24320, sext_i64_i32(num_tblocks_22569));\n    for (int32_t i_24322 = 0; i_24322 < iterations_24321; i_24322++) {\n        int32_t virt_tblock_id_24323;\n        int64_t global_tid_24324;\n        int64_t slice_24325;\n        int64_t gtid_22572;\n        int64_t remnant_24326;\n        \n        virt_tblock_id_24323 = phys_tblock_id_24320 + i_24322 * sext_i64_i32(num_tblocks_22569);\n        global_tid_24324 = sext_i32_i64(virt_tblock_id_24323) * segmap_tblock_sizze_22568 + sext_i32_i64(local_tid_24316);\n        slice_24325 = dzlz7bUZLztZRz20Utmpz20U2z7dUzg_17080;\n        gtid_22572 = global_tid_24324;\n        remnant_24326 = global_tid_24324 - gtid_22572;\n        if (slt64(gtid_22572, dzlz7bUZLztZRz20Utmpz20U2z7dUzg_17080)) {\n            int64_t new_index_22747;\n            int64_t binop_y_22753;\n            int64_t new_index_22754;\n            int64_t v_22576;\n            int8_t v_22577;\n            \n            new_index_22747 = squot64(gtid_22572, (int64_t) 2);\n            binop_y_22753 = (int64_t) 2 * new_index_22747;\n            new_index_22754 = gtid_22572 - binop_y_22753;\n            v_22576 = ((__global int64_t *) mem_23081)[new_index_22754];\n            v_22577 = ((__global int8_t *) mem_23090)[new_index_22747 * (int64_t) 2 + new_index_22754];\n            // definitions.fut:87:6-38\n            // UpdateAcc\n            if ((sle64((int64_t) 0, new_index_22747) && slt64(new_index_22747, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) && (sle64((int64_t) 0, v_22576) && slt64(v_22576, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659))) {\n                ((__global int", "8_t *) mem_23052)[new_index_22747 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + v_22576] = v_22577;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22568\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22618_dim1, 1, 1)\nvoid mainzisegmap_22618(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t num_tblocks_22614, int32_t virt_num_tblocks_24335, __global unsigned char *mem_23052, __global unsigned char *mem_23061, __global unsigned char *mem_23063, __global unsigned char *mem_23064, __global unsigned char *mem_23068, __global unsigned char *mem_23077)\n{\n    #define segmap_tblock_sizze_22613 (mainzisegmap_22618zisegmap_tblock_sizze_22613)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24337;\n    int32_t tblock_sizze_24340;\n    int32_t wave_sizze_24339;\n    int32_t block_id_24338;\n    int32_t global_tid_24336;\n    int64_t phys_tid_22618;\n    int32_t phys_tblock_id_24341;\n    int32_t iterations_24342;\n    \n    local_tid_24337 = get_local_id(0);\n    tblock_sizze_24340 = get_local_size(0);\n    wave_sizze_24339 = LOCKSTEP_WIDTH;\n    block_id_24338 = get_tblock_id(0);\n    global_tid_24336 = block_id_24338 * tblock_sizze_24340 + local_tid_24337;\n    phys_tid_22618 = sext_i32_i64(global_tid_24336);\n    phys_tblock_id_24341 = get_tblock_id(0);\n    iterations_24342 = sdiv_up32(virt_num_tblocks_24335 - phys_tblock_id_24341, sext_i64_i32(num_tblocks_22614));\n    for (int32_t i_24343 = 0; i_24343",
                                    " < iterations_24342; i_24343++) {\n        int32_t virt_tblock_id_24344;\n        int64_t global_tid_24345;\n        int64_t slice_24346;\n        int64_t gtid_22617;\n        int64_t remnant_24347;\n        \n        virt_tblock_id_24344 = phys_tblock_id_24341 + i_24343 * sext_i64_i32(num_tblocks_22614);\n        global_tid_24345 = sext_i32_i64(virt_tblock_id_24344) * segmap_tblock_sizze_22613 + sext_i32_i64(local_tid_24337);\n        slice_24346 = arg_16658;\n        gtid_22617 = global_tid_24345;\n        remnant_24347 = global_tid_24345 - gtid_22617;\n        if (slt64(gtid_22617, arg_16658)) {\n            bool y_22621;\n            bool index_certs_22623;\n            int64_t loopres_23026;\n            int64_t loopres_23027;\n            int64_t tmp_23028;\n            int64_t zzib_23029;\n            int8_t zzia_22624;\n            int8_t zzib_22625;\n            int8_t xia_22626;\n            int8_t xib_22627;\n            int8_t ri_22628;\n            int8_t zt_lhs_22629;\n            int8_t zc_lhs_22630;\n            int8_t zt_rhs_22631;\n            int8_t zc_rhs_22632;\n            int8_t tmp_22633;\n            int8_t tmp_22634;\n            int8_t tmp_22635;\n            int8_t mem_23075[(int64_t) 3];\n            \n            // definitions.fut:52:22-31\n            y_22621 = slt64(gtid_22617, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            // definitions.fut:52:22-31\n            if (!y_22621) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 35) == -1) {\n                        global_failure_args[0] = (int64_t) gtid_22617;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            loopres_23026 = ((__global int64_t *) mem_23061)[(int64_t) 0];\n            loopres_23027 = ((__global int64", "_t *) mem_23063)[(int64_t) 0];\n            tmp_23028 = ((__global int64_t *) mem_23064)[(int64_t) 0];\n            zzib_23029 = ((__global int64_t *) mem_23068)[(int64_t) 0];\n            // definitions.fut:51:5-58:18\n            zzia_22624 = ((__global int8_t *) mem_23052)[gtid_22617 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + tmp_23028];\n            // definitions.fut:51:5-58:18\n            zzib_22625 = ((__global int8_t *) mem_23052)[gtid_22617 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + zzib_23029];\n            // definitions.fut:51:5-58:18\n            xia_22626 = ((__global int8_t *) mem_23052)[gtid_22617 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + loopres_23026];\n            // definitions.fut:51:5-58:18\n            xib_22627 = ((__global int8_t *) mem_23052)[gtid_22617 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + loopres_23027];\n            // definitions.fut:51:5-58:18\n            ri_22628 = ((__global int8_t *) mem_23052)[gtid_22617 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + arg_16658];\n            // definitions.fut:57:25-30\n            zt_lhs_22629 = mul8(zzib_22625, xia_22626);\n            // definitions.fut:57:38-43\n            zc_lhs_22630 = zzia_22624 ^ xib_22627;\n            // definitions.fut:57:44-49\n            zt_rhs_22631 = (int8_t) 1 ^ zc_lhs_22630;\n            // definitions.fut:57:31-49\n            zc_rhs_22632 = mul8(zt_lhs_22629, zt_rhs_22631);\n            // definitions.fut:57:19-49\n            tmp_22633 = ri_22628 ^ zc_rhs_22632;\n            // definitions.fut:57:56-61\n            tmp_22634 = xia_22626 ^ xib_22627;\n            // definitions.fut:57:67-72\n            tmp_22635 = zzia_22624 ^ zzib_22625;\n            // definitions.fut:51:5-58:18\n            // definitions.fut:51:5-58:18\n            mem_23075[(int64_t) 0] = tmp_22633;\n            mem_23075[(int64_t) 1] = tmp_22634;\n            mem_23075[(int64_t) 2] = tmp_226", "35;\n            // definitions.fut:46:5-58:18\n            for (int64_t i_0 = 0; i_0 < (int64_t) 3; i_0++) {\n                ((__global int8_t *) mem_23077)[gtid_22617 * (int64_t) 3 + i_0] = mem_23075[i_0];\n            }\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22613\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_22658_dim1, 1, 1)\nvoid mainzisegmap_22658(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027, int64_t num_tblocks_22654, int32_t virt_num_tblocks_24348, __global unsigned char *mem_23052, __global unsigned char *mem_23065, __global unsigned char *mem_23077)\n{\n    #define segmap_tblock_sizze_22653 (mainzisegmap_22658zisegmap_tblock_sizze_22653)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24350;\n    int32_t tblock_sizze_24353;\n    int32_t wave_sizze_24352;\n    int32_t block_id_24351;\n    int32_t global_tid_24349;\n    int64_t phys_tid_22658;\n    int32_t phys_tblock_id_24354;\n    int32_t iterations_24355;\n    \n    local_tid_24350 = get_local_id(0);\n    tblock_sizze_24353 = get_local_size(0);\n    wave_sizze_24352 = LOCKSTEP_WIDTH;\n    block_id_24351 = get_tblock_id(0);\n    global_tid_24349 = block_id_24351 * tblock_sizze_24353 + local_tid_24350;\n    phys_tid_22658 = sext_i32_i64(global_tid_24349);\n    phys_tblock_id_24354 = get_tblock_id(0);\n    iterations_24355 = sdiv_up32(virt_num_tblocks_24348 - phys_tblock_id_24354, sext_i64_i32(num_tblocks_22654));\n    for (int32_t i_24356 = 0; i_24356 < iterations_24355; i_24356++) {\n        int32_t virt_tblock_id_24357;\n        int64_t global_tid_24358;\n ",
                                    "       int64_t slice_24359;\n        int64_t gtid_22657;\n        int64_t remnant_24360;\n        \n        virt_tblock_id_24357 = phys_tblock_id_24354 + i_24356 * sext_i64_i32(num_tblocks_22654);\n        global_tid_24358 = sext_i32_i64(virt_tblock_id_24357) * segmap_tblock_sizze_22653 + sext_i32_i64(local_tid_24350);\n        slice_24359 = dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027;\n        gtid_22657 = global_tid_24358;\n        remnant_24360 = global_tid_24358 - gtid_22657;\n        if (slt64(gtid_22657, dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027)) {\n            int64_t new_index_22763;\n            int64_t binop_y_22769;\n            int64_t new_index_22770;\n            int64_t v_22661;\n            int8_t v_22662;\n            \n            new_index_22763 = squot64(gtid_22657, (int64_t) 3);\n            binop_y_22769 = (int64_t) 3 * new_index_22763;\n            new_index_22770 = gtid_22657 - binop_y_22769;\n            v_22661 = ((__global int64_t *) mem_23065)[new_index_22770];\n            v_22662 = ((__global int8_t *) mem_23077)[new_index_22763 * (int64_t) 3 + new_index_22770];\n            // definitions.fut:60:6-38\n            // UpdateAcc\n            if ((sle64((int64_t) 0, new_index_22763) && slt64(new_index_22763, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659)) && (sle64((int64_t) 0, v_22661) && slt64(v_22661, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659))) {\n                ((__global int8_t *) mem_23052)[new_index_22763 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + v_22661] = v_22662;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22653\n}\nFUTHARK_KERNEL_SIZED(mainzisegred_large_21836_dim1, 1, 1)\nvoid mainzisegred_large_21836(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t dzlz7bUZLzpZRz20UZLZLztZRz2", "0U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t m_20840, int64_t num_tblocks_21830, int64_t blocks_per_segment_23815, int64_t q_23816, int64_t num_virtblocks_23817, int64_t threads_per_segment_23818, __global unsigned char *mem_23052, __global unsigned char *mem_23211, __global unsigned char *mem_23223, __global unsigned char *mem_23226, __global unsigned char *mem_23235, __global unsigned char *mem_23237, __global unsigned char *segred_tmp_mem_23819, __global unsigned char *counters_mem_23821)\n{\n    #define segred_tblock_sizze_21829 (mainzisegred_large_21836zisegred_tblock_sizze_21829)\n    #define chunk_sizze_23786 (mainzisegred_large_21836zichunk_sizze_23786)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local unsigned char *sync_arr_mem_23830_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_23830_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i8_mem_23828_backing_0 = &shared_mem[sync_arr_mem_23830_backing_1_offset];\n    const int64_t red_arr_i8_mem_23828_backing_0_offset = sync_arr_mem_23830_backing_1_offset + (segred_tblock_sizze_21829 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_21829, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_23824;\n    int32_t tblock_sizze_23827;\n    int32_t wave_sizze_23826;\n    int32_t block_id_23825;\n    int32_t global_tid_23823;\n    int64_t phys_tid_21836;\n    __local unsigned char *red_arr_i8_mem_23828;\n    __local unsigned char *sync_arr_mem_23830;\n    int32_t phys_tblock_id_23832;\n    int32_t iterations_23833;\n    \n    local_tid_23824 = get_local_id(0);\n    tblock_sizze_23827 = get_local_size(0);\n    wave_sizze_23826 = LOCKSTEP_WIDTH;\n    block_id_23825 = get_tblock_id(0);\n    global_tid_23823 = bloc", "k_id_23825 * tblock_sizze_23827 + local_tid_23824;\n    phys_tid_21836 = sext_i32_i64(global_tid_23823);\n    red_arr_i8_mem_23828 = (__local unsigned char *) red_arr_i8_mem_23828_backing_0;\n    sync_arr_mem_23830 = (__local unsigned char *) sync_arr_mem_23830_backing_1;\n    phys_tblock_id_23832 = get_tblock_id(0);\n    iterations_23833 = sdiv_up32(sext_i64_i32(num_virtblocks_23817) - phys_tblock_id_23832, sext_i64_i32(num_tblocks_21830));\n    for (int32_t i_23834 = 0; i_23834 < iterations_23833; i_23834++) {\n        int32_t virt_tblock_id_23835;\n        int64_t flat_segment_id_23836;\n        int64_t global_tid_23837;\n        int64_t slice_23838;\n        int64_t gtid_21834;\n        int64_t remnant_23839;\n        int64_t gtid_21835;\n        int8_t eta_p_block_res_acc_23840;\n        int8_t eta_p_21876;\n        int8_t eta_p_21877;\n        int64_t tblock_id_in_segment_23844;\n        int64_t block_base_offset_23845;\n        int32_t offset_23848;\n        int32_t skip_waves_23849;\n        int8_t eta_p_23841;\n        int8_t eta_p_23842;\n        \n        virt_tblock_id_23835 = phys_tblock_id_23832 + i_23834 * sext_i64_i32(num_tblocks_21830);\n        flat_segment_id_23836 = squot64(sext_i32_i64(virt_tblock_id_23835), blocks_per_segment_23815);\n        global_tid_23837 = srem64(sext_i32_i64(virt_tblock_id_23835) * segred_tblock_sizze_21829 + sext_i32_i64(local_tid_23824), threads_per_segment_23818);\n        slice_23838 = m_20840;\n        gtid_21834 = flat_segment_id_23836;\n        remnant_23839 = flat_segment_id_23836 - gtid_21834;\n        // ne-initialise the outer (per-block) accumulator(s)\n        eta_p_block_res_acc_23840 = (int8_t) 0;\n        tblock_id_in_segment_23844 = squot64(global_tid_23837, segred_tblock_sizze_21829);\n        block_base_offset_23845 = tblock_id_in_segment_23844 * q_23816 * segred_tblock_sizze_21829;\n        for (int64_t i_23846 = 0; i_23846 < q_23816; i_23846++) {\n            int64_t block_offset_23847 = block_base_offset_23845 + i_23846 * segred_tbloc",
                                    "k_sizze_21829;\n            \n            gtid_21835 = global_tid_23837 + threads_per_segment_23818 * i_23846;\n            if (slt64(gtid_21835, num_qubits_14547)) {\n                bool index_certs_21838;\n                int64_t g_arg3_21840;\n                bool x_21841;\n                bool y_21842;\n                bool bounds_check_21843;\n                bool index_certs_21844;\n                bool y_21847;\n                bool index_certs_21849;\n                int64_t defunc_0_f_res_22860;\n                int64_t eta_p_21837;\n                int8_t g_arg3_21845;\n                int8_t g_arg2_21850;\n                int8_t g_arg1_21851;\n                int8_t g_arg0_21852;\n                bool cond_21853;\n                bool cond_t_res_21854;\n                bool x_21855;\n                int8_t g_res_21856;\n                int8_t tmp_21873;\n                int8_t tmp_21874;\n                int8_t mem_23231[(int64_t) 2];\n                int8_t defunc_0_op_res_21878;\n                \n                // apply map function(s)\n                // apply map function\n                index_certs_21838 = 0;\n                // definitions.fut:25:85-88\n                g_arg3_21840 = add64(num_qubits_14547, gtid_21835);\n                // definitions.fut:25:73-89\n                x_21841 = sle64((int64_t) 0, g_arg3_21840);\n                // definitions.fut:25:73-89\n                y_21842 = slt64(g_arg3_21840, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n                // definitions.fut:25:73-89\n                bounds_check_21843 = x_21841 && y_21842;\n                // definitions.fut:25:73-89\n                if (!bounds_check_21843) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 13) == -1) {\n                            global_failure_args[0] = (int64_t) g_arg3_21840;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n        ", "                    ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                // definitions.fut:25:60-72\n                y_21847 = slt64(gtid_21835, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n                // definitions.fut:25:60-72\n                if (!y_21847) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 14) == -1) {\n                            global_failure_args[0] = (int64_t) gtid_21835;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                defunc_0_f_res_22860 = ((__global int64_t *) mem_23211)[(int64_t) 0];\n                eta_p_21837 = ((__global int64_t *) mem_23223)[gtid_21834];\n                // definitions.fut:25:17-98\n                g_arg3_21845 = ((__global int8_t *) mem_23052)[eta_p_21837 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + g_arg3_21840];\n                // definitions.fut:25:17-98\n                g_arg2_21850 = ((__global int8_t *) mem_23052)[eta_p_21837 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_21835];\n                // definitions.fut:25:17-98\n                g_arg1_21851 = ((__global int8_t *) mem_23052)[defunc_0_f_res_22860 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + g_arg3_21840];\n                // definitions.fut:25:17-98\n                g_arg0_21852 = ((__global int8_t *) mem_23052)[defunc_0_f_res_22860 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_21835];\n                // definitions.fut:12:3-20:9\n                cond_21853 = g_arg0_21852 == g_arg2_21850;\n                // defin", "itions.fut:12:21-25\n                cond_t_res_21854 = g_arg0_21852 == (int8_t) 0;\n                // definitions.fut:25:28-89\n                x_21855 = cond_21853 && cond_t_res_21854;\n                // definitions.fut:12:3-20:9\n                if (x_21855) {\n                    g_res_21856 = (int8_t) 0;\n                } else {\n                    bool cond_t_res_21857;\n                    bool x_21858;\n                    int8_t g_res_f_res_21859;\n                    \n                    // definitions.fut:14:26-30\n                    cond_t_res_21857 = g_arg0_21852 == (int8_t) 1;\n                    // definitions.fut:25:28-89\n                    x_21858 = cond_21853 && cond_t_res_21857;\n                    // definitions.fut:14:8-20:9\n                    if (x_21858) {\n                        int8_t g_res_f_res_t_res_21860;\n                        \n                        // definitions.fut:15:11-15\n                        g_res_f_res_t_res_21860 = sub8(g_arg3_21845, g_arg1_21851);\n                        g_res_f_res_21859 = g_res_f_res_t_res_21860;\n                    } else {\n                        bool cond_t_res_21861;\n                        bool x_21862;\n                        int8_t g_res_f_res_f_res_21863;\n                        \n                        // definitions.fut:16:25-29\n                        cond_t_res_21861 = g_arg2_21850 == (int8_t) 0;\n                        // definitions.fut:25:28-89\n                        x_21862 = cond_t_res_21857 && cond_t_res_21861;\n                        // definitions.fut:16:8-20:9\n                        if (x_21862) {\n                            int8_t zm_lhs_21864;\n                            int8_t zt_rhs_21865;\n                            int8_t g_res_f_res_f_res_t_res_21866;\n                            \n                            // definitions.fut:17:16-20\n                            zm_lhs_21864 = mul8((int8_t) 2, g_arg1_21851);\n                            // definitions.fut:17:21-24\n               ",
                                    "             zt_rhs_21865 = sub8(zm_lhs_21864, (int8_t) 1);\n                            // definitions.fut:17:11-24\n                            g_res_f_res_f_res_t_res_21866 = mul8(g_arg3_21845, zt_rhs_21865);\n                            g_res_f_res_f_res_21863 = g_res_f_res_f_res_t_res_21866;\n                        } else {\n                            bool cond_t_res_21867;\n                            bool x_21868;\n                            int8_t g_res_f_res_f_res_f_res_21869;\n                            \n                            // definitions.fut:18:25-29\n                            cond_t_res_21867 = g_arg2_21850 == (int8_t) 1;\n                            // definitions.fut:25:28-89\n                            x_21868 = cond_t_res_21854 && cond_t_res_21867;\n                            // definitions.fut:18:8-20:9\n                            if (x_21868) {\n                                int8_t zm_rhs_21870;\n                                int8_t zt_rhs_21871;\n                                int8_t g_res_f_res_f_res_f_res_t_res_21872;\n                                \n                                // definitions.fut:19:20-24\n                                zm_rhs_21870 = mul8((int8_t) 2, g_arg3_21845);\n                                // definitions.fut:19:16-24\n                                zt_rhs_21871 = sub8((int8_t) 1, zm_rhs_21870);\n                                // definitions.fut:19:11-24\n                                g_res_f_res_f_res_f_res_t_res_21872 = mul8(g_arg1_21851, zt_rhs_21871);\n                                g_res_f_res_f_res_f_res_21869 = g_res_f_res_f_res_f_res_t_res_21872;\n                            } else {\n                                g_res_f_res_f_res_f_res_21869 = (int8_t) 0;\n                            }\n                            g_res_f_res_f_res_21863 = g_res_f_res_f_res_f_res_21869;\n                        }\n                        g_res_f_res_21859 = g_res_f_res_f_res_21863;\n                    }\n                  ", "  g_res_21856 = g_res_f_res_21859;\n                }\n                // definitions.fut:29:37-51\n                tmp_21873 = g_arg2_21850 ^ g_arg0_21852;\n                // definitions.fut:29:70-88\n                tmp_21874 = g_arg3_21845 ^ g_arg1_21851;\n                // definitions.fut:29:12-98\n                // definitions.fut:29:12-98\n                mem_23231[(int64_t) 0] = tmp_21873;\n                mem_23231[(int64_t) 1] = tmp_21874;\n                // write map-out result(s)\n                for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                    ((__global int8_t *) mem_23235)[gtid_21834 * ((int64_t) 2 * num_qubits_14547) + gtid_21835 * (int64_t) 2 + i_0] = mem_23231[i_0];\n                }\n                // load accumulator(s)\n                eta_p_21876 = eta_p_block_res_acc_23840;\n                // load next value(s)\n                eta_p_21877 = g_res_21856;\n                // apply reduction operator(s)\n                // definitions.fut:25:110-113\n                defunc_0_op_res_21878 = add8(eta_p_21876, eta_p_21877);\n                // store in accumulator(s)\n                eta_p_block_res_acc_23840 = defunc_0_op_res_21878;\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        ((__local int8_t *) red_arr_i8_mem_23828)[sext_i32_i64(local_tid_23824)] = eta_p_block_res_acc_23840;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_23849 = 1;\n        offset_23848 = 0;\n        // participating threads read initial accumulator\n        if (slt32(local_tid_23824, sext_i64_i32(segred_tblock_sizze_21829))) {\n            eta_p_23841 = ((__local int8_t *) red_arr_i8_mem_23828)[sext_i32_i64(local_tid_23824 + offset_23848)];\n        }\n        offset_23848 = 1;\n        while (slt32(offset_23848, wave_sizze_23826)) {\n            if (slt32(local_", "tid_23824 + offset_23848, sext_i64_i32(segred_tblock_sizze_21829)) && ((local_tid_23824 - squot32(local_tid_23824, wave_sizze_23826) * wave_sizze_23826) & (2 * offset_23848 - 1)) == 0) {\n                int8_t defunc_0_op_res_23843;\n                \n                // read array element\n                eta_p_23842 = ((volatile __local int8_t *) red_arr_i8_mem_23828)[sext_i32_i64(local_tid_23824 + offset_23848)];\n                // apply reduction operation\n                // definitions.fut:25:110-113\n                defunc_0_op_res_23843 = add8(eta_p_23841, eta_p_23842);\n                eta_p_23841 = defunc_0_op_res_23843;\n                // write result of operation\n                ((volatile __local int8_t *) red_arr_i8_mem_23828)[sext_i32_i64(local_tid_23824)] = eta_p_23841;\n            }\n            offset_23848 *= 2;\n        }\n        while (slt32(skip_waves_23849, squot32(sext_i64_i32(segred_tblock_sizze_21829) + wave_sizze_23826 - 1, wave_sizze_23826))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_23848 = skip_waves_23849 * wave_sizze_23826;\n            if (slt32(local_tid_23824 + offset_23848, sext_i64_i32(segred_tblock_sizze_21829)) && ((local_tid_23824 - squot32(local_tid_23824, wave_sizze_23826) * wave_sizze_23826) == 0 && (squot32(local_tid_23824, wave_sizze_23826) & (2 * skip_waves_23849 - 1)) == 0)) {\n                int8_t defunc_0_op_res_23843;\n                \n                // read array element\n                eta_p_23842 = ((__local int8_t *) red_arr_i8_mem_23828)[sext_i32_i64(local_tid_23824 + offset_23848)];\n                // apply reduction operation\n                // definitions.fut:25:110-113\n                defunc_0_op_res_23843 = add8(eta_p_23841, eta_p_23842);\n                eta_p_23841 = defunc_0_op_res_23843;\n                // write result of operation\n                ((__local int8_t *) red_arr_i8_mem_23828)[sext_i32_i64(local_tid_23824)] = eta_p_23841;\n            }\n            skip_waves_23849 *= 2;\n        }\n",
                                    "        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        if (sext_i32_i64(local_tid_23824) == (int64_t) 0) {\n            eta_p_block_res_acc_23840 = eta_p_23841;\n        } else {\n            eta_p_block_res_acc_23840 = (int8_t) 0;\n        }\n        if (blocks_per_segment_23815 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            if (local_tid_23824 == 0) {\n                ((__global int8_t *) mem_23237)[gtid_21834] = eta_p_block_res_acc_23840;\n            }\n        } else {\n            int32_t old_counter_23850;\n            bool is_last_block_23851;\n            \n            // first thread in block saves block result to global memory\n            if (local_tid_23824 == 0) {\n                ((__global int8_t *) segred_tmp_mem_23819)[sext_i32_i64(virt_tblock_id_23835)] = eta_p_block_res_acc_23840;\n                mem_fence_global();\n                old_counter_23850 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23821)[srem64(flat_segment_id_23836, (int64_t) 20480)], 1);\n                ((__local bool *) sync_arr_mem_23830)[(int64_t) 0] = old_counter_23850 == sext_i64_i32(blocks_per_segment_23815 - (int64_t) 1);\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_23851 = ((__local bool *) sync_arr_mem_23830)[(int64_t) 0];\n            if (is_last_block_23851) {\n                int64_t read_per_thread_23852;\n                int32_t offset_23856;\n                int32_t skip_waves_23857;\n                int8_t eta_p_23841;\n                int8_t eta_p_23842;\n                \n                if (local_tid_23824 == 0) {\n                    old_counter_23850 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23821)[srem64(flat_segment_id_23836, (int64_t) 20480)], sext_i64_i32((int64_t) 0 - blocks_per_segment_23815));\n                }\n                // read in", " the per-block-results\n                read_per_thread_23852 = sdiv_up64(blocks_per_segment_23815, segred_tblock_sizze_21829);\n                eta_p_21876 = (int8_t) 0;\n                for (int64_t i_23853 = 0; i_23853 < read_per_thread_23852; i_23853++) {\n                    int64_t block_res_id_23854;\n                    int64_t index_of_block_res_23855;\n                    \n                    block_res_id_23854 = sext_i32_i64(local_tid_23824) * read_per_thread_23852 + i_23853;\n                    index_of_block_res_23855 = flat_segment_id_23836 * blocks_per_segment_23815 + block_res_id_23854;\n                    if (slt64(block_res_id_23854, blocks_per_segment_23815)) {\n                        int8_t defunc_0_op_res_21878;\n                        \n                        eta_p_21877 = ((__global int8_t *) segred_tmp_mem_23819)[index_of_block_res_23855];\n                        // definitions.fut:25:110-113\n                        defunc_0_op_res_21878 = add8(eta_p_21876, eta_p_21877);\n                        eta_p_21876 = defunc_0_op_res_21878;\n                    }\n                }\n                ((__local int8_t *) red_arr_i8_mem_23828)[sext_i32_i64(local_tid_23824)] = eta_p_21876;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                skip_waves_23857 = 1;\n                offset_23856 = 0;\n                // participating threads read initial accumulator\n                if (slt32(local_tid_23824, sext_i64_i32(segred_tblock_sizze_21829))) {\n                    eta_p_23841 = ((__local int8_t *) red_arr_i8_mem_23828)[sext_i32_i64(local_tid_23824 + offset_23856)];\n                }\n                offset_23856 = 1;\n                while (slt32(offset_23856, wave_sizze_23826)) {\n                    if (slt32(local_tid_23824 + offset_23856, sext_i64_i32(segred_tblock_sizze_21829)) && ((local_tid_23824 - squot32(local_tid_23824, wave_sizze_23826) * wave_sizze_23826) & (2 * offset_23856 - 1)) == 0) {\n          ", "              int8_t defunc_0_op_res_23843;\n                        \n                        // read array element\n                        eta_p_23842 = ((volatile __local int8_t *) red_arr_i8_mem_23828)[sext_i32_i64(local_tid_23824 + offset_23856)];\n                        // apply reduction operation\n                        // definitions.fut:25:110-113\n                        defunc_0_op_res_23843 = add8(eta_p_23841, eta_p_23842);\n                        eta_p_23841 = defunc_0_op_res_23843;\n                        // write result of operation\n                        ((volatile __local int8_t *) red_arr_i8_mem_23828)[sext_i32_i64(local_tid_23824)] = eta_p_23841;\n                    }\n                    offset_23856 *= 2;\n                }\n                while (slt32(skip_waves_23857, squot32(sext_i64_i32(segred_tblock_sizze_21829) + wave_sizze_23826 - 1, wave_sizze_23826))) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    offset_23856 = skip_waves_23857 * wave_sizze_23826;\n                    if (slt32(local_tid_23824 + offset_23856, sext_i64_i32(segred_tblock_sizze_21829)) && ((local_tid_23824 - squot32(local_tid_23824, wave_sizze_23826) * wave_sizze_23826) == 0 && (squot32(local_tid_23824, wave_sizze_23826) & (2 * skip_waves_23857 - 1)) == 0)) {\n                        int8_t defunc_0_op_res_23843;\n                        \n                        // read array element\n                        eta_p_23842 = ((__local int8_t *) red_arr_i8_mem_23828)[sext_i32_i64(local_tid_23824 + offset_23856)];\n                        // apply reduction operation\n                        // definitions.fut:25:110-113\n                        defunc_0_op_res_23843 = add8(eta_p_23841, eta_p_23842);\n                        eta_p_23841 = defunc_0_op_res_23843;\n                        // write result of operation\n                        ((__local int8_t *) red_arr_i8_mem_23828)[sext_i32_i64(local_tid_23824)] = eta_p_23841;\n                    }\n                  ",
                                    "  skip_waves_23857 *= 2;\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // and back to memory with the final result\n                if (local_tid_23824 == 0) {\n                    ((__global int8_t *) mem_23237)[gtid_21834] = eta_p_23841;\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_21829\n    #undef chunk_sizze_23786\n}\nFUTHARK_KERNEL_SIZED(mainzisegred_large_22342_dim1, 1, 1)\nvoid mainzisegred_large_22342(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t m_21071, int64_t num_tblocks_22336, int64_t blocks_per_segment_24166, int64_t q_24167, int64_t num_virtblocks_24168, int64_t threads_per_segment_24169, __global unsigned char *mem_23052, __global unsigned char *mem_23131, __global unsigned char *mem_23132, __global unsigned char *mem_23141, __global unsigned char *mem_23143, __global unsigned char *segred_tmp_mem_24170, __global unsigned char *counters_mem_24172)\n{\n    #define segred_tblock_sizze_22335 (mainzisegred_large_22342zisegred_tblock_sizze_22335)\n    #define chunk_sizze_24137 (mainzisegred_large_22342zichunk_sizze_24137)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local unsigned char *sync_arr_mem_24181_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_24181_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i8_mem_24179_backing_0 = &shared_mem[sync_arr_mem_24181_backing_1_offset];\n    const int64_t red_arr_i8_mem_24179_backing_0_offset = sync_arr_mem_24181_backing_1_offset + (segred_tblock_sizze_22335 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22335, (int64_t) 8), (int64_t) 8));\n    volatile __local int", " local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24175;\n    int32_t tblock_sizze_24178;\n    int32_t wave_sizze_24177;\n    int32_t block_id_24176;\n    int32_t global_tid_24174;\n    int64_t phys_tid_22342;\n    __local unsigned char *red_arr_i8_mem_24179;\n    __local unsigned char *sync_arr_mem_24181;\n    int32_t phys_tblock_id_24183;\n    int32_t iterations_24184;\n    \n    local_tid_24175 = get_local_id(0);\n    tblock_sizze_24178 = get_local_size(0);\n    wave_sizze_24177 = LOCKSTEP_WIDTH;\n    block_id_24176 = get_tblock_id(0);\n    global_tid_24174 = block_id_24176 * tblock_sizze_24178 + local_tid_24175;\n    phys_tid_22342 = sext_i32_i64(global_tid_24174);\n    red_arr_i8_mem_24179 = (__local unsigned char *) red_arr_i8_mem_24179_backing_0;\n    sync_arr_mem_24181 = (__local unsigned char *) sync_arr_mem_24181_backing_1;\n    phys_tblock_id_24183 = get_tblock_id(0);\n    iterations_24184 = sdiv_up32(sext_i64_i32(num_virtblocks_24168) - phys_tblock_id_24183, sext_i64_i32(num_tblocks_22336));\n    for (int32_t i_24185 = 0; i_24185 < iterations_24184; i_24185++) {\n        int32_t virt_tblock_id_24186;\n        int64_t flat_segment_id_24187;\n        int64_t global_tid_24188;\n        int64_t slice_24189;\n        int64_t gtid_22340;\n        int64_t remnant_24190;\n        int64_t gtid_22341;\n        int8_t eta_p_block_res_acc_24191;\n        int8_t eta_p_22382;\n        int8_t eta_p_22383;\n        int64_t tblock_id_in_segment_24195;\n        int64_t block_base_offset_24196;\n        int32_t offset_24199;\n        int32_t skip_waves_24200;\n        int8_t eta_p_24192;\n        int8_t eta_p_24193;\n        \n        virt_tblock_id_24186 = phys_tblock_id_24183 + i_24185 * sext_i64_i32(num_tblocks_22336);\n        flat_segment_id_24187 = squot64(sext_i32_i64(virt_tblock_id_24186), blocks_per_segment_24166);\n      ", "  global_tid_24188 = srem64(sext_i32_i64(virt_tblock_id_24186) * segred_tblock_sizze_22335 + sext_i32_i64(local_tid_24175), threads_per_segment_24169);\n        slice_24189 = m_21071;\n        gtid_22340 = flat_segment_id_24187;\n        remnant_24190 = flat_segment_id_24187 - gtid_22340;\n        // ne-initialise the outer (per-block) accumulator(s)\n        eta_p_block_res_acc_24191 = (int8_t) 0;\n        tblock_id_in_segment_24195 = squot64(global_tid_24188, segred_tblock_sizze_22335);\n        block_base_offset_24196 = tblock_id_in_segment_24195 * q_24167 * segred_tblock_sizze_22335;\n        for (int64_t i_24197 = 0; i_24197 < q_24167; i_24197++) {\n            int64_t block_offset_24198 = block_base_offset_24196 + i_24197 * segred_tblock_sizze_22335;\n            \n            gtid_22341 = global_tid_24188 + threads_per_segment_24169 * i_24197;\n            if (slt64(gtid_22341, num_qubits_14547)) {\n                bool index_certs_22344;\n                int64_t g_arg3_22346;\n                bool x_22347;\n                bool y_22348;\n                bool bounds_check_22349;\n                bool index_certs_22350;\n                bool y_22353;\n                bool index_certs_22355;\n                int64_t rowsum_arg2_22343;\n                int8_t g_arg3_22351;\n                int8_t g_arg2_22356;\n                int8_t g_arg1_22357;\n                int8_t g_arg0_22358;\n                bool cond_22359;\n                bool cond_t_res_22360;\n                bool x_22361;\n                int8_t g_res_22362;\n                int8_t tmp_22379;\n                int8_t tmp_22380;\n                int8_t mem_23137[(int64_t) 2];\n                int8_t defunc_0_op_res_22384;\n                \n                // apply map function(s)\n                // apply map function\n                index_certs_22344 = 0;\n                // definitions.fut:25:85-88\n                g_arg3_22346 = add64(num_qubits_14547, gtid_22341);\n                // definitions.fut:25:73-89\n                x_22347",
                                    " = sle64((int64_t) 0, g_arg3_22346);\n                // definitions.fut:25:73-89\n                y_22348 = slt64(g_arg3_22346, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n                // definitions.fut:25:73-89\n                bounds_check_22349 = x_22347 && y_22348;\n                // definitions.fut:25:73-89\n                if (!bounds_check_22349) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 23) == -1) {\n                            global_failure_args[0] = (int64_t) g_arg3_22346;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                // definitions.fut:25:60-72\n                y_22353 = slt64(gtid_22341, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n                // definitions.fut:25:60-72\n                if (!y_22353) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 24) == -1) {\n                            global_failure_args[0] = (int64_t) gtid_22341;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                rowsum_arg2_22343 = ((__global int64_t *) mem_23131)[gtid_22340];\n                // definitions.fut:25:17-98\n                g_arg3_22351 = ((__global int8_t *) mem_23052)[arg_16658 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + g_arg3_22346];\n                // definitions.fut:25:17-98\n                g_arg2_22356 = ((__global int8_t *) mem_23052)[arg_16658 * dzlz7bUZ", "LzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_22341];\n                // definitions.fut:25:17-98\n                g_arg1_22357 = ((__global int8_t *) mem_23052)[rowsum_arg2_22343 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + g_arg3_22346];\n                // definitions.fut:25:17-98\n                g_arg0_22358 = ((__global int8_t *) mem_23052)[rowsum_arg2_22343 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_22341];\n                // definitions.fut:12:3-20:9\n                cond_22359 = g_arg0_22358 == g_arg2_22356;\n                // definitions.fut:12:21-25\n                cond_t_res_22360 = g_arg0_22358 == (int8_t) 0;\n                // definitions.fut:25:28-89\n                x_22361 = cond_22359 && cond_t_res_22360;\n                // definitions.fut:12:3-20:9\n                if (x_22361) {\n                    g_res_22362 = (int8_t) 0;\n                } else {\n                    bool cond_t_res_22363;\n                    bool x_22364;\n                    int8_t g_res_f_res_22365;\n                    \n                    // definitions.fut:14:26-30\n                    cond_t_res_22363 = g_arg0_22358 == (int8_t) 1;\n                    // definitions.fut:25:28-89\n                    x_22364 = cond_22359 && cond_t_res_22363;\n                    // definitions.fut:14:8-20:9\n                    if (x_22364) {\n                        int8_t g_res_f_res_t_res_22366;\n                        \n                        // definitions.fut:15:11-15\n                        g_res_f_res_t_res_22366 = sub8(g_arg3_22351, g_arg1_22357);\n                        g_res_f_res_22365 = g_res_f_res_t_res_22366;\n                    } else {\n                        bool cond_t_res_22367;\n                        bool x_22368;\n                        int8_t g_res_f_res_f_res_22369;\n                        \n                        // definitions.fut:16:25-29\n                        cond_t_res_22367 = g_arg2_22356 == (int8_t) 0", ";\n                        // definitions.fut:25:28-89\n                        x_22368 = cond_t_res_22363 && cond_t_res_22367;\n                        // definitions.fut:16:8-20:9\n                        if (x_22368) {\n                            int8_t zm_lhs_22370;\n                            int8_t zt_rhs_22371;\n                            int8_t g_res_f_res_f_res_t_res_22372;\n                            \n                            // definitions.fut:17:16-20\n                            zm_lhs_22370 = mul8((int8_t) 2, g_arg1_22357);\n                            // definitions.fut:17:21-24\n                            zt_rhs_22371 = sub8(zm_lhs_22370, (int8_t) 1);\n                            // definitions.fut:17:11-24\n                            g_res_f_res_f_res_t_res_22372 = mul8(g_arg3_22351, zt_rhs_22371);\n                            g_res_f_res_f_res_22369 = g_res_f_res_f_res_t_res_22372;\n                        } else {\n                            bool cond_t_res_22373;\n                            bool x_22374;\n                            int8_t g_res_f_res_f_res_f_res_22375;\n                            \n                            // definitions.fut:18:25-29\n                            cond_t_res_22373 = g_arg2_22356 == (int8_t) 1;\n                            // definitions.fut:25:28-89\n                            x_22374 = cond_t_res_22360 && cond_t_res_22373;\n                            // definitions.fut:18:8-20:9\n                            if (x_22374) {\n                                int8_t zm_rhs_22376;\n                                int8_t zt_rhs_22377;\n                                int8_t g_res_f_res_f_res_f_res_t_res_22378;\n                                \n                                // definitions.fut:19:20-24\n                                zm_rhs_22376 = mul8((int8_t) 2, g_arg3_22351);\n                                // definitions.fut:19:16-24\n                                zt_rhs_22377 = sub8((int8_t) 1, zm_rhs_22376);\n               ",
                                    "                 // definitions.fut:19:11-24\n                                g_res_f_res_f_res_f_res_t_res_22378 = mul8(g_arg1_22357, zt_rhs_22377);\n                                g_res_f_res_f_res_f_res_22375 = g_res_f_res_f_res_f_res_t_res_22378;\n                            } else {\n                                g_res_f_res_f_res_f_res_22375 = (int8_t) 0;\n                            }\n                            g_res_f_res_f_res_22369 = g_res_f_res_f_res_f_res_22375;\n                        }\n                        g_res_f_res_22365 = g_res_f_res_f_res_22369;\n                    }\n                    g_res_22362 = g_res_f_res_22365;\n                }\n                // definitions.fut:29:37-51\n                tmp_22379 = g_arg2_22356 ^ g_arg0_22358;\n                // definitions.fut:29:70-88\n                tmp_22380 = g_arg3_22351 ^ g_arg1_22357;\n                // definitions.fut:29:12-98\n                // definitions.fut:29:12-98\n                mem_23137[(int64_t) 0] = tmp_22379;\n                mem_23137[(int64_t) 1] = tmp_22380;\n                // write map-out result(s)\n                for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                    ((__global int8_t *) mem_23141)[gtid_22340 * ((int64_t) 2 * num_qubits_14547) + gtid_22341 * (int64_t) 2 + i_0] = mem_23137[i_0];\n                }\n                // load accumulator(s)\n                eta_p_22382 = eta_p_block_res_acc_24191;\n                // load next value(s)\n                eta_p_22383 = g_res_22362;\n                // apply reduction operator(s)\n                // definitions.fut:25:110-113\n                defunc_0_op_res_22384 = add8(eta_p_22382, eta_p_22383);\n                // store in accumulator(s)\n                eta_p_block_res_acc_24191 = defunc_0_op_res_22384;\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem;", " non-prims in params (in global mem)\n        ((__local int8_t *) red_arr_i8_mem_24179)[sext_i32_i64(local_tid_24175)] = eta_p_block_res_acc_24191;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_24200 = 1;\n        offset_24199 = 0;\n        // participating threads read initial accumulator\n        if (slt32(local_tid_24175, sext_i64_i32(segred_tblock_sizze_22335))) {\n            eta_p_24192 = ((__local int8_t *) red_arr_i8_mem_24179)[sext_i32_i64(local_tid_24175 + offset_24199)];\n        }\n        offset_24199 = 1;\n        while (slt32(offset_24199, wave_sizze_24177)) {\n            if (slt32(local_tid_24175 + offset_24199, sext_i64_i32(segred_tblock_sizze_22335)) && ((local_tid_24175 - squot32(local_tid_24175, wave_sizze_24177) * wave_sizze_24177) & (2 * offset_24199 - 1)) == 0) {\n                int8_t defunc_0_op_res_24194;\n                \n                // read array element\n                eta_p_24193 = ((volatile __local int8_t *) red_arr_i8_mem_24179)[sext_i32_i64(local_tid_24175 + offset_24199)];\n                // apply reduction operation\n                // definitions.fut:25:110-113\n                defunc_0_op_res_24194 = add8(eta_p_24192, eta_p_24193);\n                eta_p_24192 = defunc_0_op_res_24194;\n                // write result of operation\n                ((volatile __local int8_t *) red_arr_i8_mem_24179)[sext_i32_i64(local_tid_24175)] = eta_p_24192;\n            }\n            offset_24199 *= 2;\n        }\n        while (slt32(skip_waves_24200, squot32(sext_i64_i32(segred_tblock_sizze_22335) + wave_sizze_24177 - 1, wave_sizze_24177))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_24199 = skip_waves_24200 * wave_sizze_24177;\n            if (slt32(local_tid_24175 + offset_24199, sext_i64_i32(segred_tblock_sizze_22335)) && ((local_tid_24175 - squot32(local_tid_24175, wave_sizze_24177) * wave_sizze_24177) == 0 && (squot32(local_tid_24175, wave_sizze_24177) & (2 * skip_waves_24200 - 1)) == 0)) {\n                int8_t defunc_0", "_op_res_24194;\n                \n                // read array element\n                eta_p_24193 = ((__local int8_t *) red_arr_i8_mem_24179)[sext_i32_i64(local_tid_24175 + offset_24199)];\n                // apply reduction operation\n                // definitions.fut:25:110-113\n                defunc_0_op_res_24194 = add8(eta_p_24192, eta_p_24193);\n                eta_p_24192 = defunc_0_op_res_24194;\n                // write result of operation\n                ((__local int8_t *) red_arr_i8_mem_24179)[sext_i32_i64(local_tid_24175)] = eta_p_24192;\n            }\n            skip_waves_24200 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        if (sext_i32_i64(local_tid_24175) == (int64_t) 0) {\n            eta_p_block_res_acc_24191 = eta_p_24192;\n        } else {\n            eta_p_block_res_acc_24191 = (int8_t) 0;\n        }\n        if (blocks_per_segment_24166 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            if (local_tid_24175 == 0) {\n                ((__global int8_t *) mem_23143)[gtid_22340] = eta_p_block_res_acc_24191;\n            }\n        } else {\n            int32_t old_counter_24201;\n            bool is_last_block_24202;\n            \n            // first thread in block saves block result to global memory\n            if (local_tid_24175 == 0) {\n                ((__global int8_t *) segred_tmp_mem_24170)[sext_i32_i64(virt_tblock_id_24186)] = eta_p_block_res_acc_24191;\n                mem_fence_global();\n                old_counter_24201 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24172)[srem64(flat_segment_id_24187, (int64_t) 20480)], 1);\n                ((__local bool *) sync_arr_mem_24181)[(int64_t) 0] = old_counter_24201 == sext_i64_i32(blocks_per_segment_24166 - (int64_t) 1);\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_2420",
                                    "2 = ((__local bool *) sync_arr_mem_24181)[(int64_t) 0];\n            if (is_last_block_24202) {\n                int64_t read_per_thread_24203;\n                int32_t offset_24207;\n                int32_t skip_waves_24208;\n                int8_t eta_p_24192;\n                int8_t eta_p_24193;\n                \n                if (local_tid_24175 == 0) {\n                    old_counter_24201 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24172)[srem64(flat_segment_id_24187, (int64_t) 20480)], sext_i64_i32((int64_t) 0 - blocks_per_segment_24166));\n                }\n                // read in the per-block-results\n                read_per_thread_24203 = sdiv_up64(blocks_per_segment_24166, segred_tblock_sizze_22335);\n                eta_p_22382 = (int8_t) 0;\n                for (int64_t i_24204 = 0; i_24204 < read_per_thread_24203; i_24204++) {\n                    int64_t block_res_id_24205;\n                    int64_t index_of_block_res_24206;\n                    \n                    block_res_id_24205 = sext_i32_i64(local_tid_24175) * read_per_thread_24203 + i_24204;\n                    index_of_block_res_24206 = flat_segment_id_24187 * blocks_per_segment_24166 + block_res_id_24205;\n                    if (slt64(block_res_id_24205, blocks_per_segment_24166)) {\n                        int8_t defunc_0_op_res_22384;\n                        \n                        eta_p_22383 = ((__global int8_t *) segred_tmp_mem_24170)[index_of_block_res_24206];\n                        // definitions.fut:25:110-113\n                        defunc_0_op_res_22384 = add8(eta_p_22382, eta_p_22383);\n                        eta_p_22382 = defunc_0_op_res_22384;\n                    }\n                }\n                ((__local int8_t *) red_arr_i8_mem_24179)[sext_i32_i64(local_tid_24175)] = eta_p_22382;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                skip_waves_24208 = 1;\n                offset_24207 = 0;\n            ", "    // participating threads read initial accumulator\n                if (slt32(local_tid_24175, sext_i64_i32(segred_tblock_sizze_22335))) {\n                    eta_p_24192 = ((__local int8_t *) red_arr_i8_mem_24179)[sext_i32_i64(local_tid_24175 + offset_24207)];\n                }\n                offset_24207 = 1;\n                while (slt32(offset_24207, wave_sizze_24177)) {\n                    if (slt32(local_tid_24175 + offset_24207, sext_i64_i32(segred_tblock_sizze_22335)) && ((local_tid_24175 - squot32(local_tid_24175, wave_sizze_24177) * wave_sizze_24177) & (2 * offset_24207 - 1)) == 0) {\n                        int8_t defunc_0_op_res_24194;\n                        \n                        // read array element\n                        eta_p_24193 = ((volatile __local int8_t *) red_arr_i8_mem_24179)[sext_i32_i64(local_tid_24175 + offset_24207)];\n                        // apply reduction operation\n                        // definitions.fut:25:110-113\n                        defunc_0_op_res_24194 = add8(eta_p_24192, eta_p_24193);\n                        eta_p_24192 = defunc_0_op_res_24194;\n                        // write result of operation\n                        ((volatile __local int8_t *) red_arr_i8_mem_24179)[sext_i32_i64(local_tid_24175)] = eta_p_24192;\n                    }\n                    offset_24207 *= 2;\n                }\n                while (slt32(skip_waves_24208, squot32(sext_i64_i32(segred_tblock_sizze_22335) + wave_sizze_24177 - 1, wave_sizze_24177))) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    offset_24207 = skip_waves_24208 * wave_sizze_24177;\n                    if (slt32(local_tid_24175 + offset_24207, sext_i64_i32(segred_tblock_sizze_22335)) && ((local_tid_24175 - squot32(local_tid_24175, wave_sizze_24177) * wave_sizze_24177) == 0 && (squot32(local_tid_24175, wave_sizze_24177) & (2 * skip_waves_24208 - 1)) == 0)) {\n                        int8_t defunc_0_op_res_24194;\n                        \n             ", "           // read array element\n                        eta_p_24193 = ((__local int8_t *) red_arr_i8_mem_24179)[sext_i32_i64(local_tid_24175 + offset_24207)];\n                        // apply reduction operation\n                        // definitions.fut:25:110-113\n                        defunc_0_op_res_24194 = add8(eta_p_24192, eta_p_24193);\n                        eta_p_24192 = defunc_0_op_res_24194;\n                        // write result of operation\n                        ((__local int8_t *) red_arr_i8_mem_24179)[sext_i32_i64(local_tid_24175)] = eta_p_24192;\n                    }\n                    skip_waves_24208 *= 2;\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // and back to memory with the final result\n                if (local_tid_24175 == 0) {\n                    ((__global int8_t *) mem_23143)[gtid_22340] = eta_p_24192;\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_22335\n    #undef chunk_sizze_24137\n}\nFUTHARK_KERNEL_SIZED(mainzisegred_nonseg_21406_dim1, 1, 1)\nvoid mainzisegred_nonseg_21406(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t n_14545, int64_t num_tblocks_21401, int64_t num_threads_23480, __global unsigned char *gates_mem_23045, __global unsigned char *mem_23049, __global unsigned char *counters_mem_23456, __global unsigned char *segred_tmp_mem_23478)\n{\n    #define segred_tblock_sizze_21399 (mainzisegred_nonseg_21406zisegred_tblock_sizze_21399)\n    #define chunk_sizze_23455 (mainzisegred_nonseg_21406zichunk_sizze_23455)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local unsigned char *sync_arr_mem_23488_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_23488_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_23486_backing_0 = &shared_mem[sync_arr_mem_23488_backi",
                                    "ng_1_offset];\n    const int64_t red_arr_i64_mem_23486_backing_0_offset = sync_arr_mem_23488_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_21399 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_21399, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23482;\n    int32_t tblock_sizze_23485;\n    int32_t wave_sizze_23484;\n    int32_t block_id_23483;\n    int32_t global_tid_23481;\n    int64_t phys_tid_21406;\n    __local unsigned char *red_arr_i64_mem_23486;\n    __local unsigned char *sync_arr_mem_23488;\n    int64_t dummy_21404;\n    int64_t gtid_21405;\n    int64_t q_23490;\n    int64_t eta_p_block_res_acc_23491;\n    int64_t eta_p_16666;\n    int64_t eta_p_16667;\n    int64_t tblock_id_in_segment_23495;\n    int64_t block_base_offset_23496;\n    int32_t offset_23499;\n    int32_t skip_waves_23500;\n    int64_t eta_p_23492;\n    int64_t eta_p_23493;\n    int32_t old_counter_23501;\n    bool is_last_block_23502;\n    \n    local_tid_23482 = get_local_id(0);\n    tblock_sizze_23485 = get_local_size(0);\n    wave_sizze_23484 = LOCKSTEP_WIDTH;\n    block_id_23483 = get_tblock_id(0);\n    global_tid_23481 = block_id_23483 * tblock_sizze_23485 + local_tid_23482;\n    phys_tid_21406 = sext_i32_i64(global_tid_23481);\n    red_arr_i64_mem_23486 = (__local unsigned char *) red_arr_i64_mem_23486_backing_0;\n    sync_arr_mem_23488 = (__local unsigned char *) sync_arr_mem_23488_backing_1;\n    dummy_21404 = (int64_t) 0;\n    gtid_21405 = (int64_t) 0;\n    q_23490 = sdiv_up64(n_14545, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_21399 * num_tblocks_21401)) * chunk_sizze_23455);\n    // ne-initialise the outer (per-block) accumulator(s)\n    eta_p_block_res_acc_23491 = (int64_t) 0;\n    tblock_id_in_segment_23495 = squot64(phys_tid_21406, segred_tblock_sizze_21399);\n    block_base_offset_23496 = tblock_id_in_segment_23495 * q_23490 * segred_tblock_sizze_21399;\n    for (int64_t i_23497 = 0; i_23497 < q_23490; i_23497++) {\n        int64_", "t block_offset_23498 = block_base_offset_23496 + i_23497 * segred_tblock_sizze_21399;\n        \n        gtid_21405 = phys_tid_21406 + num_threads_23480 * i_23497;\n        if (slt64(gtid_21405, n_14545)) {\n            int64_t eta_p_17466;\n            bool cond_17467;\n            int64_t lifted_lambda_res_17468;\n            int64_t defunc_0_op_res_16668;\n            \n            // apply map function(s)\n            // apply map function\n            eta_p_17466 = ((__global int64_t *) gates_mem_23045)[gtid_21405];\n            // main.fut:5:64-90\n            cond_17467 = eta_p_17466 == (int64_t) 0;\n            // main.fut:5:42-104\n            lifted_lambda_res_17468 = btoi_bool_i64(cond_17467);\n            // load accumulator(s)\n            eta_p_16666 = eta_p_block_res_acc_23491;\n            // load next value(s)\n            eta_p_16667 = lifted_lambda_res_17468;\n            // apply reduction operator(s)\n            // main.fut:5:33-36\n            defunc_0_op_res_16668 = add64(eta_p_16666, eta_p_16667);\n            // store in accumulator(s)\n            eta_p_block_res_acc_23491 = defunc_0_op_res_16668;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    ((__local int64_t *) red_arr_i64_mem_23486)[sext_i32_i64(local_tid_23482)] = eta_p_block_res_acc_23491;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_23500 = 1;\n    offset_23499 = 0;\n    // participating threads read initial accumulator\n    if (slt32(local_tid_23482, sext_i64_i32(segred_tblock_sizze_21399))) {\n        eta_p_23492 = ((__local int64_t *) red_arr_i64_mem_23486)[sext_i32_i64(local_tid_23482 + offset_23499)];\n    }\n    offset_23499 = 1;\n    while (slt32(offset_23499, wave_sizze_23484)) {\n        if (slt32(local_tid_23482 + offset_23499, sext_i64_i32(segred_tblock_sizze_21399)) && ((local_tid_23482 - squot32(local_tid_23482, wave_sizze_23484) * wave_sizze_23484) & (2 * offset_23499 - 1)) == 0) {\n            int64_t defunc_0_op_res_", "23494;\n            \n            // read array element\n            eta_p_23493 = ((volatile __local int64_t *) red_arr_i64_mem_23486)[sext_i32_i64(local_tid_23482 + offset_23499)];\n            // apply reduction operation\n            // main.fut:5:33-36\n            defunc_0_op_res_23494 = add64(eta_p_23492, eta_p_23493);\n            eta_p_23492 = defunc_0_op_res_23494;\n            // write result of operation\n            ((volatile __local int64_t *) red_arr_i64_mem_23486)[sext_i32_i64(local_tid_23482)] = eta_p_23492;\n        }\n        offset_23499 *= 2;\n    }\n    while (slt32(skip_waves_23500, squot32(sext_i64_i32(segred_tblock_sizze_21399) + wave_sizze_23484 - 1, wave_sizze_23484))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_23499 = skip_waves_23500 * wave_sizze_23484;\n        if (slt32(local_tid_23482 + offset_23499, sext_i64_i32(segred_tblock_sizze_21399)) && ((local_tid_23482 - squot32(local_tid_23482, wave_sizze_23484) * wave_sizze_23484) == 0 && (squot32(local_tid_23482, wave_sizze_23484) & (2 * skip_waves_23500 - 1)) == 0)) {\n            int64_t defunc_0_op_res_23494;\n            \n            // read array element\n            eta_p_23493 = ((__local int64_t *) red_arr_i64_mem_23486)[sext_i32_i64(local_tid_23482 + offset_23499)];\n            // apply reduction operation\n            // main.fut:5:33-36\n            defunc_0_op_res_23494 = add64(eta_p_23492, eta_p_23493);\n            eta_p_23492 = defunc_0_op_res_23494;\n            // write result of operation\n            ((__local int64_t *) red_arr_i64_mem_23486)[sext_i32_i64(local_tid_23482)] = eta_p_23492;\n        }\n        skip_waves_23500 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    if (sext_i32_i64(local_tid_23482) == (int64_t) 0) {\n        eta_p_block_res_acc_23491 = eta_p_23492;\n    } else {\n        eta_p_block_res_acc_23491 = (int64_t) 0;\n    }\n    // first thread in block saves block result to ",
                                    "global memory\n    if (local_tid_23482 == 0) {\n        ((__global int64_t *) segred_tmp_mem_23478)[sext_i32_i64(block_id_23483)] = eta_p_block_res_acc_23491;\n        mem_fence_global();\n        old_counter_23501 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23456)[(int64_t) 0], 1);\n        ((__local bool *) sync_arr_mem_23488)[(int64_t) 0] = old_counter_23501 == sext_i64_i32(num_tblocks_21401 - (int64_t) 1);\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_23502 = ((__local bool *) sync_arr_mem_23488)[(int64_t) 0];\n    if (is_last_block_23502) {\n        int64_t read_per_thread_23503;\n        int32_t offset_23507;\n        int32_t skip_waves_23508;\n        int64_t eta_p_23492;\n        int64_t eta_p_23493;\n        \n        if (local_tid_23482 == 0) {\n            old_counter_23501 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23456)[(int64_t) 0], sext_i64_i32((int64_t) 0 - num_tblocks_21401));\n        }\n        // read in the per-block-results\n        read_per_thread_23503 = sdiv_up64(num_tblocks_21401, segred_tblock_sizze_21399);\n        eta_p_16666 = (int64_t) 0;\n        for (int64_t i_23504 = 0; i_23504 < read_per_thread_23503; i_23504++) {\n            int64_t block_res_id_23505;\n            int64_t index_of_block_res_23506;\n            \n            block_res_id_23505 = sext_i32_i64(local_tid_23482) * read_per_thread_23503 + i_23504;\n            index_of_block_res_23506 = block_res_id_23505;\n            if (slt64(block_res_id_23505, num_tblocks_21401)) {\n                int64_t defunc_0_op_res_16668;\n                \n                eta_p_16667 = ((__global int64_t *) segred_tmp_mem_23478)[index_of_block_res_23506];\n                // main.fut:5:33-36\n                defunc_0_op_res_16668 = add64(eta_p_16666, eta_p_16667);\n                eta_p_16666 = defunc_0_op_res_16668;\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_23486)[sext_i32_i64(local_tid_23482)] = eta_p_16666;\n    ", "    barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        skip_waves_23508 = 1;\n        offset_23507 = 0;\n        // participating threads read initial accumulator\n        if (slt32(local_tid_23482, sext_i64_i32(segred_tblock_sizze_21399))) {\n            eta_p_23492 = ((__local int64_t *) red_arr_i64_mem_23486)[sext_i32_i64(local_tid_23482 + offset_23507)];\n        }\n        offset_23507 = 1;\n        while (slt32(offset_23507, wave_sizze_23484)) {\n            if (slt32(local_tid_23482 + offset_23507, sext_i64_i32(segred_tblock_sizze_21399)) && ((local_tid_23482 - squot32(local_tid_23482, wave_sizze_23484) * wave_sizze_23484) & (2 * offset_23507 - 1)) == 0) {\n                int64_t defunc_0_op_res_23494;\n                \n                // read array element\n                eta_p_23493 = ((volatile __local int64_t *) red_arr_i64_mem_23486)[sext_i32_i64(local_tid_23482 + offset_23507)];\n                // apply reduction operation\n                // main.fut:5:33-36\n                defunc_0_op_res_23494 = add64(eta_p_23492, eta_p_23493);\n                eta_p_23492 = defunc_0_op_res_23494;\n                // write result of operation\n                ((volatile __local int64_t *) red_arr_i64_mem_23486)[sext_i32_i64(local_tid_23482)] = eta_p_23492;\n            }\n            offset_23507 *= 2;\n        }\n        while (slt32(skip_waves_23508, squot32(sext_i64_i32(segred_tblock_sizze_21399) + wave_sizze_23484 - 1, wave_sizze_23484))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_23507 = skip_waves_23508 * wave_sizze_23484;\n            if (slt32(local_tid_23482 + offset_23507, sext_i64_i32(segred_tblock_sizze_21399)) && ((local_tid_23482 - squot32(local_tid_23482, wave_sizze_23484) * wave_sizze_23484) == 0 && (squot32(local_tid_23482, wave_sizze_23484) & (2 * skip_waves_23508 - 1)) == 0)) {\n                int64_t defunc_0_op_res_23494;\n                \n                // read array element\n                eta_p_23493 = ((__local in", "t64_t *) red_arr_i64_mem_23486)[sext_i32_i64(local_tid_23482 + offset_23507)];\n                // apply reduction operation\n                // main.fut:5:33-36\n                defunc_0_op_res_23494 = add64(eta_p_23492, eta_p_23493);\n                eta_p_23492 = defunc_0_op_res_23494;\n                // write result of operation\n                ((__local int64_t *) red_arr_i64_mem_23486)[sext_i32_i64(local_tid_23482)] = eta_p_23492;\n            }\n            skip_waves_23508 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // and back to memory with the final result\n        if (local_tid_23482 == 0) {\n            ((__global int64_t *) mem_23049)[(int64_t) 0] = eta_p_23492;\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_21399\n    #undef chunk_sizze_23455\n}\nFUTHARK_KERNEL_SIZED(mainzisegred_nonseg_21506_dim1, 1, 1)\nvoid mainzisegred_nonseg_21506(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t distance_16737, int64_t num_tblocks_21500, int64_t num_threads_23566, __global unsigned char *mem_23052, __global unsigned char *mem_23061, __global unsigned char *mem_23108, __global unsigned char *mem_23109, __global unsigned char *counters_mem_23560, __global unsigned char *segred_tmp_mem_23562, __global unsigned char *segred_tmp_mem_23564)\n{\n    #define segred_tblock_sizze_21498 (mainzisegred_nonseg_21506zisegred_tblock_sizze_21498)\n    #define chunk_sizze_23559 (mainzisegred_nonseg_21506zichunk_sizze_23559)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local unsigned char *sync_arr_mem_23576_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_23576_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i8_mem_23574_backing_1 = &shared_mem[sync_arr_mem_23576_backing_",
                                    "2_offset];\n    const int64_t red_arr_i8_mem_23574_backing_1_offset = sync_arr_mem_23576_backing_2_offset + (segred_tblock_sizze_21498 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_21498, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i64_mem_23572_backing_0 = &shared_mem[red_arr_i8_mem_23574_backing_1_offset];\n    const int64_t red_arr_i64_mem_23572_backing_0_offset = red_arr_i8_mem_23574_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_21498 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_21498, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_23568;\n    int32_t tblock_sizze_23571;\n    int32_t wave_sizze_23570;\n    int32_t block_id_23569;\n    int32_t global_tid_23567;\n    int64_t phys_tid_21506;\n    __local unsigned char *red_arr_i64_mem_23572;\n    __local unsigned char *red_arr_i8_mem_23574;\n    __local unsigned char *sync_arr_mem_23576;\n    int64_t dummy_21504;\n    int64_t gtid_21505;\n    int64_t q_23578;\n    int64_t eta_p_block_res_acc_23579;\n    int8_t eta_p_block_res_acc_23580;\n    int64_t eta_p_20753;\n    int8_t eta_p_20754;\n    int64_t eta_p_20755;\n    int8_t eta_p_20756;\n    int64_t tblock_id_in_segment_23597;\n    int64_t block_base_offset_23598;\n    int32_t offset_23601;\n    int32_t skip_waves_23602;\n    int64_t eta_p_23581;\n    int8_t eta_p_23582;\n    int64_t eta_p_23583;\n    int8_t eta_p_23584;\n    int32_t old_counter_23603;\n    bool is_last_block_23604;\n    \n    local_tid_23568 = get_local_id(0);\n    tblock_sizze_23571 = get_local_size(0);\n    wave_sizze_23570 = LOCKSTEP_WIDTH;\n    block_id_23569 = get_tblock_id(0);\n    global_tid_23567 = block_id_23569 * tblock_sizze_23571 + local_tid_23568;\n    phys_tid_21506 = sext_i32_i64(global_tid_23567);\n    red_arr_i64_mem_2357", "2 = (__local unsigned char *) red_arr_i64_mem_23572_backing_0;\n    red_arr_i8_mem_23574 = (__local unsigned char *) red_arr_i8_mem_23574_backing_1;\n    sync_arr_mem_23576 = (__local unsigned char *) sync_arr_mem_23576_backing_2;\n    dummy_21504 = (int64_t) 0;\n    gtid_21505 = (int64_t) 0;\n    q_23578 = sdiv_up64(distance_16737, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_21498 * num_tblocks_21500)) * chunk_sizze_23559);\n    // ne-initialise the outer (per-block) accumulator(s)\n    eta_p_block_res_acc_23579 = (int64_t) 0;\n    eta_p_block_res_acc_23580 = (int8_t) 0;\n    tblock_id_in_segment_23597 = squot64(phys_tid_21506, segred_tblock_sizze_21498);\n    block_base_offset_23598 = tblock_id_in_segment_23597 * q_23578 * segred_tblock_sizze_21498;\n    for (int64_t i_23599 = 0; i_23599 < q_23578; i_23599++) {\n        int64_t block_offset_23600 = block_base_offset_23598 + i_23599 * segred_tblock_sizze_21498;\n        \n        gtid_21505 = phys_tid_21506 + num_threads_23566 * i_23599;\n        if (slt64(gtid_21505, distance_16737)) {\n            int64_t index_primexp_22730;\n            bool x_20748;\n            bool y_20749;\n            bool bounds_check_20750;\n            bool index_certs_20751;\n            int64_t loopres_22826;\n            int8_t tmp_20752;\n            bool cond_20757;\n            bool cond_t_res_20758;\n            bool x_20759;\n            int64_t lifted_lambda_res_20760;\n            int8_t lifted_lambda_res_20761;\n            \n            // apply map function(s)\n            // apply map function\n            index_primexp_22730 = add64(num_qubits_14547, gtid_21505);\n            // definitions.fut:97:30-39\n            x_20748 = sle64((int64_t) 0, index_primexp_22730);\n            // definitions.fut:97:30-39\n            y_20749 = slt64(index_primexp_22730, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            // definitions.fut:97:30-39\n            bounds_check_20750 = x_20748 && y_20749;\n            // definitions.fut:97:30-39\n   ", "         if (!bounds_check_20750) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                        global_failure_args[0] = (int64_t) index_primexp_22730;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            loopres_22826 = ((__global int64_t *) mem_23061)[(int64_t) 0];\n            // definitions.fut:97:15-59\n            tmp_20752 = ((__global int8_t *) mem_23052)[index_primexp_22730 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + loopres_22826];\n            // load accumulator(s)\n            eta_p_20753 = eta_p_block_res_acc_23579;\n            eta_p_20754 = eta_p_block_res_acc_23580;\n            // load next value(s)\n            eta_p_20755 = index_primexp_22730;\n            eta_p_20756 = tmp_20752;\n            // apply reduction operator(s)\n            // definitions.fut:91:5-96:16\n            cond_20757 = eta_p_20754 == (int8_t) 1;\n            // definitions.fut:91:26-30\n            cond_t_res_20758 = eta_p_20756 == (int8_t) 1;\n            // definitions.fut:97:12-60\n            x_20759 = cond_20757 && cond_t_res_20758;\n            // definitions.fut:91:5-96:16\n            if (x_20759) {\n                bool cond_20762;\n                int64_t lifted_lambda_res_t_res_20763;\n                int8_t lifted_lambda_res_t_res_20764;\n                \n                // definitions.fut:92:7-93:22\n                cond_20762 = sle64(eta_p_20753, eta_p_20755);\n                // definitions.fut:97:12-60\n                if (cond_20762) {\n                    lifted_lambda_res_t_res_20763 = eta_p_20753;\n                } else {\n                    lifted_lambda_res_t_res_20763 = eta_p_20755;\n                }\n                // definitions.fut:97:12-60\n             ",
                                    "   if (cond_20762) {\n                    lifted_lambda_res_t_res_20764 = eta_p_20754;\n                } else {\n                    lifted_lambda_res_t_res_20764 = eta_p_20756;\n                }\n                lifted_lambda_res_20760 = lifted_lambda_res_t_res_20763;\n                lifted_lambda_res_20761 = lifted_lambda_res_t_res_20764;\n            } else {\n                int64_t lifted_lambda_res_f_res_20765;\n                int8_t lifted_lambda_res_f_res_20766;\n                \n                // definitions.fut:94:10-96:16\n                if (cond_20757) {\n                    lifted_lambda_res_f_res_20765 = eta_p_20753;\n                    lifted_lambda_res_f_res_20766 = eta_p_20754;\n                } else {\n                    int64_t lifted_lambda_res_f_res_f_res_20767;\n                    int8_t lifted_lambda_res_f_res_f_res_20768;\n                    \n                    // definitions.fut:97:12-60\n                    if (cond_t_res_20758) {\n                        lifted_lambda_res_f_res_f_res_20767 = eta_p_20755;\n                    } else {\n                        lifted_lambda_res_f_res_f_res_20767 = (int64_t) 0;\n                    }\n                    // definitions.fut:97:12-60\n                    if (cond_t_res_20758) {\n                        lifted_lambda_res_f_res_f_res_20768 = eta_p_20756;\n                    } else {\n                        lifted_lambda_res_f_res_f_res_20768 = (int8_t) 0;\n                    }\n                    lifted_lambda_res_f_res_20765 = lifted_lambda_res_f_res_f_res_20767;\n                    lifted_lambda_res_f_res_20766 = lifted_lambda_res_f_res_f_res_20768;\n                }\n                lifted_lambda_res_20760 = lifted_lambda_res_f_res_20765;\n                lifted_lambda_res_20761 = lifted_lambda_res_f_res_20766;\n            }\n            // store in accumulator(s)\n            eta_p_block_res_acc_23579 = lifted_lambda_res_20760;\n            eta_p_block_res_acc_23580 = lifted_lambda_res_20761;\n        }\n    }\n ", "   \n  error_0:\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_failure)\n        return;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    ((__local int64_t *) red_arr_i64_mem_23572)[sext_i32_i64(local_tid_23568)] = eta_p_block_res_acc_23579;\n    ((__local int8_t *) red_arr_i8_mem_23574)[sext_i32_i64(local_tid_23568)] = eta_p_block_res_acc_23580;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_23602 = 1;\n    offset_23601 = 0;\n    // participating threads read initial accumulator\n    if (slt32(local_tid_23568, sext_i64_i32(segred_tblock_sizze_21498))) {\n        eta_p_23581 = ((__local int64_t *) red_arr_i64_mem_23572)[sext_i32_i64(local_tid_23568 + offset_23601)];\n        eta_p_23582 = ((__local int8_t *) red_arr_i8_mem_23574)[sext_i32_i64(local_tid_23568 + offset_23601)];\n    }\n    offset_23601 = 1;\n    while (slt32(offset_23601, wave_sizze_23570)) {\n        if (slt32(local_tid_23568 + offset_23601, sext_i64_i32(segred_tblock_sizze_21498)) && ((local_tid_23568 - squot32(local_tid_23568, wave_sizze_23570) * wave_sizze_23570) & (2 * offset_23601 - 1)) == 0) {\n            bool cond_23585;\n            bool cond_t_res_23586;\n            bool x_23587;\n            int64_t lifted_lambda_res_23588;\n            int8_t lifted_lambda_res_23589;\n            \n            // read array element\n            eta_p_23583 = ((volatile __local int64_t *) red_arr_i64_mem_23572)[sext_i32_i64(local_tid_23568 + offset_23601)];\n            eta_p_23584 = ((volatile __local int8_t *) red_arr_i8_mem_23574)[sext_i32_i64(local_tid_23568 + offset_23601)];\n            // apply reduction operation\n            // definitions.fut:91:5-96:16\n            cond_23585 = eta_p_23582 == (int8_t) 1;\n            // definitions.fut:91:26-30\n            cond_t_res_23586 = eta_p_23584 == (int8_t) 1;\n            // definitions.fut:97:12-60\n            x_23587 = cond_23585 && cond_t_res_23586;\n            // definitions.fut:91:5-96:16\n            if (x_23", "587) {\n                bool cond_23590;\n                int64_t lifted_lambda_res_t_res_23591;\n                int8_t lifted_lambda_res_t_res_23592;\n                \n                // definitions.fut:92:7-93:22\n                cond_23590 = sle64(eta_p_23581, eta_p_23583);\n                // definitions.fut:97:12-60\n                if (cond_23590) {\n                    lifted_lambda_res_t_res_23591 = eta_p_23581;\n                } else {\n                    lifted_lambda_res_t_res_23591 = eta_p_23583;\n                }\n                // definitions.fut:97:12-60\n                if (cond_23590) {\n                    lifted_lambda_res_t_res_23592 = eta_p_23582;\n                } else {\n                    lifted_lambda_res_t_res_23592 = eta_p_23584;\n                }\n                lifted_lambda_res_23588 = lifted_lambda_res_t_res_23591;\n                lifted_lambda_res_23589 = lifted_lambda_res_t_res_23592;\n            } else {\n                int64_t lifted_lambda_res_f_res_23593;\n                int8_t lifted_lambda_res_f_res_23594;\n                \n                // definitions.fut:94:10-96:16\n                if (cond_23585) {\n                    lifted_lambda_res_f_res_23593 = eta_p_23581;\n                    lifted_lambda_res_f_res_23594 = eta_p_23582;\n                } else {\n                    int64_t lifted_lambda_res_f_res_f_res_23595;\n                    int8_t lifted_lambda_res_f_res_f_res_23596;\n                    \n                    // definitions.fut:97:12-60\n                    if (cond_t_res_23586) {\n                        lifted_lambda_res_f_res_f_res_23595 = eta_p_23583;\n                    } else {\n                        lifted_lambda_res_f_res_f_res_23595 = (int64_t) 0;\n                    }\n                    // definitions.fut:97:12-60\n                    if (cond_t_res_23586) {\n                        lifted_lambda_res_f_res_f_res_23596 = eta_p_23584;\n                    } else {\n                        lifted_lambda_res_f_res_f_res_23",
                                    "596 = (int8_t) 0;\n                    }\n                    lifted_lambda_res_f_res_23593 = lifted_lambda_res_f_res_f_res_23595;\n                    lifted_lambda_res_f_res_23594 = lifted_lambda_res_f_res_f_res_23596;\n                }\n                lifted_lambda_res_23588 = lifted_lambda_res_f_res_23593;\n                lifted_lambda_res_23589 = lifted_lambda_res_f_res_23594;\n            }\n            eta_p_23581 = lifted_lambda_res_23588;\n            eta_p_23582 = lifted_lambda_res_23589;\n            // write result of operation\n            ((volatile __local int64_t *) red_arr_i64_mem_23572)[sext_i32_i64(local_tid_23568)] = eta_p_23581;\n            ((volatile __local int8_t *) red_arr_i8_mem_23574)[sext_i32_i64(local_tid_23568)] = eta_p_23582;\n        }\n        offset_23601 *= 2;\n    }\n    while (slt32(skip_waves_23602, squot32(sext_i64_i32(segred_tblock_sizze_21498) + wave_sizze_23570 - 1, wave_sizze_23570))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_23601 = skip_waves_23602 * wave_sizze_23570;\n        if (slt32(local_tid_23568 + offset_23601, sext_i64_i32(segred_tblock_sizze_21498)) && ((local_tid_23568 - squot32(local_tid_23568, wave_sizze_23570) * wave_sizze_23570) == 0 && (squot32(local_tid_23568, wave_sizze_23570) & (2 * skip_waves_23602 - 1)) == 0)) {\n            bool cond_23585;\n            bool cond_t_res_23586;\n            bool x_23587;\n            int64_t lifted_lambda_res_23588;\n            int8_t lifted_lambda_res_23589;\n            \n            // read array element\n            eta_p_23583 = ((__local int64_t *) red_arr_i64_mem_23572)[sext_i32_i64(local_tid_23568 + offset_23601)];\n            eta_p_23584 = ((__local int8_t *) red_arr_i8_mem_23574)[sext_i32_i64(local_tid_23568 + offset_23601)];\n            // apply reduction operation\n            // definitions.fut:91:5-96:16\n            cond_23585 = eta_p_23582 == (int8_t) 1;\n            // definitions.fut:91:26-30\n            cond_t_res_23586 = eta_p_23584 == (int8_t) 1;\n            ", "// definitions.fut:97:12-60\n            x_23587 = cond_23585 && cond_t_res_23586;\n            // definitions.fut:91:5-96:16\n            if (x_23587) {\n                bool cond_23590;\n                int64_t lifted_lambda_res_t_res_23591;\n                int8_t lifted_lambda_res_t_res_23592;\n                \n                // definitions.fut:92:7-93:22\n                cond_23590 = sle64(eta_p_23581, eta_p_23583);\n                // definitions.fut:97:12-60\n                if (cond_23590) {\n                    lifted_lambda_res_t_res_23591 = eta_p_23581;\n                } else {\n                    lifted_lambda_res_t_res_23591 = eta_p_23583;\n                }\n                // definitions.fut:97:12-60\n                if (cond_23590) {\n                    lifted_lambda_res_t_res_23592 = eta_p_23582;\n                } else {\n                    lifted_lambda_res_t_res_23592 = eta_p_23584;\n                }\n                lifted_lambda_res_23588 = lifted_lambda_res_t_res_23591;\n                lifted_lambda_res_23589 = lifted_lambda_res_t_res_23592;\n            } else {\n                int64_t lifted_lambda_res_f_res_23593;\n                int8_t lifted_lambda_res_f_res_23594;\n                \n                // definitions.fut:94:10-96:16\n                if (cond_23585) {\n                    lifted_lambda_res_f_res_23593 = eta_p_23581;\n                    lifted_lambda_res_f_res_23594 = eta_p_23582;\n                } else {\n                    int64_t lifted_lambda_res_f_res_f_res_23595;\n                    int8_t lifted_lambda_res_f_res_f_res_23596;\n                    \n                    // definitions.fut:97:12-60\n                    if (cond_t_res_23586) {\n                        lifted_lambda_res_f_res_f_res_23595 = eta_p_23583;\n                    } else {\n                        lifted_lambda_res_f_res_f_res_23595 = (int64_t) 0;\n                    }\n                    // definitions.fut:97:12-60\n                    if (cond_t_res_23586) {\n                ", "        lifted_lambda_res_f_res_f_res_23596 = eta_p_23584;\n                    } else {\n                        lifted_lambda_res_f_res_f_res_23596 = (int8_t) 0;\n                    }\n                    lifted_lambda_res_f_res_23593 = lifted_lambda_res_f_res_f_res_23595;\n                    lifted_lambda_res_f_res_23594 = lifted_lambda_res_f_res_f_res_23596;\n                }\n                lifted_lambda_res_23588 = lifted_lambda_res_f_res_23593;\n                lifted_lambda_res_23589 = lifted_lambda_res_f_res_23594;\n            }\n            eta_p_23581 = lifted_lambda_res_23588;\n            eta_p_23582 = lifted_lambda_res_23589;\n            // write result of operation\n            ((__local int64_t *) red_arr_i64_mem_23572)[sext_i32_i64(local_tid_23568)] = eta_p_23581;\n            ((__local int8_t *) red_arr_i8_mem_23574)[sext_i32_i64(local_tid_23568)] = eta_p_23582;\n        }\n        skip_waves_23602 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    if (sext_i32_i64(local_tid_23568) == (int64_t) 0) {\n        eta_p_block_res_acc_23579 = eta_p_23581;\n        eta_p_block_res_acc_23580 = eta_p_23582;\n    } else {\n        eta_p_block_res_acc_23579 = (int64_t) 0;\n        eta_p_block_res_acc_23580 = (int8_t) 0;\n    }\n    // first thread in block saves block result to global memory\n    if (local_tid_23568 == 0) {\n        ((__global int64_t *) segred_tmp_mem_23562)[sext_i32_i64(block_id_23569)] = eta_p_block_res_acc_23579;\n        mem_fence_global();\n        ((__global int8_t *) segred_tmp_mem_23564)[sext_i32_i64(block_id_23569)] = eta_p_block_res_acc_23580;\n        mem_fence_global();\n        old_counter_23603 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23560)[(int64_t) 0], 1);\n        ((__local bool *) sync_arr_mem_23576)[(int64_t) 0] = old_counter_23603 == sext_i64_i32(num_tblocks_21500 - (int64_t) 1);\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_M",
                                    "EM_FENCE);\n    is_last_block_23604 = ((__local bool *) sync_arr_mem_23576)[(int64_t) 0];\n    if (is_last_block_23604) {\n        int64_t read_per_thread_23605;\n        int32_t offset_23609;\n        int32_t skip_waves_23610;\n        int64_t eta_p_23581;\n        int8_t eta_p_23582;\n        int64_t eta_p_23583;\n        int8_t eta_p_23584;\n        \n        if (local_tid_23568 == 0) {\n            old_counter_23603 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23560)[(int64_t) 0], sext_i64_i32((int64_t) 0 - num_tblocks_21500));\n        }\n        // read in the per-block-results\n        read_per_thread_23605 = sdiv_up64(num_tblocks_21500, segred_tblock_sizze_21498);\n        eta_p_20753 = (int64_t) 0;\n        eta_p_20754 = (int8_t) 0;\n        for (int64_t i_23606 = 0; i_23606 < read_per_thread_23605; i_23606++) {\n            int64_t block_res_id_23607;\n            int64_t index_of_block_res_23608;\n            \n            block_res_id_23607 = sext_i32_i64(local_tid_23568) * read_per_thread_23605 + i_23606;\n            index_of_block_res_23608 = block_res_id_23607;\n            if (slt64(block_res_id_23607, num_tblocks_21500)) {\n                bool cond_20757;\n                bool cond_t_res_20758;\n                bool x_20759;\n                int64_t lifted_lambda_res_20760;\n                int8_t lifted_lambda_res_20761;\n                \n                eta_p_20755 = ((__global int64_t *) segred_tmp_mem_23562)[index_of_block_res_23608];\n                eta_p_20756 = ((__global int8_t *) segred_tmp_mem_23564)[index_of_block_res_23608];\n                // definitions.fut:91:5-96:16\n                cond_20757 = eta_p_20754 == (int8_t) 1;\n                // definitions.fut:91:26-30\n                cond_t_res_20758 = eta_p_20756 == (int8_t) 1;\n                // definitions.fut:97:12-60\n                x_20759 = cond_20757 && cond_t_res_20758;\n                // definitions.fut:91:5-96:16\n                if (x_20759) {\n                    bool cond_20762;\n    ", "                int64_t lifted_lambda_res_t_res_20763;\n                    int8_t lifted_lambda_res_t_res_20764;\n                    \n                    // definitions.fut:92:7-93:22\n                    cond_20762 = sle64(eta_p_20753, eta_p_20755);\n                    // definitions.fut:97:12-60\n                    if (cond_20762) {\n                        lifted_lambda_res_t_res_20763 = eta_p_20753;\n                    } else {\n                        lifted_lambda_res_t_res_20763 = eta_p_20755;\n                    }\n                    // definitions.fut:97:12-60\n                    if (cond_20762) {\n                        lifted_lambda_res_t_res_20764 = eta_p_20754;\n                    } else {\n                        lifted_lambda_res_t_res_20764 = eta_p_20756;\n                    }\n                    lifted_lambda_res_20760 = lifted_lambda_res_t_res_20763;\n                    lifted_lambda_res_20761 = lifted_lambda_res_t_res_20764;\n                } else {\n                    int64_t lifted_lambda_res_f_res_20765;\n                    int8_t lifted_lambda_res_f_res_20766;\n                    \n                    // definitions.fut:94:10-96:16\n                    if (cond_20757) {\n                        lifted_lambda_res_f_res_20765 = eta_p_20753;\n                        lifted_lambda_res_f_res_20766 = eta_p_20754;\n                    } else {\n                        int64_t lifted_lambda_res_f_res_f_res_20767;\n                        int8_t lifted_lambda_res_f_res_f_res_20768;\n                        \n                        // definitions.fut:97:12-60\n                        if (cond_t_res_20758) {\n                            lifted_lambda_res_f_res_f_res_20767 = eta_p_20755;\n                        } else {\n                            lifted_lambda_res_f_res_f_res_20767 = (int64_t) 0;\n                        }\n                        // definitions.fut:97:12-60\n                        if (cond_t_res_20758) {\n                            lifted_lambda_res_f_", "res_f_res_20768 = eta_p_20756;\n                        } else {\n                            lifted_lambda_res_f_res_f_res_20768 = (int8_t) 0;\n                        }\n                        lifted_lambda_res_f_res_20765 = lifted_lambda_res_f_res_f_res_20767;\n                        lifted_lambda_res_f_res_20766 = lifted_lambda_res_f_res_f_res_20768;\n                    }\n                    lifted_lambda_res_20760 = lifted_lambda_res_f_res_20765;\n                    lifted_lambda_res_20761 = lifted_lambda_res_f_res_20766;\n                }\n                eta_p_20753 = lifted_lambda_res_20760;\n                eta_p_20754 = lifted_lambda_res_20761;\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_23572)[sext_i32_i64(local_tid_23568)] = eta_p_20753;\n        ((__local int8_t *) red_arr_i8_mem_23574)[sext_i32_i64(local_tid_23568)] = eta_p_20754;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        skip_waves_23610 = 1;\n        offset_23609 = 0;\n        // participating threads read initial accumulator\n        if (slt32(local_tid_23568, sext_i64_i32(segred_tblock_sizze_21498))) {\n            eta_p_23581 = ((__local int64_t *) red_arr_i64_mem_23572)[sext_i32_i64(local_tid_23568 + offset_23609)];\n            eta_p_23582 = ((__local int8_t *) red_arr_i8_mem_23574)[sext_i32_i64(local_tid_23568 + offset_23609)];\n        }\n        offset_23609 = 1;\n        while (slt32(offset_23609, wave_sizze_23570)) {\n            if (slt32(local_tid_23568 + offset_23609, sext_i64_i32(segred_tblock_sizze_21498)) && ((local_tid_23568 - squot32(local_tid_23568, wave_sizze_23570) * wave_sizze_23570) & (2 * offset_23609 - 1)) == 0) {\n                bool cond_23585;\n                bool cond_t_res_23586;\n                bool x_23587;\n                int64_t lifted_lambda_res_23588;\n                int8_t lifted_lambda_res_23589;\n                \n                // read array element\n                eta_p_23583 = ((volatile __local int64_t *) ",
                                    "red_arr_i64_mem_23572)[sext_i32_i64(local_tid_23568 + offset_23609)];\n                eta_p_23584 = ((volatile __local int8_t *) red_arr_i8_mem_23574)[sext_i32_i64(local_tid_23568 + offset_23609)];\n                // apply reduction operation\n                // definitions.fut:91:5-96:16\n                cond_23585 = eta_p_23582 == (int8_t) 1;\n                // definitions.fut:91:26-30\n                cond_t_res_23586 = eta_p_23584 == (int8_t) 1;\n                // definitions.fut:97:12-60\n                x_23587 = cond_23585 && cond_t_res_23586;\n                // definitions.fut:91:5-96:16\n                if (x_23587) {\n                    bool cond_23590;\n                    int64_t lifted_lambda_res_t_res_23591;\n                    int8_t lifted_lambda_res_t_res_23592;\n                    \n                    // definitions.fut:92:7-93:22\n                    cond_23590 = sle64(eta_p_23581, eta_p_23583);\n                    // definitions.fut:97:12-60\n                    if (cond_23590) {\n                        lifted_lambda_res_t_res_23591 = eta_p_23581;\n                    } else {\n                        lifted_lambda_res_t_res_23591 = eta_p_23583;\n                    }\n                    // definitions.fut:97:12-60\n                    if (cond_23590) {\n                        lifted_lambda_res_t_res_23592 = eta_p_23582;\n                    } else {\n                        lifted_lambda_res_t_res_23592 = eta_p_23584;\n                    }\n                    lifted_lambda_res_23588 = lifted_lambda_res_t_res_23591;\n                    lifted_lambda_res_23589 = lifted_lambda_res_t_res_23592;\n                } else {\n                    int64_t lifted_lambda_res_f_res_23593;\n                    int8_t lifted_lambda_res_f_res_23594;\n                    \n                    // definitions.fut:94:10-96:16\n                    if (cond_23585) {\n                        lifted_lambda_res_f_res_23593 = eta_p_23581;\n                        lifted_lambda_res_f_res_23594 ", "= eta_p_23582;\n                    } else {\n                        int64_t lifted_lambda_res_f_res_f_res_23595;\n                        int8_t lifted_lambda_res_f_res_f_res_23596;\n                        \n                        // definitions.fut:97:12-60\n                        if (cond_t_res_23586) {\n                            lifted_lambda_res_f_res_f_res_23595 = eta_p_23583;\n                        } else {\n                            lifted_lambda_res_f_res_f_res_23595 = (int64_t) 0;\n                        }\n                        // definitions.fut:97:12-60\n                        if (cond_t_res_23586) {\n                            lifted_lambda_res_f_res_f_res_23596 = eta_p_23584;\n                        } else {\n                            lifted_lambda_res_f_res_f_res_23596 = (int8_t) 0;\n                        }\n                        lifted_lambda_res_f_res_23593 = lifted_lambda_res_f_res_f_res_23595;\n                        lifted_lambda_res_f_res_23594 = lifted_lambda_res_f_res_f_res_23596;\n                    }\n                    lifted_lambda_res_23588 = lifted_lambda_res_f_res_23593;\n                    lifted_lambda_res_23589 = lifted_lambda_res_f_res_23594;\n                }\n                eta_p_23581 = lifted_lambda_res_23588;\n                eta_p_23582 = lifted_lambda_res_23589;\n                // write result of operation\n                ((volatile __local int64_t *) red_arr_i64_mem_23572)[sext_i32_i64(local_tid_23568)] = eta_p_23581;\n                ((volatile __local int8_t *) red_arr_i8_mem_23574)[sext_i32_i64(local_tid_23568)] = eta_p_23582;\n            }\n            offset_23609 *= 2;\n        }\n        while (slt32(skip_waves_23610, squot32(sext_i64_i32(segred_tblock_sizze_21498) + wave_sizze_23570 - 1, wave_sizze_23570))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_23609 = skip_waves_23610 * wave_sizze_23570;\n            if (slt32(local_tid_23568 + offset_23609, sext_i64_i32(segred_tblock_sizze_21498)) && ((loca", "l_tid_23568 - squot32(local_tid_23568, wave_sizze_23570) * wave_sizze_23570) == 0 && (squot32(local_tid_23568, wave_sizze_23570) & (2 * skip_waves_23610 - 1)) == 0)) {\n                bool cond_23585;\n                bool cond_t_res_23586;\n                bool x_23587;\n                int64_t lifted_lambda_res_23588;\n                int8_t lifted_lambda_res_23589;\n                \n                // read array element\n                eta_p_23583 = ((__local int64_t *) red_arr_i64_mem_23572)[sext_i32_i64(local_tid_23568 + offset_23609)];\n                eta_p_23584 = ((__local int8_t *) red_arr_i8_mem_23574)[sext_i32_i64(local_tid_23568 + offset_23609)];\n                // apply reduction operation\n                // definitions.fut:91:5-96:16\n                cond_23585 = eta_p_23582 == (int8_t) 1;\n                // definitions.fut:91:26-30\n                cond_t_res_23586 = eta_p_23584 == (int8_t) 1;\n                // definitions.fut:97:12-60\n                x_23587 = cond_23585 && cond_t_res_23586;\n                // definitions.fut:91:5-96:16\n                if (x_23587) {\n                    bool cond_23590;\n                    int64_t lifted_lambda_res_t_res_23591;\n                    int8_t lifted_lambda_res_t_res_23592;\n                    \n                    // definitions.fut:92:7-93:22\n                    cond_23590 = sle64(eta_p_23581, eta_p_23583);\n                    // definitions.fut:97:12-60\n                    if (cond_23590) {\n                        lifted_lambda_res_t_res_23591 = eta_p_23581;\n                    } else {\n                        lifted_lambda_res_t_res_23591 = eta_p_23583;\n                    }\n                    // definitions.fut:97:12-60\n                    if (cond_23590) {\n                        lifted_lambda_res_t_res_23592 = eta_p_23582;\n                    } else {\n                        lifted_lambda_res_t_res_23592 = eta_p_23584;\n                    }\n                    lifted_lambda_res_23588 = lifted_lambda_res_t",
                                    "_res_23591;\n                    lifted_lambda_res_23589 = lifted_lambda_res_t_res_23592;\n                } else {\n                    int64_t lifted_lambda_res_f_res_23593;\n                    int8_t lifted_lambda_res_f_res_23594;\n                    \n                    // definitions.fut:94:10-96:16\n                    if (cond_23585) {\n                        lifted_lambda_res_f_res_23593 = eta_p_23581;\n                        lifted_lambda_res_f_res_23594 = eta_p_23582;\n                    } else {\n                        int64_t lifted_lambda_res_f_res_f_res_23595;\n                        int8_t lifted_lambda_res_f_res_f_res_23596;\n                        \n                        // definitions.fut:97:12-60\n                        if (cond_t_res_23586) {\n                            lifted_lambda_res_f_res_f_res_23595 = eta_p_23583;\n                        } else {\n                            lifted_lambda_res_f_res_f_res_23595 = (int64_t) 0;\n                        }\n                        // definitions.fut:97:12-60\n                        if (cond_t_res_23586) {\n                            lifted_lambda_res_f_res_f_res_23596 = eta_p_23584;\n                        } else {\n                            lifted_lambda_res_f_res_f_res_23596 = (int8_t) 0;\n                        }\n                        lifted_lambda_res_f_res_23593 = lifted_lambda_res_f_res_f_res_23595;\n                        lifted_lambda_res_f_res_23594 = lifted_lambda_res_f_res_f_res_23596;\n                    }\n                    lifted_lambda_res_23588 = lifted_lambda_res_f_res_23593;\n                    lifted_lambda_res_23589 = lifted_lambda_res_f_res_23594;\n                }\n                eta_p_23581 = lifted_lambda_res_23588;\n                eta_p_23582 = lifted_lambda_res_23589;\n                // write result of operation\n                ((__local int64_t *) red_arr_i64_mem_23572)[sext_i32_i64(local_tid_23568)] = eta_p_23581;\n                ((__local int8_t *) red_arr_i8_mem_23574", ")[sext_i32_i64(local_tid_23568)] = eta_p_23582;\n            }\n            skip_waves_23610 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // and back to memory with the final result\n        if (local_tid_23568 == 0) {\n            ((__global int64_t *) mem_23108)[(int64_t) 0] = eta_p_23581;\n            ((__global int8_t *) mem_23109)[(int64_t) 0] = eta_p_23582;\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_21498\n    #undef chunk_sizze_23559\n}\nFUTHARK_KERNEL_SIZED(mainzisegred_nonseg_23378_dim1, 1, 1)\nvoid mainzisegred_nonseg_23378(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t m_20840, int64_t num_threads_23728, __global unsigned char *mem_23223, __global unsigned char *mem_23393, __global unsigned char *counters_mem_23724, __global unsigned char *segred_tmp_mem_23726)\n{\n    #define segred_num_tblocks_23369 (mainzisegred_nonseg_23378zisegred_num_tblocks_23369)\n    #define segred_tblock_sizze_23371 (mainzisegred_nonseg_23378zisegred_tblock_sizze_23371)\n    #define chunk_sizze_23723 (mainzisegred_nonseg_23378zichunk_sizze_23723)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local unsigned char *sync_arr_mem_23736_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_23736_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_23734_backing_0 = &shared_mem[sync_arr_mem_23736_backing_1_offset];\n    const int64_t red_arr_i64_mem_23734_backing_0_offset = sync_arr_mem_23736_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_23371 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_23371, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n      ", "  \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_23730;\n    int32_t tblock_sizze_23733;\n    int32_t wave_sizze_23732;\n    int32_t block_id_23731;\n    int32_t global_tid_23729;\n    int64_t phys_tid_23378;\n    __local unsigned char *red_arr_i64_mem_23734;\n    __local unsigned char *sync_arr_mem_23736;\n    int64_t dummy_23376;\n    int64_t gtid_23377;\n    int64_t q_23738;\n    int64_t x_block_res_acc_23739;\n    int64_t x_23386;\n    int64_t y_23387;\n    int64_t tblock_id_in_segment_23743;\n    int64_t block_base_offset_23744;\n    int32_t offset_23747;\n    int32_t skip_waves_23748;\n    int64_t x_23740;\n    int64_t y_23741;\n    int32_t old_counter_23749;\n    bool is_last_block_23750;\n    \n    local_tid_23730 = get_local_id(0);\n    tblock_sizze_23733 = get_local_size(0);\n    wave_sizze_23732 = LOCKSTEP_WIDTH;\n    block_id_23731 = get_tblock_id(0);\n    global_tid_23729 = block_id_23731 * tblock_sizze_23733 + local_tid_23730;\n    phys_tid_23378 = sext_i32_i64(global_tid_23729);\n    red_arr_i64_mem_23734 = (__local unsigned char *) red_arr_i64_mem_23734_backing_0;\n    sync_arr_mem_23736 = (__local unsigned char *) sync_arr_mem_23736_backing_1;\n    dummy_23376 = (int64_t) 0;\n    gtid_23377 = (int64_t) 0;\n    q_23738 = sdiv_up64(m_20840, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_23371 * segred_num_tblocks_23369)) * chunk_sizze_23723);\n    // ne-initialise the outer (per-block) accumulator(s)\n    x_block_res_acc_23739 = (int64_t) 0;\n    tblock_id_in_segment_23743 = squot64(phys_tid_23378, segred_tblock_sizze_23371);\n    block_base_offset_23744 = tblock_id_in_segment_23743 * q_23738 * segred_tblock_sizze_23371;\n    for (int64_t i_23745 = 0; i_23745 < q_23738; i_23745++) {\n        int64_t block_offset_23746 = block_base_offset_23744 + i_23745 * segred_tblock_sizze_23371;\n        \n        gtid_23377 = phys_tid_23378 + num_threads_23728 * i_23745;\n        if (slt64(gtid_23377, m_20840)) {\n          ",
                                    "  int64_t eta_p_23380;\n            bool x_23381;\n            bool y_23382;\n            bool bounds_check_23383;\n            bool index_certs_23384;\n            int64_t bytes_23385;\n            int64_t zz_23388;\n            \n            // apply map function(s)\n            // apply map function\n            eta_p_23380 = ((__global int64_t *) mem_23223)[gtid_23377];\n            // definitions.fut:25:73-82\n            x_23381 = sle64((int64_t) 0, eta_p_23380);\n            // definitions.fut:25:73-82\n            y_23382 = slt64(eta_p_23380, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            // definitions.fut:25:73-82\n            bounds_check_23383 = x_23381 && y_23382;\n            // definitions.fut:25:73-82\n            if (!bounds_check_23383) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 6) == -1) {\n                        global_failure_args[0] = (int64_t) eta_p_23380;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            // definitions.fut:25:17-29:98\n            bytes_23385 = (int64_t) 2 * num_qubits_14547;\n            // load accumulator(s)\n            x_23386 = x_block_res_acc_23739;\n            // load next value(s)\n            y_23387 = bytes_23385;\n            // apply reduction operator(s)\n            zz_23388 = smax64(x_23386, y_23387);\n            // store in accumulator(s)\n            x_block_res_acc_23739 = zz_23388;\n        }\n    }\n    \n  error_0:\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_failure)\n        return;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    ((__local int64_t *) red_arr_i64_mem_23734)[sext_i32_i64(local_tid_23730)] = x_block_res_acc_23739;\n    barrier(CLK_LOCAL_MEM_F", "ENCE);\n    skip_waves_23748 = 1;\n    offset_23747 = 0;\n    // participating threads read initial accumulator\n    if (slt32(local_tid_23730, sext_i64_i32(segred_tblock_sizze_23371))) {\n        x_23740 = ((__local int64_t *) red_arr_i64_mem_23734)[sext_i32_i64(local_tid_23730 + offset_23747)];\n    }\n    offset_23747 = 1;\n    while (slt32(offset_23747, wave_sizze_23732)) {\n        if (slt32(local_tid_23730 + offset_23747, sext_i64_i32(segred_tblock_sizze_23371)) && ((local_tid_23730 - squot32(local_tid_23730, wave_sizze_23732) * wave_sizze_23732) & (2 * offset_23747 - 1)) == 0) {\n            int64_t zz_23742;\n            \n            // read array element\n            y_23741 = ((volatile __local int64_t *) red_arr_i64_mem_23734)[sext_i32_i64(local_tid_23730 + offset_23747)];\n            // apply reduction operation\n            zz_23742 = smax64(x_23740, y_23741);\n            x_23740 = zz_23742;\n            // write result of operation\n            ((volatile __local int64_t *) red_arr_i64_mem_23734)[sext_i32_i64(local_tid_23730)] = x_23740;\n        }\n        offset_23747 *= 2;\n    }\n    while (slt32(skip_waves_23748, squot32(sext_i64_i32(segred_tblock_sizze_23371) + wave_sizze_23732 - 1, wave_sizze_23732))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_23747 = skip_waves_23748 * wave_sizze_23732;\n        if (slt32(local_tid_23730 + offset_23747, sext_i64_i32(segred_tblock_sizze_23371)) && ((local_tid_23730 - squot32(local_tid_23730, wave_sizze_23732) * wave_sizze_23732) == 0 && (squot32(local_tid_23730, wave_sizze_23732) & (2 * skip_waves_23748 - 1)) == 0)) {\n            int64_t zz_23742;\n            \n            // read array element\n            y_23741 = ((__local int64_t *) red_arr_i64_mem_23734)[sext_i32_i64(local_tid_23730 + offset_23747)];\n            // apply reduction operation\n            zz_23742 = smax64(x_23740, y_23741);\n            x_23740 = zz_23742;\n            // write result of operation\n            ((__local int64_t *) red_arr_i64_mem_23734)[", "sext_i32_i64(local_tid_23730)] = x_23740;\n        }\n        skip_waves_23748 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    if (sext_i32_i64(local_tid_23730) == (int64_t) 0) {\n        x_block_res_acc_23739 = x_23740;\n    } else {\n        x_block_res_acc_23739 = (int64_t) 0;\n    }\n    // first thread in block saves block result to global memory\n    if (local_tid_23730 == 0) {\n        ((__global int64_t *) segred_tmp_mem_23726)[sext_i32_i64(block_id_23731)] = x_block_res_acc_23739;\n        mem_fence_global();\n        old_counter_23749 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23724)[(int64_t) 0], 1);\n        ((__local bool *) sync_arr_mem_23736)[(int64_t) 0] = old_counter_23749 == sext_i64_i32(segred_num_tblocks_23369 - (int64_t) 1);\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_23750 = ((__local bool *) sync_arr_mem_23736)[(int64_t) 0];\n    if (is_last_block_23750) {\n        int64_t read_per_thread_23751;\n        int32_t offset_23755;\n        int32_t skip_waves_23756;\n        int64_t x_23740;\n        int64_t y_23741;\n        \n        if (local_tid_23730 == 0) {\n            old_counter_23749 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23724)[(int64_t) 0], sext_i64_i32((int64_t) 0 - segred_num_tblocks_23369));\n        }\n        // read in the per-block-results\n        read_per_thread_23751 = sdiv_up64(segred_num_tblocks_23369, segred_tblock_sizze_23371);\n        x_23386 = (int64_t) 0;\n        for (int64_t i_23752 = 0; i_23752 < read_per_thread_23751; i_23752++) {\n            int64_t block_res_id_23753;\n            int64_t index_of_block_res_23754;\n            \n            block_res_id_23753 = sext_i32_i64(local_tid_23730) * read_per_thread_23751 + i_23752;\n            index_of_block_res_23754 = block_res_id_23753;\n            if (slt64(block_res_id_23753, segred_num_tblocks_23369)) {\n             ",
                                    "   int64_t zz_23388;\n                \n                y_23387 = ((__global int64_t *) segred_tmp_mem_23726)[index_of_block_res_23754];\n                zz_23388 = smax64(x_23386, y_23387);\n                x_23386 = zz_23388;\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_23734)[sext_i32_i64(local_tid_23730)] = x_23386;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        skip_waves_23756 = 1;\n        offset_23755 = 0;\n        // participating threads read initial accumulator\n        if (slt32(local_tid_23730, sext_i64_i32(segred_tblock_sizze_23371))) {\n            x_23740 = ((__local int64_t *) red_arr_i64_mem_23734)[sext_i32_i64(local_tid_23730 + offset_23755)];\n        }\n        offset_23755 = 1;\n        while (slt32(offset_23755, wave_sizze_23732)) {\n            if (slt32(local_tid_23730 + offset_23755, sext_i64_i32(segred_tblock_sizze_23371)) && ((local_tid_23730 - squot32(local_tid_23730, wave_sizze_23732) * wave_sizze_23732) & (2 * offset_23755 - 1)) == 0) {\n                int64_t zz_23742;\n                \n                // read array element\n                y_23741 = ((volatile __local int64_t *) red_arr_i64_mem_23734)[sext_i32_i64(local_tid_23730 + offset_23755)];\n                // apply reduction operation\n                zz_23742 = smax64(x_23740, y_23741);\n                x_23740 = zz_23742;\n                // write result of operation\n                ((volatile __local int64_t *) red_arr_i64_mem_23734)[sext_i32_i64(local_tid_23730)] = x_23740;\n            }\n            offset_23755 *= 2;\n        }\n        while (slt32(skip_waves_23756, squot32(sext_i64_i32(segred_tblock_sizze_23371) + wave_sizze_23732 - 1, wave_sizze_23732))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_23755 = skip_waves_23756 * wave_sizze_23732;\n            if (slt32(local_tid_23730 + offset_23755, sext_i64_i32(segred_tblock_sizze_23371)) && ((local_tid_23730 - squot32(local_tid_23730, wave_sizze_23732) * wave_", "sizze_23732) == 0 && (squot32(local_tid_23730, wave_sizze_23732) & (2 * skip_waves_23756 - 1)) == 0)) {\n                int64_t zz_23742;\n                \n                // read array element\n                y_23741 = ((__local int64_t *) red_arr_i64_mem_23734)[sext_i32_i64(local_tid_23730 + offset_23755)];\n                // apply reduction operation\n                zz_23742 = smax64(x_23740, y_23741);\n                x_23740 = zz_23742;\n                // write result of operation\n                ((__local int64_t *) red_arr_i64_mem_23734)[sext_i32_i64(local_tid_23730)] = x_23740;\n            }\n            skip_waves_23756 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // and back to memory with the final result\n        if (local_tid_23730 == 0) {\n            ((__global int64_t *) mem_23393)[(int64_t) 0] = x_23740;\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_num_tblocks_23369\n    #undef segred_tblock_sizze_23371\n    #undef chunk_sizze_23723\n}\nFUTHARK_KERNEL_SIZED(mainzisegred_nonseg_23424_dim1, 1, 1)\nvoid mainzisegred_nonseg_23424(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t m_21071, int64_t num_threads_24082, __global unsigned char *mem_23126, __global unsigned char *mem_23440, __global unsigned char *counters_mem_24078, __global unsigned char *segred_tmp_mem_24080)\n{\n    #define segred_num_tblocks_23415 (mainzisegred_nonseg_23424zisegred_num_tblocks_23415)\n    #define segred_tblock_sizze_23417 (mainzisegred_nonseg_23424zisegred_tblock_sizze_23417)\n    #define chunk_sizze_24077 (mainzisegred_nonseg_23424zichunk_sizze_24077)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local unsigned char *sync_arr_mem_24090_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_24090_backing", "_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_24088_backing_0 = &shared_mem[sync_arr_mem_24090_backing_1_offset];\n    const int64_t red_arr_i64_mem_24088_backing_0_offset = sync_arr_mem_24090_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_23417 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_23417, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24084;\n    int32_t tblock_sizze_24087;\n    int32_t wave_sizze_24086;\n    int32_t block_id_24085;\n    int32_t global_tid_24083;\n    int64_t phys_tid_23424;\n    __local unsigned char *red_arr_i64_mem_24088;\n    __local unsigned char *sync_arr_mem_24090;\n    int64_t dummy_23422;\n    int64_t gtid_23423;\n    int64_t q_24092;\n    int64_t x_block_res_acc_24093;\n    int64_t x_23433;\n    int64_t y_23434;\n    int64_t tblock_id_in_segment_24097;\n    int64_t block_base_offset_24098;\n    int32_t offset_24101;\n    int32_t skip_waves_24102;\n    int64_t x_24094;\n    int64_t y_24095;\n    int32_t old_counter_24103;\n    bool is_last_block_24104;\n    \n    local_tid_24084 = get_local_id(0);\n    tblock_sizze_24087 = get_local_size(0);\n    wave_sizze_24086 = LOCKSTEP_WIDTH;\n    block_id_24085 = get_tblock_id(0);\n    global_tid_24083 = block_id_24085 * tblock_sizze_24087 + local_tid_24084;\n    phys_tid_23424 = sext_i32_i64(global_tid_24083);\n    red_arr_i64_mem_24088 = (__local unsigned char *) red_arr_i64_mem_24088_backing_0;\n    sync_arr_mem_24090 = (__local unsigned char *) sync_arr_mem_24090_backing_1;\n    dummy_23422 = (int64_t) 0;\n    gtid_23423 = (int64_t) 0;\n    q_24092 = sdiv_up64(m_21071, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_23417 * segred_num_tblocks_23415)) * chunk_sizze_24077);\n    // ne-initialise the outer (per-block) accumulator(s)\n    x_blo",
                                    "ck_res_acc_24093 = (int64_t) 0;\n    tblock_id_in_segment_24097 = squot64(phys_tid_23424, segred_tblock_sizze_23417);\n    block_base_offset_24098 = tblock_id_in_segment_24097 * q_24092 * segred_tblock_sizze_23417;\n    for (int64_t i_24099 = 0; i_24099 < q_24092; i_24099++) {\n        int64_t block_offset_24100 = block_base_offset_24098 + i_24099 * segred_tblock_sizze_23417;\n        \n        gtid_23423 = phys_tid_23424 + num_threads_24082 * i_24099;\n        if (slt64(gtid_23423, m_21071)) {\n            int64_t eta_p_23426;\n            int64_t rowsum_arg2_23427;\n            bool x_23428;\n            bool y_23429;\n            bool bounds_check_23430;\n            bool index_certs_23431;\n            int64_t bytes_23432;\n            int64_t zz_23435;\n            \n            // apply map function(s)\n            // apply map function\n            eta_p_23426 = ((__global int64_t *) mem_23126)[gtid_23423];\n            // definitions.fut:133:64-67\n            rowsum_arg2_23427 = add64(num_qubits_14547, eta_p_23426);\n            // definitions.fut:25:43-52\n            x_23428 = sle64((int64_t) 0, rowsum_arg2_23427);\n            // definitions.fut:25:43-52\n            y_23429 = slt64(rowsum_arg2_23427, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            // definitions.fut:25:43-52\n            bounds_check_23430 = x_23428 && y_23429;\n            // definitions.fut:25:43-52\n            if (!bounds_check_23430) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 16) == -1) {\n                        global_failure_args[0] = (int64_t) rowsum_arg2_23427;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            // definitions.fut:25:17-29:98\n            bytes_23432 = (int64_t) 2 * num_qubits_1454", "7;\n            // load accumulator(s)\n            x_23433 = x_block_res_acc_24093;\n            // load next value(s)\n            y_23434 = bytes_23432;\n            // apply reduction operator(s)\n            zz_23435 = smax64(x_23433, y_23434);\n            // store in accumulator(s)\n            x_block_res_acc_24093 = zz_23435;\n        }\n    }\n    \n  error_0:\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_failure)\n        return;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    ((__local int64_t *) red_arr_i64_mem_24088)[sext_i32_i64(local_tid_24084)] = x_block_res_acc_24093;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_24102 = 1;\n    offset_24101 = 0;\n    // participating threads read initial accumulator\n    if (slt32(local_tid_24084, sext_i64_i32(segred_tblock_sizze_23417))) {\n        x_24094 = ((__local int64_t *) red_arr_i64_mem_24088)[sext_i32_i64(local_tid_24084 + offset_24101)];\n    }\n    offset_24101 = 1;\n    while (slt32(offset_24101, wave_sizze_24086)) {\n        if (slt32(local_tid_24084 + offset_24101, sext_i64_i32(segred_tblock_sizze_23417)) && ((local_tid_24084 - squot32(local_tid_24084, wave_sizze_24086) * wave_sizze_24086) & (2 * offset_24101 - 1)) == 0) {\n            int64_t zz_24096;\n            \n            // read array element\n            y_24095 = ((volatile __local int64_t *) red_arr_i64_mem_24088)[sext_i32_i64(local_tid_24084 + offset_24101)];\n            // apply reduction operation\n            zz_24096 = smax64(x_24094, y_24095);\n            x_24094 = zz_24096;\n            // write result of operation\n            ((volatile __local int64_t *) red_arr_i64_mem_24088)[sext_i32_i64(local_tid_24084)] = x_24094;\n        }\n        offset_24101 *= 2;\n    }\n    while (slt32(skip_waves_24102, squot32(sext_i64_i32(segred_tblock_sizze_23417) + wave_sizze_24086 - 1, wave_sizze_24086))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_24101 = skip_waves_24102 * wave_sizze_24086;\n     ", "   if (slt32(local_tid_24084 + offset_24101, sext_i64_i32(segred_tblock_sizze_23417)) && ((local_tid_24084 - squot32(local_tid_24084, wave_sizze_24086) * wave_sizze_24086) == 0 && (squot32(local_tid_24084, wave_sizze_24086) & (2 * skip_waves_24102 - 1)) == 0)) {\n            int64_t zz_24096;\n            \n            // read array element\n            y_24095 = ((__local int64_t *) red_arr_i64_mem_24088)[sext_i32_i64(local_tid_24084 + offset_24101)];\n            // apply reduction operation\n            zz_24096 = smax64(x_24094, y_24095);\n            x_24094 = zz_24096;\n            // write result of operation\n            ((__local int64_t *) red_arr_i64_mem_24088)[sext_i32_i64(local_tid_24084)] = x_24094;\n        }\n        skip_waves_24102 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    if (sext_i32_i64(local_tid_24084) == (int64_t) 0) {\n        x_block_res_acc_24093 = x_24094;\n    } else {\n        x_block_res_acc_24093 = (int64_t) 0;\n    }\n    // first thread in block saves block result to global memory\n    if (local_tid_24084 == 0) {\n        ((__global int64_t *) segred_tmp_mem_24080)[sext_i32_i64(block_id_24085)] = x_block_res_acc_24093;\n        mem_fence_global();\n        old_counter_24103 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24078)[(int64_t) 0], 1);\n        ((__local bool *) sync_arr_mem_24090)[(int64_t) 0] = old_counter_24103 == sext_i64_i32(segred_num_tblocks_23415 - (int64_t) 1);\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_24104 = ((__local bool *) sync_arr_mem_24090)[(int64_t) 0];\n    if (is_last_block_24104) {\n        int64_t read_per_thread_24105;\n        int32_t offset_24109;\n        int32_t skip_waves_24110;\n        int64_t x_24094;\n        int64_t y_24095;\n        \n        if (local_tid_24084 == 0) {\n            old_counter_24103 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24",
                                    "078)[(int64_t) 0], sext_i64_i32((int64_t) 0 - segred_num_tblocks_23415));\n        }\n        // read in the per-block-results\n        read_per_thread_24105 = sdiv_up64(segred_num_tblocks_23415, segred_tblock_sizze_23417);\n        x_23433 = (int64_t) 0;\n        for (int64_t i_24106 = 0; i_24106 < read_per_thread_24105; i_24106++) {\n            int64_t block_res_id_24107;\n            int64_t index_of_block_res_24108;\n            \n            block_res_id_24107 = sext_i32_i64(local_tid_24084) * read_per_thread_24105 + i_24106;\n            index_of_block_res_24108 = block_res_id_24107;\n            if (slt64(block_res_id_24107, segred_num_tblocks_23415)) {\n                int64_t zz_23435;\n                \n                y_23434 = ((__global int64_t *) segred_tmp_mem_24080)[index_of_block_res_24108];\n                zz_23435 = smax64(x_23433, y_23434);\n                x_23433 = zz_23435;\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_24088)[sext_i32_i64(local_tid_24084)] = x_23433;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        skip_waves_24110 = 1;\n        offset_24109 = 0;\n        // participating threads read initial accumulator\n        if (slt32(local_tid_24084, sext_i64_i32(segred_tblock_sizze_23417))) {\n            x_24094 = ((__local int64_t *) red_arr_i64_mem_24088)[sext_i32_i64(local_tid_24084 + offset_24109)];\n        }\n        offset_24109 = 1;\n        while (slt32(offset_24109, wave_sizze_24086)) {\n            if (slt32(local_tid_24084 + offset_24109, sext_i64_i32(segred_tblock_sizze_23417)) && ((local_tid_24084 - squot32(local_tid_24084, wave_sizze_24086) * wave_sizze_24086) & (2 * offset_24109 - 1)) == 0) {\n                int64_t zz_24096;\n                \n                // read array element\n                y_24095 = ((volatile __local int64_t *) red_arr_i64_mem_24088)[sext_i32_i64(local_tid_24084 + offset_24109)];\n                // apply reduction operation\n                zz_24096 = smax64(x", "_24094, y_24095);\n                x_24094 = zz_24096;\n                // write result of operation\n                ((volatile __local int64_t *) red_arr_i64_mem_24088)[sext_i32_i64(local_tid_24084)] = x_24094;\n            }\n            offset_24109 *= 2;\n        }\n        while (slt32(skip_waves_24110, squot32(sext_i64_i32(segred_tblock_sizze_23417) + wave_sizze_24086 - 1, wave_sizze_24086))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_24109 = skip_waves_24110 * wave_sizze_24086;\n            if (slt32(local_tid_24084 + offset_24109, sext_i64_i32(segred_tblock_sizze_23417)) && ((local_tid_24084 - squot32(local_tid_24084, wave_sizze_24086) * wave_sizze_24086) == 0 && (squot32(local_tid_24084, wave_sizze_24086) & (2 * skip_waves_24110 - 1)) == 0)) {\n                int64_t zz_24096;\n                \n                // read array element\n                y_24095 = ((__local int64_t *) red_arr_i64_mem_24088)[sext_i32_i64(local_tid_24084 + offset_24109)];\n                // apply reduction operation\n                zz_24096 = smax64(x_24094, y_24095);\n                x_24094 = zz_24096;\n                // write result of operation\n                ((__local int64_t *) red_arr_i64_mem_24088)[sext_i32_i64(local_tid_24084)] = x_24094;\n            }\n            skip_waves_24110 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // and back to memory with the final result\n        if (local_tid_24084 == 0) {\n            ((__global int64_t *) mem_23440)[(int64_t) 0] = x_24094;\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_num_tblocks_23415\n    #undef segred_tblock_sizze_23417\n    #undef chunk_sizze_24077\n}\nFUTHARK_KERNEL_SIZED(mainzisegred_small_21836_dim1, 1, 1)\nvoid mainzisegred_small_21836(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, int64_t m_20840", ", int64_t num_tblocks_21830, int64_t segment_sizze_nonzzero_23787, __global unsigned char *mem_23052, __global unsigned char *mem_23211, __global unsigned char *mem_23223, __global unsigned char *mem_23226, __global unsigned char *mem_23235, __global unsigned char *mem_23237)\n{\n    #define segred_tblock_sizze_21829 (mainzisegred_small_21836zisegred_tblock_sizze_21829)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local unsigned char *red_arr_i8_mem_23794_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i8_mem_23794_backing_0_offset = 0 + (segred_tblock_sizze_21829 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_21829, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_23790;\n    int32_t tblock_sizze_23793;\n    int32_t wave_sizze_23792;\n    int32_t block_id_23791;\n    int32_t global_tid_23789;\n    int64_t phys_tid_21836;\n    __local unsigned char *red_arr_i8_mem_23794;\n    int32_t phys_tblock_id_23796;\n    int32_t iterations_23797;\n    \n    local_tid_23790 = get_local_id(0);\n    tblock_sizze_23793 = get_local_size(0);\n    wave_sizze_23792 = LOCKSTEP_WIDTH;\n    block_id_23791 = get_tblock_id(0);\n    global_tid_23789 = block_id_23791 * tblock_sizze_23793 + local_tid_23790;\n    phys_tid_21836 = sext_i32_i64(global_tid_23789);\n    red_arr_i8_mem_23794 = (__local unsigned char *) red_arr_i8_mem_23794_backing_0;\n    phys_tblock_id_23796 = get_tblock_id(0);\n    iterations_23797 = sdiv_up32(sext_i64_i32(sdiv_up64(m_20840, squot64(segred_tblock_sizze_21829, segment_sizze_nonzzero_23787))) - phys_tblock_id_23796, sext_i64_i32(num_tblocks_21830));\n    for (int32_t i_23798 = 0; i_23798 < iterations_23797; i_23798++) {\n        int32_t virt_tblock_id_23799;\n        int64_t slice_238",
                                    "00;\n        int64_t gtid_21834;\n        int64_t remnant_23801;\n        int64_t gtid_21835;\n        \n        virt_tblock_id_23799 = phys_tblock_id_23796 + i_23798 * sext_i64_i32(num_tblocks_21830);\n        slice_23800 = m_20840;\n        gtid_21834 = squot64(sext_i32_i64(local_tid_23790), segment_sizze_nonzzero_23787) + sext_i32_i64(virt_tblock_id_23799) * squot64(segred_tblock_sizze_21829, segment_sizze_nonzzero_23787);\n        remnant_23801 = squot64(sext_i32_i64(local_tid_23790), segment_sizze_nonzzero_23787) + sext_i32_i64(virt_tblock_id_23799) * squot64(segred_tblock_sizze_21829, segment_sizze_nonzzero_23787) - gtid_21834;\n        gtid_21835 = srem64(sext_i32_i64(local_tid_23790), num_qubits_14547);\n        // apply map function if in bounds\n        if (slt64((int64_t) 0, num_qubits_14547) && (slt64(gtid_21834, m_20840) && slt64(sext_i32_i64(local_tid_23790), num_qubits_14547 * squot64(segred_tblock_sizze_21829, segment_sizze_nonzzero_23787)))) {\n            bool index_certs_21838;\n            int64_t g_arg3_21840;\n            bool x_21841;\n            bool y_21842;\n            bool bounds_check_21843;\n            bool index_certs_21844;\n            bool y_21847;\n            bool index_certs_21849;\n            int64_t defunc_0_f_res_22860;\n            int64_t eta_p_21837;\n            int8_t g_arg3_21845;\n            int8_t g_arg2_21850;\n            int8_t g_arg1_21851;\n            int8_t g_arg0_21852;\n            bool cond_21853;\n            bool cond_t_res_21854;\n            bool x_21855;\n            int8_t g_res_21856;\n            int8_t tmp_21873;\n            int8_t tmp_21874;\n            int8_t mem_23231[(int64_t) 2];\n            \n            // apply map function\n            index_certs_21838 = 0;\n            // definitions.fut:25:85-88\n            g_arg3_21840 = add64(num_qubits_14547, gtid_21835);\n            // definitions.fut:25:73-89\n            x_21841 = sle64((int64_t) 0, g_arg3_21840);\n            // definitions.fut:25:73-89\n            y_21842 = slt", "64(g_arg3_21840, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            // definitions.fut:25:73-89\n            bounds_check_21843 = x_21841 && y_21842;\n            // definitions.fut:25:73-89\n            if (!bounds_check_21843) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 11) == -1) {\n                        global_failure_args[0] = (int64_t) g_arg3_21840;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            // definitions.fut:25:60-72\n            y_21847 = slt64(gtid_21835, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            // definitions.fut:25:60-72\n            if (!y_21847) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 12) == -1) {\n                        global_failure_args[0] = (int64_t) gtid_21835;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            defunc_0_f_res_22860 = ((__global int64_t *) mem_23211)[(int64_t) 0];\n            eta_p_21837 = ((__global int64_t *) mem_23223)[gtid_21834];\n            // definitions.fut:25:17-98\n            g_arg3_21845 = ((__global int8_t *) mem_23052)[eta_p_21837 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + g_arg3_21840];\n            // definitions.fut:25:17-98\n            g_arg2_21850 = ((__global int8_t *) mem_23052)[eta_p_21837 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_21835];\n            // definitions.fut:25:17-98\n            g_arg1_21851 = ((__global int8_t *) mem", "_23052)[defunc_0_f_res_22860 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + g_arg3_21840];\n            // definitions.fut:25:17-98\n            g_arg0_21852 = ((__global int8_t *) mem_23052)[defunc_0_f_res_22860 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_21835];\n            // definitions.fut:12:3-20:9\n            cond_21853 = g_arg0_21852 == g_arg2_21850;\n            // definitions.fut:12:21-25\n            cond_t_res_21854 = g_arg0_21852 == (int8_t) 0;\n            // definitions.fut:25:28-89\n            x_21855 = cond_21853 && cond_t_res_21854;\n            // definitions.fut:12:3-20:9\n            if (x_21855) {\n                g_res_21856 = (int8_t) 0;\n            } else {\n                bool cond_t_res_21857;\n                bool x_21858;\n                int8_t g_res_f_res_21859;\n                \n                // definitions.fut:14:26-30\n                cond_t_res_21857 = g_arg0_21852 == (int8_t) 1;\n                // definitions.fut:25:28-89\n                x_21858 = cond_21853 && cond_t_res_21857;\n                // definitions.fut:14:8-20:9\n                if (x_21858) {\n                    int8_t g_res_f_res_t_res_21860;\n                    \n                    // definitions.fut:15:11-15\n                    g_res_f_res_t_res_21860 = sub8(g_arg3_21845, g_arg1_21851);\n                    g_res_f_res_21859 = g_res_f_res_t_res_21860;\n                } else {\n                    bool cond_t_res_21861;\n                    bool x_21862;\n                    int8_t g_res_f_res_f_res_21863;\n                    \n                    // definitions.fut:16:25-29\n                    cond_t_res_21861 = g_arg2_21850 == (int8_t) 0;\n                    // definitions.fut:25:28-89\n                    x_21862 = cond_t_res_21857 && cond_t_res_21861;\n                    // definitions.fut:16:8-20:9\n                    if (x_21862) {\n                        int8_t zm_lhs_21864;\n                        int8_t zt_rhs_21865;\n        ",
                                    "                int8_t g_res_f_res_f_res_t_res_21866;\n                        \n                        // definitions.fut:17:16-20\n                        zm_lhs_21864 = mul8((int8_t) 2, g_arg1_21851);\n                        // definitions.fut:17:21-24\n                        zt_rhs_21865 = sub8(zm_lhs_21864, (int8_t) 1);\n                        // definitions.fut:17:11-24\n                        g_res_f_res_f_res_t_res_21866 = mul8(g_arg3_21845, zt_rhs_21865);\n                        g_res_f_res_f_res_21863 = g_res_f_res_f_res_t_res_21866;\n                    } else {\n                        bool cond_t_res_21867;\n                        bool x_21868;\n                        int8_t g_res_f_res_f_res_f_res_21869;\n                        \n                        // definitions.fut:18:25-29\n                        cond_t_res_21867 = g_arg2_21850 == (int8_t) 1;\n                        // definitions.fut:25:28-89\n                        x_21868 = cond_t_res_21854 && cond_t_res_21867;\n                        // definitions.fut:18:8-20:9\n                        if (x_21868) {\n                            int8_t zm_rhs_21870;\n                            int8_t zt_rhs_21871;\n                            int8_t g_res_f_res_f_res_f_res_t_res_21872;\n                            \n                            // definitions.fut:19:20-24\n                            zm_rhs_21870 = mul8((int8_t) 2, g_arg3_21845);\n                            // definitions.fut:19:16-24\n                            zt_rhs_21871 = sub8((int8_t) 1, zm_rhs_21870);\n                            // definitions.fut:19:11-24\n                            g_res_f_res_f_res_f_res_t_res_21872 = mul8(g_arg1_21851, zt_rhs_21871);\n                            g_res_f_res_f_res_f_res_21869 = g_res_f_res_f_res_f_res_t_res_21872;\n                        } else {\n                            g_res_f_res_f_res_f_res_21869 = (int8_t) 0;\n                        }\n                        g_res_f_res_f_res_21863 = g_res_f_res_f_res", "_f_res_21869;\n                    }\n                    g_res_f_res_21859 = g_res_f_res_f_res_21863;\n                }\n                g_res_21856 = g_res_f_res_21859;\n            }\n            // definitions.fut:29:37-51\n            tmp_21873 = g_arg2_21850 ^ g_arg0_21852;\n            // definitions.fut:29:70-88\n            tmp_21874 = g_arg3_21845 ^ g_arg1_21851;\n            // definitions.fut:29:12-98\n            // definitions.fut:29:12-98\n            mem_23231[(int64_t) 0] = tmp_21873;\n            mem_23231[(int64_t) 1] = tmp_21874;\n            // write map-out result(s)\n            for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                ((__global int8_t *) mem_23235)[gtid_21834 * ((int64_t) 2 * num_qubits_14547) + gtid_21835 * (int64_t) 2 + i_0] = mem_23231[i_0];\n            }\n            // save results to be reduced\n            ((__local int8_t *) red_arr_i8_mem_23794)[sext_i32_i64(local_tid_23790)] = g_res_21856;\n        } else {\n            ((__local int8_t *) red_arr_i8_mem_23794)[sext_i32_i64(local_tid_23790)] = (int8_t) 0;\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_qubits_14547)) {\n            int8_t eta_p_21876;\n            int8_t eta_p_21877;\n            int8_t eta_p_23802;\n            int8_t eta_p_23803;\n            bool ltid_in_bounds_23805;\n            int32_t skip_threads_23806;\n            int32_t skip_threads_23809;\n            bool no_carry_in_23812;\n            bool inactive_23813;\n            \n            // perform segmented scan to imitate reduction\n            ltid_in_bounds_23805 = slt64(sext_i32_i64(local_tid_23790), num_qubits_14547 * squot64(segred_tblock_sizze_21829, segment_sizze_nonzzero_23787));\n            // read input for in-block scan\n            if (ltid_in_bounds_23805) {\n                eta_p_21877 = ((volatile __local int8_t *) red_arr_i8_mem_23794)[sext_i32_i64(loca", "l_tid_23790)];\n                if ((local_tid_23790 - squot32(local_tid_23790, 32) * 32) == 0) {\n                    eta_p_21876 = eta_p_21877;\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            skip_threads_23806 = 1;\n            while (slt32(skip_threads_23806, 32)) {\n                bool thread_active_23807;\n                bool inactive_23808;\n                \n                thread_active_23807 = sle32(skip_threads_23806, local_tid_23790 - squot32(local_tid_23790, 32) * 32) && ltid_in_bounds_23805;\n                if (thread_active_23807) {\n                    // read operands\n                    eta_p_21876 = ((volatile __local int8_t *) red_arr_i8_mem_23794)[sext_i32_i64(local_tid_23790) - sext_i32_i64(skip_threads_23806)];\n                }\n                // perform operation\n                inactive_23808 = slt64(srem64(sext_i32_i64(local_tid_23790), num_qubits_14547), sext_i32_i64(local_tid_23790) - sext_i32_i64(local_tid_23790 - skip_threads_23806));\n                if (thread_active_23807 && inactive_23808) {\n                    eta_p_21876 = eta_p_21877;\n                }\n                if (thread_active_23807) {\n                    if (!inactive_23808) {\n                        int8_t defunc_0_op_res_21878;\n                        \n                        // definitions.fut:25:110-113\n                        defunc_0_op_res_21878 = add8(eta_p_21876, eta_p_21877);\n                        eta_p_21876 = defunc_0_op_res_21878;\n                    }\n                }\n                if (sle32(wave_sizze_23792, skip_threads_23806)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_23807) {\n                    // write result\n                    ((volatile __local int8_t *) red_arr_i8_mem_23794)[sext_i32_i64(local_tid_23790)] = eta_p_21876;\n                    eta_p_21877 = eta_p_21876;\n                }\n                if (sle32(wave_sizze_23792, skip",
                                    "_threads_23806)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_23806 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            if ((local_tid_23790 - squot32(local_tid_23790, 32) * 32) == 31 && ltid_in_bounds_23805) {\n                ((volatile __local int8_t *) red_arr_i8_mem_23794)[sext_i32_i64(squot32(local_tid_23790, 32))] = eta_p_21876;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            // read input for in-block scan\n            if (squot32(local_tid_23790, 32) == 0 && ltid_in_bounds_23805) {\n                eta_p_23803 = ((volatile __local int8_t *) red_arr_i8_mem_23794)[sext_i32_i64(local_tid_23790)];\n                if ((local_tid_23790 - squot32(local_tid_23790, 32) * 32) == 0) {\n                    eta_p_23802 = eta_p_23803;\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            skip_threads_23809 = 1;\n            while (slt32(skip_threads_23809, 32)) {\n                bool thread_active_23810;\n                bool inactive_23811;\n                \n                thread_active_23810 = sle32(skip_threads_23809, local_tid_23790 - squot32(local_tid_23790, 32) * 32) && (squot32(local_tid_23790, 32) == 0 && ltid_in_bounds_23805);\n                if (thread_active_23810) {\n                    // read operands\n                    eta_p_23802 = ((volatile __local int8_t *) red_arr_i8_mem_23794)[sext_i32_i64(local_tid_23790) - sext_i32_i64(skip_threads_23809)];\n                }\n                // perform operation\n                inactive_23811 = slt64(srem64(sext_i32_i64(local_tid_23790 * 32 + 32 - 1), num_qubits_14547), sext_i32_i64(local_tid_23790 * 32 + 32 - 1) - sext_i32_i64((local_tid_23790 - skip_threads_23809) * 32 + 32 - 1));\n                if (thread_active", "_23810 && inactive_23811) {\n                    eta_p_23802 = eta_p_23803;\n                }\n                if (thread_active_23810) {\n                    if (!inactive_23811) {\n                        int8_t defunc_0_op_res_23804;\n                        \n                        // definitions.fut:25:110-113\n                        defunc_0_op_res_23804 = add8(eta_p_23802, eta_p_23803);\n                        eta_p_23802 = defunc_0_op_res_23804;\n                    }\n                }\n                if (sle32(wave_sizze_23792, skip_threads_23809)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_23810) {\n                    // write result\n                    ((volatile __local int8_t *) red_arr_i8_mem_23794)[sext_i32_i64(local_tid_23790)] = eta_p_23802;\n                    eta_p_23803 = eta_p_23802;\n                }\n                if (sle32(wave_sizze_23792, skip_threads_23809)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_23809 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            no_carry_in_23812 = squot32(local_tid_23790, 32) == 0 || !ltid_in_bounds_23805;\n            // carry-in for every block except the first\n            // read operands\n            if (!no_carry_in_23812) {\n                eta_p_21877 = eta_p_21876;\n                eta_p_21876 = ((__local int8_t *) red_arr_i8_mem_23794)[sext_i32_i64(squot32(local_tid_23790, 32)) - (int64_t) 1];\n            }\n            // perform operation\n            inactive_23813 = slt64(srem64(sext_i32_i64(local_tid_23790), num_qubits_14547), sext_i32_i64(local_tid_23790) - sext_i32_i64(squot32(local_tid_23790, 32) * 32 - 1));\n            if (!no_carry_in_23812) {\n                if (inactive_23813) {\n                    eta_p_21876 = eta_p_21877;\n                }\n            }\n            if (!no_carry_in_23812) {\n                if (!inactive_23813) {\n                    int8_t defun", "c_0_op_res_21878;\n                    \n                    // definitions.fut:25:110-113\n                    defunc_0_op_res_21878 = add8(eta_p_21876, eta_p_21877);\n                    eta_p_21876 = defunc_0_op_res_21878;\n                }\n            }\n            // write final result\n            if (!no_carry_in_23812) {\n                ((__local int8_t *) red_arr_i8_mem_23794)[sext_i32_i64(local_tid_23790)] = eta_p_21876;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            if (squot32(local_tid_23790, 32) == 0 && ltid_in_bounds_23805) {\n                ((__local int8_t *) red_arr_i8_mem_23794)[sext_i32_i64(local_tid_23790)] = eta_p_21877;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        if (slt64(sext_i32_i64(virt_tblock_id_23799) * squot64(segred_tblock_sizze_21829, segment_sizze_nonzzero_23787) + sext_i32_i64(local_tid_23790), m_20840) && slt64(sext_i32_i64(local_tid_23790), squot64(segred_tblock_sizze_21829, segment_sizze_nonzzero_23787))) {\n            int8_t tmp_23814 = ((__local int8_t *) red_arr_i8_mem_23794)[(sext_i32_i64(local_tid_23790) + (int64_t) 1) * segment_sizze_nonzzero_23787 - (int64_t) 1];\n            \n            ((__global int8_t *) mem_23237)[sext_i32_i64(virt_tblock_id_23799) * squot64(segred_tblock_sizze_21829, segment_sizze_nonzzero_23787) + sext_i32_i64(local_tid_23790)] = tmp_23814;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_21829\n}\nFUTHARK_KERNEL_SIZED(mainzisegred_small_22342_dim1, 1, 1)\nvoid mainzisegred_small_22342(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_14547, int64_t arg_16658, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unu",
                                    "m_qubitsZRz20U1z7dUzg_16659, int64_t m_21071, int64_t num_tblocks_22336, int64_t segment_sizze_nonzzero_24138, __global unsigned char *mem_23052, __global unsigned char *mem_23131, __global unsigned char *mem_23132, __global unsigned char *mem_23141, __global unsigned char *mem_23143)\n{\n    #define segred_tblock_sizze_22335 (mainzisegred_small_22342zisegred_tblock_sizze_22335)\n    \n    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;\n    volatile __local unsigned char *red_arr_i8_mem_24145_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i8_mem_24145_backing_0_offset = 0 + (segred_tblock_sizze_22335 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22335, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24141;\n    int32_t tblock_sizze_24144;\n    int32_t wave_sizze_24143;\n    int32_t block_id_24142;\n    int32_t global_tid_24140;\n    int64_t phys_tid_22342;\n    __local unsigned char *red_arr_i8_mem_24145;\n    int32_t phys_tblock_id_24147;\n    int32_t iterations_24148;\n    \n    local_tid_24141 = get_local_id(0);\n    tblock_sizze_24144 = get_local_size(0);\n    wave_sizze_24143 = LOCKSTEP_WIDTH;\n    block_id_24142 = get_tblock_id(0);\n    global_tid_24140 = block_id_24142 * tblock_sizze_24144 + local_tid_24141;\n    phys_tid_22342 = sext_i32_i64(global_tid_24140);\n    red_arr_i8_mem_24145 = (__local unsigned char *) red_arr_i8_mem_24145_backing_0;\n    phys_tblock_id_24147 = get_tblock_id(0);\n    iterations_24148 = sdiv_up32(sext_i64_i32(sdiv_up64(m_21071, squot64(segred_tblock_sizze_22335, segment_sizze_nonzzero_24138))) - phys_tblock_id_24147, sext_i64_i32(num_tblocks_22336));\n    for (int32_t i_24149 = 0; i_24149 < iterations_24148; i_24149++) {\n        int32_t virt_tblock_id_24150;\n        int64_t ", "slice_24151;\n        int64_t gtid_22340;\n        int64_t remnant_24152;\n        int64_t gtid_22341;\n        \n        virt_tblock_id_24150 = phys_tblock_id_24147 + i_24149 * sext_i64_i32(num_tblocks_22336);\n        slice_24151 = m_21071;\n        gtid_22340 = squot64(sext_i32_i64(local_tid_24141), segment_sizze_nonzzero_24138) + sext_i32_i64(virt_tblock_id_24150) * squot64(segred_tblock_sizze_22335, segment_sizze_nonzzero_24138);\n        remnant_24152 = squot64(sext_i32_i64(local_tid_24141), segment_sizze_nonzzero_24138) + sext_i32_i64(virt_tblock_id_24150) * squot64(segred_tblock_sizze_22335, segment_sizze_nonzzero_24138) - gtid_22340;\n        gtid_22341 = srem64(sext_i32_i64(local_tid_24141), num_qubits_14547);\n        // apply map function if in bounds\n        if (slt64((int64_t) 0, num_qubits_14547) && (slt64(gtid_22340, m_21071) && slt64(sext_i32_i64(local_tid_24141), num_qubits_14547 * squot64(segred_tblock_sizze_22335, segment_sizze_nonzzero_24138)))) {\n            bool index_certs_22344;\n            int64_t g_arg3_22346;\n            bool x_22347;\n            bool y_22348;\n            bool bounds_check_22349;\n            bool index_certs_22350;\n            bool y_22353;\n            bool index_certs_22355;\n            int64_t rowsum_arg2_22343;\n            int8_t g_arg3_22351;\n            int8_t g_arg2_22356;\n            int8_t g_arg1_22357;\n            int8_t g_arg0_22358;\n            bool cond_22359;\n            bool cond_t_res_22360;\n            bool x_22361;\n            int8_t g_res_22362;\n            int8_t tmp_22379;\n            int8_t tmp_22380;\n            int8_t mem_23137[(int64_t) 2];\n            \n            // apply map function\n            index_certs_22344 = 0;\n            // definitions.fut:25:85-88\n            g_arg3_22346 = add64(num_qubits_14547, gtid_22341);\n            // definitions.fut:25:73-89\n            x_22347 = sle64((int64_t) 0, g_arg3_22346);\n            // definitions.fut:25:73-89\n            y_22348 = slt64(g_arg3_22346, dzlz7bUZLz", "pZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            // definitions.fut:25:73-89\n            bounds_check_22349 = x_22347 && y_22348;\n            // definitions.fut:25:73-89\n            if (!bounds_check_22349) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 21) == -1) {\n                        global_failure_args[0] = (int64_t) g_arg3_22346;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            // definitions.fut:25:60-72\n            y_22353 = slt64(gtid_22341, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);\n            // definitions.fut:25:60-72\n            if (!y_22353) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 22) == -1) {\n                        global_failure_args[0] = (int64_t) gtid_22341;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            rowsum_arg2_22343 = ((__global int64_t *) mem_23131)[gtid_22340];\n            // definitions.fut:25:17-98\n            g_arg3_22351 = ((__global int8_t *) mem_23052)[arg_16658 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + g_arg3_22346];\n            // definitions.fut:25:17-98\n            g_arg2_22356 = ((__global int8_t *) mem_23052)[arg_16658 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_22341];\n            // definitions.fut:25:17-98\n            g_arg1_22357 = ((__global int8_t *) mem_23052)[rowsum_arg2_22343 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + g_arg3_22346]",
                                    ";\n            // definitions.fut:25:17-98\n            g_arg0_22358 = ((__global int8_t *) mem_23052)[rowsum_arg2_22343 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 + gtid_22341];\n            // definitions.fut:12:3-20:9\n            cond_22359 = g_arg0_22358 == g_arg2_22356;\n            // definitions.fut:12:21-25\n            cond_t_res_22360 = g_arg0_22358 == (int8_t) 0;\n            // definitions.fut:25:28-89\n            x_22361 = cond_22359 && cond_t_res_22360;\n            // definitions.fut:12:3-20:9\n            if (x_22361) {\n                g_res_22362 = (int8_t) 0;\n            } else {\n                bool cond_t_res_22363;\n                bool x_22364;\n                int8_t g_res_f_res_22365;\n                \n                // definitions.fut:14:26-30\n                cond_t_res_22363 = g_arg0_22358 == (int8_t) 1;\n                // definitions.fut:25:28-89\n                x_22364 = cond_22359 && cond_t_res_22363;\n                // definitions.fut:14:8-20:9\n                if (x_22364) {\n                    int8_t g_res_f_res_t_res_22366;\n                    \n                    // definitions.fut:15:11-15\n                    g_res_f_res_t_res_22366 = sub8(g_arg3_22351, g_arg1_22357);\n                    g_res_f_res_22365 = g_res_f_res_t_res_22366;\n                } else {\n                    bool cond_t_res_22367;\n                    bool x_22368;\n                    int8_t g_res_f_res_f_res_22369;\n                    \n                    // definitions.fut:16:25-29\n                    cond_t_res_22367 = g_arg2_22356 == (int8_t) 0;\n                    // definitions.fut:25:28-89\n                    x_22368 = cond_t_res_22363 && cond_t_res_22367;\n                    // definitions.fut:16:8-20:9\n                    if (x_22368) {\n                        int8_t zm_lhs_22370;\n                        int8_t zt_rhs_22371;\n                        int8_t g_res_f_res_f_res_t_res_22372;\n                        \n                        // definit", "ions.fut:17:16-20\n                        zm_lhs_22370 = mul8((int8_t) 2, g_arg1_22357);\n                        // definitions.fut:17:21-24\n                        zt_rhs_22371 = sub8(zm_lhs_22370, (int8_t) 1);\n                        // definitions.fut:17:11-24\n                        g_res_f_res_f_res_t_res_22372 = mul8(g_arg3_22351, zt_rhs_22371);\n                        g_res_f_res_f_res_22369 = g_res_f_res_f_res_t_res_22372;\n                    } else {\n                        bool cond_t_res_22373;\n                        bool x_22374;\n                        int8_t g_res_f_res_f_res_f_res_22375;\n                        \n                        // definitions.fut:18:25-29\n                        cond_t_res_22373 = g_arg2_22356 == (int8_t) 1;\n                        // definitions.fut:25:28-89\n                        x_22374 = cond_t_res_22360 && cond_t_res_22373;\n                        // definitions.fut:18:8-20:9\n                        if (x_22374) {\n                            int8_t zm_rhs_22376;\n                            int8_t zt_rhs_22377;\n                            int8_t g_res_f_res_f_res_f_res_t_res_22378;\n                            \n                            // definitions.fut:19:20-24\n                            zm_rhs_22376 = mul8((int8_t) 2, g_arg3_22351);\n                            // definitions.fut:19:16-24\n                            zt_rhs_22377 = sub8((int8_t) 1, zm_rhs_22376);\n                            // definitions.fut:19:11-24\n                            g_res_f_res_f_res_f_res_t_res_22378 = mul8(g_arg1_22357, zt_rhs_22377);\n                            g_res_f_res_f_res_f_res_22375 = g_res_f_res_f_res_f_res_t_res_22378;\n                        } else {\n                            g_res_f_res_f_res_f_res_22375 = (int8_t) 0;\n                        }\n                        g_res_f_res_f_res_22369 = g_res_f_res_f_res_f_res_22375;\n                    }\n                    g_res_f_res_22365 = g_res_f_res_f_res_22369;\n            ", "    }\n                g_res_22362 = g_res_f_res_22365;\n            }\n            // definitions.fut:29:37-51\n            tmp_22379 = g_arg2_22356 ^ g_arg0_22358;\n            // definitions.fut:29:70-88\n            tmp_22380 = g_arg3_22351 ^ g_arg1_22357;\n            // definitions.fut:29:12-98\n            // definitions.fut:29:12-98\n            mem_23137[(int64_t) 0] = tmp_22379;\n            mem_23137[(int64_t) 1] = tmp_22380;\n            // write map-out result(s)\n            for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                ((__global int8_t *) mem_23141)[gtid_22340 * ((int64_t) 2 * num_qubits_14547) + gtid_22341 * (int64_t) 2 + i_0] = mem_23137[i_0];\n            }\n            // save results to be reduced\n            ((__local int8_t *) red_arr_i8_mem_24145)[sext_i32_i64(local_tid_24141)] = g_res_22362;\n        } else {\n            ((__local int8_t *) red_arr_i8_mem_24145)[sext_i32_i64(local_tid_24141)] = (int8_t) 0;\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_qubits_14547)) {\n            int8_t eta_p_22382;\n            int8_t eta_p_22383;\n            int8_t eta_p_24153;\n            int8_t eta_p_24154;\n            bool ltid_in_bounds_24156;\n            int32_t skip_threads_24157;\n            int32_t skip_threads_24160;\n            bool no_carry_in_24163;\n            bool inactive_24164;\n            \n            // perform segmented scan to imitate reduction\n            ltid_in_bounds_24156 = slt64(sext_i32_i64(local_tid_24141), num_qubits_14547 * squot64(segred_tblock_sizze_22335, segment_sizze_nonzzero_24138));\n            // read input for in-block scan\n            if (ltid_in_bounds_24156) {\n                eta_p_22383 = ((volatile __local int8_t *) red_arr_i8_mem_24145)[sext_i32_i64(local_tid_24141)];\n                if ((local_tid_24141 - squot32(local_tid_24141, 32) * 32) == 0) {\n                ",
                                    "    eta_p_22382 = eta_p_22383;\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            skip_threads_24157 = 1;\n            while (slt32(skip_threads_24157, 32)) {\n                bool thread_active_24158;\n                bool inactive_24159;\n                \n                thread_active_24158 = sle32(skip_threads_24157, local_tid_24141 - squot32(local_tid_24141, 32) * 32) && ltid_in_bounds_24156;\n                if (thread_active_24158) {\n                    // read operands\n                    eta_p_22382 = ((volatile __local int8_t *) red_arr_i8_mem_24145)[sext_i32_i64(local_tid_24141) - sext_i32_i64(skip_threads_24157)];\n                }\n                // perform operation\n                inactive_24159 = slt64(srem64(sext_i32_i64(local_tid_24141), num_qubits_14547), sext_i32_i64(local_tid_24141) - sext_i32_i64(local_tid_24141 - skip_threads_24157));\n                if (thread_active_24158 && inactive_24159) {\n                    eta_p_22382 = eta_p_22383;\n                }\n                if (thread_active_24158) {\n                    if (!inactive_24159) {\n                        int8_t defunc_0_op_res_22384;\n                        \n                        // definitions.fut:25:110-113\n                        defunc_0_op_res_22384 = add8(eta_p_22382, eta_p_22383);\n                        eta_p_22382 = defunc_0_op_res_22384;\n                    }\n                }\n                if (sle32(wave_sizze_24143, skip_threads_24157)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_24158) {\n                    // write result\n                    ((volatile __local int8_t *) red_arr_i8_mem_24145)[sext_i32_i64(local_tid_24141)] = eta_p_22382;\n                    eta_p_22383 = eta_p_22382;\n                }\n                if (sle32(wave_sizze_24143, skip_threads_24157)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threa", "ds_24157 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            if ((local_tid_24141 - squot32(local_tid_24141, 32) * 32) == 31 && ltid_in_bounds_24156) {\n                ((volatile __local int8_t *) red_arr_i8_mem_24145)[sext_i32_i64(squot32(local_tid_24141, 32))] = eta_p_22382;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            // read input for in-block scan\n            if (squot32(local_tid_24141, 32) == 0 && ltid_in_bounds_24156) {\n                eta_p_24154 = ((volatile __local int8_t *) red_arr_i8_mem_24145)[sext_i32_i64(local_tid_24141)];\n                if ((local_tid_24141 - squot32(local_tid_24141, 32) * 32) == 0) {\n                    eta_p_24153 = eta_p_24154;\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            skip_threads_24160 = 1;\n            while (slt32(skip_threads_24160, 32)) {\n                bool thread_active_24161;\n                bool inactive_24162;\n                \n                thread_active_24161 = sle32(skip_threads_24160, local_tid_24141 - squot32(local_tid_24141, 32) * 32) && (squot32(local_tid_24141, 32) == 0 && ltid_in_bounds_24156);\n                if (thread_active_24161) {\n                    // read operands\n                    eta_p_24153 = ((volatile __local int8_t *) red_arr_i8_mem_24145)[sext_i32_i64(local_tid_24141) - sext_i32_i64(skip_threads_24160)];\n                }\n                // perform operation\n                inactive_24162 = slt64(srem64(sext_i32_i64(local_tid_24141 * 32 + 32 - 1), num_qubits_14547), sext_i32_i64(local_tid_24141 * 32 + 32 - 1) - sext_i32_i64((local_tid_24141 - skip_threads_24160) * 32 + 32 - 1));\n                if (thread_active_24161 && inactive_24162) {\n                    eta_p_24153 = eta_p_24154;\n                }\n                if (", "thread_active_24161) {\n                    if (!inactive_24162) {\n                        int8_t defunc_0_op_res_24155;\n                        \n                        // definitions.fut:25:110-113\n                        defunc_0_op_res_24155 = add8(eta_p_24153, eta_p_24154);\n                        eta_p_24153 = defunc_0_op_res_24155;\n                    }\n                }\n                if (sle32(wave_sizze_24143, skip_threads_24160)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_24161) {\n                    // write result\n                    ((volatile __local int8_t *) red_arr_i8_mem_24145)[sext_i32_i64(local_tid_24141)] = eta_p_24153;\n                    eta_p_24154 = eta_p_24153;\n                }\n                if (sle32(wave_sizze_24143, skip_threads_24160)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_24160 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            no_carry_in_24163 = squot32(local_tid_24141, 32) == 0 || !ltid_in_bounds_24156;\n            // carry-in for every block except the first\n            // read operands\n            if (!no_carry_in_24163) {\n                eta_p_22383 = eta_p_22382;\n                eta_p_22382 = ((__local int8_t *) red_arr_i8_mem_24145)[sext_i32_i64(squot32(local_tid_24141, 32)) - (int64_t) 1];\n            }\n            // perform operation\n            inactive_24164 = slt64(srem64(sext_i32_i64(local_tid_24141), num_qubits_14547), sext_i32_i64(local_tid_24141) - sext_i32_i64(squot32(local_tid_24141, 32) * 32 - 1));\n            if (!no_carry_in_24163) {\n                if (inactive_24164) {\n                    eta_p_22382 = eta_p_22383;\n                }\n            }\n            if (!no_carry_in_24163) {\n                if (!inactive_24164) {\n                    int8_t defunc_0_op_res_22384;\n                    \n                    // definitions.fut:25:110-113\n                    defu", "nc_0_op_res_22384 = add8(eta_p_22382, eta_p_22383);\n                    eta_p_22382 = defunc_0_op_res_22384;\n                }\n            }\n            // write final result\n            if (!no_carry_in_24163) {\n                ((__local int8_t *) red_arr_i8_mem_24145)[sext_i32_i64(local_tid_24141)] = eta_p_22382;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            if (squot32(local_tid_24141, 32) == 0 && ltid_in_bounds_24156) {\n                ((__local int8_t *) red_arr_i8_mem_24145)[sext_i32_i64(local_tid_24141)] = eta_p_22383;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        if (slt64(sext_i32_i64(virt_tblock_id_24150) * squot64(segred_tblock_sizze_22335, segment_sizze_nonzzero_24138) + sext_i32_i64(local_tid_24141), m_21071) && slt64(sext_i32_i64(local_tid_24141), squot64(segred_tblock_sizze_22335, segment_sizze_nonzzero_24138))) {\n            int8_t tmp_24165 = ((__local int8_t *) red_arr_i8_mem_24145)[(sext_i32_i64(local_tid_24141) + (int64_t) 1) * segment_sizze_nonzzero_24138 - (int64_t) 1];\n            \n            ((__global int8_t *) mem_23143)[sext_i32_i64(virt_tblock_id_24150) * squot64(segred_tblock_sizze_22335, segment_sizze_nonzzero_24138) + sext_i32_i64(local_tid_24141)] = tmp_24165;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_22335\n}\n", NULL};
// Start of gpu_prototypes.h

// Constants used for transpositions.  In principle these should be configurable.
#define TR_BLOCK_DIM 16
#define TR_TILE_DIM (TR_BLOCK_DIM*2)
#define TR_ELEMS_PER_THREAD 8

// Config stuff included in every GPU backend.
struct gpu_config {
  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_cache;
  size_t default_shared_memory;
  size_t default_registers;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

// The following are dummy sizes that mean the concrete defaults
// will be set during initialisation via hardware-inspection-based
// heuristics.
struct gpu_config gpu_config_initial = {
  0
};

// Must be defined by the user.
static int gpu_macros(struct futhark_context *ctx, char*** names, int64_t** values);

static void gpu_init_log(struct futhark_context *ctx);
struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);
static int gpu_free_all(struct futhark_context *ctx);

// End of gpu_prototypes.h

// Start of backends/opencl.h

// Note [32-bit transpositions]
//
// Transposition kernels are much slower when they have to use 64-bit
// arithmetic.  I observed about 0.67x slowdown on an A100 GPU when
// transposing four-byte elements (much less when transposing 8-byte
// elements).  Unfortunately, 64-bit arithmetic is a requirement for
// large arrays (see #1953 for what happens otherwise).  We generate
// both 32- and 64-bit index arithmetic versions of transpositions,
// and dynamically pick between them at runtime.  This is an
// unfortunate code bloat, and it would be preferable if we could
// simply optimise the 64-bit version to make this distinction
// unnecessary.  Fortunately these kernels are quite small.

// Forward declarations.
struct opencl_device_option;
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void post_opencl_setup(struct futhark_context*, struct opencl_device_option*);
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define OPENCL_SUCCEED_FATAL(e) opencl_succeed_fatal(e, #e, __FILE__, __LINE__)
#define OPENCL_SUCCEED_NONFATAL(e) opencl_succeed_nonfatal(e, #e, __FILE__, __LINE__)
// Take care not to override an existing error.
#define OPENCL_SUCCEED_OR_RETURN(e) {           \
    char *serror = OPENCL_SUCCEED_NONFATAL(e);  \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
      } else {                                  \
        free(serror);                           \
      }                                         \
      return bad;                               \
    }                                           \
  }

// OPENCL_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static const char* opencl_error_string(cl_int err) {
  switch (err) {
  case CL_SUCCESS:                            return "Success!";
  case CL_DEVICE_NOT_FOUND:                   return "Device not found.";
  case CL_DEVICE_NOT_AVAILABLE:               return "Device not available";
  case CL_COMPILER_NOT_AVAILABLE:             return "Compiler not available";
  case CL_MEM_OBJECT_ALLOCATION_FAILURE:      return "Memory object allocation failure";
  case CL_OUT_OF_RESOURCES:                   return "Out of resources";
  case CL_OUT_OF_HOST_MEMORY:                 return "Out of host memory";
  case CL_PROFILING_INFO_NOT_AVAILABLE:       return "Profiling information not available";
  case CL_MEM_COPY_OVERLAP:                   return "Memory copy overlap";
  case CL_IMAGE_FORMAT_MISMATCH:              return "Image format mismatch";
  case CL_IMAGE_FORMAT_NOT_SUPPORTED:         return "Image format not supported";
  case CL_BUILD_PROGRAM_FAILURE:              return "Program build failure";
  case CL_MAP_FAILURE:                        return "Map failure";
  case CL_INVALID_VALUE:                      return "Invalid value";
  case CL_INVALID_DEVICE_TYPE:                return "Invalid device type";
  case CL_INVALID_PLATFORM:                   return "Invalid platform";
  case CL_INVALID_DEVICE:                     return "Invalid device";
  case CL_INVALID_CONTEXT:                    return "Invalid context";
  case CL_INVALID_QUEUE_PROPERTIES:           return "Invalid queue properties";
  case CL_INVALID_COMMAND_QUEUE:              return "Invalid command queue";
  case CL_INVALID_HOST_PTR:                   return "Invalid host pointer";
  case CL_INVALID_MEM_OBJECT:                 return "Invalid memory object";
  case CL_INVALID_IMAGE_FORMAT_DESCRIPTOR:    return "Invalid image format descriptor";
  case CL_INVALID_IMAGE_SIZE:                 return "Invalid image size";
  case CL_INVALID_SAMPLER:                    return "Invalid sampler";
  case CL_INVALID_BINARY:                     return "Invalid binary";
  case CL_INVALID_BUILD_OPTIONS:              return "Invalid build options";
  case CL_INVALID_PROGRAM:                    return "Invalid program";
  case CL_INVALID_PROGRAM_EXECUTABLE:         return "Invalid program executable";
  case CL_INVALID_KERNEL_NAME:                return "Invalid kernel name";
  case CL_INVALID_KERNEL_DEFINITION:          return "Invalid kernel definition";
  case CL_INVALID_KERNEL:                     return "Invalid kernel";
  case CL_INVALID_ARG_INDEX:                  return "Invalid argument index";
  case CL_INVALID_ARG_VALUE:                  return "Invalid argument value";
  case CL_INVALID_ARG_SIZE:                   return "Invalid argument size";
  case CL_INVALID_KERNEL_ARGS:                return "Invalid kernel arguments";
  case CL_INVALID_WORK_DIMENSION:             return "Invalid work dimension";
  case CL_INVALID_WORK_GROUP_SIZE:            return "Invalid work group size";
  case CL_INVALID_WORK_ITEM_SIZE:             return "Invalid work item size";
  case CL_INVALID_GLOBAL_OFFSET:              return "Invalid global offset";
  case CL_INVALID_EVENT_WAIT_LIST:            return "Invalid event wait list";
  case CL_INVALID_EVENT:                      return "Invalid event";
  case CL_INVALID_OPERATION:                  return "Invalid operation";
  case CL_INVALID_GL_OBJECT:                  return "Invalid OpenGL object";
  case CL_INVALID_BUFFER_SIZE:                return "Invalid buffer size";
  case CL_INVALID_MIP_LEVEL:                  return "Invalid mip-map level";
  default:                                    return "Unknown";
  }
}

static void opencl_succeed_fatal(cl_int ret,
                                 const char *call,
                                 const char *file,
                                 int line) {
  if (ret != CL_SUCCESS) {
    futhark_panic(-1, "%s:%d: OpenCL call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, ret, opencl_error_string(ret));
  }
}

static char* opencl_succeed_nonfatal(cl_int ret,
                                     const char *call,
                                     const char *file,
                                     int line) {
  if (ret != CL_SUCCESS) {
    return msgprintf("%s:%d: OpenCL call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, ret, opencl_error_string(ret));
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  char *cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  char* program;
  int preferred_device_num;
  char* preferred_platform;
  char* preferred_device;
  int ignore_blacklist;

  int unified_memory;

  char* dump_binary_to;
  char* load_binary_from;

  int num_build_opts;
  char* *build_opts;

  cl_command_queue queue;
  int queue_set;

  struct gpu_config gpu;
};

static void backend_context_config_setup(struct futhark_context_config* cfg) {
  cfg->num_build_opts = 0;
  cfg->build_opts = (char**) malloc(sizeof(const char*));
  cfg->build_opts[0] = NULL;
  cfg->preferred_device_num = 0;
  cfg->preferred_platform = strdup("");
  cfg->preferred_device = strdup("");
  cfg->ignore_blacklist = 0;
  cfg->dump_binary_to = NULL;
  cfg->load_binary_from = NULL;
  cfg->program = strconcat(gpu_program);

  cfg->unified_memory = 2;

  cfg->gpu = gpu_config_initial;

  cfg->queue_set = 0;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  for (int i = 0; i < cfg->num_build_opts; i++) {
    free(cfg->build_opts[i]);
  }
  free(cfg->build_opts);
  free(cfg->dump_binary_to);
  free(cfg->load_binary_from);
  free(cfg->preferred_device);
  free(cfg->preferred_platform);
  free(cfg->program);
}

void futhark_context_config_add_build_option(struct futhark_context_config* cfg, const char *opt) {
  cfg->build_opts[cfg->num_build_opts] = strdup(opt);
  cfg->num_build_opts++;
  cfg->build_opts = (char**) realloc(cfg->build_opts, (cfg->num_build_opts+1) * sizeof(char*));
  cfg->build_opts[cfg->num_build_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char* s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  free(cfg->preferred_device);
  cfg->preferred_device = strdup(s);
  cfg->preferred_device_num = x;
  cfg->ignore_blacklist = 1;
}

void futhark_context_config_set_platform(struct futhark_context_config *cfg, const char *s) {
  free(cfg->preferred_platform);
  cfg->preferred_platform = strdup(s);
  cfg->ignore_blacklist = 1;
}

void futhark_context_config_set_command_queue(struct futhark_context_config *cfg, cl_command_queue q) {
  cfg->queue = q;
  cfg->queue_set = 1;
}

struct opencl_device_option {
  cl_platform_id platform;
  cl_device_id device;
  cl_device_type device_type;
  char *platform_name;
  char *device_name;
};

static char* opencl_platform_info(cl_platform_id platform,
                                  cl_platform_info param) {
  size_t req_bytes;
  char *info;

  OPENCL_SUCCEED_FATAL(clGetPlatformInfo(platform, param, 0, NULL, &req_bytes));

  info = (char*) malloc(req_bytes);

  OPENCL_SUCCEED_FATAL(clGetPlatformInfo(platform, param, req_bytes, info, NULL));

  return info;
}

static char* opencl_device_info(cl_device_id device,
                                cl_device_info param) {
  size_t req_bytes;
  char *info;

  OPENCL_SUCCEED_FATAL(clGetDeviceInfo(device, param, 0, NULL, &req_bytes));

  info = (char*) malloc(req_bytes);

  OPENCL_SUCCEED_FATAL(clGetDeviceInfo(device, param, req_bytes, info, NULL));

  return info;
}

static int is_blacklisted(const char *platform_name, const char *device_name,
                          const struct futhark_context_config *cfg) {
  if (strcmp(cfg->preferred_platform, "") != 0 ||
      strcmp(cfg->preferred_device, "") != 0) {
    return 0;
  } else if (strstr(platform_name, "Apple") != NULL &&
             strstr(device_name, "Intel(R) Core(TM)") != NULL) {
    return 1;
  } else {
    return 0;
  }
}

static void opencl_all_device_options(struct opencl_device_option **devices_out,
                                      size_t *num_devices_out) {
  size_t num_devices = 0, num_devices_added = 0;

  cl_platform_id *all_platforms;
  cl_uint *platform_num_devices;

  cl_uint num_platforms;

  // Find the number of platforms.
  OPENCL_SUCCEED_FATAL(clGetPlatformIDs(0, NULL, &num_platforms));

  // Make room for them.
  all_platforms = calloc(num_platforms, sizeof(cl_platform_id));
  platform_num_devices = calloc(num_platforms, sizeof(cl_uint));

  // Fetch all the platforms.
  OPENCL_SUCCEED_FATAL(clGetPlatformIDs(num_platforms, all_platforms, NULL));

  // Count the number of devices for each platform, as well as the
  // total number of devices.
  for (cl_uint i = 0; i < num_platforms; i++) {
    if (clGetDeviceIDs(all_platforms[i], CL_DEVICE_TYPE_ALL,
                       0, NULL, &platform_num_devices[i]) == CL_SUCCESS) {
      num_devices += platform_num_devices[i];
    } else {
      platform_num_devices[i] = 0;
    }
  }

  // Make room for all the device options.
  struct opencl_device_option *devices =
    calloc(num_devices, sizeof(struct opencl_device_option));

  // Loop through the platforms, getting information about their devices.
  for (cl_uint i = 0; i < num_platforms; i++) {
    cl_platform_id platform = all_platforms[i];
    cl_uint num_platform_devices = platform_num_devices[i];

    if (num_platform_devices == 0) {
      continue;
    }

    char *platform_name = opencl_platform_info(platform, CL_PLATFORM_NAME);
    cl_device_id *platform_devices =
      calloc(num_platform_devices, sizeof(cl_device_id));

    // Fetch all the devices.
    OPENCL_SUCCEED_FATAL(clGetDeviceIDs(platform, CL_DEVICE_TYPE_ALL,
                                        num_platform_devices, platform_devices, NULL));

    // Loop through the devices, adding them to the devices array.
    for (cl_uint i = 0; i < num_platform_devices; i++) {
      char *device_name = opencl_device_info(platform_devices[i], CL_DEVICE_NAME);
      devices[num_devices_added].platform = platform;
      devices[num_devices_added].device = platform_devices[i];
      OPENCL_SUCCEED_FATAL(clGetDeviceInfo(platform_devices[i], CL_DEVICE_TYPE,
                                           sizeof(cl_device_type),
                                           &devices[num_devices_added].device_type,
                                           NULL));
      // We don't want the structs to share memory, so copy the platform name.
      // Each device name is already unique.
      devices[num_devices_added].platform_name = strclone(platform_name);
      devices[num_devices_added].device_name = device_name;
      num_devices_added++;
    }
    free(platform_devices);
    free(platform_name);
  }
  free(all_platforms);
  free(platform_num_devices);

  *devices_out = devices;
  *num_devices_out = num_devices;
}

void futhark_context_config_select_device_interactively(struct futhark_context_config *cfg) {
  struct opencl_device_option *devices;
  size_t num_devices;

  opencl_all_device_options(&devices, &num_devices);

  printf("Choose OpenCL device:\n");
  const char *cur_platform = "";
  for (size_t i = 0; i < num_devices; i++) {
    struct opencl_device_option device = devices[i];
    if (strcmp(cur_platform, device.platform_name) != 0) {
      printf("Platform: %s\n", device.platform_name);
      cur_platform = device.platform_name;
    }
    printf("[%d] %s\n", (int)i, device.device_name);
  }

  int selection;
  printf("Choice: ");
  if (scanf("%d", &selection) == 1) {
    cfg->preferred_platform = "";
    cfg->preferred_device = "";
    cfg->preferred_device_num = selection;
    cfg->ignore_blacklist = 1;
  }

  // Free all the platform and device names.
  for (size_t j = 0; j < num_devices; j++) {
    free(devices[j].platform_name);
    free(devices[j].device_name);
  }
  free(devices);
}

void futhark_context_config_list_devices(struct futhark_context_config *cfg) {
  (void)cfg;
  struct opencl_device_option *devices;
  size_t num_devices;

  opencl_all_device_options(&devices, &num_devices);

  const char *cur_platform = "";
  for (size_t i = 0; i < num_devices; i++) {
    struct opencl_device_option device = devices[i];
    if (strcmp(cur_platform, device.platform_name) != 0) {
      printf("Platform: %s\n", device.platform_name);
      cur_platform = device.platform_name;
    }
    printf("[%d]: %s\n", (int)i, device.device_name);
  }

  // Free all the platform and device names.
  for (size_t j = 0; j < num_devices; j++) {
    free(devices[j].platform_name);
    free(devices[j].device_name);
  }
  free(devices);
}

const char* futhark_context_config_get_program(struct futhark_context_config *cfg) {
  return cfg->program;
}

void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s) {
  free(cfg->program);
  cfg->program = strdup(s);
}

void futhark_context_config_dump_binary_to(struct futhark_context_config *cfg, const char *path) {
  free(cfg->dump_binary_to);
  cfg->dump_binary_to = strdup(path);
}

void futhark_context_config_load_binary_from(struct futhark_context_config *cfg, const char *path) {
  free(cfg->load_binary_from);
  cfg->load_binary_from = strdup(path);
}

void futhark_context_config_set_unified_memory(struct futhark_context_config* cfg, int flag) {
  cfg->unified_memory = flag;
}

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list free_list;
  struct event_list event_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  struct program* program;
  bool program_initialised;
  // Uniform fields above.

  cl_mem global_failure;
  cl_mem global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  cl_int failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;

  cl_device_id device;
  cl_context ctx;
  cl_command_queue queue;
  cl_program clprogram;

  struct free_list gpu_free_list;

  size_t max_thread_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;
  size_t max_registers;
  size_t max_cache;

  size_t lockstep_width;

  struct builtin_kernels* kernels;
};

static cl_build_status build_gpu_program(cl_program program, cl_device_id device, const char* options, char** log) {
  cl_int clBuildProgram_error = clBuildProgram(program, 1, &device, options, NULL, NULL);

  // Avoid termination due to CL_BUILD_PROGRAM_FAILURE
  if (clBuildProgram_error != CL_SUCCESS &&
      clBuildProgram_error != CL_BUILD_PROGRAM_FAILURE) {
    OPENCL_SUCCEED_FATAL(clBuildProgram_error);
  }

  cl_build_status build_status;
  OPENCL_SUCCEED_FATAL(clGetProgramBuildInfo(program,
                                             device,
                                             CL_PROGRAM_BUILD_STATUS,
                                             sizeof(cl_build_status),
                                             &build_status,
                                             NULL));

  if (build_status != CL_BUILD_SUCCESS) {
    char *build_log;
    size_t ret_val_size;
    OPENCL_SUCCEED_FATAL(clGetProgramBuildInfo(program, device, CL_PROGRAM_BUILD_LOG, 0, NULL, &ret_val_size));

    build_log = (char*) malloc(ret_val_size+1);
    OPENCL_SUCCEED_FATAL(clGetProgramBuildInfo(program, device, CL_PROGRAM_BUILD_LOG, ret_val_size, build_log, NULL));

    // The spec technically does not say whether the build log is
    // zero-terminated, so let's be careful.
    build_log[ret_val_size] = '\0';
    *log = build_log;
  }

  return build_status;
}

static char* mk_compile_opts(struct futhark_context *ctx,
                             const char *extra_build_opts[],
                             struct opencl_device_option device_option) {
  int compile_opts_size = 1024;

  for (int i = 0; i < ctx->cfg->num_tuning_params; i++) {
    compile_opts_size += strlen(ctx->cfg->tuning_param_names[i]) + 20;
  }

  char** macro_names;
  int64_t* macro_vals;
  int num_macros = gpu_macros(ctx, &macro_names, &macro_vals);

  for (int i = 0; extra_build_opts[i] != NULL; i++) {
    compile_opts_size += strlen(extra_build_opts[i] + 1);
  }

  for (int i = 0; i < num_macros; i++) {
    compile_opts_size += strlen(macro_names[i]) + 1 + 20;
  }

  char *compile_opts = (char*) malloc(compile_opts_size);

  int w = snprintf(compile_opts, compile_opts_size,
                   "-DLOCKSTEP_WIDTH=%d ",
                   (int)ctx->lockstep_width);

  w += snprintf(compile_opts+w, compile_opts_size-w,
                "-D%s=%d ",
                "max_thread_block_size",
                (int)ctx->max_thread_block_size);

  w += snprintf(compile_opts+w, compile_opts_size-w,
                "-D%s=%d ",
                "max_shared_memory",
                (int)ctx->max_shared_memory);

  w += snprintf(compile_opts+w, compile_opts_size-w,
                "-D%s=%d ",
                "max_registers",
                (int)ctx->max_registers);

  for (int i = 0; i < ctx->cfg->num_tuning_params; i++) {
    w += snprintf(compile_opts+w, compile_opts_size-w,
                  "-D%s=%d ",
                  ctx->cfg->tuning_param_vars[i],
                  (int)ctx->cfg->tuning_params[i]);
  }

  for (int i = 0; extra_build_opts[i] != NULL; i++) {
    w += snprintf(compile_opts+w, compile_opts_size-w,
                  "%s ", extra_build_opts[i]);
  }

  for (int i = 0; i < num_macros; i++) {
    w += snprintf(compile_opts+w, compile_opts_size-w,
                  "-D%s=%zu ", macro_names[i], macro_vals[i]);
  }

  w += snprintf(compile_opts+w, compile_opts_size-w,
                "-DTR_BLOCK_DIM=%d -DTR_TILE_DIM=%d -DTR_ELEMS_PER_THREAD=%d ",
                TR_BLOCK_DIM, TR_TILE_DIM, TR_ELEMS_PER_THREAD);

  // Oclgrind claims to support cl_khr_fp16, but this is not actually
  // the case.
  if (strcmp(device_option.platform_name, "Oclgrind") == 0) {
    w += snprintf(compile_opts+w, compile_opts_size-w, "-DEMULATE_F16 ");
  }

  // By default, OpenCL allows imprecise (but faster) division and
  // square root operations. For equivalence with other backends, ask
  // for correctly rounded ones here.
  w += snprintf(compile_opts+w, compile_opts_size-w,
                "-cl-fp32-correctly-rounded-divide-sqrt");

  free(macro_names);
  free(macro_vals);

  return compile_opts;
}

static cl_event* opencl_event_new(struct futhark_context* ctx) {
  if (ctx->profiling && !ctx->profiling_paused) {
    return malloc(sizeof(cl_event));
  } else {
    return NULL;
  }
}

static int opencl_event_report(struct str_builder* sb, cl_event* e) {
  cl_int err;
  cl_ulong start_t, end_t;

  assert(e != NULL);
  OPENCL_SUCCEED_FATAL(clGetEventProfilingInfo(*e,
                                               CL_PROFILING_COMMAND_START,
                                               sizeof(start_t),
                                               &start_t,
                                               NULL));
  OPENCL_SUCCEED_FATAL(clGetEventProfilingInfo(*e,
                                               CL_PROFILING_COMMAND_END,
                                               sizeof(end_t),
                                               &end_t,
                                               NULL));

  // OpenCL provides nanosecond resolution, but we want microseconds.
  str_builder(sb, ",\"duration\":%f", (end_t - start_t)/1000.0);

  OPENCL_SUCCEED_FATAL(clReleaseEvent(*e));

  free(e);

  return 0;
}

int futhark_context_sync(struct futhark_context* ctx) {
  // Check for any delayed error.
  cl_int failure_idx = -1;
  if (ctx->failure_is_an_option) {
    OPENCL_SUCCEED_OR_RETURN(
                             clEnqueueReadBuffer(ctx->queue,
                                                 ctx->global_failure,
                                                 CL_FALSE,
                                                 0, sizeof(cl_int), &failure_idx,
                                                 0, NULL, NULL));
    ctx->failure_is_an_option = 0;
  }

  OPENCL_SUCCEED_OR_RETURN(clFinish(ctx->queue));

  if (failure_idx >= 0) {
    // We have to clear global_failure so that the next entry point
    // is not considered a failure from the start.
    cl_int no_failure = -1;
    OPENCL_SUCCEED_OR_RETURN(
                             clEnqueueWriteBuffer(ctx->queue, ctx->global_failure, CL_TRUE,
                                                  0, sizeof(cl_int), &no_failure,
                                                  0, NULL, NULL));

    int64_t args[max_failure_args+1];
    OPENCL_SUCCEED_OR_RETURN(
                             clEnqueueReadBuffer(ctx->queue,
                                                 ctx->global_failure_args,
                                                 CL_TRUE,
                                                 0, sizeof(args), &args,
                                                 0, NULL, NULL));

    ctx->error = get_failure_msg(failure_idx, args);

    return FUTHARK_PROGRAM_ERROR;
  }
  return 0;
}


// We take as input several strings representing the program, because
// C does not guarantee that the compiler supports particularly large
// literals.  Notably, Visual C has a limit of 2048 characters.  The
// array must be NULL-terminated.
static void setup_opencl_with_command_queue(struct futhark_context *ctx,
                                            cl_command_queue queue,
                                            const char* extra_build_opts[],
                                            const char* cache_fname) {
  int error;

  free_list_init(&ctx->gpu_free_list);
  ctx->queue = queue;

  OPENCL_SUCCEED_FATAL(clGetCommandQueueInfo(ctx->queue, CL_QUEUE_CONTEXT, sizeof(cl_context), &ctx->ctx, NULL));

  // Fill out the device info.  This is redundant work if we are
  // called from setup_opencl() (which is the common case), but I
  // doubt it matters much.
  struct opencl_device_option device_option;
  OPENCL_SUCCEED_FATAL(clGetCommandQueueInfo(ctx->queue, CL_QUEUE_DEVICE,
                                             sizeof(cl_device_id),
                                             &device_option.device,
                                             NULL));
  OPENCL_SUCCEED_FATAL(clGetDeviceInfo(device_option.device, CL_DEVICE_PLATFORM,
                                       sizeof(cl_platform_id),
                                       &device_option.platform,
                                       NULL));
  OPENCL_SUCCEED_FATAL(clGetDeviceInfo(device_option.device, CL_DEVICE_TYPE,
                                       sizeof(cl_device_type),
                                       &device_option.device_type,
                                       NULL));
  device_option.platform_name = opencl_platform_info(device_option.platform, CL_PLATFORM_NAME);
  device_option.device_name = opencl_device_info(device_option.device, CL_DEVICE_NAME);

  ctx->device = device_option.device;

  if (f64_required) {
    cl_uint supported;
    OPENCL_SUCCEED_FATAL(clGetDeviceInfo(device_option.device, CL_DEVICE_PREFERRED_VECTOR_WIDTH_DOUBLE,
                                         sizeof(cl_uint), &supported, NULL));
    if (!supported) {
      futhark_panic(1, "Program uses double-precision floats, but this is not supported on the chosen device: %s\n",
                    device_option.device_name);
    }
  }

  bool is_amd = strstr(device_option.platform_name, "AMD") != NULL;
  bool is_nvidia = strstr(device_option.platform_name, "NVIDIA CUDA") != NULL;

  size_t max_thread_block_size;
  OPENCL_SUCCEED_FATAL(clGetDeviceInfo(device_option.device, CL_DEVICE_MAX_WORK_GROUP_SIZE,
                                       sizeof(size_t), &max_thread_block_size, NULL));

  size_t max_tile_size = sqrt(max_thread_block_size);

  cl_ulong max_shared_memory;
  OPENCL_SUCCEED_FATAL(clGetDeviceInfo(device_option.device, CL_DEVICE_LOCAL_MEM_SIZE,
                                       sizeof(size_t), &max_shared_memory, NULL));

  // Futhark reserves 4 bytes for bookkeeping information.
  max_shared_memory -= 4;

  // The OpenCL implementation may reserve some local memory bytes for
  // various purposes.  In principle, we should use
  // clGetKernelWorkGroupInfo() to figure out for each kernel how much
  // is actually available, but our current code generator design
  // makes this infeasible.  Instead, we have this nasty hack where we
  // arbitrarily subtract some bytes, based on empirical measurements
  // (but which might be arbitrarily wrong).  Fortunately, we rarely
  // try to really push the local memory usage.
  if (is_nvidia) {
    max_shared_memory -= 12;
  } else if (is_amd) {
    max_shared_memory -= 16;
  }

  // Make sure this function is defined.
  post_opencl_setup(ctx, &device_option);

  if (max_thread_block_size < ctx->cfg->gpu.default_block_size) {
    if (ctx->cfg->gpu.default_block_size_changed) {
      fprintf(stderr, "Note: Device limits default group size to %zu (down from %zu).\n",
              max_thread_block_size, ctx->cfg->gpu.default_block_size);
    }
    ctx->cfg->gpu.default_block_size = max_thread_block_size;
  }

  if (max_tile_size < ctx->cfg->gpu.default_tile_size) {
    if (ctx->cfg->gpu.default_tile_size_changed) {
      fprintf(stderr, "Note: Device limits default tile size to %zu (down from %zu).\n",
              max_tile_size, ctx->cfg->gpu.default_tile_size);
    }
    ctx->cfg->gpu.default_tile_size = max_tile_size;
  }

  // Some of the code generated by Futhark will use the L2 cache size
  // to make very precise decisions about execution. OpenCL does not
  // specify whether CL_DEVICE_GLOBAL_MEM_CACHE_SIZE is L1 or L2 cache
  // (or maybe something else entirely). NVIDIA's implementation
  // reports L2, but AMDs reports L1 (and provides no way to query for
  // the L2 size). That means it is time to hack.

  cl_ulong l2_cache_size;
  if (ctx->cfg->gpu.default_cache != 0) {
    l2_cache_size = ctx->cfg->gpu.default_cache;
  } else {
    cl_ulong opencl_cache_size;
    OPENCL_SUCCEED_FATAL(clGetDeviceInfo(device_option.device, CL_DEVICE_GLOBAL_MEM_CACHE_SIZE,
                                         sizeof(opencl_cache_size), &opencl_cache_size, NULL));

    if (is_amd) {
      // We multiply the L1 cache size with the number of compute units
      // times 4 (number of SIMD units with GCN). Empirically this
      // doesn't get us the right result, but it gets us fairly close.
      cl_ulong compute_units;
      OPENCL_SUCCEED_FATAL(clGetDeviceInfo(device_option.device, CL_DEVICE_MAX_COMPUTE_UNITS,
                                           sizeof(compute_units), &compute_units, NULL));
      l2_cache_size = opencl_cache_size * compute_units * 4;
    } else {
      l2_cache_size = opencl_cache_size;
    }

    if (l2_cache_size == 0) {
      // Some code assumes nonzero cache.
      l2_cache_size = 1024*1024;
    }
  }

  ctx->max_thread_block_size = max_thread_block_size;
  ctx->max_tile_size = max_tile_size; // No limit.
  ctx->max_threshold = ctx->max_grid_size = 1U<<31; // No limit.

  if (ctx->cfg->gpu.default_cache != 0) {
    ctx->max_cache = ctx->cfg->gpu.default_cache;
  } else {
    ctx->max_cache = l2_cache_size;
  }

  if (ctx->cfg->gpu.default_registers != 0) {
    ctx->max_registers = ctx->cfg->gpu.default_registers;
  } else {
    ctx->max_registers = 1<<16; // I cannot find a way to query for this.
  }

  if (ctx->cfg->gpu.default_shared_memory != 0) {
    ctx->max_shared_memory = ctx->cfg->gpu.default_shared_memory;
  } else {
    ctx->max_shared_memory = max_shared_memory;
  }

  // Now we go through all the sizes, clamp them to the valid range,
  // or set them to the default.
  for (int i = 0; i < ctx->cfg->num_tuning_params; i++) {
    const char *size_class = ctx->cfg->tuning_param_classes[i];
    int64_t *size_value = &ctx->cfg->tuning_params[i];
    const char* size_name = ctx->cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "thread_block_size") == size_class) {
      max_value = max_thread_block_size;
      default_value = ctx->cfg->gpu.default_block_size;
    } else if (strstr(size_class, "grid_size") == size_class) {
      max_value = max_thread_block_size; // Futhark assumes this constraint.
      default_value = ctx->cfg->gpu.default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = sqrt(max_thread_block_size);
      default_value = ctx->cfg->gpu.default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = ctx->cfg->gpu.default_reg_tile_size;
    } else if (strstr(size_class, "shared_memory") == size_class) {
      max_value = ctx->max_shared_memory;
      default_value = ctx->max_shared_memory;
    } else if (strstr(size_class, "cache") == size_class) {
      max_value = ctx->max_cache;
      default_value = ctx->max_cache;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = ctx->cfg->gpu.default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }
    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %d (down from %d)\n",
              size_name, (int)max_value, (int)*size_value);
      *size_value = max_value;
    }
  }

  if (ctx->lockstep_width == 0) {
    ctx->lockstep_width = 1;
  }

  gpu_init_log(ctx);

  char *compile_opts = mk_compile_opts(ctx, extra_build_opts, device_option);

  if (ctx->cfg->logging) {
    fprintf(stderr, "OpenCL compiler options: %s\n", compile_opts);
  }

  const char* opencl_src = ctx->cfg->program;
  cl_program prog;
  error = CL_SUCCESS;

  struct cache_hash h;

  int loaded_from_cache = 0;
  if (ctx->cfg->load_binary_from == NULL) {
    size_t src_size = 0;

    if (cache_fname != NULL) {
      if (ctx->cfg->logging) {
        fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
      }
      cache_hash_init(&h);
      cache_hash(&h, opencl_src, strlen(opencl_src));
      cache_hash(&h, compile_opts, strlen(compile_opts));

      unsigned char *buf;
      size_t bufsize;
      errno = 0;
      if (cache_restore(cache_fname, &h, &buf, &bufsize) != 0) {
        if (ctx->cfg->logging) {
          fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
        }
      } else {
        if (ctx->cfg->logging) {
          fprintf(stderr, "Cache restored; loading OpenCL binary...\n");
        }

        cl_int status = 0;
        prog = clCreateProgramWithBinary(ctx->ctx, 1, &device_option.device,
                                         &bufsize, (const unsigned char**)&buf,
                                         &status, &error);
        if (status == CL_SUCCESS) {
          loaded_from_cache = 1;
          if (ctx->cfg->logging) {
            fprintf(stderr, "Loading succeeded.\n");
          }
        } else {
          if (ctx->cfg->logging) {
            fprintf(stderr, "Loading failed.\n");
          }
        }
      }
    }

    if (!loaded_from_cache) {
      if (ctx->cfg->logging) {
        fprintf(stderr, "Creating OpenCL program...\n");
      }

      const char* src_ptr[] = {opencl_src};
      prog = clCreateProgramWithSource(ctx->ctx, 1, src_ptr, &src_size, &error);
      OPENCL_SUCCEED_FATAL(error);
    }
  } else {
    if (ctx->cfg->logging) {
      fprintf(stderr, "Loading OpenCL binary from %s...\n", ctx->cfg->load_binary_from);
    }
    size_t binary_size;
    unsigned char *fut_opencl_bin =
      (unsigned char*) slurp_file(ctx->cfg->load_binary_from, &binary_size);
    assert(fut_opencl_bin != NULL);
    const unsigned char *binaries[1] = { fut_opencl_bin };
    cl_int status = 0;

    prog = clCreateProgramWithBinary(ctx->ctx, 1, &device_option.device,
                                     &binary_size, binaries,
                                     &status, &error);

    OPENCL_SUCCEED_FATAL(status);
    OPENCL_SUCCEED_FATAL(error);
  }

  if (ctx->cfg->logging) {
    fprintf(stderr, "Building OpenCL program...\n");
  }
  char* build_log;
  cl_build_status status =
    build_gpu_program(prog, device_option.device, compile_opts, &build_log);
  free(compile_opts);

  if (status != CL_BUILD_SUCCESS) {
    ctx->error = msgprintf("Compilation of OpenCL program failed.\nBuild log:\n%s",
                           build_log);
    // We are giving up on initialising this OpenCL context. That also
    // means we need to free all the OpenCL bits we have managed to
    // allocate thus far, as futhark_context_free() will not touch
    // these unless initialisation was completely successful.
    (void)clReleaseProgram(prog);
    (void)clReleaseCommandQueue(ctx->queue);
    (void)clReleaseContext(ctx->ctx);
    free(build_log);
    return;
  }

  size_t binary_size = 0;
  unsigned char *binary = NULL;
  int store_in_cache = cache_fname != NULL && !loaded_from_cache;
  if (store_in_cache || ctx->cfg->dump_binary_to != NULL) {
    OPENCL_SUCCEED_FATAL(clGetProgramInfo(prog, CL_PROGRAM_BINARY_SIZES,
                                          sizeof(size_t), &binary_size, NULL));
    binary = (unsigned char*) malloc(binary_size);
    OPENCL_SUCCEED_FATAL(clGetProgramInfo(prog, CL_PROGRAM_BINARIES,
                                          sizeof(unsigned char*), &binary, NULL));
  }

  if (store_in_cache) {
    if (ctx->cfg->logging) {
      fprintf(stderr, "Caching OpenCL binary in %s...\n", cache_fname);
    }
    if (cache_store(cache_fname, &h, binary, binary_size) != 0) {
      printf("Failed to cache binary: %s\n", strerror(errno));
    }
  }

  if (ctx->cfg->dump_binary_to != NULL) {
    if (ctx->cfg->logging) {
      fprintf(stderr, "Dumping OpenCL binary to %s...\n", ctx->cfg->dump_binary_to);
    }
    dump_file(ctx->cfg->dump_binary_to, binary, binary_size);
  }

  ctx->clprogram = prog;
}

static struct opencl_device_option get_preferred_device(struct futhark_context *ctx,
                                                        const struct futhark_context_config *cfg) {
  struct opencl_device_option *devices;
  size_t num_devices;

  opencl_all_device_options(&devices, &num_devices);

  int num_device_matches = 0;

  for (size_t i = 0; i < num_devices; i++) {
    struct opencl_device_option device = devices[i];
    if (strstr(device.platform_name, cfg->preferred_platform) != NULL &&
        strstr(device.device_name, cfg->preferred_device) != NULL &&
        (cfg->ignore_blacklist ||
         !is_blacklisted(device.platform_name, device.device_name, cfg)) &&
        num_device_matches++ == cfg->preferred_device_num) {
      // Free all the platform and device names, except the ones we have chosen.
      for (size_t j = 0; j < num_devices; j++) {
        if (j != i) {
          free(devices[j].platform_name);
          free(devices[j].device_name);
        }
      }
      free(devices);
      return device;
    }
  }

  ctx->error = strdup("Could not find acceptable OpenCL device.\n");
  struct opencl_device_option device;
  return device;
}

static void setup_opencl(struct futhark_context *ctx,
                         const char *extra_build_opts[],
                         const char* cache_fname) {
  struct opencl_device_option device_option = get_preferred_device(ctx, ctx->cfg);

  if (ctx->error != NULL) {
    return;
  }

  if (ctx->cfg->logging) {
    fprintf(stderr, "Using platform: %s\n", device_option.platform_name);
    fprintf(stderr, "Using device: %s\n", device_option.device_name);
  }

  // Note that NVIDIA's OpenCL requires the platform property
  cl_context_properties properties[] = {
    CL_CONTEXT_PLATFORM,
    (cl_context_properties)device_option.platform,
    0
  };

  cl_int clCreateContext_error;
  ctx->ctx = clCreateContext(properties, 1, &device_option.device, NULL, NULL, &clCreateContext_error);
  OPENCL_SUCCEED_FATAL(clCreateContext_error);

  cl_int clCreateCommandQueue_error;
  cl_command_queue queue =
    clCreateCommandQueue(ctx->ctx,
                         device_option.device,
                         ctx->cfg->profiling ? CL_QUEUE_PROFILING_ENABLE : 0,
                         &clCreateCommandQueue_error);
  OPENCL_SUCCEED_FATAL(clCreateCommandQueue_error);

  setup_opencl_with_command_queue(ctx, queue, extra_build_opts, cache_fname);
}

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);

int backend_context_setup(struct futhark_context* ctx) {
  ctx->lockstep_width = 0; // Real value set later.
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;
  ctx->kernels = NULL;

  if (ctx->cfg->queue_set) {
    setup_opencl_with_command_queue(ctx, ctx->cfg->queue, (const char**)ctx->cfg->build_opts, ctx->cfg->cache_fname);
  } else {
    setup_opencl(ctx, (const char**)ctx->cfg->build_opts, ctx->cfg->cache_fname);
  }

  if (ctx->error != NULL) {
    return 1;
  }

  cl_int error;
  cl_int no_error = -1;
  ctx->global_failure =
    clCreateBuffer(ctx->ctx,
                   CL_MEM_READ_WRITE | CL_MEM_COPY_HOST_PTR,
                   sizeof(cl_int), &no_error, &error);
  OPENCL_SUCCEED_OR_RETURN(error);

  // The +1 is to avoid zero-byte allocations.
  ctx->global_failure_args =
    clCreateBuffer(ctx->ctx,
                   CL_MEM_READ_WRITE,
                   sizeof(int64_t)*(max_failure_args+1), NULL, &error);
  OPENCL_SUCCEED_OR_RETURN(error);

  if ((ctx->kernels = init_builtin_kernels(ctx)) == NULL) {
    return 1;
  }

  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx);

void backend_context_teardown(struct futhark_context* ctx) {
  if (ctx->kernels != NULL) {
    free_builtin_kernels(ctx, ctx->kernels);
    OPENCL_SUCCEED_FATAL(clReleaseMemObject(ctx->global_failure));
    OPENCL_SUCCEED_FATAL(clReleaseMemObject(ctx->global_failure_args));
    (void)gpu_free_all(ctx);
    (void)clReleaseProgram(ctx->clprogram);
    (void)clReleaseCommandQueue(ctx->queue);
    (void)clReleaseContext(ctx->ctx);
  }
  free_list_destroy(&ctx->gpu_free_list);
}

cl_command_queue futhark_context_get_command_queue(struct futhark_context* ctx) {
  return ctx->queue;
}

// GPU ABSTRACTION LAYER

// Types.

typedef cl_kernel gpu_kernel;
typedef cl_mem gpu_mem;

static void gpu_create_kernel(struct futhark_context *ctx,
                              gpu_kernel* kernel,
                              const char* name) {
  if (ctx->debugging) {
    fprintf(ctx->log, "Creating kernel %s.\n", name);
  }
  cl_int error;
  *kernel = clCreateKernel(ctx->clprogram, name, &error);
  OPENCL_SUCCEED_FATAL(error);
}

static void gpu_free_kernel(struct futhark_context *ctx,
                            gpu_kernel kernel) {
  (void)ctx;
  clReleaseKernel(kernel);
}

static int gpu_scalar_to_device(struct futhark_context* ctx,
                                const char *provenance,
                                gpu_mem dst, size_t offset, size_t size,
                                void *src) {
  cl_event* event = opencl_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_to_dev",
              provenance,
              NULL,
              event,
              (event_report_fn)opencl_event_report);
  }
  OPENCL_SUCCEED_OR_RETURN
    (clEnqueueWriteBuffer
     (ctx->queue, dst, CL_TRUE,
      offset, size, src, 0, NULL, event));
  return 0;
}

static int gpu_scalar_from_device(struct futhark_context* ctx,
                                  const char *provenance,
                                  void *dst,
                                  gpu_mem src, size_t offset, size_t size) {
  cl_event* event = opencl_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_from_dev",
              provenance,
              NULL,
              event,
              (event_report_fn)opencl_event_report);
  }
  OPENCL_SUCCEED_OR_RETURN
    (clEnqueueReadBuffer
     (ctx->queue, src, ctx->failure_is_an_option ? CL_FALSE : CL_TRUE,
      offset, size, dst, 0, NULL, event));
  return 0;
}

static int gpu_memcpy(struct futhark_context* ctx, const char *provenance,
                      gpu_mem dst, int64_t dst_offset,
                      gpu_mem src, int64_t src_offset,
                      int64_t nbytes) {
  if (nbytes > 0) {
    cl_event* event = opencl_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_dev_to_dev",
                provenance,
                NULL,
                event,
                (event_report_fn)opencl_event_report);
    }
    // OpenCL swaps the usual order of operands for memcpy()-like
    // functions.  The order below is not a typo.
    OPENCL_SUCCEED_OR_RETURN
      (clEnqueueCopyBuffer
       (ctx->queue, src, dst, src_offset, dst_offset, nbytes,
        0, NULL, event));
    if (ctx->debugging) {
      OPENCL_SUCCEED_FATAL(clFinish(ctx->queue));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_host2gpu(struct futhark_context* ctx, const char *provenance,
                           bool sync,
                           gpu_mem dst, int64_t dst_offset,
                           const unsigned char* src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    cl_event* event = opencl_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_host_to_dev",
                provenance,
                NULL,
                event,
                (event_report_fn)opencl_event_report);
    }
    OPENCL_SUCCEED_OR_RETURN
      (clEnqueueWriteBuffer(ctx->queue,
                            dst,
                            sync ? CL_TRUE : CL_FALSE,
                            (size_t)dst_offset, (size_t)nbytes,
                            src + src_offset,
                            0, NULL, event));
    if (ctx->debugging) {
      OPENCL_SUCCEED_FATAL(clFinish(ctx->queue));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_gpu2host(struct futhark_context* ctx, const char *provenance,
                           bool sync,
                           unsigned char* dst, int64_t dst_offset,
                           gpu_mem src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    cl_event* event = opencl_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_dev_to_host",
                provenance,
                NULL,
                event,
                (event_report_fn)opencl_event_report);
    }
    OPENCL_SUCCEED_OR_RETURN
      (clEnqueueReadBuffer(ctx->queue, src,
                           ctx->failure_is_an_option ? CL_FALSE
                           : sync ? CL_TRUE : CL_FALSE,
                           src_offset, nbytes,
                           dst + dst_offset,
                           0, NULL, event));
    if (sync &&
        ctx->failure_is_an_option &&
        futhark_context_sync(ctx) != 0) {
      return 1;
    }
  }
  return FUTHARK_SUCCESS;
}

static int gpu_launch_kernel(struct futhark_context* ctx,
                             gpu_kernel kernel,
                             const char *name,
                             const char *provenance,
                             const int32_t grid[3],
                             const int32_t block[3],
                             unsigned int shared_mem_bytes,
                             int num_args,
                             void* args[num_args],
                             size_t args_sizes[num_args]) {
  if (shared_mem_bytes > ctx->max_shared_memory) {
    set_error(ctx, msgprintf("Kernel %s with %d bytes of memory exceeds device limit of %d\n",
                             name, shared_mem_bytes, (int)ctx->max_shared_memory));
    return 1;
  }

  int64_t time_start = 0, time_end = 0;

  cl_event* event = opencl_event_new(ctx);
  if (event != NULL) {

    struct kvs *kvs = kvs_new();
    kvs_printf(kvs, "kernel", "\"%s\"", name);
    kvs_printf(kvs, "grid", "[%d,%d,%d]", grid[0], grid[1], grid[2]);
    kvs_printf(kvs, "block", "[%d,%d,%d]", block[0], block[1], block[2]);
    kvs_printf(kvs, "shared memory", "%d", shared_mem_bytes);

    add_event(ctx,
              name,
              provenance,
              kvs,
              event,
              (event_report_fn)opencl_event_report);
  }

  if (ctx->debugging) {
    time_start = get_wall_time();
  }

  // Some implementations do not work with 0-byte shared memory.
  if (shared_mem_bytes == 0) {
    shared_mem_bytes = 4;
  }

  OPENCL_SUCCEED_OR_RETURN
    (clSetKernelArg(kernel, 0, shared_mem_bytes, NULL));
  for (int i = 0; i < num_args; i++) {
    OPENCL_SUCCEED_OR_RETURN
      (clSetKernelArg(kernel, i+1, args_sizes[i], args[i]));
  }

  const size_t global_work_size[3] =
    {(size_t)grid[0]*block[0],
     (size_t)grid[1]*block[1],
     (size_t)grid[2]*block[2]};
  const size_t local_work_size[3] =
    {block[0],
     block[1],
     block[2]};

  OPENCL_SUCCEED_OR_RETURN
    (clEnqueueNDRangeKernel(ctx->queue,
                            kernel,
                            3, NULL, global_work_size, local_work_size,
                            0, NULL, event));

  if (ctx->debugging) {
    OPENCL_SUCCEED_FATAL(clFinish(ctx->queue));
    time_end = get_wall_time();
    long int time_diff = time_end - time_start;
    fprintf(ctx->log, "  runtime: %ldus\n", time_diff);
  }
  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return FUTHARK_SUCCESS;
}

// Allocate memory from driver. The problem is that OpenCL may perform
// lazy allocation, so we cannot know whether an allocation succeeded
// until the first time we try to use it.  Hence we immediately
// perform a write to see if the allocation succeeded.  This is slow,
// but the assumption is that this operation will be rare (most things
// will go through the free list).
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out) {
  int error;
  *mem_out = clCreateBuffer(ctx->ctx, CL_MEM_READ_WRITE, size, NULL, &error);

  OPENCL_SUCCEED_OR_RETURN(error);

  int x = 2;
  error = clEnqueueWriteBuffer(ctx->queue, *mem_out,
                               CL_TRUE,
                               0, sizeof(x), &x,
                               0, NULL, NULL);

  // No need to wait for completion here. clWaitForEvents() cannot
  // return mem object allocation failures. This implies that the
  // buffer is faulted onto the device on enqueue. (Observation by
  // Andreas Kloeckner.)

  if (error == CL_MEM_OBJECT_ALLOCATION_FAILURE) {
    return FUTHARK_OUT_OF_MEMORY;
  }
  OPENCL_SUCCEED_OR_RETURN(error);
  return FUTHARK_SUCCESS;
}

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem) {
  (void)ctx;
  OPENCL_SUCCEED_OR_RETURN(clReleaseMemObject(mem));
  return FUTHARK_SUCCESS;
}

// End of backends/opencl.h

// Start of gpu.h

// Generic functions that use our tiny GPU abstraction layer.  The
// entire context must be defined before this header is included.  In
// particular we expect the following functions to be available:

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem);
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out);
int gpu_launch_kernel(struct futhark_context* ctx,
                      gpu_kernel kernel,
                      const char *name, const char *provenance,
                      const int32_t grid[3],
                      const int32_t block[3],
                      unsigned int shared_mem_bytes,
                      int num_args,
                      void* args[num_args],
                      size_t args_sizes[num_args]);
int gpu_memcpy(struct futhark_context* ctx, const char* provenance,
               gpu_mem dst, int64_t dst_offset,
               gpu_mem src, int64_t src_offset,
               int64_t nbytes);
int gpu_scalar_from_device(struct futhark_context* ctx, const char* provenance,
                           void *dst,
                           gpu_mem src, size_t offset, size_t size);
int gpu_scalar_to_device(struct futhark_context* ctx, const char* provenance,
                         gpu_mem dst, size_t offset, size_t size,
                         void *src);
void gpu_create_kernel(struct futhark_context *ctx,
                       gpu_kernel* kernel,
                       const char* name);

static void gpu_init_log(struct futhark_context *ctx) {
  if (ctx->cfg->logging) {
    fprintf(ctx->log, "Default block size: %ld\n", (long)ctx->cfg->gpu.default_block_size);
    fprintf(ctx->log, "Default grid size: %ld\n", (long)ctx->cfg->gpu.default_grid_size);
    fprintf(ctx->log, "Default tile size: %ld\n", (long)ctx->cfg->gpu.default_tile_size);
    fprintf(ctx->log, "Default register tile size: %ld\n", (long)ctx->cfg->gpu.default_reg_tile_size);
    fprintf(ctx->log, "Default cache: %ld\n", (long)ctx->cfg->gpu.default_cache);
    fprintf(ctx->log, "Default registers: %ld\n", (long)ctx->cfg->gpu.default_registers);
    fprintf(ctx->log, "Default threshold: %ld\n", (long)ctx->cfg->gpu.default_threshold);
    fprintf(ctx->log, "Max thread block size: %ld\n", (long)ctx->max_thread_block_size);
    fprintf(ctx->log, "Max grid size: %ld\n", (long)ctx->max_grid_size);
    fprintf(ctx->log, "Max tile size: %ld\n", (long)ctx->max_tile_size);
    fprintf(ctx->log, "Max threshold: %ld\n", (long)ctx->max_threshold);
    fprintf(ctx->log, "Max shared memory: %ld\n", (long)ctx->max_shared_memory);
    fprintf(ctx->log, "Max registers: %ld\n", (long)ctx->max_registers);
    fprintf(ctx->log, "Max cache: %ld\n", (long)ctx->max_cache);
    fprintf(ctx->log, "Lockstep width: %ld\n", (long)ctx->lockstep_width);
  }
}

// Generic GPU command line options.

void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_block_size = size;
  cfg->gpu.default_block_size_changed = 1;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  futhark_context_config_set_default_thread_block_size(cfg, size);
}

void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int num) {
  cfg->gpu.default_grid_size = num;
  cfg->gpu.default_grid_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  futhark_context_config_set_default_grid_size(cfg, num);
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_tile_size = size;
  cfg->gpu.default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_reg_tile_size = size;
}

void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_cache = size;
}

void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_registers = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_thread_block_size") == 0 ||
      strcmp(param_name, "default_group_size") == 0) {
    cfg->gpu.default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_grid_size") == 0 ||
      strcmp(param_name, "default_num_groups") == 0) {
    cfg->gpu.default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->gpu.default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->gpu.default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->gpu.default_reg_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_cache") == 0) {
    cfg->gpu.default_cache = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_shared_memory") == 0) {
    cfg->gpu.default_shared_memory = new_value;
    return 0;
  }

  return 1;
}

// End of GPU command line optiopns.

// Max number of thead blocks we allow along the second or third
// dimension for transpositions.
#define MAX_TR_THREAD_BLOCKS 65535

struct builtin_kernels {
  // We have a lot of ways to transpose arrays.
  gpu_kernel map_transpose_1b;
  gpu_kernel map_transpose_1b_low_height;
  gpu_kernel map_transpose_1b_low_width;
  gpu_kernel map_transpose_1b_small;
  gpu_kernel map_transpose_1b_large;
  gpu_kernel map_transpose_2b;
  gpu_kernel map_transpose_2b_low_height;
  gpu_kernel map_transpose_2b_low_width;
  gpu_kernel map_transpose_2b_small;
  gpu_kernel map_transpose_2b_large;
  gpu_kernel map_transpose_4b;
  gpu_kernel map_transpose_4b_low_height;
  gpu_kernel map_transpose_4b_low_width;
  gpu_kernel map_transpose_4b_small;
  gpu_kernel map_transpose_4b_large;
  gpu_kernel map_transpose_8b;
  gpu_kernel map_transpose_8b_low_height;
  gpu_kernel map_transpose_8b_low_width;
  gpu_kernel map_transpose_8b_small;
  gpu_kernel map_transpose_8b_large;

  // And a few ways of copying.
  gpu_kernel lmad_copy_1b;
  gpu_kernel lmad_copy_2b;
  gpu_kernel lmad_copy_4b;
  gpu_kernel lmad_copy_8b;
};

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx) {
  struct builtin_kernels *kernels = malloc(sizeof(struct builtin_kernels));
  gpu_create_kernel(ctx, &kernels->map_transpose_1b, "map_transpose_1b");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_large, "map_transpose_1b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_height, "map_transpose_1b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_width, "map_transpose_1b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_small, "map_transpose_1b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_2b, "map_transpose_2b");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_large, "map_transpose_2b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_height, "map_transpose_2b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_width, "map_transpose_2b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_small, "map_transpose_2b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_4b, "map_transpose_4b");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_large, "map_transpose_4b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_height, "map_transpose_4b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_width, "map_transpose_4b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_small, "map_transpose_4b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_8b, "map_transpose_8b");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_large, "map_transpose_8b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_height, "map_transpose_8b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_width, "map_transpose_8b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_small, "map_transpose_8b_small");

  gpu_create_kernel(ctx, &kernels->lmad_copy_1b, "lmad_copy_1b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_2b, "lmad_copy_2b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_4b, "lmad_copy_4b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_8b, "lmad_copy_8b");

  return kernels;
}

void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels) {
  gpu_free_kernel(ctx, kernels->map_transpose_1b);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_2b);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_4b);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_8b);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_small);

  gpu_free_kernel(ctx, kernels->lmad_copy_1b);
  gpu_free_kernel(ctx, kernels->lmad_copy_2b);
  gpu_free_kernel(ctx, kernels->lmad_copy_4b);
  gpu_free_kernel(ctx, kernels->lmad_copy_8b);

  free(kernels);
}

static int gpu_alloc(struct futhark_context *ctx, FILE *log,
                     size_t min_size, const char *tag,
                     gpu_mem *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  // Round up the allocation to be at least divisible by 4, because that is
  // assumed by the code generator.
  min_size = (min_size+3) & ~3;

  gpu_mem* memptr;
  if (free_list_find(&ctx->gpu_free_list, min_size, tag, size_out, (fl_mem*)&memptr) == 0) {
    // Successfully found a free block.  Is it big enough?
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      *mem_out = *memptr;
      free(memptr);
      return FUTHARK_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }
      int error = gpu_free_actual(ctx, *memptr);
      free(memptr);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    }
  }

  *size_out = min_size;

  // We have to allocate a new block from the driver.  If the
  // allocation does not succeed, then we might be in an out-of-memory
  // situation.  We now start freeing things from the free list until
  // we think we have freed enough that the allocation will succeed.
  // Since we don't know how far the allocation is from fitting, we
  // have to check after every deallocation.  This might be pretty
  // expensive.  Let's hope that this case is hit rarely.

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  int error = gpu_alloc_actual(ctx, min_size, mem_out);

  while (error == FUTHARK_OUT_OF_MEMORY) {
    if (ctx->cfg->debugging) {
      fprintf(log, "Out of GPU memory: releasing entry from the free list...\n");
    }
    gpu_mem* memptr;
    if (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
      gpu_mem mem = *memptr;
      free(memptr);
      error = gpu_free_actual(ctx, mem);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    } else {
      break;
    }
    error = gpu_alloc_actual(ctx, min_size, mem_out);
  }

  return error;
}

static int gpu_free(struct futhark_context *ctx,
                    gpu_mem mem, size_t size, const char *tag) {
  gpu_mem* memptr = malloc(sizeof(gpu_mem));
  *memptr = mem;
  free_list_insert(&ctx->gpu_free_list, size, (fl_mem)memptr, tag);
  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx) {
  free_list_pack(&ctx->gpu_free_list);
  gpu_mem* memptr;
  while (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
    gpu_mem mem = *memptr;
    free(memptr);
    int error = gpu_free_actual(ctx, mem);
    if (error != FUTHARK_SUCCESS) {
      return error;
    }
  }

  return FUTHARK_SUCCESS;
}

static int gpu_map_transpose(struct futhark_context* ctx,
                             const char* provenance,
                             gpu_kernel kernel_default,
                             gpu_kernel kernel_low_height,
                             gpu_kernel kernel_low_width,
                             gpu_kernel kernel_small,
                             gpu_kernel kernel_large,
                             const char *name, size_t elem_size,
                             gpu_mem dst, int64_t dst_offset,
                             gpu_mem src, int64_t src_offset,
                             int64_t k, int64_t n, int64_t m) {
  int64_t mulx = TR_BLOCK_DIM / n;
  int64_t muly = TR_BLOCK_DIM / m;
  int32_t mulx32 = mulx;
  int32_t muly32 = muly;
  int32_t k32 = k;
  int32_t n32 = n;
  int32_t m32 = m;

  gpu_kernel kernel = kernel_default;
  int32_t grid[3];
  int32_t block[3];

  void* args[11];
  size_t args_sizes[11] = {
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t)
  };

  args[0] = &dst;
  args[1] = &dst_offset;
  args[2] = &src;
  args[3] = &src_offset;
  args[7] = &mulx;
  args[8] = &muly;

  if (dst_offset + k * n * m <= 2147483647L &&
      src_offset + k * n * m <= 2147483647L) {
    if (m <= TR_BLOCK_DIM/2 && n <= TR_BLOCK_DIM/2) {
      if (ctx->logging) { fprintf(ctx->log, "Using small kernel\n"); }
      kernel = kernel_small;
      grid[0] = ((k * n * m) + (TR_BLOCK_DIM*TR_BLOCK_DIM) - 1) / (TR_BLOCK_DIM*TR_BLOCK_DIM);
      grid[1] = 1;
      grid[2] = 1;
      block[0] = TR_BLOCK_DIM*TR_BLOCK_DIM;
      block[1] = 1;
      block[2] = 1;
    } else if (m <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < n) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-width kernel\n"); }
      kernel = kernel_low_width;
      int64_t x_elems = m;
      int64_t y_elems = (n + muly - 1) / muly;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else if (n <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < m) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-height kernel\n"); }
      kernel = kernel_low_height;
      int64_t x_elems = (m + mulx - 1) / mulx;
      int64_t y_elems = n;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else {
      if (ctx->logging) { fprintf(ctx->log, "Using default kernel\n"); }
      kernel = kernel_default;
      grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[2] = k;
      block[0] = TR_TILE_DIM;
      block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
      block[2] = 1;
    }
    args[4] = &k32;
    args[5] = &m32;
    args[6] = &n32;
    args[7] = &mulx32;
    args[8] = &muly32;
  } else {
    if (ctx->logging) { fprintf(ctx->log, "Using large kernel\n"); }
    kernel = kernel_large;
    grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[2] = k;
    block[0] = TR_TILE_DIM;
    block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
    block[2] = 1;
    args[4] = &k;
    args[5] = &m;
    args[6] = &n;
    args[7] = &mulx;
    args[8] = &muly;
    args_sizes[4] = sizeof(int64_t);
    args_sizes[5] = sizeof(int64_t);
    args_sizes[6] = sizeof(int64_t);
    args_sizes[7] = sizeof(int64_t);
    args_sizes[8] = sizeof(int64_t);
  }

  // Cap the number of thead blocks we launch and figure out how many
  // repeats we need alongside each dimension.
  int32_t repeat_1 = grid[1] / MAX_TR_THREAD_BLOCKS;
  int32_t repeat_2 = grid[2] / MAX_TR_THREAD_BLOCKS;
  grid[1] = repeat_1 > 0 ? MAX_TR_THREAD_BLOCKS : grid[1];
  grid[2] = repeat_2 > 0 ? MAX_TR_THREAD_BLOCKS : grid[2];
  args[9] = &repeat_1;
  args[10] = &repeat_2;
  args_sizes[9] = sizeof(repeat_1);
  args_sizes[10] = sizeof(repeat_2);

  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return gpu_launch_kernel(ctx, kernel, name, provenance, grid, block,
                           TR_TILE_DIM*(TR_TILE_DIM+1)*elem_size,
                           sizeof(args)/sizeof(args[0]), args, args_sizes);
}

#define GEN_MAP_TRANSPOSE_GPU2GPU(NAME, ELEM_TYPE)                      \
  static int map_transpose_gpu2gpu_##NAME                               \
  (struct futhark_context* ctx, const char* provenance,                 \
   gpu_mem dst, int64_t dst_offset,                                     \
   gpu_mem src, int64_t src_offset,                                     \
   int64_t k, int64_t m, int64_t n)                                     \
  {                                                                     \
    return                                                              \
      gpu_map_transpose                                                 \
      (ctx,                                                             \
       provenance,                                                      \
       ctx->kernels->map_transpose_##NAME,                              \
       ctx->kernels->map_transpose_##NAME##_low_height,                 \
       ctx->kernels->map_transpose_##NAME##_low_width,                  \
       ctx->kernels->map_transpose_##NAME##_small,                      \
       ctx->kernels->map_transpose_##NAME##_large,                      \
       "map_transpose_" #NAME, sizeof(ELEM_TYPE),                       \
       dst, dst_offset, src, src_offset,                                \
       k, n, m);                                                        \
  }

static int gpu_lmad_copy(struct futhark_context* ctx, const char* provenance,
                         gpu_kernel kernel, int r,
                         gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                         gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                         int64_t shape[r]) {
  if (r > 8) {
    set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n"));
    return 1;
  }

  int64_t n = 1;
  for (int i = 0; i < r; i++) { n *= shape[i]; }

  void* args[6+(8*3)];
  size_t args_sizes[6+(8*3)];

  args[0] = &dst;
  args_sizes[0] = sizeof(gpu_mem);
  args[1] = &dst_offset;
  args_sizes[1] = sizeof(dst_offset);
  args[2] = &src;
  args_sizes[2] = sizeof(gpu_mem);
  args[3] = &src_offset;
  args_sizes[3] = sizeof(src_offset);
  args[4] = &n;
  args_sizes[4] = sizeof(n);
  args[5] = &r;
  args_sizes[5] = sizeof(r);

  int64_t zero = 0;

  for (int i = 0; i < 8; i++) {
    args_sizes[6+i*3] = sizeof(int64_t);
    args_sizes[6+i*3+1] = sizeof(int64_t);
    args_sizes[6+i*3+2] = sizeof(int64_t);
    if (i < r) {
      args[6+i*3] = &shape[i];
      args[6+i*3+1] = &dst_strides[i];
      args[6+i*3+2] = &src_strides[i];
    } else {
      args[6+i*3] = &zero;
      args[6+i*3+1] = &zero;
      args[6+i*3+2] = &zero;
    }
  }
  const size_t w = 256; // XXX: hardcoded thread block size.

  return gpu_launch_kernel(ctx, kernel, "copy_lmad_dev_to_dev", provenance,
                           (const int32_t[3]) {(n+w-1)/w,1,1},
                           (const int32_t[3]) {w,1,1},
                           0, 6+(8*3), args, args_sizes);
}

#define GEN_LMAD_COPY_ELEMENTS_GPU2GPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx, const char* provenance,                 \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return gpu_lmad_copy(ctx, provenance,                               \
                         ctx->kernels->lmad_copy_##NAME,                \
                         r,                                             \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \

#define GEN_LMAD_COPY_GPU2GPU(NAME, ELEM_TYPE)                          \
  static int lmad_copy_gpu2gpu_##NAME                                   \
  (struct futhark_context* ctx, const char* provenance,                 \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "GPU to GPU", provenance, r, dst_offset, dst_strides, \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return FUTHARK_SUCCESS; }                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      return map_transpose_gpu2gpu_##NAME                               \
        (ctx, provenance, dst, dst_offset, src, src_offset, k, n, m);   \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}        \
      return gpu_memcpy(ctx,                                            \
                        provenance,                                     \
                        dst, dst_offset*sizeof(ELEM_TYPE),              \
                        src, src_offset*sizeof(ELEM_TYPE),              \
                        size * sizeof(ELEM_TYPE));                      \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}     \
      return lmad_copy_elements_gpu2gpu_##NAME                          \
        (ctx, provenance,                                               \
         r,                                                             \
         dst, dst_offset, dst_strides,                                  \
         src, src_offset, src_strides,                                  \
         shape);                                                        \
    }                                                                   \
  }

static int
lmad_copy_elements_host2gpu(struct futhark_context *ctx, const char *provenance,
                            size_t elem_size,
                            int r,
                            gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                            unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                            int64_t shape[r]) {
  (void)ctx; (void)provenance; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from host to GPU.\n"));
  return 1;
}

static int
lmad_copy_elements_gpu2host (struct futhark_context *ctx, const char *provenance,
                             size_t elem_size,
                             int r,
                             unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                             gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                             int64_t shape[r]) {
  (void)ctx; (void)provenance; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from GPU to host.\n"));
  return 1;
}

static int lmad_copy_host2gpu(struct futhark_context* ctx, const char* provenance,
                              size_t elem_size, bool sync,
                              int r,
                              gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                              unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", provenance, r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_host2gpu(ctx, provenance,
                           sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_host2gpu
      (ctx, provenance,
       elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

static int lmad_copy_gpu2host(struct futhark_context* ctx, const char* provenance,
                              size_t elem_size, bool sync,
                              int r,
                              unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                              gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", provenance, r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_gpu2host(ctx, provenance,
                           sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_gpu2host
      (ctx, provenance, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

GEN_MAP_TRANSPOSE_GPU2GPU(1b, uint8_t)
GEN_MAP_TRANSPOSE_GPU2GPU(2b, uint16_t)
GEN_MAP_TRANSPOSE_GPU2GPU(4b, uint32_t)
GEN_MAP_TRANSPOSE_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_GPU2GPU(8b, uint64_t)

// End of gpu.h

static int gpu_macros(struct futhark_context *ctx, char ***names_out, int64_t **values_out)
{
    int num_macros = 87;
    char **names = malloc(num_macros * sizeof(char *));
    int64_t *values = malloc(num_macros * sizeof(int64_t));
    
    {
        names[0] = "mainzisegmap_22658_dim1";
        values[0] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22640;
    }
    {
        names[1] = "mainzisegmap_22658zisegmap_tblock_sizze_22653";
        values[1] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22640;
    }
    {
        names[2] = "mainzisegmap_22618_dim1";
        values[2] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22582;
    }
    {
        names[3] = "mainzisegmap_22618zisegmap_tblock_sizze_22613";
        values[3] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22582;
    }
    {
        names[4] = "mainzigpuseq_24329_dim1";
        values[4] = (int64_t) 1;
    }
    {
        names[5] = "mainzisegmap_22573_dim1";
        values[5] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22555;
    }
    {
        names[6] = "mainzisegmap_22573zisegmap_tblock_sizze_22568";
        values[6] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22555;
    }
    {
        names[7] = "mainzisegmap_22539_dim1";
        values[7] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22509;
    }
    {
        names[8] = "mainzisegmap_22539zisegmap_tblock_sizze_22534";
        values[8] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22509;
    }
    {
        names[9] = "mainzigpuseq_24295_dim1";
        values[9] = (int64_t) 1;
    }
    {
        names[10] = "mainzisegmap_22500_dim1";
        values[10] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22482;
    }
    {
        names[11] = "mainzisegmap_22500zisegmap_tblock_sizze_22495";
        values[11] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22482;
    }
    {
        names[12] = "mainzisegmap_22467_dim1";
        values[12] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22438;
    }
    {
        names[13] = "mainzisegmap_22467zisegmap_tblock_sizze_22462";
        values[13] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22438;
    }
    {
        names[14] = "mainzigpuseq_24261_dim1";
        values[14] = (int64_t) 1;
    }
    {
        names[15] = "mainzigpuseq_24253_dim1";
        values[15] = (int64_t) 1;
    }
    {
        names[16] = "mainzisegmap_22429_dim1";
        values[16] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22411;
    }
    {
        names[17] = "mainzisegmap_22429zisegmap_tblock_sizze_22424";
        values[17] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22411;
    }
    {
        names[18] = "mainzisegmap_22390_dim1";
        values[18] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22235;
    }
    {
        names[19] = "mainzisegmap_22390zisegmap_tblock_sizze_22386";
        values[19] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22235;
    }
    {
        names[20] = "mainzisegred_large_22342_dim1";
        values[20] = *ctx->tuning_params.mainzisegred_tblock_sizze_22254;
    }
    {
        names[21] = "mainzisegred_large_22342zisegred_tblock_sizze_22335";
        values[21] = *ctx->tuning_params.mainzisegred_tblock_sizze_22254;
    }
    {
        names[22] = "mainzisegred_large_22342zichunk_sizze_24137";
        values[22] = (int64_t) 1;
    }
    {
        names[23] = "mainzisegred_small_22342_dim1";
        values[23] = *ctx->tuning_params.mainzisegred_tblock_sizze_22254;
    }
    {
        names[24] = "mainzisegred_small_22342zisegred_tblock_sizze_22335";
        values[24] = *ctx->tuning_params.mainzisegred_tblock_sizze_22254;
    }
    {
        names[25] = "mainzisegmap_22326_dim1";
        values[25] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22309;
    }
    {
        names[26] = "mainzisegmap_22326zisegmap_tblock_sizze_22321";
        values[26] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22309;
    }
    {
        names[27] = "mainzisegmap_22162_dim1";
        values[27] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22090;
    }
    {
        names[28] = "mainzisegmap_22162zisegmap_tblock_sizze_22157";
        values[28] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22090;
    }
    {
        names[29] = "mainzisegred_nonseg_23424_dim1";
        values[29] = *ctx->tuning_params.mainzisegred_tblock_sizze_23416;
    }
    {
        names[30] = "mainzisegred_nonseg_23424zisegred_num_tblocks_23415";
        values[30] = *ctx->tuning_params.mainzisegred_num_tblocks_23414;
    }
    {
        names[31] = "mainzisegred_nonseg_23424zisegred_tblock_sizze_23417";
        values[31] = *ctx->tuning_params.mainzisegred_tblock_sizze_23416;
    }
    {
        names[32] = "mainzisegred_nonseg_23424zichunk_sizze_24077";
        values[32] = (int64_t) 1;
    }
    {
        names[33] = "mainzigpuseq_24069_dim1";
        values[33] = (int64_t) 1;
    }
    {
        names[34] = "mainzisegmap_22076_dim1";
        values[34] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22055;
    }
    {
        names[35] = "mainzisegmap_22076zisegmap_tblock_sizze_22071";
        values[35] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22055;
    }
    {
        names[36] = "mainziscan_stage3_22051_dim1";
        values[36] = *ctx->tuning_params.mainzisegscan_tblock_sizze_22045;
    }
    {
        names[37] = "mainziscan_stage3_22051zisegscan_tblock_sizze_22046";
        values[37] = *ctx->tuning_params.mainzisegscan_tblock_sizze_22045;
    }
    {
        names[38] = "mainziscan_stage2_22051zisegscan_tblock_sizze_22046";
        values[38] = *ctx->tuning_params.mainzisegscan_tblock_sizze_22045;
    }
    {
        names[39] = "mainziscan_stage1_22051_dim1";
        values[39] = *ctx->tuning_params.mainzisegscan_tblock_sizze_22045;
    }
    {
        names[40] = "mainziscan_stage1_22051zisegscan_tblock_sizze_22046";
        values[40] = *ctx->tuning_params.mainzisegscan_tblock_sizze_22045;
    }
    {
        names[41] = "mainzisegmap_22040_dim1";
        values[41] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22024;
    }
    {
        names[42] = "mainzisegmap_22040zisegmap_tblock_sizze_22035";
        values[42] = *ctx->tuning_params.mainzisegmap_tblock_sizze_22024;
    }
    {
        names[43] = "mainzisegmap_22012_dim1";
        values[43] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21991;
    }
    {
        names[44] = "mainzisegmap_22012zisegmap_tblock_sizze_22007";
        values[44] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21991;
    }
    {
        names[45] = "mainzisegmap_21983_dim1";
        values[45] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21966;
    }
    {
        names[46] = "mainzisegmap_21983zisegmap_tblock_sizze_21978";
        values[46] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21966;
    }
    {
        names[47] = "mainzisegmap_21956_dim1";
        values[47] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21940;
    }
    {
        names[48] = "mainzisegmap_21956zisegmap_tblock_sizze_21952";
        values[48] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21940;
    }
    {
        names[49] = "mainzisegmap_21931_dim1";
        values[49] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21913;
    }
    {
        names[50] = "mainzisegmap_21931zisegmap_tblock_sizze_21926";
        values[50] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21913;
    }
    {
        names[51] = "mainzisegmap_21884_dim1";
        values[51] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21732;
    }
    {
        names[52] = "mainzisegmap_21884zisegmap_tblock_sizze_21880";
        values[52] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21732;
    }
    {
        names[53] = "mainzisegred_large_21836_dim1";
        values[53] = *ctx->tuning_params.mainzisegred_tblock_sizze_21751;
    }
    {
        names[54] = "mainzisegred_large_21836zisegred_tblock_sizze_21829";
        values[54] = *ctx->tuning_params.mainzisegred_tblock_sizze_21751;
    }
    {
        names[55] = "mainzisegred_large_21836zichunk_sizze_23786";
        values[55] = (int64_t) 1;
    }
    {
        names[56] = "mainzisegred_small_21836_dim1";
        values[56] = *ctx->tuning_params.mainzisegred_tblock_sizze_21751;
    }
    {
        names[57] = "mainzisegred_small_21836zisegred_tblock_sizze_21829";
        values[57] = *ctx->tuning_params.mainzisegred_tblock_sizze_21751;
    }
    {
        names[58] = "mainzisegmap_21821_dim1";
        values[58] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21806;
    }
    {
        names[59] = "mainzisegmap_21821zisegmap_tblock_sizze_21817";
        values[59] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21806;
    }
    {
        names[60] = "mainzisegmap_21651_dim1";
        values[60] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21576;
    }
    {
        names[61] = "mainzisegmap_21651zisegmap_tblock_sizze_21645";
        values[61] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21576;
    }
    {
        names[62] = "mainzisegred_nonseg_23378_dim1";
        values[62] = *ctx->tuning_params.mainzisegred_tblock_sizze_23370;
    }
    {
        names[63] = "mainzisegred_nonseg_23378zisegred_num_tblocks_23369";
        values[63] = *ctx->tuning_params.mainzisegred_num_tblocks_23368;
    }
    {
        names[64] = "mainzisegred_nonseg_23378zisegred_tblock_sizze_23371";
        values[64] = *ctx->tuning_params.mainzisegred_tblock_sizze_23370;
    }
    {
        names[65] = "mainzisegred_nonseg_23378zichunk_sizze_23723";
        values[65] = (int64_t) 1;
    }
    {
        names[66] = "mainzisegmap_21539_dim1";
        values[66] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21518;
    }
    {
        names[67] = "mainzisegmap_21539zisegmap_tblock_sizze_21534";
        values[67] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21518;
    }
    {
        names[68] = "mainzisegmap_21567_dim1";
        values[68] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21551;
    }
    {
        names[69] = "mainzisegmap_21567zisegmap_tblock_sizze_21562";
        values[69] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21551;
    }
    {
        names[70] = "mainziscan_stage3_21514_dim1";
        values[70] = *ctx->tuning_params.mainzisegscan_tblock_sizze_21508;
    }
    {
        names[71] = "mainziscan_stage3_21514zisegscan_tblock_sizze_21509";
        values[71] = *ctx->tuning_params.mainzisegscan_tblock_sizze_21508;
    }
    {
        names[72] = "mainziscan_stage2_21514zisegscan_tblock_sizze_21509";
        values[72] = *ctx->tuning_params.mainzisegscan_tblock_sizze_21508;
    }
    {
        names[73] = "mainziscan_stage1_21514_dim1";
        values[73] = *ctx->tuning_params.mainzisegscan_tblock_sizze_21508;
    }
    {
        names[74] = "mainziscan_stage1_21514zisegscan_tblock_sizze_21509";
        values[74] = *ctx->tuning_params.mainzisegscan_tblock_sizze_21508;
    }
    {
        names[75] = "mainzigpuseq_23623_dim1";
        values[75] = (int64_t) 1;
    }
    {
        names[76] = "mainzigpuseq_23614_dim1";
        values[76] = (int64_t) 1;
    }
    {
        names[77] = "mainzisegred_nonseg_21506_dim1";
        values[77] = *ctx->tuning_params.mainzisegred_tblock_sizze_21497;
    }
    {
        names[78] = "mainzisegred_nonseg_21506zisegred_tblock_sizze_21498";
        values[78] = *ctx->tuning_params.mainzisegred_tblock_sizze_21497;
    }
    {
        names[79] = "mainzisegred_nonseg_21506zichunk_sizze_23559";
        values[79] = (int64_t) 1;
    }
    {
        names[80] = "mainzigpuseq_23553_dim1";
        values[80] = (int64_t) 1;
    }
    {
        names[81] = "mainzigpuseq_23546_dim1";
        values[81] = (int64_t) 1;
    }
    {
        names[82] = "mainzisegmap_21484_dim1";
        values[82] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21421;
    }
    {
        names[83] = "mainzisegmap_21484zisegmap_tblock_sizze_21479";
        values[83] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21421;
    }
    {
        names[84] = "mainzisegred_nonseg_21406_dim1";
        values[84] = *ctx->tuning_params.mainzisegred_tblock_sizze_21398;
    }
    {
        names[85] = "mainzisegred_nonseg_21406zisegred_tblock_sizze_21399";
        values[85] = *ctx->tuning_params.mainzisegred_tblock_sizze_21398;
    }
    {
        names[86] = "mainzisegred_nonseg_21406zichunk_sizze_23455";
        values[86] = (int64_t) 1;
    }
    *names_out = names;
    *values_out = values;
    return num_macros;
}
static char *get_failure_msg(int failure_idx, int64_t args[])
{
    (void) args;
    switch (failure_idx) {
        
      case 0:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:97:30-42\n   #1  main.fut:7:78-11:83\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 1:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:97:30-39\n   #1  main.fut:7:78-11:83\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 2:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:132:43-53\n   #1  main.fut:7:78-11:83\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 3:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:43-52\n   #1  definitions.fut:89:58-103:37\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 4:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:100:53-62\n   #1  main.fut:7:78-11:83\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 5:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:100:53-65\n   #1  main.fut:7:78-11:83\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 6:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-82\n   #1  definitions.fut:89:58-103:37\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 7:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-82\n   #1  definitions.fut:89:58-103:37\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 8:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-89\n   #1  definitions.fut:89:58-103:37\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 9:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:60-72\n   #1  definitions.fut:89:58-103:37\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 10:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-82\n   #1  definitions.fut:89:58-103:37\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 11:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-89\n   #1  definitions.fut:89:58-103:37\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 12:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:60-72\n   #1  definitions.fut:89:58-103:37\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 13:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-89\n   #1  definitions.fut:89:58-103:37\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 14:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:60-72\n   #1  definitions.fut:89:58-103:37\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 15:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:132:43-50\n   #1  main.fut:7:78-11:83\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 16:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:43-52\n   #1  definitions.fut:89:58-133:67\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 17:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:43-52\n   #1  definitions.fut:89:58-133:67\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 18:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-89\n   #1  definitions.fut:89:58-133:67\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 19:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:60-72\n   #1  definitions.fut:89:58-133:67\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 20:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:43-52\n   #1  definitions.fut:89:58-133:67\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 21:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-89\n   #1  definitions.fut:89:58-133:67\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 22:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:60-72\n   #1  definitions.fut:89:58-133:67\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 23:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-89\n   #1  definitions.fut:89:58-133:67\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 24:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:60-72\n   #1  definitions.fut:89:58-133:67\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 25:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:69:22-38\n   #1  main.fut:7:78-19:39\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 26:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:68:22-34\n   #1  main.fut:7:78-19:39\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 27:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:67:21-30\n   #1  main.fut:7:78-19:39\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 28:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:83:22-38\n   #1  main.fut:7:78-21:36\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 29:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:82:22-34\n   #1  main.fut:7:78-21:36\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 30:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:81:21-30\n   #1  main.fut:7:78-21:36\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 31:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:55:22-34\n   #1  main.fut:7:78-23:42\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 32:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:54:22-34\n   #1  main.fut:7:78-23:42\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 33:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:53:22-38\n   #1  main.fut:7:78-23:42\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 34:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:52:22-38\n   #1  main.fut:7:78-23:42\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
        
      case 35:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:52:22-31\n   #1  main.fut:7:78-23:42\n   #2  main.fut:53:34-70\n", args[0], args[1]);
            break;
        }
    }
    return strdup("Unknown error.  This is a compiler bug.");
}
struct program {
    int dummy;
    gpu_kernel builtinzhreplicate_i32zireplicate_23463;
    gpu_kernel builtinzhreplicate_i8zireplicate_23525;
    gpu_kernel mainzigpuseq_23546;
    gpu_kernel mainzigpuseq_23553;
    gpu_kernel mainzigpuseq_23614;
    gpu_kernel mainzigpuseq_23623;
    gpu_kernel mainzigpuseq_24069;
    gpu_kernel mainzigpuseq_24253;
    gpu_kernel mainzigpuseq_24261;
    gpu_kernel mainzigpuseq_24295;
    gpu_kernel mainzigpuseq_24329;
    gpu_kernel mainzireplicate_23868;
    gpu_kernel mainzireplicate_23888;
    gpu_kernel mainzireplicate_23908;
    gpu_kernel mainzireplicate_24219;
    gpu_kernel mainziscan_stage1_21514;
    gpu_kernel mainziscan_stage1_22051;
    gpu_kernel mainziscan_stage2_21514;
    gpu_kernel mainziscan_stage2_22051;
    gpu_kernel mainziscan_stage3_21514;
    gpu_kernel mainziscan_stage3_22051;
    gpu_kernel mainzisegmap_21484;
    gpu_kernel mainzisegmap_21539;
    gpu_kernel mainzisegmap_21567;
    gpu_kernel mainzisegmap_21651;
    gpu_kernel mainzisegmap_21821;
    gpu_kernel mainzisegmap_21884;
    gpu_kernel mainzisegmap_21931;
    gpu_kernel mainzisegmap_21956;
    gpu_kernel mainzisegmap_21983;
    gpu_kernel mainzisegmap_22012;
    gpu_kernel mainzisegmap_22040;
    gpu_kernel mainzisegmap_22076;
    gpu_kernel mainzisegmap_22162;
    gpu_kernel mainzisegmap_22326;
    gpu_kernel mainzisegmap_22390;
    gpu_kernel mainzisegmap_22429;
    gpu_kernel mainzisegmap_22467;
    gpu_kernel mainzisegmap_22500;
    gpu_kernel mainzisegmap_22539;
    gpu_kernel mainzisegmap_22573;
    gpu_kernel mainzisegmap_22618;
    gpu_kernel mainzisegmap_22658;
    gpu_kernel mainzisegred_large_21836;
    gpu_kernel mainzisegred_large_22342;
    gpu_kernel mainzisegred_nonseg_21406;
    gpu_kernel mainzisegred_nonseg_21506;
    gpu_kernel mainzisegred_nonseg_23378;
    gpu_kernel mainzisegred_nonseg_23424;
    gpu_kernel mainzisegred_small_21836;
    gpu_kernel mainzisegred_small_22342;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_23463, "builtinzhreplicate_i32zireplicate_23463");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i8zireplicate_23525, "builtinzhreplicate_i8zireplicate_23525");
    gpu_create_kernel(ctx, &ctx->program->mainzigpuseq_23546, "mainzigpuseq_23546");
    gpu_create_kernel(ctx, &ctx->program->mainzigpuseq_23553, "mainzigpuseq_23553");
    gpu_create_kernel(ctx, &ctx->program->mainzigpuseq_23614, "mainzigpuseq_23614");
    gpu_create_kernel(ctx, &ctx->program->mainzigpuseq_23623, "mainzigpuseq_23623");
    gpu_create_kernel(ctx, &ctx->program->mainzigpuseq_24069, "mainzigpuseq_24069");
    gpu_create_kernel(ctx, &ctx->program->mainzigpuseq_24253, "mainzigpuseq_24253");
    gpu_create_kernel(ctx, &ctx->program->mainzigpuseq_24261, "mainzigpuseq_24261");
    gpu_create_kernel(ctx, &ctx->program->mainzigpuseq_24295, "mainzigpuseq_24295");
    gpu_create_kernel(ctx, &ctx->program->mainzigpuseq_24329, "mainzigpuseq_24329");
    gpu_create_kernel(ctx, &ctx->program->mainzireplicate_23868, "mainzireplicate_23868");
    gpu_create_kernel(ctx, &ctx->program->mainzireplicate_23888, "mainzireplicate_23888");
    gpu_create_kernel(ctx, &ctx->program->mainzireplicate_23908, "mainzireplicate_23908");
    gpu_create_kernel(ctx, &ctx->program->mainzireplicate_24219, "mainzireplicate_24219");
    gpu_create_kernel(ctx, &ctx->program->mainziscan_stage1_21514, "mainziscan_stage1_21514");
    gpu_create_kernel(ctx, &ctx->program->mainziscan_stage1_22051, "mainziscan_stage1_22051");
    gpu_create_kernel(ctx, &ctx->program->mainziscan_stage2_21514, "mainziscan_stage2_21514");
    gpu_create_kernel(ctx, &ctx->program->mainziscan_stage2_22051, "mainziscan_stage2_22051");
    gpu_create_kernel(ctx, &ctx->program->mainziscan_stage3_21514, "mainziscan_stage3_21514");
    gpu_create_kernel(ctx, &ctx->program->mainziscan_stage3_22051, "mainziscan_stage3_22051");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21484, "mainzisegmap_21484");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21539, "mainzisegmap_21539");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21567, "mainzisegmap_21567");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21651, "mainzisegmap_21651");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21821, "mainzisegmap_21821");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21884, "mainzisegmap_21884");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21931, "mainzisegmap_21931");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21956, "mainzisegmap_21956");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21983, "mainzisegmap_21983");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22012, "mainzisegmap_22012");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22040, "mainzisegmap_22040");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22076, "mainzisegmap_22076");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22162, "mainzisegmap_22162");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22326, "mainzisegmap_22326");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22390, "mainzisegmap_22390");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22429, "mainzisegmap_22429");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22467, "mainzisegmap_22467");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22500, "mainzisegmap_22500");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22539, "mainzisegmap_22539");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22573, "mainzisegmap_22573");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22618, "mainzisegmap_22618");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_22658, "mainzisegmap_22658");
    gpu_create_kernel(ctx, &ctx->program->mainzisegred_large_21836, "mainzisegred_large_21836");
    gpu_create_kernel(ctx, &ctx->program->mainzisegred_large_22342, "mainzisegred_large_22342");
    gpu_create_kernel(ctx, &ctx->program->mainzisegred_nonseg_21406, "mainzisegred_nonseg_21406");
    gpu_create_kernel(ctx, &ctx->program->mainzisegred_nonseg_21506, "mainzisegred_nonseg_21506");
    gpu_create_kernel(ctx, &ctx->program->mainzisegred_nonseg_23378, "mainzisegred_nonseg_23378");
    gpu_create_kernel(ctx, &ctx->program->mainzisegred_nonseg_23424, "mainzisegred_nonseg_23424");
    gpu_create_kernel(ctx, &ctx->program->mainzisegred_small_21836, "mainzisegred_small_21836");
    gpu_create_kernel(ctx, &ctx->program->mainzisegred_small_22342, "mainzisegred_small_22342");
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_23463);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_23525);
    gpu_free_kernel(ctx, ctx->program->mainzigpuseq_23546);
    gpu_free_kernel(ctx, ctx->program->mainzigpuseq_23553);
    gpu_free_kernel(ctx, ctx->program->mainzigpuseq_23614);
    gpu_free_kernel(ctx, ctx->program->mainzigpuseq_23623);
    gpu_free_kernel(ctx, ctx->program->mainzigpuseq_24069);
    gpu_free_kernel(ctx, ctx->program->mainzigpuseq_24253);
    gpu_free_kernel(ctx, ctx->program->mainzigpuseq_24261);
    gpu_free_kernel(ctx, ctx->program->mainzigpuseq_24295);
    gpu_free_kernel(ctx, ctx->program->mainzigpuseq_24329);
    gpu_free_kernel(ctx, ctx->program->mainzireplicate_23868);
    gpu_free_kernel(ctx, ctx->program->mainzireplicate_23888);
    gpu_free_kernel(ctx, ctx->program->mainzireplicate_23908);
    gpu_free_kernel(ctx, ctx->program->mainzireplicate_24219);
    gpu_free_kernel(ctx, ctx->program->mainziscan_stage1_21514);
    gpu_free_kernel(ctx, ctx->program->mainziscan_stage1_22051);
    gpu_free_kernel(ctx, ctx->program->mainziscan_stage2_21514);
    gpu_free_kernel(ctx, ctx->program->mainziscan_stage2_22051);
    gpu_free_kernel(ctx, ctx->program->mainziscan_stage3_21514);
    gpu_free_kernel(ctx, ctx->program->mainziscan_stage3_22051);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21484);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21539);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21567);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21651);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21821);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21884);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21931);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21956);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21983);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22012);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22040);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22076);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22162);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22326);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22390);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22429);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22467);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22500);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22539);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22573);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22618);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_22658);
    gpu_free_kernel(ctx, ctx->program->mainzisegred_large_21836);
    gpu_free_kernel(ctx, ctx->program->mainzisegred_large_22342);
    gpu_free_kernel(ctx, ctx->program->mainzisegred_nonseg_21406);
    gpu_free_kernel(ctx, ctx->program->mainzisegred_nonseg_21506);
    gpu_free_kernel(ctx, ctx->program->mainzisegred_nonseg_23378);
    gpu_free_kernel(ctx, ctx->program->mainzisegred_nonseg_23424);
    gpu_free_kernel(ctx, ctx->program->mainzisegred_small_21836);
    gpu_free_kernel(ctx, ctx->program->mainzisegred_small_22342);
    free(ctx->program);
}
void post_opencl_setup(struct futhark_context *ctx, struct opencl_device_option *option)
{
    if ((ctx->lockstep_width == 0 && strstr(option->platform_name, "NVIDIA CUDA") != NULL) && (option->device_type & CL_DEVICE_TYPE_GPU) == CL_DEVICE_TYPE_GPU) {
        ctx->lockstep_width = 32;
    }
    if ((ctx->lockstep_width == 0 && strstr(option->platform_name, "AMD Accelerated Parallel Processing") != NULL) && (option->device_type & CL_DEVICE_TYPE_GPU) == CL_DEVICE_TYPE_GPU) {
        ctx->lockstep_width = 32;
    }
    if ((ctx->lockstep_width == 0 && strstr(option->platform_name, "rusticl") != NULL) && (option->device_type & CL_DEVICE_TYPE_GPU) == CL_DEVICE_TYPE_GPU) {
        ctx->lockstep_width = 32;
    }
    if ((ctx->lockstep_width == 0 && strstr(option->platform_name, "") != NULL) && (option->device_type & CL_DEVICE_TYPE_GPU) == CL_DEVICE_TYPE_GPU) {
        ctx->lockstep_width = 1;
    }
    if ((ctx->cfg->gpu.default_grid_size == 0 && strstr(option->platform_name, "") != NULL) && (option->device_type & CL_DEVICE_TYPE_GPU) == CL_DEVICE_TYPE_GPU) {
        size_t MAX_COMPUTE_UNITS_val = 0;
        
        clGetDeviceInfo(ctx->device, CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(MAX_COMPUTE_UNITS_val), &MAX_COMPUTE_UNITS_val, NULL);
        ctx->cfg->gpu.default_grid_size = 4 * MAX_COMPUTE_UNITS_val;
    }
    if ((ctx->cfg->gpu.default_block_size == 0 && strstr(option->platform_name, "") != NULL) && (option->device_type & CL_DEVICE_TYPE_GPU) == CL_DEVICE_TYPE_GPU) {
        ctx->cfg->gpu.default_block_size = 256;
    }
    if ((ctx->cfg->gpu.default_tile_size == 0 && strstr(option->platform_name, "") != NULL) && (option->device_type & CL_DEVICE_TYPE_GPU) == CL_DEVICE_TYPE_GPU) {
        ctx->cfg->gpu.default_tile_size = 32;
    }
    if ((ctx->cfg->gpu.default_reg_tile_size == 0 && strstr(option->platform_name, "") != NULL) && (option->device_type & CL_DEVICE_TYPE_GPU) == CL_DEVICE_TYPE_GPU) {
        ctx->cfg->gpu.default_reg_tile_size = 2;
    }
    if ((ctx->cfg->gpu.default_threshold == 0 && strstr(option->platform_name, "") != NULL) && (option->device_type & CL_DEVICE_TYPE_GPU) == CL_DEVICE_TYPE_GPU) {
        ctx->cfg->gpu.default_threshold = 32768;
    }
    if ((ctx->lockstep_width == 0 && strstr(option->platform_name, "") != NULL) && (option->device_type & CL_DEVICE_TYPE_CPU) == CL_DEVICE_TYPE_CPU) {
        ctx->lockstep_width = 1;
    }
    if ((ctx->cfg->gpu.default_grid_size == 0 && strstr(option->platform_name, "") != NULL) && (option->device_type & CL_DEVICE_TYPE_CPU) == CL_DEVICE_TYPE_CPU) {
        size_t MAX_COMPUTE_UNITS_val = 0;
        
        clGetDeviceInfo(ctx->device, CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(MAX_COMPUTE_UNITS_val), &MAX_COMPUTE_UNITS_val, NULL);
        ctx->cfg->gpu.default_grid_size = MAX_COMPUTE_UNITS_val;
    }
    if ((ctx->cfg->gpu.default_block_size == 0 && strstr(option->platform_name, "") != NULL) && (option->device_type & CL_DEVICE_TYPE_CPU) == CL_DEVICE_TYPE_CPU) {
        ctx->cfg->gpu.default_block_size = 32;
    }
    if ((ctx->cfg->gpu.default_tile_size == 0 && strstr(option->platform_name, "") != NULL) && (option->device_type & CL_DEVICE_TYPE_CPU) == CL_DEVICE_TYPE_CPU) {
        ctx->cfg->gpu.default_tile_size = 4;
    }
    if ((ctx->cfg->gpu.default_reg_tile_size == 0 && strstr(option->platform_name, "") != NULL) && (option->device_type & CL_DEVICE_TYPE_CPU) == CL_DEVICE_TYPE_CPU) {
        ctx->cfg->gpu.default_reg_tile_size = 1;
    }
    if ((ctx->cfg->gpu.default_threshold == 0 && strstr(option->platform_name, "") != NULL) && (option->device_type & CL_DEVICE_TYPE_CPU) == CL_DEVICE_TYPE_CPU) {
        size_t MAX_COMPUTE_UNITS_val = 0;
        
        clGetDeviceInfo(ctx->device, CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(MAX_COMPUTE_UNITS_val), &MAX_COMPUTE_UNITS_val, NULL);
        ctx->cfg->gpu.default_threshold = MAX_COMPUTE_UNITS_val;
    }
}
static void set_tuning_params(struct futhark_context *ctx)
{
    (void) ctx;
    ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_23467 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_23529 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.mainzisegmap_num_tblocks_21520 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.mainzisegmap_num_tblocks_21553 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.mainzisegmap_num_tblocks_21578 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.mainzisegmap_num_tblocks_21915 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.mainzisegmap_num_tblocks_21968 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.mainzisegmap_num_tblocks_21993 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.mainzisegmap_num_tblocks_22026 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.mainzisegmap_num_tblocks_22057 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.mainzisegmap_num_tblocks_22092 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.mainzisegmap_num_tblocks_22413 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.mainzisegmap_num_tblocks_22440 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.mainzisegmap_num_tblocks_22484 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.mainzisegmap_num_tblocks_22511 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.mainzisegmap_num_tblocks_22557 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.mainzisegmap_num_tblocks_22584 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.mainzisegmap_num_tblocks_22642 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21421 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21518 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21551 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21576 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21732 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21806 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21913 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21940 = &ctx->cfg->tuning_params[25];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21966 = &ctx->cfg->tuning_params[26];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21991 = &ctx->cfg->tuning_params[27];
    ctx->tuning_params.mainzisegmap_tblock_sizze_22024 = &ctx->cfg->tuning_params[28];
    ctx->tuning_params.mainzisegmap_tblock_sizze_22055 = &ctx->cfg->tuning_params[29];
    ctx->tuning_params.mainzisegmap_tblock_sizze_22090 = &ctx->cfg->tuning_params[30];
    ctx->tuning_params.mainzisegmap_tblock_sizze_22235 = &ctx->cfg->tuning_params[31];
    ctx->tuning_params.mainzisegmap_tblock_sizze_22309 = &ctx->cfg->tuning_params[32];
    ctx->tuning_params.mainzisegmap_tblock_sizze_22411 = &ctx->cfg->tuning_params[33];
    ctx->tuning_params.mainzisegmap_tblock_sizze_22438 = &ctx->cfg->tuning_params[34];
    ctx->tuning_params.mainzisegmap_tblock_sizze_22482 = &ctx->cfg->tuning_params[35];
    ctx->tuning_params.mainzisegmap_tblock_sizze_22509 = &ctx->cfg->tuning_params[36];
    ctx->tuning_params.mainzisegmap_tblock_sizze_22555 = &ctx->cfg->tuning_params[37];
    ctx->tuning_params.mainzisegmap_tblock_sizze_22582 = &ctx->cfg->tuning_params[38];
    ctx->tuning_params.mainzisegmap_tblock_sizze_22640 = &ctx->cfg->tuning_params[39];
    ctx->tuning_params.mainzisegred_num_tblocks_21400 = &ctx->cfg->tuning_params[40];
    ctx->tuning_params.mainzisegred_num_tblocks_21499 = &ctx->cfg->tuning_params[41];
    ctx->tuning_params.mainzisegred_num_tblocks_21753 = &ctx->cfg->tuning_params[42];
    ctx->tuning_params.mainzisegred_num_tblocks_22256 = &ctx->cfg->tuning_params[43];
    ctx->tuning_params.mainzisegred_num_tblocks_23368 = &ctx->cfg->tuning_params[44];
    ctx->tuning_params.mainzisegred_num_tblocks_23414 = &ctx->cfg->tuning_params[45];
    ctx->tuning_params.mainzisegred_tblock_sizze_21398 = &ctx->cfg->tuning_params[46];
    ctx->tuning_params.mainzisegred_tblock_sizze_21497 = &ctx->cfg->tuning_params[47];
    ctx->tuning_params.mainzisegred_tblock_sizze_21751 = &ctx->cfg->tuning_params[48];
    ctx->tuning_params.mainzisegred_tblock_sizze_22254 = &ctx->cfg->tuning_params[49];
    ctx->tuning_params.mainzisegred_tblock_sizze_23370 = &ctx->cfg->tuning_params[50];
    ctx->tuning_params.mainzisegred_tblock_sizze_23416 = &ctx->cfg->tuning_params[51];
    ctx->tuning_params.mainzisegscan_num_tblocks_21510 = &ctx->cfg->tuning_params[52];
    ctx->tuning_params.mainzisegscan_num_tblocks_22047 = &ctx->cfg->tuning_params[53];
    ctx->tuning_params.mainzisegscan_tblock_sizze_21508 = &ctx->cfg->tuning_params[54];
    ctx->tuning_params.mainzisegscan_tblock_sizze_22045 = &ctx->cfg->tuning_params[55];
    ctx->tuning_params.mainzisuff_outer_par_0 = &ctx->cfg->tuning_params[56];
    ctx->tuning_params.mainzisuff_outer_par_1 = &ctx->cfg->tuning_params[57];
    ctx->tuning_params.mainzitblock_sizze_23872 = &ctx->cfg->tuning_params[58];
    ctx->tuning_params.mainzitblock_sizze_23892 = &ctx->cfg->tuning_params[59];
    ctx->tuning_params.mainzitblock_sizze_23912 = &ctx->cfg->tuning_params[60];
    ctx->tuning_params.mainzitblock_sizze_24223 = &ctx->cfg->tuning_params[61];
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            (void) gpu_free(ctx, block->mem, block->size, desc);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device);
    (void) gpu_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_device + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_device = new_usage;
        if (new_usage > ctx->peak_mem_usage_device) {
            ctx->peak_mem_usage_device = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default);
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_default + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_default = new_usage;
        if (new_usage > ctx->peak_mem_usage_default) {
            ctx->peak_mem_usage_default = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder_char(&builder, '{');
    str_builder_str(&builder, "\"memory\":{");
    str_builder(&builder, "\"space 'device'\": %lld", (long long) ctx->peak_mem_usage_device);
    str_builder_char(&builder, ',');
    str_builder(&builder, "\"default space\": %lld", (long long) ctx->peak_mem_usage_default);
    str_builder_str(&builder, "},\"events\":[");
    if (report_events_in_list(&ctx->event_list, &builder) != 0) {
        free(builder.str);
        return NULL;
    } else {
        str_builder_str(&builder, "]}");
        return builder.str;
    }
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        gpu_free_all(ctx);
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      const char* provenance,
                      struct kvs *kvs,
                      void* data,
                      event_report_fn f) {
  if (provenance == NULL) {
    provenance = "unknown";
  }
  if (ctx->logging) {
    fprintf(ctx->log, "Event: %s\n  at: %s\n", name, provenance);
    if (kvs) {
      kvs_log(kvs, "  ", ctx->log);
    }
  }
  add_event_to_list(&ctx->event_list, name, provenance, kvs, data, f);
}

char *futhark_context_get_error(struct futhark_context *ctx) {
  char *error = ctx->error;
  ctx->error = NULL;
  return error;
}

void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}

void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = flag;
}

void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag) {
    cfg->logging = flag;
}

void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f) {
  cfg->cache_fname = strdup(f);
}

int futhark_get_tuning_param_count(void) {
  return num_tuning_params;
}

const char *futhark_get_tuning_param_name(int i) {
  return tuning_param_names[i];
}

const char *futhark_get_tuning_param_class(int i) {
    return tuning_param_classes[i];
}

void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f){
  ctx->log = f;
}

void futhark_context_pause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 1;
}

void futhark_context_unpause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 0;
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->cache_fname);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  ctx->program_initialised = false;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  event_list_init(&ctx->event_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->detail_memory = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  set_tuning_params(ctx);
  if (backend_context_setup(ctx) == 0) {
    setup_program(ctx);
    init_constants(ctx);
    ctx->program_initialised = true;
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  if (ctx->program_initialised) {
    free_constants(ctx);
    teardown_program(ctx);
  }
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  event_list_free(&ctx->event_list);
  free(ctx->constants);
  free(ctx->error);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

// Start of copy.h

// Cache-oblivious map-transpose function.
#define GEN_MAP_TRANSPOSE(NAME, ELEM_TYPE)                              \
  static void map_transpose_##NAME                                      \
  (ELEM_TYPE* dst, ELEM_TYPE* src,                                      \
   int64_t k, int64_t m, int64_t n,                                     \
   int64_t cb, int64_t ce, int64_t rb, int64_t re)                      \
  {                                                                     \
  int32_t r = re - rb;                                                  \
  int32_t c = ce - cb;                                                  \
  if (k == 1) {                                                         \
    if (r <= 64 && c <= 64) {                                           \
      for (int64_t j = 0; j < c; j++) {                                 \
        for (int64_t i = 0; i < r; i++) {                               \
          dst[(j + cb) * n + (i + rb)] = src[(i + rb) * m + (j + cb)];  \
        }                                                               \
      }                                                                 \
    } else if (c <= r) {                                                \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb, rb + r/2);    \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb + r/2, re);    \
    } else {                                                            \
      map_transpose_##NAME(dst, src, k, m, n, cb, cb + c/2, rb, re);    \
      map_transpose_##NAME(dst, src, k, m, n, cb + c/2, ce, rb, re);    \
    }                                                                   \
  } else {                                                              \
  for (int64_t i = 0; i < k; i++) {                                     \
    map_transpose_##NAME(dst + i * m * n, src + i * m * n, 1, m, n, cb, ce, rb, re); \
  }\
} \
}

// Straightforward LMAD copy function.
#define GEN_LMAD_COPY_ELEMENTS(NAME, ELEM_TYPE)                         \
  static void lmad_copy_elements_##NAME(int r,                          \
                                        ELEM_TYPE* dst, int64_t dst_strides[r], \
                                        ELEM_TYPE *src, int64_t src_strides[r], \
                                        int64_t shape[r]) {             \
    if (r == 1) {                                                       \
      for (int i = 0; i < shape[0]; i++) {                              \
        dst[i*dst_strides[0]] = src[i*src_strides[0]];                  \
      }                                                                 \
    } else if (r > 1) {                                                 \
      for (int i = 0; i < shape[0]; i++) {                              \
        lmad_copy_elements_##NAME(r-1,                                  \
                                  dst+i*dst_strides[0], dst_strides+1,  \
                                  src+i*src_strides[0], src_strides+1,  \
                                  shape+1);                             \
      }                                                                 \
    }                                                                   \
  }                                                                     \

// Check whether this LMAD can be seen as a transposed 2D array.  This
// is done by checking every possible splitting point.
static bool lmad_is_tr(int64_t *n_out, int64_t *m_out,
                       int r,
                       const int64_t strides[r],
                       const int64_t shape[r]) {
  for (int i = 1; i < r; i++) {
    int n = 1, m = 1;
    bool ok = true;
    int64_t expected = 1;
    // Check strides before 'i'.
    for (int j = i-1; j >= 0; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      n *= shape[j];
    }
    // Check strides after 'i'.
    for (int j = r-1; j >= i; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      m *= shape[j];
    }
    if (ok) {
      *n_out = n;
      *m_out = m;
      return true;
    }
  }
  return false;
}

// This function determines whether the a 'dst' LMAD is row-major and
// 'src' LMAD is column-major.  Both LMADs are for arrays of the same
// shape.  Both LMADs are allowed to have additional dimensions "on
// top".  Essentially, this function determines whether a copy from
// 'src' to 'dst' is a "map(transpose)" that we know how to implement
// efficiently.  The LMADs can have arbitrary rank, and the main
// challenge here is checking whether the src LMAD actually
// corresponds to a 2D column-major layout by morally collapsing
// dimensions.  There is a lot of looping here, but the actual trip
// count is going to be very low in practice.
//
// Returns true if this is indeed a map(transpose), and writes the
// number of arrays, and moral array size to appropriate output
// parameters.
static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]) {
  int64_t rowmajor_strides[r];
  rowmajor_strides[r-1] = 1;

  for (int i = r-2; i >= 0; i--) {
    rowmajor_strides[i] = rowmajor_strides[i+1] * shape[i+1];
  }

  // map_r will be the number of mapped dimensions on top.
  int map_r = 0;
  int64_t num_arrays = 1;
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != rowmajor_strides[i] ||
        src_strides[i] != rowmajor_strides[i]) {
      break;
    } else {
      num_arrays *= shape[i];
      map_r++;
    }
  }

  *num_arrays_out = num_arrays;

  if (r==map_r) {
    return false;
  }

  if (memcmp(&rowmajor_strides[map_r],
             &dst_strides[map_r],
             sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(n_out, m_out, r-map_r, src_strides+map_r, shape+map_r);
  } else if (memcmp(&rowmajor_strides[map_r],
                    &src_strides[map_r],
                    sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(m_out, n_out, r-map_r, dst_strides+map_r, shape+map_r);
  }
  return false;
}

// Check if the strides correspond to row-major strides of *any*
// permutation of the shape.  This is done by recursive search with
// backtracking.  This is worst-case exponential, but hopefully the
// arrays we encounter do not have that many dimensions.
static bool lmad_contiguous_search(int checked, int64_t expected,
                                   int r,
                                   int64_t strides[r], int64_t shape[r], bool used[r]) {
  for (int i = 0; i < r; i++) {
    for (int j = 0; j < r; j++) {
      if (!used[j] && strides[j] == expected && strides[j] >= 0) {
        used[j] = true;
        if (checked+1 == r ||
            lmad_contiguous_search(checked+1, expected * shape[j], r, strides, shape, used)) {
          return true;
        }
        used[j] = false;
      }
    }
  }
  return false;
}

// Does this LMAD correspond to an array with positive strides and no
// holes?
static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]) {
  bool used[r];
  for (int i = 0; i < r; i++) {
    used[i] = false;
  }
  return lmad_contiguous_search(0, 1, r, strides, shape, used);
}

// Does this copy correspond to something that could be done with a
// memcpy()-like operation?  I.e. do the LMADs actually represent the
// same in-memory layout and are they contiguous?
static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]) {
  if (!lmad_contiguous(r, dst_strides, shape)) {
    return false;
  }
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != src_strides[i] && shape[i] != 1) {
      return false;
    }
  }
  return true;
}


static void log_copy(struct futhark_context* ctx,
                     const char *kind, const char *provenance,
                     int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]) {
  if (ctx->logging) {
    fprintf(ctx->log, "\n# Copy %s\n", kind);
    if (provenance) { fprintf(ctx->log, "At: %s\n", provenance); }
    fprintf(ctx->log, "Shape: ");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, "[%ld]", (long int)shape[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Dst offset: %ld\n", (long int)dst_offset);
    fprintf(ctx->log, "Dst strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)dst_strides[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Src offset: %ld\n", (long int)src_offset);
    fprintf(ctx->log, "Src strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)src_strides[i]); }
    fprintf(ctx->log, "\n");
  }
}

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t n, int64_t m) {
  if (ctx->logging) {
    fprintf(ctx->log, "## Transpose\n");
    fprintf(ctx->log, "Arrays     : %ld\n", (long int)k);
    fprintf(ctx->log, "X elements : %ld\n", (long int)m);
    fprintf(ctx->log, "Y elements : %ld\n", (long int)n);
    fprintf(ctx->log, "\n");
  }
}

#define GEN_LMAD_COPY(NAME, ELEM_TYPE)                                  \
  static void lmad_copy_##NAME                                          \
  (struct futhark_context *ctx, int r,                                  \
   ELEM_TYPE* dst, int64_t dst_offset, int64_t dst_strides[r],          \
   ELEM_TYPE *src, int64_t src_offset, int64_t src_strides[r],          \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "CPU to CPU", NULL, r, dst_offset, dst_strides,       \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return; }                                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      map_transpose_##NAME                                              \
        (dst+dst_offset, src+src_offset, k, n, m, 0, n, 0, m);          \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}          \
      memcpy(dst+dst_offset, src+src_offset, size*sizeof(*dst));        \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}       \
      lmad_copy_elements_##NAME                                         \
        (r,                                                             \
         dst+dst_offset, dst_strides,                                   \
         src+src_offset, src_strides, shape);                           \
    }                                                                   \
  }

GEN_MAP_TRANSPOSE(1b, uint8_t)
GEN_MAP_TRANSPOSE(2b, uint16_t)
GEN_MAP_TRANSPOSE(4b, uint32_t)
GEN_MAP_TRANSPOSE(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS(8b, uint64_t)

GEN_LMAD_COPY(1b, uint8_t)
GEN_LMAD_COPY(2b, uint16_t)
GEN_LMAD_COPY(4b, uint32_t)
GEN_LMAD_COPY(8b, uint64_t)

// End of copy.h

#define FUTHARK_FUN_ATTR static

FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_23458, int64_t num_elems_23459, int32_t val_23460);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_23520, int64_t num_elems_23521, int8_t val_23522);
FUTHARK_FUN_ATTR int futrts_entry_main(struct futhark_context *ctx, struct memblock_device *mem_out_p_24363, int64_t *out_prim_out_24364, struct memblock_device gates_mem_23045, struct memblock_device cQ_mem_23046, struct memblock_device tQ_mem_23047, int64_t n_14545, int32_t seed_14546, int64_t num_qubits_14547);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define counters_mem_23456 (ctx->constants->counters_mem_23456)
    #define counters_mem_23560 (ctx->constants->counters_mem_23560)
    #define counters_mem_23724 (ctx->constants->counters_mem_23724)
    #define counters_mem_23821 (ctx->constants->counters_mem_23821)
    #define counters_mem_24078 (ctx->constants->counters_mem_24078)
    #define counters_mem_24172 (ctx->constants->counters_mem_24172)
    counters_mem_23456.references = NULL;
    counters_mem_23560.references = NULL;
    counters_mem_23724.references = NULL;
    counters_mem_23821.references = NULL;
    counters_mem_24078.references = NULL;
    counters_mem_24172.references = NULL;
    if (memblock_alloc_device(ctx, &counters_mem_23456, (int64_t) 80, "counters_mem_23456")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_23456, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_23560, (int64_t) 80, "counters_mem_23560")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_23560, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_23724, (int64_t) 80, "counters_mem_23724")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_23724, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_23821, (int64_t) 81920, "counters_mem_23821")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_23821, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_24078, (int64_t) 80, "counters_mem_24078")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_24078, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_24172, (int64_t) 81920, "counters_mem_24172")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_24172, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    #undef counters_mem_23456
    #undef counters_mem_23560
    #undef counters_mem_23724
    #undef counters_mem_23821
    #undef counters_mem_24078
    #undef counters_mem_24172
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_23456, "ctx->constants->counters_mem_23456") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_23560, "ctx->constants->counters_mem_23560") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_23724, "ctx->constants->counters_mem_23724") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_23821, "ctx->constants->counters_mem_23821") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_24078, "ctx->constants->counters_mem_24078") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_24172, "ctx->constants->counters_mem_24172") != 0)
        return 1;
    return 0;
}
static int gpu_kernel_builtinzhreplicate_i32zireplicate_23463(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_23463, "builtin#replicate_i32.replicate_23463", NULL, (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i8zireplicate_23525(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int8_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_23525, "builtin#replicate_i8.replicate_23525", NULL, (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegred_nonseg_21406(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegred_nonseg_21406, "main.segred_nonseg_21406", "main.fut:53:34-70->main.fut:5:33-104", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21484(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21484, "main.segmap_21484", "main.fut:53:34-70->main.fut:7:63-88->definitions.fut:34:6-41:35", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzigpuseq_23546(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzigpuseq_23546, "main.gpuseq_23546", "main.fut:53:34-70", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzigpuseq_23553(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzigpuseq_23553, "main.gpuseq_23553", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:97:30-42", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegred_nonseg_21506(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegred_nonseg_21506, "main.segred_nonseg_21506", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:97:12-60", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzigpuseq_23614(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, bool arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzigpuseq_23614, "main.gpuseq_23614", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:132:43-53", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzigpuseq_23623(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int8_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[17] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[17] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzigpuseq_23623, "main.gpuseq_23623", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-117:34", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 17, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainziscan_stage1_21514(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainziscan_stage1_21514, "main.scan_stage1_21514", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:100:29-85", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainziscan_stage2_21514(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainziscan_stage2_21514, "main.scan_stage2_21514", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:100:29-85", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainziscan_stage3_21514(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, int32_t arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainziscan_stage3_21514, "main.scan_stage3_21514", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:100:29-85", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21567(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21567, "main.segmap_21567", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-103:37->definitions.fut:28:12-52", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21539(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21539, "main.segmap_21539", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:100:29-85", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegred_nonseg_23378(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegred_nonseg_23378, "main.segred_nonseg_23378", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-103:37->definitions.fut:25:17-29:98", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21651(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int32_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[19] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15};
        size_t args_sizes[19] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21651, "main.segmap_21651", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:23:79-104:29", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 19, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21821(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21821, "main.segmap_21821", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-103:37->definitions.fut:25:73-82", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegred_small_21836(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegred_small_21836, "main.segred_small_21836", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-103:37->definitions.fut:25:17-29:98", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegred_large_21836(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[19] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15};
        size_t args_sizes[19] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegred_large_21836, "main.segred_large_21836", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-103:37->definitions.fut:25:17-29:98", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 19, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21884(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21884, "main.segmap_21884", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-103:37", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzireplicate_23868(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[7] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzireplicate_23868, "main.replicate_23868", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-103:37", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzireplicate_23888(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[7] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzireplicate_23888, "main.replicate_23888", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-103:37", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzireplicate_23908(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzireplicate_23908, "main.replicate_23908", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-103:37", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21931(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, int32_t arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21931, "main.segmap_21931", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:106:22-72", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21956(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21956, "main.segmap_21956", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:109:21-58", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21983(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21983, "main.segmap_21983", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:110:22-45", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22012(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int8_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22012, "main.segmap_22012", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:117:20-124:45", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22040(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22040, "main.segmap_22040", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:130:22-47", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainziscan_stage1_22051(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainziscan_stage1_22051, "main.scan_stage1_22051", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:132:29-67", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainziscan_stage2_22051(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainziscan_stage2_22051, "main.scan_stage2_22051", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:132:29-67", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainziscan_stage3_22051(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, int32_t arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainziscan_stage3_22051, "main.scan_stage3_22051", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:132:29-67", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22076(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22076, "main.segmap_22076", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:132:29-67", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzigpuseq_24069(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzigpuseq_24069, "main.gpuseq_24069", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-133:67->definitions.fut:26:16-36", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegred_nonseg_23424(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegred_nonseg_23424, "main.segred_nonseg_23424", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-133:67->definitions.fut:25:17-29:98", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22162(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int32_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22162, "main.segmap_22162", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:23:79-133:82", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22326(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22326, "main.segmap_22326", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-133:67->definitions.fut:25:43-52", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegred_small_22342(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegred_small_22342, "main.segred_small_22342", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-133:67->definitions.fut:25:17-29:98", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegred_large_22342(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[19] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15};
        size_t args_sizes[19] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegred_large_22342, "main.segred_large_22342", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-133:67->definitions.fut:25:17-29:98", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 19, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22390(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22390, "main.segmap_22390", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-133:67", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzireplicate_24219(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzireplicate_24219, "main.replicate_24219", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-133:67", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22429(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int32_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22429, "main.segmap_22429", "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:134:22-70", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzigpuseq_24253(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzigpuseq_24253, "main.gpuseq_24253", "main.fut:53:34-70->main.fut:7:78-11:83", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzigpuseq_24261(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzigpuseq_24261, "main.gpuseq_24261", "main.fut:53:34-70->main.fut:7:78-19:39->definitions.fut:64:17-69:38", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22467(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22467, "main.segmap_22467", "main.fut:53:34-70->main.fut:7:78-19:39->definitions.fut:64:17-72:18", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22500(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22500, "main.segmap_22500", "main.fut:53:34-70->main.fut:7:78-19:39->definitions.fut:74:6-38", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzigpuseq_24295(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzigpuseq_24295, "main.gpuseq_24295", "main.fut:53:34-70->main.fut:7:78-21:36->definitions.fut:78:17-83:38", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22539(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22539, "main.segmap_22539", "main.fut:53:34-70->main.fut:7:78-21:36->definitions.fut:78:17-85:18", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22573(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22573, "main.segmap_22573", "main.fut:53:34-70->main.fut:7:78-21:36->definitions.fut:87:6-38", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzigpuseq_24329(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzigpuseq_24329, "main.gpuseq_24329", "main.fut:53:34-70->main.fut:7:78-23:42->definitions.fut:46:5-55:34", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22618(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22618, "main.segmap_22618", "main.fut:53:34-70->main.fut:7:78-23:42->definitions.fut:46:5-58:18", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_22658(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_22658, "main.segmap_22658", "main.fut:53:34-70->main.fut:7:78-23:42->definitions.fut:60:6-38", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
struct futhark_i8_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i8_1d *futhark_new_i8_1d(struct futhark_context *ctx, const int8_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i8_1d *bad = NULL;
    struct futhark_i8_1d *arr = (struct futhark_i8_1d *) malloc(sizeof(struct futhark_i8_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 1, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, NULL, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 1);
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i8_1d *futhark_new_raw_i8_1d(struct futhark_context *ctx, cl_mem data, int64_t dim0)
{
    int err = 0;
    struct futhark_i8_1d *bad = NULL;
    struct futhark_i8_1d *arr = (struct futhark_i8_1d *) malloc(sizeof(struct futhark_i8_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr)
{
    lock_lock(&ctx->lock);
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr, int8_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    err = memcpy_gpu2host(ctx, NULL, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 1);
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i8_1d(struct futhark_context *ctx, int8_t *out, struct futhark_i8_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        err = memcpy_gpu2host(ctx, NULL, false, (unsigned char *) out, 0, arr->mem.mem, 1 * (i0 * 1), 1);
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
cl_mem futhark_values_raw_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_i64_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, NULL, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 8);
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, cl_mem data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    lock_lock(&ctx->lock);
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    err = memcpy_gpu2host(ctx, NULL, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 8);
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        err = memcpy_gpu2host(ctx, NULL, false, (unsigned char *) out, 0, arr->mem.mem, 8 * (i0 * 1), 8);
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
cl_mem futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->shape;
}

FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_23458, int64_t num_elems_23459, int32_t val_23460)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_23456 = ctx->constants->counters_mem_23456;
    struct memblock_device counters_mem_23560 = ctx->constants->counters_mem_23560;
    struct memblock_device counters_mem_23724 = ctx->constants->counters_mem_23724;
    struct memblock_device counters_mem_23821 = ctx->constants->counters_mem_23821;
    struct memblock_device counters_mem_24078 = ctx->constants->counters_mem_24078;
    struct memblock_device counters_mem_24172 = ctx->constants->counters_mem_24172;
    int64_t replicate_n_23462 = num_elems_23459;
    int64_t tblock_sizze_23467;
    
    tblock_sizze_23467 = *ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_23467;
    
    int64_t virt_num_tblocks_23468 = sdiv_up64(replicate_n_23462, tblock_sizze_23467);
    int64_t num_tblocks_23469 = smin64(virt_num_tblocks_23468, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i32zireplicate_23463(ctx, num_tblocks_23469, 1, 1, tblock_sizze_23467, 1, 1, (int64_t) 0, num_elems_23459, val_23460, replicate_n_23462, virt_num_tblocks_23468, num_tblocks_23469, mem_23458.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_23520, int64_t num_elems_23521, int8_t val_23522)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_23456 = ctx->constants->counters_mem_23456;
    struct memblock_device counters_mem_23560 = ctx->constants->counters_mem_23560;
    struct memblock_device counters_mem_23724 = ctx->constants->counters_mem_23724;
    struct memblock_device counters_mem_23821 = ctx->constants->counters_mem_23821;
    struct memblock_device counters_mem_24078 = ctx->constants->counters_mem_24078;
    struct memblock_device counters_mem_24172 = ctx->constants->counters_mem_24172;
    int64_t replicate_n_23524 = num_elems_23521;
    int64_t tblock_sizze_23529;
    
    tblock_sizze_23529 = *ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_23529;
    
    int64_t virt_num_tblocks_23530 = sdiv_up64(replicate_n_23524, tblock_sizze_23529);
    int64_t num_tblocks_23531 = smin64(virt_num_tblocks_23530, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i8zireplicate_23525(ctx, num_tblocks_23531, 1, 1, tblock_sizze_23529, 1, 1, (int64_t) 0, num_elems_23521, val_23522, replicate_n_23524, virt_num_tblocks_23530, num_tblocks_23531, mem_23520.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_main(struct futhark_context *ctx, struct memblock_device *mem_out_p_24363, int64_t *out_prim_out_24364, struct memblock_device gates_mem_23045, struct memblock_device cQ_mem_23046, struct memblock_device tQ_mem_23047, int64_t n_14545, int32_t seed_14546, int64_t num_qubits_14547)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_23077;
    
    mem_23077.references = NULL;
    
    struct memblock_device mem_23070;
    
    mem_23070.references = NULL;
    
    struct memblock_device mem_23069;
    
    mem_23069.references = NULL;
    
    struct memblock_device mem_23068;
    
    mem_23068.references = NULL;
    
    struct memblock_device mem_23067;
    
    mem_23067.references = NULL;
    
    struct memblock_device mem_23066;
    
    mem_23066.references = NULL;
    
    struct memblock_device mem_23065;
    
    mem_23065.references = NULL;
    
    struct memblock_device mem_23064;
    
    mem_23064.references = NULL;
    
    struct memblock_device mem_23063;
    
    mem_23063.references = NULL;
    
    struct memblock_device mem_23062;
    
    mem_23062.references = NULL;
    
    struct memblock_device mem_23090;
    
    mem_23090.references = NULL;
    
    struct memblock_device mem_23083;
    
    mem_23083.references = NULL;
    
    struct memblock_device mem_23082;
    
    mem_23082.references = NULL;
    
    struct memblock_device mem_23081;
    
    mem_23081.references = NULL;
    
    struct memblock_device mem_23080;
    
    mem_23080.references = NULL;
    
    struct memblock_device mem_23079;
    
    mem_23079.references = NULL;
    
    struct memblock_device mem_23103;
    
    mem_23103.references = NULL;
    
    struct memblock_device mem_23096;
    
    mem_23096.references = NULL;
    
    struct memblock_device mem_23095;
    
    mem_23095.references = NULL;
    
    struct memblock_device mem_23094;
    
    mem_23094.references = NULL;
    
    struct memblock_device mem_23093;
    
    mem_23093.references = NULL;
    
    struct memblock_device mem_23092;
    
    mem_23092.references = NULL;
    
    struct memblock_device mem_23146;
    
    mem_23146.references = NULL;
    
    struct memblock_device mem_23144;
    
    mem_23144.references = NULL;
    
    struct memblock_device segred_tmp_mem_24170;
    
    segred_tmp_mem_24170.references = NULL;
    
    struct memblock_device mem_23143;
    
    mem_23143.references = NULL;
    
    struct memblock_device mem_23141;
    
    mem_23141.references = NULL;
    
    struct memblock_device mem_23132;
    
    mem_23132.references = NULL;
    
    struct memblock_device mem_23131;
    
    mem_23131.references = NULL;
    
    struct memblock_device mem_23159;
    
    mem_23159.references = NULL;
    
    struct memblock_device segred_tmp_mem_24080;
    
    segred_tmp_mem_24080.references = NULL;
    
    struct memblock_device mem_23440;
    
    mem_23440.references = NULL;
    
    struct memblock_device color_23358;
    
    color_23358.references = NULL;
    
    struct memblock_device mem_23189;
    
    mem_23189.references = NULL;
    
    struct memblock_device mem_23156;
    
    mem_23156.references = NULL;
    
    struct memblock_device ext_mem_23192;
    
    ext_mem_23192.references = NULL;
    
    struct memblock_device mem_23128;
    
    mem_23128.references = NULL;
    
    struct memblock_device mem_23126;
    
    mem_23126.references = NULL;
    
    struct memblock_device mem_23124;
    
    mem_23124.references = NULL;
    
    struct memblock_device mem_23122;
    
    mem_23122.references = NULL;
    
    struct memblock_device mem_23119;
    
    mem_23119.references = NULL;
    
    struct memblock_device mem_23308;
    
    mem_23308.references = NULL;
    
    struct memblock_device mem_23248;
    
    mem_23248.references = NULL;
    
    struct memblock_device mem_23243;
    
    mem_23243.references = NULL;
    
    struct memblock_device mem_23246;
    
    mem_23246.references = NULL;
    
    struct memblock_device segred_tmp_mem_23819;
    
    segred_tmp_mem_23819.references = NULL;
    
    struct memblock_device mem_23237;
    
    mem_23237.references = NULL;
    
    struct memblock_device mem_23235;
    
    mem_23235.references = NULL;
    
    struct memblock_device mem_23226;
    
    mem_23226.references = NULL;
    
    struct memblock_device mem_23251;
    
    mem_23251.references = NULL;
    
    struct memblock_device segred_tmp_mem_23726;
    
    segred_tmp_mem_23726.references = NULL;
    
    struct memblock_device mem_23393;
    
    mem_23393.references = NULL;
    
    struct memblock_device color_23357;
    
    color_23357.references = NULL;
    
    struct memblock_device mem_23301;
    
    mem_23301.references = NULL;
    
    struct memblock_device mem_23290;
    
    mem_23290.references = NULL;
    
    struct memblock_device ext_mem_23302;
    
    ext_mem_23302.references = NULL;
    
    struct memblock_device ext_mem_23305;
    
    ext_mem_23305.references = NULL;
    
    struct memblock_device mem_23223;
    
    mem_23223.references = NULL;
    
    struct memblock_device mem_23210;
    
    mem_23210.references = NULL;
    
    struct memblock_device mem_23221;
    
    mem_23221.references = NULL;
    
    struct memblock_device mem_23219;
    
    mem_23219.references = NULL;
    
    struct memblock_device mem_23215;
    
    mem_23215.references = NULL;
    
    struct memblock_device mem_23214;
    
    mem_23214.references = NULL;
    
    struct memblock_device mem_23213;
    
    mem_23213.references = NULL;
    
    struct memblock_device mem_23212;
    
    mem_23212.references = NULL;
    
    struct memblock_device mem_23211;
    
    mem_23211.references = NULL;
    
    struct memblock_device mem_23110;
    
    mem_23110.references = NULL;
    
    struct memblock_device segred_tmp_mem_23564;
    
    segred_tmp_mem_23564.references = NULL;
    
    struct memblock_device segred_tmp_mem_23562;
    
    segred_tmp_mem_23562.references = NULL;
    
    struct memblock_device mem_23109;
    
    mem_23109.references = NULL;
    
    struct memblock_device mem_23108;
    
    mem_23108.references = NULL;
    
    struct memblock_device mem_23106;
    
    mem_23106.references = NULL;
    
    struct memblock_device mem_23105;
    
    mem_23105.references = NULL;
    
    struct memblock_device mem_23061;
    
    mem_23061.references = NULL;
    
    struct memblock_device mem_23053;
    
    mem_23053.references = NULL;
    
    struct memblock_device mem_23052;
    
    mem_23052.references = NULL;
    
    struct memblock_device segred_tmp_mem_23478;
    
    segred_tmp_mem_23478.references = NULL;
    
    struct memblock_device mem_23049;
    
    mem_23049.references = NULL;
    
    struct memblock_device mem_out_23452;
    
    mem_out_23452.references = NULL;
    
    struct memblock_device counters_mem_23456 = ctx->constants->counters_mem_23456;
    struct memblock_device counters_mem_23560 = ctx->constants->counters_mem_23560;
    struct memblock_device counters_mem_23724 = ctx->constants->counters_mem_23724;
    struct memblock_device counters_mem_23821 = ctx->constants->counters_mem_23821;
    struct memblock_device counters_mem_24078 = ctx->constants->counters_mem_24078;
    struct memblock_device counters_mem_24172 = ctx->constants->counters_mem_24172;
    int64_t prim_out_23453;
    
    // definitions.fut:6:28-7:88
    
    int64_t arg_16658 = mul64((int64_t) 2, num_qubits_14547);
    
    // definitions.fut:6:28-7:88
    
    int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 = add64((int64_t) 1, arg_16658);
    int64_t segred_tblock_sizze_21399;
    
    segred_tblock_sizze_21399 = *ctx->tuning_params.mainzisegred_tblock_sizze_21398;
    
    int64_t num_tblocks_21401;
    int64_t max_num_tblocks_23454;
    
    max_num_tblocks_23454 = *ctx->tuning_params.mainzisegred_num_tblocks_21400;
    num_tblocks_21401 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(n_14545, segred_tblock_sizze_21399), max_num_tblocks_23454)));
    if (memblock_alloc_device(ctx, &mem_23049, (int64_t) 8, "mem_23049")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegRed");
    
    int64_t chunk_sizze_23455 = (int64_t) 1;
    
    if (memblock_alloc_device(ctx, &segred_tmp_mem_23478, (int64_t) 8 * num_tblocks_21401, "segred_tmp_mem_23478")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t num_threads_23480 = num_tblocks_21401 * segred_tblock_sizze_21399;
    
    // main.fut:5:33-104
    {
        err = gpu_kernel_mainzisegred_nonseg_21406(ctx, num_tblocks_21401, 1, 1, *ctx->tuning_params.mainzisegred_tblock_sizze_21398, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_21399 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_21399, (int64_t) 8), (int64_t) 8)), n_14545, num_tblocks_21401, num_threads_23480, gates_mem_23045.mem, mem_23049.mem, counters_mem_23456.mem, segred_tmp_mem_23478.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t read_res_24365;
    
    if ((err = gpu_scalar_from_device(ctx, "main.fut:53:34-70->main.fut:5:33-104", &read_res_24365, mem_23049.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
        goto cleanup;
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t defunc_0_f_res_21395 = read_res_24365;
    
    if (memblock_unref_device(ctx, &mem_23049, "mem_23049") != 0)
        return 1;
    // definitions.fut:34:6-41:35
    
    bool bounds_invalid_upwards_16671 = slt64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, (int64_t) 0);
    
    // definitions.fut:34:6-41:35
    
    bool valid_16672 = !bounds_invalid_upwards_16671;
    
    // definitions.fut:34:6-41:35
    
    bool range_valid_c_16673;
    
    if (!valid_16672) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, " is invalid.", "-> #0  definitions.fut:34:6-41:35\n   #1  main.fut:7:63-88\n   #2  main.fut:53:34-70\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t nest_sizze_21478 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;
    int64_t segmap_tblock_sizze_21479;
    
    segmap_tblock_sizze_21479 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21421;
    
    int64_t segmap_usable_groups_21480 = sdiv_up64(nest_sizze_21478, segmap_tblock_sizze_21479);
    
    // definitions.fut:34:6-41:35
    if (memblock_alloc_device(ctx, &mem_23052, nest_sizze_21478, "mem_23052")) {
        err = 1;
        goto cleanup;
    }
    // definitions.fut:34:6-41:35
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_23509 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, segmap_tblock_sizze_21479));
    
    // definitions.fut:34:6-41:35
    {
        err = gpu_kernel_mainzisegmap_21484(ctx, segmap_usable_groups_21480, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21421, 1, 1, (int64_t) 0, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, mem_23052.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    // lib/github.com/diku-dk/cpprandom/random.fut:176:29-177:46
    
    int32_t unsign_arg0_17222 = 5460 ^ seed_14546;
    
    // lib/github.com/diku-dk/cpprandom/random.fut:169:17-26
    
    int32_t unsign_arg0_16698 = mul32(48271, unsign_arg0_17222);
    
    // lib/github.com/diku-dk/cpprandom/random.fut:169:27-44
    
    int32_t unsign_arg0_17228 = umod32(unsign_arg0_16698, 2147483647);
    
    // main.fut:7:126-154
    if (memblock_alloc_device(ctx, &mem_23053, defunc_0_f_res_21395, "mem_23053")) {
        err = 1;
        goto cleanup;
    }
    // main.fut:7:126-154
    if (futrts_builtinzhreplicate_i8(ctx, mem_23053, defunc_0_f_res_21395, (int8_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    // main.fut:7:5-25:68
    
    bool loop_cond_16702 = slt64((int64_t) 0, n_14545);
    
    // definitions.fut:97:56-59
    
    int64_t map_arg1_16734 = sub64(arg_16658, (int64_t) 1);
    
    // definitions.fut:97:46-59
    
    int64_t distance_upwards_exclusive_16736 = sub64(map_arg1_16734, num_qubits_14547);
    
    // definitions.fut:97:46-59
    
    int64_t distance_16737 = add64((int64_t) 1, distance_upwards_exclusive_16736);
    
    if (memblock_alloc_device(ctx, &mem_23061, (int64_t) 8, "mem_23061")) {
        err = 1;
        goto cleanup;
    }
    // main.fut:7:5-25:68
    
    bool simulate_res_16707;
    int64_t simulate_res_16709;
    int32_t simulate_res_16710;
    int32_t simulate_res_16712;
    bool loop_while_16713;
    int64_t i_16715;
    int32_t rng_16716;
    int32_t measurement_count_16718;
    
    loop_while_16713 = loop_cond_16702;
    i_16715 = (int64_t) 0;
    rng_16716 = unsign_arg0_17228;
    measurement_count_16718 = 0;
    while (loop_while_16713) {
        // main.fut:9:37-52
        
        bool x_16719 = sle64((int64_t) 0, i_16715);
        
        // main.fut:9:37-52
        
        bool y_16720 = slt64(i_16715, n_14545);
        
        // main.fut:9:37-52
        
        bool bounds_check_16721 = x_16719 && y_16720;
        
        // main.fut:9:37-52
        
        bool index_certs_16722;
        
        if (!bounds_check_16721) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) i_16715, "] out of bounds for array of shape [", (long long) n_14545, "].", "-> #0  main.fut:9:37-52\n   #1  main.fut:53:34-70\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        // main.fut:53:34-70
        
        int64_t read_res_24366;
        
        if ((err = gpu_scalar_from_device(ctx, "main.fut:53:34-70", &read_res_24366, gates_mem_23045.mem, i_16715 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_16723 = read_res_24366;
        
        // main.fut:10:10-25:68
        
        bool cond_16726 = loopres_16723 == (int64_t) 0;
        
        // main.fut:53:34-70
        {
            err = gpu_kernel_mainzigpuseq_23546(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, i_16715, cQ_mem_23046.mem, mem_23061.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        // main.fut:15:20-71
        
        int64_t measurement_count_21197 = sext_i32_i64(measurement_count_16718);
        
        // main.fut:10:10-25:68
        
        int64_t loopres_16728;
        int32_t loopres_16729;
        int32_t loopres_16731;
        
        if (cond_16726) {
            // definitions.fut:97:46-59
            
            bool bounds_invalid_upwards_20737 = slt64(map_arg1_16734, num_qubits_14547);
            
            // definitions.fut:97:46-59
            
            bool valid_20738 = !bounds_invalid_upwards_20737;
            
            // definitions.fut:97:46-59
            
            bool range_valid_c_20739;
            
            if (!valid_20738) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) num_qubits_14547, "...", (long long) map_arg1_16734, " is invalid.", "-> #0  definitions.fut:97:46-59\n   #1  main.fut:7:78-11:83\n   #2  main.fut:53:34-70\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t segred_tblock_sizze_21498;
            
            segred_tblock_sizze_21498 = *ctx->tuning_params.mainzisegred_tblock_sizze_21497;
            
            int64_t num_tblocks_21500;
            int64_t max_num_tblocks_23552;
            
            max_num_tblocks_23552 = *ctx->tuning_params.mainzisegred_num_tblocks_21499;
            num_tblocks_21500 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(distance_16737, segred_tblock_sizze_21498), max_num_tblocks_23552)));
            // definitions.fut:132:61-67
            
            bool bounds_invalid_upwards_20778 = slt64(num_qubits_14547, (int64_t) 0);
            
            // definitions.fut:132:61-67
            
            bool valid_20779 = !bounds_invalid_upwards_20778;
            
            // definitions.fut:100:73-84
            
            bool bounds_invalid_upwards_20782 = slt64(arg_16658, (int64_t) 0);
            
            // definitions.fut:100:73-84
            
            bool valid_20783 = !bounds_invalid_upwards_20782;
            
            // definitions.fut:132:29-67
            
            bool cond_20789 = num_qubits_14547 == (int64_t) 0;
            
            // definitions.fut:132:29-67
            
            int64_t tmp_20791 = sub64(num_qubits_14547, (int64_t) 1);
            
            // definitions.fut:132:29-67
            
            bool x_20792 = sle64((int64_t) 0, tmp_20791);
            
            // definitions.fut:132:29-67
            
            bool y_20793 = slt64(tmp_20791, num_qubits_14547);
            
            // definitions.fut:132:29-67
            
            bool bounds_check_20794 = x_20792 && y_20793;
            
            // definitions.fut:132:29-67
            
            bool protect_assert_disj_20795 = cond_20789 || bounds_check_20794;
            
            // definitions.fut:100:29-85
            
            bool cond_20798 = arg_16658 == (int64_t) 0;
            
            // definitions.fut:100:29-85
            
            bool x_20800 = sle64((int64_t) 0, map_arg1_16734);
            
            // definitions.fut:100:29-85
            
            bool y_20801 = slt64(map_arg1_16734, arg_16658);
            
            // definitions.fut:100:29-85
            
            bool bounds_check_20802 = x_20800 && y_20801;
            
            // definitions.fut:100:29-85
            
            bool protect_assert_disj_20803 = cond_20798 || bounds_check_20802;
            
            // main.fut:15:20-71
            
            bool x_21198 = sle64((int64_t) 0, measurement_count_21197);
            
            // main.fut:15:20-71
            
            bool y_21199 = slt64(measurement_count_21197, defunc_0_f_res_21395);
            
            // main.fut:15:20-71
            
            bool bounds_check_21200 = x_21198 && y_21199;
            
            // main.fut:15:20-71
            
            bool index_certs_21201;
            
            if (!bounds_check_21200) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) measurement_count_21197, "] out of bounds for array of shape [", (long long) defunc_0_f_res_21395, "].", "-> #0  main.fut:15:20-71\n   #1  main.fut:53:34-70\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_23105, (int64_t) 1, "mem_23105")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_23106, (int64_t) 0, "mem_23106")) {
                err = 1;
                goto cleanup;
            }
            // definitions.fut:97:30-42
            {
                err = gpu_kernel_mainzigpuseq_23553(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, mem_23061.mem, mem_23105.mem, mem_23106.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            
            bool index_certs_20744 = 0;
            
            if (memblock_unref_device(ctx, &mem_23106, "mem_23106") != 0)
                return 1;
            if (memblock_alloc_device(ctx, &mem_23108, (int64_t) 8, "mem_23108")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_23109, (int64_t) 1, "mem_23109")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegRed");
            
            int64_t chunk_sizze_23559 = (int64_t) 1;
            
            if (memblock_alloc_device(ctx, &segred_tmp_mem_23562, (int64_t) 8 * num_tblocks_21500, "segred_tmp_mem_23562")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &segred_tmp_mem_23564, num_tblocks_21500, "segred_tmp_mem_23564")) {
                err = 1;
                goto cleanup;
            }
            
            int64_t num_threads_23566 = num_tblocks_21500 * segred_tblock_sizze_21498;
            
            // definitions.fut:97:12-60
            {
                err = gpu_kernel_mainzisegred_nonseg_21506(ctx, num_tblocks_21500, 1, 1, *ctx->tuning_params.mainzisegred_tblock_sizze_21497, 1, 1, 8 + (segred_tblock_sizze_21498 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_21498, (int64_t) 8), (int64_t) 8)) + ((int64_t) 8 * segred_tblock_sizze_21498 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_21498, (int64_t) 8), (int64_t) 8)), num_qubits_14547, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, distance_16737, num_tblocks_21500, num_threads_23566, mem_23052.mem, mem_23061.mem, mem_23108.mem, mem_23109.mem, counters_mem_23560.mem, segred_tmp_mem_23562.mem, segred_tmp_mem_23564.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            
            int8_t read_res_24367;
            
            if ((err = gpu_scalar_from_device(ctx, "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:97:12-60", &read_res_24367, mem_23109.mem, (int64_t) 0 * sizeof(int8_t), sizeof(int8_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int8_t defunc_0_f_res_20746 = read_res_24367;
            
            if (memblock_unref_device(ctx, &mem_23109, "mem_23109") != 0)
                return 1;
            // definitions.fut:98:6-135:49
            
            bool cond_20775 = defunc_0_f_res_20746 == (int8_t) 1;
            
            // main.fut:7:78-11:83
            
            bool protect_assert_disj_20776 = valid_16672 || cond_20775;
            
            // definitions.fut:128:47-59
            
            bool range_valid_c_20777;
            
            if (!protect_assert_disj_20776) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, " is invalid.", "-> #0  definitions.fut:128:47-59\n   #1  main.fut:7:78-11:83\n   #2  main.fut:53:34-70\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            // main.fut:7:78-11:83
            
            bool protect_assert_disj_20780 = cond_20775 || valid_20779;
            
            // definitions.fut:132:61-67
            
            bool range_valid_c_20781;
            
            if (!protect_assert_disj_20780) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) num_qubits_14547, " is invalid.", "-> #0  definitions.fut:132:61-67\n   #1  main.fut:7:78-11:83\n   #2  main.fut:53:34-70\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            // main.fut:7:78-11:83
            
            bool loop_not_taken_20784 = !cond_20775;
            
            // main.fut:7:78-11:83
            
            bool protect_assert_disj_20785 = valid_20783 || loop_not_taken_20784;
            
            // definitions.fut:100:73-84
            
            bool range_valid_c_20786;
            
            if (!protect_assert_disj_20785) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) arg_16658, " is invalid.", "-> #0  definitions.fut:100:73-84\n   #1  main.fut:7:78-11:83\n   #2  main.fut:53:34-70\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool protect_assert_disj_20796 = cond_20775 || protect_assert_disj_20795;
            
            // definitions.fut:132:29-67
            
            bool index_certs_20797;
            
            if (!protect_assert_disj_20796) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_20791, "] out of bounds for array of shape [", (long long) num_qubits_14547, "].", "-> #0  definitions.fut:132:29-67\n   #1  main.fut:7:78-11:83\n   #2  main.fut:53:34-70\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool protect_assert_disj_20804 = loop_not_taken_20784 || protect_assert_disj_20803;
            
            // definitions.fut:100:29-85
            
            bool index_certs_20805;
            
            if (!protect_assert_disj_20804) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) map_arg1_16734, "] out of bounds for array of shape [", (long long) arg_16658, "].", "-> #0  definitions.fut:100:29-85\n   #1  main.fut:7:78-11:83\n   #2  main.fut:53:34-70\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            // definitions.fut:26:18-36
            
            bool y_20865 = slt64(arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);
            bool protect_assert_disj_23033 = loop_not_taken_20784 || y_20865;
            
            // definitions.fut:26:18-36
            
            bool index_certs_20866;
            
            if (!protect_assert_disj_23033) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) arg_16658, "] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, "].", "-> #0  definitions.fut:26:18-36\n   #1  definitions.fut:89:58-103:37\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            // definitions.fut:132:29-67
            
            bool x_20790 = !cond_20789;
            
            // definitions.fut:100:29-85
            
            bool x_20799 = !cond_20798;
            int64_t segmap_tblock_sizze_22035;
            
            segmap_tblock_sizze_22035 = *ctx->tuning_params.mainzisegmap_tblock_sizze_22024;
            
            int64_t num_tblocks_22036;
            int64_t max_num_tblocks_23611;
            
            max_num_tblocks_23611 = *ctx->tuning_params.mainzisegmap_num_tblocks_22026;
            num_tblocks_22036 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, segmap_tblock_sizze_22035), max_num_tblocks_23611)));
            
            int64_t segscan_tblock_sizze_22046;
            
            segscan_tblock_sizze_22046 = *ctx->tuning_params.mainzisegscan_tblock_sizze_22045;
            
            int64_t num_tblocks_22048;
            int64_t max_num_tblocks_23612;
            
            max_num_tblocks_23612 = *ctx->tuning_params.mainzisegscan_num_tblocks_22047;
            num_tblocks_22048 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(num_qubits_14547, segscan_tblock_sizze_22046), max_num_tblocks_23612)));
            
            int64_t segscan_tblock_sizze_21509;
            
            segscan_tblock_sizze_21509 = *ctx->tuning_params.mainzisegscan_tblock_sizze_21508;
            
            int64_t num_tblocks_21511;
            int64_t max_num_tblocks_23613;
            
            max_num_tblocks_23613 = *ctx->tuning_params.mainzisegscan_num_tblocks_21510;
            num_tblocks_21511 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_16658, segscan_tblock_sizze_21509), max_num_tblocks_23613)));
            // main.fut:13:22-25
            
            int64_t tmp_21196 = add64((int64_t) 1, i_16715);
            
            // main.fut:16:38-41
            
            int32_t tmp_21203 = add32(1, measurement_count_16718);
            
            if (memblock_alloc_device(ctx, &mem_23110, (int64_t) 0, "mem_23110")) {
                err = 1;
                goto cleanup;
            }
            // definitions.fut:132:43-53
            {
                err = gpu_kernel_mainzigpuseq_23614(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, cond_20775, mem_23061.mem, mem_23105.mem, mem_23110.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (memblock_unref_device(ctx, &mem_23105, "mem_23105") != 0)
                return 1;
            // lib/github.com/diku-dk/cpprandom/random.fut:169:17-26
            
            int32_t unsign_arg0_21001 = mul32(48271, rng_16716);
            
            // lib/github.com/diku-dk/cpprandom/random.fut:169:27-44
            
            int32_t unsign_arg0_21002 = umod32(unsign_arg0_21001, 2147483647);
            
            // lib/github.com/diku-dk/cpprandom/random.fut:533:15-535:27
            
            bool zgze_res_21003 = ule32(2147483646, unsign_arg0_21002);
            bool x_23034;
            int32_t x_23035;
            int32_t x_23036;
            bool loop_while_21007;
            int32_t rng_21008;
            int32_t x_21009;
            
            loop_while_21007 = zgze_res_21003;
            rng_21008 = unsign_arg0_21002;
            x_21009 = unsign_arg0_21002;
            while (loop_while_21007) {
                // lib/github.com/diku-dk/cpprandom/random.fut:169:17-26
                
                int32_t unsign_arg0_21010 = mul32(48271, rng_21008);
                
                // lib/github.com/diku-dk/cpprandom/random.fut:169:27-44
                
                int32_t unsign_arg0_21011 = umod32(unsign_arg0_21010, 2147483647);
                
                // lib/github.com/diku-dk/cpprandom/random.fut:534:21-36
                
                bool zgze_res_21012 = ule32(2147483646, unsign_arg0_21011);
                bool loop_while_tmp_23620 = zgze_res_21012;
                int32_t rng_tmp_23621 = unsign_arg0_21011;
                int32_t x_tmp_23622 = unsign_arg0_21011;
                
                loop_while_21007 = loop_while_tmp_23620;
                rng_21008 = rng_tmp_23621;
                x_21009 = x_tmp_23622;
            }
            x_23034 = loop_while_21007;
            x_23035 = rng_21008;
            x_23036 = x_21009;
            // lib/github.com/diku-dk/cpprandom/random.fut:536:38-47
            
            int32_t unsign_arg0_21013 = umod32(x_23036, 2);
            
            // lib/github.com/diku-dk/cpprandom/random.fut:510:23-50
            
            int8_t u64_res_21014 = zext_i32_i8(unsign_arg0_21013);
            int32_t Measurement_res_20806;
            
            if (cond_20775) {
                Measurement_res_20806 = x_23035;
            } else {
                Measurement_res_20806 = rng_16716;
            }
            
            bool index_certs_20788;
            
            if (loop_not_taken_20784) {
                bool x_23043 = 0;
                
                index_certs_20788 = x_23043;
            } else {
                index_certs_20788 = 0;
            }
            if (memblock_unref_device(ctx, &mem_23110, "mem_23110") != 0)
                return 1;
            
            int64_t bytes_23118 = (int64_t) 8 * num_qubits_14547;
            int64_t bytes_23121 = (int64_t) 16 * num_qubits_14547;
            
            // definitions.fut:28:12-52
            
            int64_t binop_x_23203 = smax64((int64_t) 0, tmp_20791);
            
            // definitions.fut:28:12-52
            
            int64_t binop_y_23206 = smax64((int64_t) 0, num_qubits_14547);
            
            // definitions.fut:28:12-52
            
            int64_t binop_y_23207 = binop_x_23203 + binop_y_23206;
            
            // definitions.fut:28:12-52
            
            int64_t binop_y_23208 = (int64_t) 1 + binop_y_23207;
            
            // definitions.fut:28:12-52
            
            int64_t bytes_23209 = (int64_t) 8 * binop_y_23208;
            
            if (cond_20775) {
                // definitions.fut:25:92-98
                
                bool range_valid_c_20859;
                
                if (!valid_20779) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) num_qubits_14547, " is invalid.", "-> #0  definitions.fut:25:92-98\n   #1  definitions.fut:89:58-103:37\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23211, (int64_t) 8, "mem_23211")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23212, (int64_t) 0, "mem_23212")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23213, (int64_t) 1, "mem_23213")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23214, (int64_t) 8, "mem_23214")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23215, (int64_t) 8, "mem_23215")) {
                    err = 1;
                    goto cleanup;
                }
                // definitions.fut:89:58-117:34
                {
                    err = gpu_kernel_mainzigpuseq_23623(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, num_qubits_14547, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, u64_res_21014, measurement_count_21197, mem_23052.mem, mem_23053.mem, mem_23061.mem, mem_23108.mem, mem_23211.mem, mem_23212.mem, mem_23213.mem, mem_23214.mem, mem_23215.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
                if (memblock_alloc_device(ctx, &mem_23219, bytes_23121, "mem_23219")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23221, bytes_23121, "mem_23221")) {
                    err = 1;
                    goto cleanup;
                }
                if (slt64((int64_t) 0, arg_16658)) {
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegScan");
                    
                    int64_t stage1_max_num_tblocks_23629;
                    
                    stage1_max_num_tblocks_23629 = ctx->max_thread_block_size;
                    
                    int64_t stage1_num_tblocks_23630 = smin64(stage1_max_num_tblocks_23629, num_tblocks_21511);
                    int32_t num_threads_23631 = sext_i64_i32(stage1_num_tblocks_23630 * segscan_tblock_sizze_21509);
                    
                    // definitions.fut:100:29-85
                    {
                        err = gpu_kernel_mainziscan_stage1_21514(ctx, stage1_num_tblocks_23630, 1, 1, *ctx->tuning_params.mainzisegscan_tblock_sizze_21508, 1, 1, smax64((int64_t) 1, (int64_t) 8 * segscan_tblock_sizze_21509) + srem64((int64_t) 8 - srem64(smax64((int64_t) 1, (int64_t) 8 * segscan_tblock_sizze_21509), (int64_t) 8), (int64_t) 8), arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, num_threads_23631, mem_23052.mem, mem_23061.mem, mem_23211.mem, mem_23219.mem, mem_23221.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "elems_per_group", (long long) (segscan_tblock_sizze_21509 * sdiv_up64(arg_16658, sext_i32_i64(num_threads_23631))), '\n');
                    // definitions.fut:100:29-85
                    {
                        err = gpu_kernel_mainziscan_stage2_21514(ctx, (int64_t) 1, 1, 1, stage1_num_tblocks_23630, 1, 1, smax64((int64_t) 1, (int64_t) 8 * stage1_num_tblocks_23630) + srem64((int64_t) 8 - srem64(smax64((int64_t) 1, (int64_t) 8 * stage1_num_tblocks_23630), (int64_t) 8), (int64_t) 8), arg_16658, stage1_num_tblocks_23630, num_threads_23631, mem_23219.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    
                    int32_t required_groups_23676 = sext_i64_i32(sdiv_up64(arg_16658, segscan_tblock_sizze_21509));
                    
                    // definitions.fut:100:29-85
                    {
                        err = gpu_kernel_mainziscan_stage3_21514(ctx, num_tblocks_21511, 1, 1, *ctx->tuning_params.mainzisegscan_tblock_sizze_21508, 1, 1, (int64_t) 0, arg_16658, num_tblocks_21511, num_threads_23631, required_groups_23676, mem_23219.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                }
                // definitions.fut:100:29-85
                
                int64_t m_f_res_20838;
                
                if (x_20799) {
                    // definitions.fut:100:29-85
                    
                    int64_t read_res_24368;
                    
                    if ((err = gpu_scalar_from_device(ctx, "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:100:29-85", &read_res_24368, mem_23219.mem, map_arg1_16734 * sizeof(int64_t), sizeof(int64_t))) != 0)
                        goto cleanup;
                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t x_20839 = read_res_24368;
                    
                    m_f_res_20838 = x_20839;
                } else {
                    m_f_res_20838 = (int64_t) 0;
                }
                // definitions.fut:100:29-85
                
                int64_t m_20840;
                
                if (cond_20798) {
                    m_20840 = (int64_t) 0;
                } else {
                    m_20840 = m_f_res_20838;
                }
                // definitions.fut:100:29-85
                
                int64_t bytes_23222 = (int64_t) 8 * m_20840;
                int64_t segmap_tblock_sizze_21534;
                
                segmap_tblock_sizze_21534 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21518;
                
                int64_t num_tblocks_21535;
                int64_t max_num_tblocks_23689;
                
                max_num_tblocks_23689 = *ctx->tuning_params.mainzisegmap_num_tblocks_21520;
                num_tblocks_21535 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_16658, segmap_tblock_sizze_21534), max_num_tblocks_23689)));
                
                int64_t segmap_tblock_sizze_21562;
                
                segmap_tblock_sizze_21562 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21551;
                
                int64_t num_tblocks_21563;
                int64_t max_num_tblocks_23690;
                
                max_num_tblocks_23690 = *ctx->tuning_params.mainzisegmap_num_tblocks_21553;
                num_tblocks_21563 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(num_qubits_14547, segmap_tblock_sizze_21562), max_num_tblocks_23690)));
                // definitions.fut:28:12-52
                if (memblock_alloc_device(ctx, &mem_23210, bytes_23209, "mem_23210")) {
                    err = 1;
                    goto cleanup;
                }
                // definitions.fut:28:12-52
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_23691 = sext_i64_i32(sdiv_up64(num_qubits_14547, segmap_tblock_sizze_21562));
                
                // definitions.fut:28:12-52
                {
                    err = gpu_kernel_mainzisegmap_21567(ctx, num_tblocks_21563, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21551, 1, 1, (int64_t) 0, num_qubits_14547, num_tblocks_21563, virt_num_tblocks_23691, mem_23210.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                
                int64_t segmap_tblock_sizze_21817;
                
                segmap_tblock_sizze_21817 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21806;
                
                int64_t segred_tblock_sizze_21829;
                
                segred_tblock_sizze_21829 = *ctx->tuning_params.mainzisegred_tblock_sizze_21751;
                
                int64_t segmap_tblock_sizze_21880;
                
                segmap_tblock_sizze_21880 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21732;
                
                int64_t segmap_tblock_sizze_21645;
                
                segmap_tblock_sizze_21645 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21576;
                
                int64_t segmap_tblock_sizze_21926;
                
                segmap_tblock_sizze_21926 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21913;
                
                int64_t segmap_tblock_sizze_21952;
                
                segmap_tblock_sizze_21952 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21940;
                
                int64_t segmap_usable_groups_21953 = sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, segmap_tblock_sizze_21952);
                int64_t segmap_tblock_sizze_21978;
                
                segmap_tblock_sizze_21978 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21966;
                
                int64_t num_tblocks_21979;
                int64_t max_num_tblocks_23704;
                
                max_num_tblocks_23704 = *ctx->tuning_params.mainzisegmap_num_tblocks_21968;
                num_tblocks_21979 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, segmap_tblock_sizze_21978), max_num_tblocks_23704)));
                
                int64_t segmap_tblock_sizze_22007;
                
                segmap_tblock_sizze_22007 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21991;
                
                int64_t num_tblocks_22008;
                int64_t max_num_tblocks_23705;
                
                max_num_tblocks_23705 = *ctx->tuning_params.mainzisegmap_num_tblocks_21993;
                num_tblocks_22008 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, segmap_tblock_sizze_22007), max_num_tblocks_23705)));
                // definitions.fut:100:29-85
                if (memblock_alloc_device(ctx, &mem_23223, bytes_23222, "mem_23223")) {
                    err = 1;
                    goto cleanup;
                }
                // definitions.fut:100:29-85
                
                bool acc_cert_20844;
                
                // definitions.fut:100:29-85
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_23706 = sext_i64_i32(sdiv_up64(arg_16658, segmap_tblock_sizze_21534));
                
                // definitions.fut:100:29-85
                {
                    err = gpu_kernel_mainzisegmap_21539(ctx, num_tblocks_21535, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21518, 1, 1, (int64_t) 0, arg_16658, m_20840, num_tblocks_21535, virt_num_tblocks_23706, mem_23219.mem, mem_23221.mem, mem_23223.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23219, "mem_23219") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23221, "mem_23221") != 0)
                    return 1;
                // main.fut:7:78-11:83
                
                int64_t dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20858 = mul64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_20840);
                bool index_certs_20864 = 0;
                
                if (memblock_unref_device(ctx, &mem_23212, "mem_23212") != 0)
                    return 1;
                
                bool suff_outer_par_21572;
                
                suff_outer_par_21572 = *ctx->tuning_params.mainzisuff_outer_par_0 <= m_20840;
                if (ctx->logging)
                    fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "main.suff_outer_par_0", (long) m_20840, suff_outer_par_21572 ? "true" : "false");
                
                int64_t nest_sizze_21828 = num_qubits_14547 * m_20840;
                int64_t num_tblocks_21830;
                int64_t max_num_tblocks_23719;
                
                max_num_tblocks_23719 = *ctx->tuning_params.mainzisegred_num_tblocks_21753;
                num_tblocks_21830 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_21828, segred_tblock_sizze_21829), max_num_tblocks_23719)));
                
                int64_t num_tblocks_21646;
                int64_t max_num_tblocks_23720;
                
                max_num_tblocks_23720 = *ctx->tuning_params.mainzisegmap_num_tblocks_21578;
                num_tblocks_21646 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_20840, segmap_tblock_sizze_21645), max_num_tblocks_23720)));
                
                int64_t ext_23304;
                int64_t shared_memory_capacity_23721;
                
                shared_memory_capacity_23721 = ctx->max_shared_memory;
                if (suff_outer_par_21572) {
                    ext_23304 = (int64_t) 1;
                } else {
                    ext_23304 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;
                }
                
                int64_t ext_23303;
                int64_t shared_memory_capacity_23722;
                
                shared_memory_capacity_23722 = ctx->max_shared_memory;
                if (suff_outer_par_21572) {
                    ext_23303 = m_20840;
                } else {
                    ext_23303 = (int64_t) 1;
                }
                
                int64_t bytes_23234 = (int64_t) 2 * nest_sizze_21828;
                int64_t binop_x_23244 = (int64_t) 8 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;
                int64_t bytes_23245 = m_20840 * binop_x_23244;
                
                // definitions.fut:23:79-104:29
                
                int64_t binop_y_23281 = m_20840 - (int64_t) 1;
                
                // definitions.fut:23:79-104:29
                
                int64_t binop_x_23283 = smax64((int64_t) 0, binop_y_23281);
                
                // definitions.fut:23:79-104:29
                
                int64_t binop_x_23285 = smax64((int64_t) 0, arg_16658);
                
                // definitions.fut:23:79-104:29
                
                int64_t binop_y_23286 = m_20840 * binop_x_23285;
                
                // definitions.fut:23:79-104:29
                
                int64_t binop_y_23287 = smax64((int64_t) 0, binop_y_23286);
                
                // definitions.fut:23:79-104:29
                
                int64_t binop_y_23288 = binop_x_23283 + binop_y_23287;
                
                // definitions.fut:23:79-104:29
                
                int64_t bytes_23289 = (int64_t) 1 + binop_y_23288;
                
                // definitions.fut:23:79-104:29
                
                int64_t bytes_23300 = (int64_t) 8 * bytes_23289;
                int64_t num_threads_23359 = segmap_tblock_sizze_21645 * num_tblocks_21646;
                int64_t total_sizze_23360 = arg_16658 * num_threads_23359;
                int64_t segred_num_tblocks_23369;
                
                segred_num_tblocks_23369 = *ctx->tuning_params.mainzisegred_num_tblocks_23368;
                
                int64_t segred_tblock_sizze_23371;
                
                segred_tblock_sizze_23371 = *ctx->tuning_params.mainzisegred_tblock_sizze_23370;
                
                int64_t ctx_23400 = (int64_t) 2 * num_threads_23359;
                int64_t shared_memory_capacity_23929;
                
                shared_memory_capacity_23929 = ctx->max_shared_memory;
                if (suff_outer_par_21572 && (sle64(sdiv_up64((int64_t) 8 * segred_tblock_sizze_23371, (int64_t) 8) * (int64_t) 8 + (int64_t) 8, shared_memory_capacity_23929) && sle64((int64_t) 0, shared_memory_capacity_23929))) {
                    // definitions.fut:23:79-104:29
                    if (memblock_alloc_device(ctx, &mem_23290, bytes_23289, "mem_23290")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:23:79-104:29
                    if (memblock_alloc_device(ctx, &mem_23301, bytes_23300, "mem_23301")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &color_23357, total_sizze_23360, "color_23357")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23393, (int64_t) 8, "mem_23393")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_23723 = (int64_t) 1;
                    
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_23726, (int64_t) 8 * segred_num_tblocks_23369, "segred_tmp_mem_23726")) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t num_threads_23728 = segred_num_tblocks_23369 * segred_tblock_sizze_23371;
                    
                    // definitions.fut:25:17-29:98
                    {
                        err = gpu_kernel_mainzisegred_nonseg_23378(ctx, segred_num_tblocks_23369, 1, 1, *ctx->tuning_params.mainzisegred_tblock_sizze_23370, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_23371 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_23371, (int64_t) 8), (int64_t) 8)), num_qubits_14547, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_20840, num_threads_23728, mem_23223.mem, mem_23393.mem, counters_mem_23724.mem, segred_tmp_mem_23726.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    
                    int64_t read_res_24369;
                    
                    if ((err = gpu_scalar_from_device(ctx, "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-103:37->definitions.fut:25:17-29:98", &read_res_24369, mem_23393.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
                        goto cleanup;
                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t max_per_thread_23365 = read_res_24369;
                    
                    if (memblock_unref_device(ctx, &mem_23393, "mem_23393") != 0)
                        return 1;
                    
                    int64_t sizze_sum_23389 = num_threads_23359 * max_per_thread_23365;
                    
                    if (memblock_alloc_device(ctx, &mem_23251, sizze_sum_23389, "mem_23251")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:23:79-104:29
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_23757 = sext_i64_i32(sdiv_up64(m_20840, segmap_tblock_sizze_21645));
                    
                    // definitions.fut:23:79-104:29
                    {
                        err = gpu_kernel_mainzisegmap_21651(ctx, num_tblocks_21646, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21576, 1, 1, (int64_t) 0, num_qubits_14547, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_20840, num_tblocks_21646, num_threads_23359, ctx_23400, virt_num_tblocks_23757, mem_23052.mem, mem_23211.mem, mem_23213.mem, mem_23223.mem, mem_23251.mem, mem_23290.mem, mem_23301.mem, color_23357.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23251, "mem_23251") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &color_23357, "color_23357") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23305, &mem_23290, "mem_23290") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23302, &mem_23301, "mem_23301") != 0)
                        return 1;
                } else {
                    int64_t segmap_usable_groups_21818 = sdiv_up64(m_20840, segmap_tblock_sizze_21817);
                    
                    // definitions.fut:23:79-104:29
                    if (memblock_alloc_device(ctx, &mem_23226, (int64_t) 0, "mem_23226")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:23:79-104:29
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_23777 = sext_i64_i32(sdiv_up64(m_20840, segmap_tblock_sizze_21817));
                    
                    // definitions.fut:25:73-82
                    {
                        err = gpu_kernel_mainzisegmap_21821(ctx, segmap_usable_groups_21818, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21806, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_20840, mem_23223.mem, mem_23226.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_alloc_device(ctx, &mem_23235, bytes_23234, "mem_23235")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:23:79-104:29
                    if (memblock_alloc_device(ctx, &mem_23237, m_20840, "mem_23237")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_23786 = (int64_t) 1;
                    
                    if (slt64(num_qubits_14547 * (int64_t) 2, segred_tblock_sizze_21829 * chunk_sizze_23786)) {
                        int64_t segment_sizze_nonzzero_23787 = smax64((int64_t) 1, num_qubits_14547);
                        int64_t num_threads_23788 = num_tblocks_21830 * segred_tblock_sizze_21829;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-small");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) m_20840, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_qubits_14547, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_21829, segment_sizze_nonzzero_23787), '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(m_20840, squot64(segred_tblock_sizze_21829, segment_sizze_nonzzero_23787))), '\n');
                        // definitions.fut:25:17-29:98
                        {
                            err = gpu_kernel_mainzisegred_small_21836(ctx, num_tblocks_21830, 1, 1, *ctx->tuning_params.mainzisegred_tblock_sizze_21751, 1, 1, segred_tblock_sizze_21829 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_21829, (int64_t) 8), (int64_t) 8), num_qubits_14547, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_20840, num_tblocks_21830, segment_sizze_nonzzero_23787, mem_23052.mem, mem_23211.mem, mem_23223.mem, mem_23226.mem, mem_23235.mem, mem_23237.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                    } else {
                        int64_t blocks_per_segment_23815 = sdiv_up64(num_tblocks_21830, smax64((int64_t) 1, m_20840));
                        int64_t q_23816 = sdiv_up64(num_qubits_14547, segred_tblock_sizze_21829 * blocks_per_segment_23815 * chunk_sizze_23786);
                        int64_t num_virtblocks_23817 = blocks_per_segment_23815 * m_20840;
                        int64_t threads_per_segment_23818 = blocks_per_segment_23815 * segred_tblock_sizze_21829;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-large");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) m_20840, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_qubits_14547, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_23817, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_21830, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_21829, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_23816, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_23815, '\n');
                        if (memblock_alloc_device(ctx, &segred_tmp_mem_23819, num_virtblocks_23817, "segred_tmp_mem_23819")) {
                            err = 1;
                            goto cleanup;
                        }
                        // definitions.fut:25:17-29:98
                        {
                            err = gpu_kernel_mainzisegred_large_21836(ctx, num_tblocks_21830, 1, 1, *ctx->tuning_params.mainzisegred_tblock_sizze_21751, 1, 1, 8 + (segred_tblock_sizze_21829 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_21829, (int64_t) 8), (int64_t) 8)), num_qubits_14547, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_20840, num_tblocks_21830, blocks_per_segment_23815, q_23816, num_virtblocks_23817, threads_per_segment_23818, mem_23052.mem, mem_23211.mem, mem_23223.mem, mem_23226.mem, mem_23235.mem, mem_23237.mem, segred_tmp_mem_23819.mem, counters_mem_23821.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    
                    int64_t segmap_usable_groups_21881 = sdiv_up64(m_20840, segmap_tblock_sizze_21880);
                    
                    // definitions.fut:23:79-104:29
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_23858 = sext_i64_i32(sdiv_up64(m_20840, segmap_tblock_sizze_21880));
                    
                    // definitions.fut:89:58-103:37
                    {
                        err = gpu_kernel_mainzisegmap_21884(ctx, segmap_usable_groups_21881, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21732, 1, 1, (int64_t) 0, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_20840, mem_23052.mem, mem_23213.mem, mem_23223.mem, mem_23226.mem, mem_23237.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23226, "mem_23226") != 0)
                        return 1;
                    if (memblock_alloc_device(ctx, &mem_23246, bytes_23245, "mem_23246")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:89:58-103:37
                    
                    int64_t replicate_n_23867 = arg_16658 * m_20840;
                    int64_t tblock_sizze_23872;
                    
                    tblock_sizze_23872 = *ctx->tuning_params.mainzitblock_sizze_23872;
                    
                    int64_t virt_num_tblocks_23873 = sdiv_up64(replicate_n_23867, tblock_sizze_23872);
                    int64_t num_tblocks_23874 = smin64(virt_num_tblocks_23873, (int64_t) 1048576);
                    
                    {
                        err = gpu_kernel_mainzireplicate_23868(ctx, num_tblocks_23874, 1, 1, tblock_sizze_23872, 1, 1, (int64_t) 0, arg_16658, m_20840, replicate_n_23867, virt_num_tblocks_23873, num_tblocks_23874, mem_23223.mem, mem_23246.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    // definitions.fut:89:58-103:37
                    
                    int64_t replicate_n_23887 = m_20840;
                    int64_t tblock_sizze_23892;
                    
                    tblock_sizze_23892 = *ctx->tuning_params.mainzitblock_sizze_23892;
                    
                    int64_t virt_num_tblocks_23893 = sdiv_up64(replicate_n_23887, tblock_sizze_23892);
                    int64_t num_tblocks_23894 = smin64(virt_num_tblocks_23893, (int64_t) 1048576);
                    
                    {
                        err = gpu_kernel_mainzireplicate_23888(ctx, num_tblocks_23894, 1, 1, tblock_sizze_23892, 1, 1, (int64_t) 0, arg_16658, m_20840, replicate_n_23887, virt_num_tblocks_23893, num_tblocks_23894, mem_23223.mem, mem_23246.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    // definitions.fut:89:58-103:37
                    if (memblock_alloc_device(ctx, &mem_23243, m_20840, "mem_23243")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:89:58-103:37
                    
                    int64_t replicate_n_23907 = m_20840;
                    int64_t tblock_sizze_23912;
                    
                    tblock_sizze_23912 = *ctx->tuning_params.mainzitblock_sizze_23912;
                    
                    int64_t virt_num_tblocks_23913 = sdiv_up64(replicate_n_23907, tblock_sizze_23912);
                    int64_t num_tblocks_23914 = smin64(virt_num_tblocks_23913, (int64_t) 1048576);
                    
                    {
                        err = gpu_kernel_mainzireplicate_23908(ctx, num_tblocks_23914, 1, 1, tblock_sizze_23912, 1, 1, (int64_t) 0, m_20840, replicate_n_23907, virt_num_tblocks_23913, num_tblocks_23914, mem_23237.mem, mem_23243.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (memblock_unref_device(ctx, &mem_23237, "mem_23237") != 0)
                        return 1;
                    
                    int64_t tmp_offs_23927 = (int64_t) 0;
                    
                    if (!(m_20840 * tmp_offs_23927 == (int64_t) 0)) {
                        if ((err = lmad_copy_gpu2gpu_8b(ctx, "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-103:37", 2, mem_23246.mem, m_20840 * tmp_offs_23927, (int64_t []) {m_20840, (int64_t) 1}, mem_23246.mem, (int64_t) 0, (int64_t []) {m_20840, (int64_t) 1}, (int64_t []) {arg_16658, m_20840})) != 0)
                            goto cleanup;
                    }
                    tmp_offs_23927 += arg_16658;
                    if (!(m_20840 * tmp_offs_23927 == m_20840 * arg_16658)) {
                        if ((err = lmad_copy_gpu2gpu_8b(ctx, "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-103:37", 2, mem_23246.mem, m_20840 * tmp_offs_23927, (int64_t []) {m_20840, (int64_t) 1}, mem_23246.mem, m_20840 * arg_16658, (int64_t []) {m_20840, (int64_t) 1}, (int64_t []) {(int64_t) 1, m_20840})) != 0)
                            goto cleanup;
                    }
                    tmp_offs_23927 += (int64_t) 1;
                    // definitions.fut:23:79-104:29
                    if (memblock_alloc_device(ctx, &mem_23248, dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20858, "mem_23248")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:23:79-104:29
                    
                    int64_t tmp_offs_23928 = (int64_t) 0;
                    
                    // definitions.fut:23:79-104:29
                    if ((err = lmad_copy_gpu2gpu_1b(ctx, "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:23:79-104:29", 2, mem_23248.mem, tmp_offs_23928, (int64_t []) {dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, (int64_t) 1}, mem_23235.mem, (int64_t) 0, (int64_t []) {arg_16658, (int64_t) 1}, (int64_t []) {m_20840, arg_16658})) != 0)
                        goto cleanup;
                    tmp_offs_23928 += arg_16658;
                    // definitions.fut:23:79-104:29
                    if ((err = lmad_copy_gpu2gpu_1b(ctx, "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:23:79-104:29", 2, mem_23248.mem, tmp_offs_23928, (int64_t []) {dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, (int64_t) 1}, mem_23243.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, m_20840}, (int64_t []) {m_20840, (int64_t) 1})) != 0)
                        goto cleanup;
                    tmp_offs_23928 += (int64_t) 1;
                    if (memblock_unref_device(ctx, &mem_23235, "mem_23235") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &mem_23243, "mem_23243") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23305, &mem_23248, "mem_23248") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23302, &mem_23246, "mem_23246") != 0)
                        return 1;
                }
                if (memblock_unref_device(ctx, &mem_23213, "mem_23213") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23223, "mem_23223") != 0)
                    return 1;
                
                int64_t num_tblocks_21927;
                int64_t max_num_tblocks_23930;
                
                max_num_tblocks_23930 = *ctx->tuning_params.mainzisegmap_num_tblocks_21915;
                num_tblocks_21927 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20858, segmap_tblock_sizze_21926), max_num_tblocks_23930)));
                // definitions.fut:106:22-72
                
                bool acc_cert_20971;
                
                // definitions.fut:106:22-72
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_23931 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20858, segmap_tblock_sizze_21926));
                
                // definitions.fut:106:22-72
                {
                    err = gpu_kernel_mainzisegmap_21931(ctx, num_tblocks_21927, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21913, 1, 1, (int64_t) 0, num_qubits_14547, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_20840, dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20858, num_tblocks_21927, ext_23303, ext_23304, virt_num_tblocks_23931, mem_23052.mem, mem_23210.mem, ext_mem_23302.mem, ext_mem_23305.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23210, "mem_23210") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &ext_mem_23302, "ext_mem_23302") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &ext_mem_23305, "ext_mem_23305") != 0)
                    return 1;
                // definitions.fut:109:21-58
                if (memblock_alloc_device(ctx, &mem_23308, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, "mem_23308")) {
                    err = 1;
                    goto cleanup;
                }
                // definitions.fut:109:21-58
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_23944 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, segmap_tblock_sizze_21952));
                
                // definitions.fut:109:21-58
                {
                    err = gpu_kernel_mainzisegmap_21956(ctx, segmap_usable_groups_21953, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21940, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, mem_23052.mem, mem_23211.mem, mem_23308.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                // definitions.fut:110:22-45
                
                bool acc_cert_20993;
                
                // definitions.fut:110:22-45
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_23953 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, segmap_tblock_sizze_21978));
                
                // definitions.fut:110:22-45
                {
                    err = gpu_kernel_mainzisegmap_21983(ctx, num_tblocks_21979, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21966, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, num_tblocks_21979, virt_num_tblocks_23953, mem_23052.mem, mem_23214.mem, mem_23308.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23214, "mem_23214") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23308, "mem_23308") != 0)
                    return 1;
                // definitions.fut:124:22-45
                
                bool acc_cert_21018;
                
                // definitions.fut:115:13-124:45
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_23966 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, segmap_tblock_sizze_22007));
                
                // definitions.fut:117:20-124:45
                {
                    err = gpu_kernel_mainzisegmap_22012(ctx, num_tblocks_22008, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21991, 1, 1, (int64_t) 0, num_qubits_14547, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, u64_res_21014, num_tblocks_22008, virt_num_tblocks_23966, mem_23052.mem, mem_23211.mem, mem_23215.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23211, "mem_23211") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23215, "mem_23215") != 0)
                    return 1;
            } else {
                // definitions.fut:130:22-47
                
                bool acc_cert_21033;
                
                // definitions.fut:130:22-47
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_23979 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, segmap_tblock_sizze_22035));
                
                // definitions.fut:130:22-47
                {
                    err = gpu_kernel_mainzisegmap_22040(ctx, num_tblocks_22036, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_22024, 1, 1, (int64_t) 0, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, num_tblocks_22036, virt_num_tblocks_23979, mem_23052.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_alloc_device(ctx, &mem_23119, bytes_23118, "mem_23119")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23122, bytes_23121, "mem_23122")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23124, bytes_23118, "mem_23124")) {
                    err = 1;
                    goto cleanup;
                }
                if (slt64((int64_t) 0, num_qubits_14547)) {
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegScan");
                    
                    int64_t stage1_max_num_tblocks_23992;
                    
                    stage1_max_num_tblocks_23992 = ctx->max_thread_block_size;
                    
                    int64_t stage1_num_tblocks_23993 = smin64(stage1_max_num_tblocks_23992, num_tblocks_22048);
                    int32_t num_threads_23994 = sext_i64_i32(stage1_num_tblocks_23993 * segscan_tblock_sizze_22046);
                    
                    // definitions.fut:132:29-67
                    {
                        err = gpu_kernel_mainziscan_stage1_22051(ctx, stage1_num_tblocks_23993, 1, 1, *ctx->tuning_params.mainzisegscan_tblock_sizze_22045, 1, 1, smax64((int64_t) 1, (int64_t) 8 * segscan_tblock_sizze_22046) + srem64((int64_t) 8 - srem64(smax64((int64_t) 1, (int64_t) 8 * segscan_tblock_sizze_22046), (int64_t) 8), (int64_t) 8), num_qubits_14547, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, num_threads_23994, mem_23052.mem, mem_23061.mem, mem_23119.mem, mem_23122.mem, mem_23124.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "elems_per_group", (long long) (segscan_tblock_sizze_22046 * sdiv_up64(num_qubits_14547, sext_i32_i64(num_threads_23994))), '\n');
                    // definitions.fut:132:29-67
                    {
                        err = gpu_kernel_mainziscan_stage2_22051(ctx, (int64_t) 1, 1, 1, stage1_num_tblocks_23993, 1, 1, smax64((int64_t) 1, (int64_t) 8 * stage1_num_tblocks_23993) + srem64((int64_t) 8 - srem64(smax64((int64_t) 1, (int64_t) 8 * stage1_num_tblocks_23993), (int64_t) 8), (int64_t) 8), num_qubits_14547, stage1_num_tblocks_23993, num_threads_23994, mem_23119.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    
                    int32_t required_groups_24039 = sext_i64_i32(sdiv_up64(num_qubits_14547, segscan_tblock_sizze_22046));
                    
                    // definitions.fut:132:29-67
                    {
                        err = gpu_kernel_mainziscan_stage3_22051(ctx, num_tblocks_22048, 1, 1, *ctx->tuning_params.mainzisegscan_tblock_sizze_22045, 1, 1, (int64_t) 0, num_qubits_14547, num_tblocks_22048, num_threads_23994, required_groups_24039, mem_23119.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                }
                // definitions.fut:132:29-67
                
                int64_t m_f_res_21069;
                
                if (x_20790) {
                    // definitions.fut:132:29-67
                    
                    int64_t read_res_24370;
                    
                    if ((err = gpu_scalar_from_device(ctx, "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:132:29-67", &read_res_24370, mem_23119.mem, tmp_20791 * sizeof(int64_t), sizeof(int64_t))) != 0)
                        goto cleanup;
                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t x_21070 = read_res_24370;
                    
                    m_f_res_21069 = x_21070;
                } else {
                    m_f_res_21069 = (int64_t) 0;
                }
                // definitions.fut:132:29-67
                
                int64_t m_21071;
                
                if (cond_20789) {
                    m_21071 = (int64_t) 0;
                } else {
                    m_21071 = m_f_res_21069;
                }
                // definitions.fut:132:29-67
                
                int64_t bytes_23125 = (int64_t) 8 * m_21071;
                
                // definitions.fut:25:73-82
                
                bool x_21090 = sle64((int64_t) 0, arg_16658);
                
                // definitions.fut:25:73-82
                
                bool bounds_check_21092 = y_20865 && x_21090;
                
                // definitions.fut:25:73-82
                
                bool index_certs_21093;
                
                if (!bounds_check_21092) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) arg_16658, "] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, "].", "-> #0  definitions.fut:25:73-82\n   #1  definitions.fut:89:58-133:67\n   #2  main.fut:7:78-11:83\n   #3  main.fut:53:34-70\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                // definitions.fut:132:29-67
                if (memblock_alloc_device(ctx, &mem_23126, bytes_23125, "mem_23126")) {
                    err = 1;
                    goto cleanup;
                }
                
                int64_t segmap_tblock_sizze_22071;
                
                segmap_tblock_sizze_22071 = *ctx->tuning_params.mainzisegmap_tblock_sizze_22055;
                
                int64_t num_tblocks_22072;
                int64_t max_num_tblocks_24052;
                
                max_num_tblocks_24052 = *ctx->tuning_params.mainzisegmap_num_tblocks_22057;
                num_tblocks_22072 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(num_qubits_14547, segmap_tblock_sizze_22071), max_num_tblocks_24052)));
                // definitions.fut:132:29-67
                
                bool acc_cert_21075;
                
                // definitions.fut:132:29-67
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24053 = sext_i64_i32(sdiv_up64(num_qubits_14547, segmap_tblock_sizze_22071));
                
                // definitions.fut:132:29-67
                {
                    err = gpu_kernel_mainzisegmap_22076(ctx, num_tblocks_22072, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_22055, 1, 1, (int64_t) 0, num_qubits_14547, m_21071, num_tblocks_22072, virt_num_tblocks_24053, mem_23119.mem, mem_23124.mem, mem_23126.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23119, "mem_23119") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23124, "mem_23124") != 0)
                    return 1;
                // main.fut:7:78-11:83
                
                int64_t dzlz7bUZLztZRz20Udz2081Uz2083Uz2082Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_21089 = mul64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_21071);
                bool suff_outer_par_22086;
                
                suff_outer_par_22086 = *ctx->tuning_params.mainzisuff_outer_par_1 <= m_21071;
                if (ctx->logging)
                    fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "main.suff_outer_par_1", (long) m_21071, suff_outer_par_22086 ? "true" : "false");
                
                int64_t segmap_tblock_sizze_22321;
                
                segmap_tblock_sizze_22321 = *ctx->tuning_params.mainzisegmap_tblock_sizze_22309;
                
                int64_t nest_sizze_22334 = num_qubits_14547 * m_21071;
                int64_t segred_tblock_sizze_22335;
                
                segred_tblock_sizze_22335 = *ctx->tuning_params.mainzisegred_tblock_sizze_22254;
                
                int64_t num_tblocks_22336;
                int64_t max_num_tblocks_24066;
                
                max_num_tblocks_24066 = *ctx->tuning_params.mainzisegred_num_tblocks_22256;
                num_tblocks_22336 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_22334, segred_tblock_sizze_22335), max_num_tblocks_24066)));
                
                int64_t segmap_tblock_sizze_22386;
                
                segmap_tblock_sizze_22386 = *ctx->tuning_params.mainzisegmap_tblock_sizze_22235;
                
                int64_t segmap_tblock_sizze_22157;
                
                segmap_tblock_sizze_22157 = *ctx->tuning_params.mainzisegmap_tblock_sizze_22090;
                
                int64_t num_tblocks_22158;
                int64_t max_num_tblocks_24067;
                
                max_num_tblocks_24067 = *ctx->tuning_params.mainzisegmap_num_tblocks_22092;
                num_tblocks_22158 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_21071, segmap_tblock_sizze_22157), max_num_tblocks_24067)));
                
                int64_t segmap_tblock_sizze_22424;
                
                segmap_tblock_sizze_22424 = *ctx->tuning_params.mainzisegmap_tblock_sizze_22411;
                
                int64_t num_tblocks_22425;
                int64_t max_num_tblocks_24068;
                
                max_num_tblocks_24068 = *ctx->tuning_params.mainzisegmap_num_tblocks_22413;
                num_tblocks_22425 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20Udz2081Uz2083Uz2082Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_21089, segmap_tblock_sizze_22424), max_num_tblocks_24068)));
                if (memblock_alloc_device(ctx, &mem_23128, (int64_t) 1, "mem_23128")) {
                    err = 1;
                    goto cleanup;
                }
                // definitions.fut:26:16-36
                {
                    err = gpu_kernel_mainzigpuseq_24069(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, mem_23052.mem, mem_23128.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                
                int64_t ext_23191;
                int64_t shared_memory_capacity_24075;
                
                shared_memory_capacity_24075 = ctx->max_shared_memory;
                if (suff_outer_par_22086) {
                    ext_23191 = (int64_t) 1;
                } else {
                    ext_23191 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659;
                }
                
                int64_t ext_23190;
                int64_t shared_memory_capacity_24076;
                
                shared_memory_capacity_24076 = ctx->max_shared_memory;
                if (suff_outer_par_22086) {
                    ext_23190 = m_21071;
                } else {
                    ext_23190 = (int64_t) 1;
                }
                
                int64_t bytes_23140 = (int64_t) 2 * nest_sizze_22334;
                
                // definitions.fut:23:79-133:82
                
                int64_t binop_x_23149 = smax64((int64_t) 0, arg_16658);
                
                // definitions.fut:23:79-133:82
                
                int64_t binop_y_23152 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659 * binop_x_23149;
                
                // definitions.fut:23:79-133:82
                
                int64_t binop_y_23153 = smax64((int64_t) 0, binop_y_23152);
                
                // definitions.fut:23:79-133:82
                
                int64_t binop_y_23154 = binop_x_23149 + binop_y_23153;
                
                // definitions.fut:23:79-133:82
                
                int64_t bytes_23155 = (int64_t) 1 + binop_y_23154;
                
                // definitions.fut:23:79-133:82
                
                int64_t binop_y_23180 = m_21071 - (int64_t) 1;
                
                // definitions.fut:23:79-133:82
                
                int64_t binop_x_23182 = smax64((int64_t) 0, binop_y_23180);
                
                // definitions.fut:23:79-133:82
                
                int64_t binop_y_23185 = m_21071 * binop_x_23149;
                
                // definitions.fut:23:79-133:82
                
                int64_t binop_y_23186 = smax64((int64_t) 0, binop_y_23185);
                
                // definitions.fut:23:79-133:82
                
                int64_t binop_y_23187 = binop_x_23182 + binop_y_23186;
                
                // definitions.fut:23:79-133:82
                
                int64_t bytes_23188 = (int64_t) 1 + binop_y_23187;
                int64_t num_threads_23405 = segmap_tblock_sizze_22157 * num_tblocks_22158;
                int64_t total_sizze_23406 = arg_16658 * num_threads_23405;
                int64_t segred_num_tblocks_23415;
                
                segred_num_tblocks_23415 = *ctx->tuning_params.mainzisegred_num_tblocks_23414;
                
                int64_t segred_tblock_sizze_23417;
                
                segred_tblock_sizze_23417 = *ctx->tuning_params.mainzisegred_tblock_sizze_23416;
                
                int64_t ctx_23447 = (int64_t) 2 * num_threads_23405;
                int64_t shared_memory_capacity_24239;
                
                shared_memory_capacity_24239 = ctx->max_shared_memory;
                if (suff_outer_par_22086 && (sle64(sdiv_up64((int64_t) 8 * segred_tblock_sizze_23417, (int64_t) 8) * (int64_t) 8 + (int64_t) 8, shared_memory_capacity_24239) && sle64((int64_t) 0, shared_memory_capacity_24239))) {
                    // definitions.fut:23:79-133:82
                    if (memblock_alloc_device(ctx, &mem_23156, bytes_23155, "mem_23156")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:23:79-133:82
                    // definitions.fut:23:79-133:82
                    if ((err = lmad_copy_gpu2gpu_1b(ctx, "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:23:79-133:82", 2, mem_23156.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659}, mem_23052.mem, (int64_t) 0, (int64_t []) {dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, (int64_t) 1}, (int64_t []) {dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659})) != 0)
                        goto cleanup;
                    // definitions.fut:23:79-133:82
                    if (memblock_alloc_device(ctx, &mem_23189, bytes_23188, "mem_23189")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &color_23358, total_sizze_23406, "color_23358")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23440, (int64_t) 8, "mem_23440")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_24077 = (int64_t) 1;
                    
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_24080, (int64_t) 8 * segred_num_tblocks_23415, "segred_tmp_mem_24080")) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t num_threads_24082 = segred_num_tblocks_23415 * segred_tblock_sizze_23417;
                    
                    // definitions.fut:25:17-29:98
                    {
                        err = gpu_kernel_mainzisegred_nonseg_23424(ctx, segred_num_tblocks_23415, 1, 1, *ctx->tuning_params.mainzisegred_tblock_sizze_23416, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_23417 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_23417, (int64_t) 8), (int64_t) 8)), num_qubits_14547, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_21071, num_threads_24082, mem_23126.mem, mem_23440.mem, counters_mem_24078.mem, segred_tmp_mem_24080.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    
                    int64_t read_res_24371;
                    
                    if ((err = gpu_scalar_from_device(ctx, "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:89:58-133:67->definitions.fut:25:17-29:98", &read_res_24371, mem_23440.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
                        goto cleanup;
                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t max_per_thread_23411 = read_res_24371;
                    
                    if (memblock_unref_device(ctx, &mem_23440, "mem_23440") != 0)
                        return 1;
                    
                    int64_t sizze_sum_23436 = num_threads_23405 * max_per_thread_23411;
                    
                    if (memblock_alloc_device(ctx, &mem_23159, sizze_sum_23436, "mem_23159")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:23:79-133:82
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_24111 = sext_i64_i32(sdiv_up64(m_21071, segmap_tblock_sizze_22157));
                    
                    // definitions.fut:23:79-133:82
                    {
                        err = gpu_kernel_mainzisegmap_22162(ctx, num_tblocks_22158, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_22090, 1, 1, (int64_t) 0, num_qubits_14547, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_21071, num_tblocks_22158, num_threads_23405, ctx_23447, virt_num_tblocks_24111, mem_23052.mem, mem_23126.mem, mem_23128.mem, mem_23156.mem, mem_23159.mem, mem_23189.mem, color_23358.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23156, "mem_23156") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &mem_23159, "mem_23159") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &color_23358, "color_23358") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23192, &mem_23189, "mem_23189") != 0)
                        return 1;
                } else {
                    int64_t segmap_usable_groups_22322 = sdiv_up64(m_21071, segmap_tblock_sizze_22321);
                    
                    // definitions.fut:23:79-133:82
                    if (memblock_alloc_device(ctx, &mem_23131, bytes_23125, "mem_23131")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:23:79-133:82
                    if (memblock_alloc_device(ctx, &mem_23132, (int64_t) 0, "mem_23132")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:23:79-133:82
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_24128 = sext_i64_i32(sdiv_up64(m_21071, segmap_tblock_sizze_22321));
                    
                    // definitions.fut:25:43-52
                    {
                        err = gpu_kernel_mainzisegmap_22326(ctx, segmap_usable_groups_22322, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_22309, 1, 1, (int64_t) 0, num_qubits_14547, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_21071, mem_23126.mem, mem_23131.mem, mem_23132.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_alloc_device(ctx, &mem_23141, bytes_23140, "mem_23141")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:23:79-133:82
                    if (memblock_alloc_device(ctx, &mem_23143, m_21071, "mem_23143")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_24137 = (int64_t) 1;
                    
                    if (slt64(num_qubits_14547 * (int64_t) 2, segred_tblock_sizze_22335 * chunk_sizze_24137)) {
                        int64_t segment_sizze_nonzzero_24138 = smax64((int64_t) 1, num_qubits_14547);
                        int64_t num_threads_24139 = num_tblocks_22336 * segred_tblock_sizze_22335;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-small");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) m_21071, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_qubits_14547, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_22335, segment_sizze_nonzzero_24138), '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(m_21071, squot64(segred_tblock_sizze_22335, segment_sizze_nonzzero_24138))), '\n');
                        // definitions.fut:25:17-29:98
                        {
                            err = gpu_kernel_mainzisegred_small_22342(ctx, num_tblocks_22336, 1, 1, *ctx->tuning_params.mainzisegred_tblock_sizze_22254, 1, 1, segred_tblock_sizze_22335 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22335, (int64_t) 8), (int64_t) 8), num_qubits_14547, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_21071, num_tblocks_22336, segment_sizze_nonzzero_24138, mem_23052.mem, mem_23131.mem, mem_23132.mem, mem_23141.mem, mem_23143.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                    } else {
                        int64_t blocks_per_segment_24166 = sdiv_up64(num_tblocks_22336, smax64((int64_t) 1, m_21071));
                        int64_t q_24167 = sdiv_up64(num_qubits_14547, segred_tblock_sizze_22335 * blocks_per_segment_24166 * chunk_sizze_24137);
                        int64_t num_virtblocks_24168 = blocks_per_segment_24166 * m_21071;
                        int64_t threads_per_segment_24169 = blocks_per_segment_24166 * segred_tblock_sizze_22335;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-large");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) m_21071, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_qubits_14547, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_24168, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_22336, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_22335, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_24167, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_24166, '\n');
                        if (memblock_alloc_device(ctx, &segred_tmp_mem_24170, num_virtblocks_24168, "segred_tmp_mem_24170")) {
                            err = 1;
                            goto cleanup;
                        }
                        // definitions.fut:25:17-29:98
                        {
                            err = gpu_kernel_mainzisegred_large_22342(ctx, num_tblocks_22336, 1, 1, *ctx->tuning_params.mainzisegred_tblock_sizze_22254, 1, 1, 8 + (segred_tblock_sizze_22335 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22335, (int64_t) 8), (int64_t) 8)), num_qubits_14547, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_21071, num_tblocks_22336, blocks_per_segment_24166, q_24167, num_virtblocks_24168, threads_per_segment_24169, mem_23052.mem, mem_23131.mem, mem_23132.mem, mem_23141.mem, mem_23143.mem, segred_tmp_mem_24170.mem, counters_mem_24172.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    
                    int64_t segmap_usable_groups_22387 = sdiv_up64(m_21071, segmap_tblock_sizze_22386);
                    
                    // definitions.fut:23:79-133:82
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_24209 = sext_i64_i32(sdiv_up64(m_21071, segmap_tblock_sizze_22386));
                    
                    // definitions.fut:89:58-133:67
                    {
                        err = gpu_kernel_mainzisegmap_22390(ctx, segmap_usable_groups_22387, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_22235, 1, 1, (int64_t) 0, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, m_21071, mem_23052.mem, mem_23128.mem, mem_23131.mem, mem_23132.mem, mem_23143.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23131, "mem_23131") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &mem_23132, "mem_23132") != 0)
                        return 1;
                    // definitions.fut:89:58-133:67
                    if (memblock_alloc_device(ctx, &mem_23144, m_21071, "mem_23144")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:89:58-133:67
                    
                    int64_t replicate_n_24218 = m_21071;
                    int64_t tblock_sizze_24223;
                    
                    tblock_sizze_24223 = *ctx->tuning_params.mainzitblock_sizze_24223;
                    
                    int64_t virt_num_tblocks_24224 = sdiv_up64(replicate_n_24218, tblock_sizze_24223);
                    int64_t num_tblocks_24225 = smin64(virt_num_tblocks_24224, (int64_t) 1048576);
                    
                    {
                        err = gpu_kernel_mainzireplicate_24219(ctx, num_tblocks_24225, 1, 1, tblock_sizze_24223, 1, 1, (int64_t) 0, m_21071, replicate_n_24218, virt_num_tblocks_24224, num_tblocks_24225, mem_23143.mem, mem_23144.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (memblock_unref_device(ctx, &mem_23143, "mem_23143") != 0)
                        return 1;
                    // definitions.fut:23:79-133:82
                    if (memblock_alloc_device(ctx, &mem_23146, dzlz7bUZLztZRz20Udz2081Uz2083Uz2082Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_21089, "mem_23146")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:23:79-133:82
                    
                    int64_t tmp_offs_24238 = (int64_t) 0;
                    
                    // definitions.fut:23:79-133:82
                    if ((err = lmad_copy_gpu2gpu_1b(ctx, "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:23:79-133:82", 2, mem_23146.mem, tmp_offs_24238, (int64_t []) {dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, (int64_t) 1}, mem_23141.mem, (int64_t) 0, (int64_t []) {arg_16658, (int64_t) 1}, (int64_t []) {m_21071, arg_16658})) != 0)
                        goto cleanup;
                    tmp_offs_24238 += arg_16658;
                    // definitions.fut:23:79-133:82
                    if ((err = lmad_copy_gpu2gpu_1b(ctx, "main.fut:53:34-70->main.fut:7:78-11:83->definitions.fut:23:79-133:82", 2, mem_23146.mem, tmp_offs_24238, (int64_t []) {dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, (int64_t) 1}, mem_23144.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, m_21071}, (int64_t []) {m_21071, (int64_t) 1})) != 0)
                        goto cleanup;
                    tmp_offs_24238 += (int64_t) 1;
                    if (memblock_unref_device(ctx, &mem_23141, "mem_23141") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &mem_23144, "mem_23144") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23192, &mem_23146, "mem_23146") != 0)
                        return 1;
                }
                if (memblock_unref_device(ctx, &mem_23126, "mem_23126") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23128, "mem_23128") != 0)
                    return 1;
                // definitions.fut:134:22-70
                
                bool acc_cert_21186;
                
                // definitions.fut:134:22-70
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24240 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Udz2081Uz2083Uz2082Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_21089, segmap_tblock_sizze_22424));
                
                // definitions.fut:134:22-70
                {
                    err = gpu_kernel_mainzisegmap_22429(ctx, num_tblocks_22425, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_22411, 1, 1, (int64_t) 0, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, dzlz7bUZLztZRz20Udz2081Uz2083Uz2082Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_21089, num_tblocks_22425, ext_23190, ext_23191, virt_num_tblocks_24240, mem_23052.mem, mem_23122.mem, ext_mem_23192.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23122, "mem_23122") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &ext_mem_23192, "ext_mem_23192") != 0)
                    return 1;
                // main.fut:7:78-11:83
                {
                    err = gpu_kernel_mainzigpuseq_24253(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, measurement_count_21197, mem_23052.mem, mem_23053.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            }
            if (memblock_unref_device(ctx, &mem_23108, "mem_23108") != 0)
                return 1;
            loopres_16728 = tmp_21196;
            loopres_16729 = Measurement_res_20806;
            loopres_16731 = tmp_21203;
        } else {
            // main.fut:18:15-25:68
            
            bool cond_17026 = loopres_16723 == (int64_t) 1;
            
            // main.fut:7:78-19:39
            
            int64_t dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027 = mul64((int64_t) 6, num_qubits_14547);
            
            // main.fut:53:34-70
            
            int64_t loopres_f_res_17029;
            
            if (cond_17026) {
                // definitions.fut:64:61-69
                
                bool bounds_invalid_upwards_21207 = slt64(arg_16658, (int64_t) 0);
                
                // definitions.fut:64:61-69
                
                bool valid_21208 = !bounds_invalid_upwards_21207;
                
                // definitions.fut:64:61-69
                
                bool range_valid_c_21209;
                
                if (!valid_21208) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) arg_16658, " is invalid.", "-> #0  definitions.fut:64:61-69\n   #1  main.fut:7:78-19:39\n   #2  main.fut:53:34-70\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                // definitions.fut:67:21-35
                
                bool y_21222 = slt64(arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);
                
                // definitions.fut:67:21-35
                
                bool index_certs_21223;
                
                if (!y_21222) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) arg_16658, "] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, "].", "-> #0  definitions.fut:67:21-35\n   #1  main.fut:7:78-19:39\n   #2  main.fut:53:34-70\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                
                int64_t segmap_tblock_sizze_22462;
                
                segmap_tblock_sizze_22462 = *ctx->tuning_params.mainzisegmap_tblock_sizze_22438;
                
                int64_t num_tblocks_22463;
                int64_t max_num_tblocks_24259;
                
                max_num_tblocks_24259 = *ctx->tuning_params.mainzisegmap_num_tblocks_22440;
                num_tblocks_22463 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_16658, segmap_tblock_sizze_22462), max_num_tblocks_24259)));
                
                int64_t segmap_tblock_sizze_22495;
                
                segmap_tblock_sizze_22495 = *ctx->tuning_params.mainzisegmap_tblock_sizze_22482;
                
                int64_t num_tblocks_22496;
                int64_t max_num_tblocks_24260;
                
                max_num_tblocks_24260 = *ctx->tuning_params.mainzisegmap_num_tblocks_22484;
                num_tblocks_22496 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027, segmap_tblock_sizze_22495), max_num_tblocks_24260)));
                // main.fut:19:43-46
                
                int64_t tmp_21259 = add64((int64_t) 1, i_16715);
                
                // definitions.fut:64:17-69
                if (memblock_alloc_device(ctx, &mem_23092, (int64_t) 24, "mem_23092")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23093, (int64_t) 8, "mem_23093")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23094, (int64_t) 24, "mem_23094")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23095, (int64_t) 0, "mem_23095")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23096, (int64_t) 0, "mem_23096")) {
                    err = 1;
                    goto cleanup;
                }
                // definitions.fut:64:17-69:38
                {
                    err = gpu_kernel_mainzigpuseq_24261(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, num_qubits_14547, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, mem_23061.mem, mem_23092.mem, mem_23093.mem, mem_23094.mem, mem_23095.mem, mem_23096.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
                if (memblock_unref_device(ctx, &mem_23092, "mem_23092") != 0)
                    return 1;
                
                bool index_certs_21217 = 0;
                
                if (memblock_unref_device(ctx, &mem_23095, "mem_23095") != 0)
                    return 1;
                
                bool index_certs_21221 = 0;
                
                if (memblock_unref_device(ctx, &mem_23096, "mem_23096") != 0)
                    return 1;
                // definitions.fut:64:17-72:18
                if (memblock_alloc_device(ctx, &mem_23103, dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027, "mem_23103")) {
                    err = 1;
                    goto cleanup;
                }
                // definitions.fut:64:17-72:18
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24267 = sext_i64_i32(sdiv_up64(arg_16658, segmap_tblock_sizze_22462));
                
                // definitions.fut:64:17-72:18
                {
                    err = gpu_kernel_mainzisegmap_22467(ctx, num_tblocks_22463, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_22438, 1, 1, (int64_t) 0, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, num_tblocks_22463, virt_num_tblocks_24267, mem_23052.mem, mem_23061.mem, mem_23093.mem, mem_23103.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23093, "mem_23093") != 0)
                    return 1;
                // definitions.fut:74:6-38
                
                bool acc_cert_21250;
                
                // definitions.fut:74:6-38
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24280 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027, segmap_tblock_sizze_22495));
                
                // definitions.fut:74:6-38
                {
                    err = gpu_kernel_mainzisegmap_22500(ctx, num_tblocks_22496, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_22482, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027, num_tblocks_22496, virt_num_tblocks_24280, mem_23052.mem, mem_23094.mem, mem_23103.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23094, "mem_23094") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23103, "mem_23103") != 0)
                    return 1;
                loopres_f_res_17029 = tmp_21259;
            } else {
                // main.fut:20:15-25:68
                
                bool cond_17079 = loopres_16723 == (int64_t) 2;
                
                // main.fut:7:78-21:36
                
                int64_t dzlz7bUZLztZRz20Utmpz20U2z7dUzg_17080 = mul64((int64_t) 4, num_qubits_14547);
                
                // main.fut:53:34-70
                
                int64_t loopres_f_res_f_res_17082;
                
                if (cond_17079) {
                    // definitions.fut:78:53-61
                    
                    bool bounds_invalid_upwards_21263 = slt64(arg_16658, (int64_t) 0);
                    
                    // definitions.fut:78:53-61
                    
                    bool valid_21264 = !bounds_invalid_upwards_21263;
                    
                    // definitions.fut:78:53-61
                    
                    bool range_valid_c_21265;
                    
                    if (!valid_21264) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) arg_16658, " is invalid.", "-> #0  definitions.fut:78:53-61\n   #1  main.fut:7:78-21:36\n   #2  main.fut:53:34-70\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    // definitions.fut:81:21-35
                    
                    bool y_21278 = slt64(arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);
                    
                    // definitions.fut:81:21-35
                    
                    bool index_certs_21279;
                    
                    if (!y_21278) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) arg_16658, "] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, "].", "-> #0  definitions.fut:81:21-35\n   #1  main.fut:7:78-21:36\n   #2  main.fut:53:34-70\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    int64_t segmap_tblock_sizze_22534;
                    
                    segmap_tblock_sizze_22534 = *ctx->tuning_params.mainzisegmap_tblock_sizze_22509;
                    
                    int64_t num_tblocks_22535;
                    int64_t max_num_tblocks_24293;
                    
                    max_num_tblocks_24293 = *ctx->tuning_params.mainzisegmap_num_tblocks_22511;
                    num_tblocks_22535 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_16658, segmap_tblock_sizze_22534), max_num_tblocks_24293)));
                    
                    int64_t segmap_tblock_sizze_22568;
                    
                    segmap_tblock_sizze_22568 = *ctx->tuning_params.mainzisegmap_tblock_sizze_22555;
                    
                    int64_t num_tblocks_22569;
                    int64_t max_num_tblocks_24294;
                    
                    max_num_tblocks_24294 = *ctx->tuning_params.mainzisegmap_num_tblocks_22557;
                    num_tblocks_22569 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20Utmpz20U2z7dUzg_17080, segmap_tblock_sizze_22568), max_num_tblocks_24294)));
                    // main.fut:21:40-43
                    
                    int64_t tmp_21318 = add64((int64_t) 1, i_16715);
                    
                    // definitions.fut:78:17-61
                    if (memblock_alloc_device(ctx, &mem_23079, (int64_t) 16, "mem_23079")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23080, (int64_t) 8, "mem_23080")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23081, (int64_t) 16, "mem_23081")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23082, (int64_t) 0, "mem_23082")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23083, (int64_t) 0, "mem_23083")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:78:17-83:38
                    {
                        err = gpu_kernel_mainzigpuseq_24295(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, num_qubits_14547, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, mem_23061.mem, mem_23079.mem, mem_23080.mem, mem_23081.mem, mem_23082.mem, mem_23083.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (memblock_unref_device(ctx, &mem_23079, "mem_23079") != 0)
                        return 1;
                    
                    bool index_certs_21273 = 0;
                    
                    if (memblock_unref_device(ctx, &mem_23082, "mem_23082") != 0)
                        return 1;
                    
                    bool index_certs_21277 = 0;
                    
                    if (memblock_unref_device(ctx, &mem_23083, "mem_23083") != 0)
                        return 1;
                    // definitions.fut:78:17-85:18
                    if (memblock_alloc_device(ctx, &mem_23090, dzlz7bUZLztZRz20Utmpz20U2z7dUzg_17080, "mem_23090")) {
                        err = 1;
                        goto cleanup;
                    }
                    // definitions.fut:78:17-85:18
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_24301 = sext_i64_i32(sdiv_up64(arg_16658, segmap_tblock_sizze_22534));
                    
                    // definitions.fut:78:17-85:18
                    {
                        err = gpu_kernel_mainzisegmap_22539(ctx, num_tblocks_22535, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_22509, 1, 1, (int64_t) 0, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, num_tblocks_22535, virt_num_tblocks_24301, mem_23052.mem, mem_23061.mem, mem_23080.mem, mem_23090.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23080, "mem_23080") != 0)
                        return 1;
                    // definitions.fut:87:6-38
                    
                    bool acc_cert_21309;
                    
                    // definitions.fut:87:6-38
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_24314 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Utmpz20U2z7dUzg_17080, segmap_tblock_sizze_22568));
                    
                    // definitions.fut:87:6-38
                    {
                        err = gpu_kernel_mainzisegmap_22573(ctx, num_tblocks_22569, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_22555, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, dzlz7bUZLztZRz20Utmpz20U2z7dUzg_17080, num_tblocks_22569, virt_num_tblocks_24314, mem_23052.mem, mem_23081.mem, mem_23090.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23081, "mem_23081") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &mem_23090, "mem_23090") != 0)
                        return 1;
                    loopres_f_res_f_res_17082 = tmp_21318;
                } else {
                    // main.fut:22:15-25:68
                    
                    bool cond_17133 = loopres_16723 == (int64_t) 3;
                    
                    // main.fut:53:34-70
                    
                    int64_t loopres_f_res_f_res_f_res_17135;
                    
                    if (cond_17133) {
                        // definitions.fut:48:10-18
                        
                        bool bounds_invalid_upwards_21322 = slt64(arg_16658, (int64_t) 0);
                        
                        // definitions.fut:48:10-18
                        
                        bool valid_21323 = !bounds_invalid_upwards_21322;
                        
                        // definitions.fut:48:10-18
                        
                        bool range_valid_c_21324;
                        
                        if (!valid_21323) {
                            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) arg_16658, " is invalid.", "-> #0  definitions.fut:48:10-18\n   #1  main.fut:7:78-23:42\n   #2  main.fut:53:34-70\n"));
                            err = FUTHARK_PROGRAM_ERROR;
                            goto cleanup;
                        }
                        // definitions.fut:56:21-35
                        
                        bool y_21329 = slt64(arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659);
                        
                        // definitions.fut:56:21-35
                        
                        bool index_certs_21330;
                        
                        if (!y_21329) {
                            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) arg_16658, "] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, "].", "-> #0  definitions.fut:56:21-35\n   #1  main.fut:7:78-23:42\n   #2  main.fut:53:34-70\n"));
                            err = FUTHARK_PROGRAM_ERROR;
                            goto cleanup;
                        }
                        
                        int64_t segmap_tblock_sizze_22613;
                        
                        segmap_tblock_sizze_22613 = *ctx->tuning_params.mainzisegmap_tblock_sizze_22582;
                        
                        int64_t num_tblocks_22614;
                        int64_t max_num_tblocks_24327;
                        
                        max_num_tblocks_24327 = *ctx->tuning_params.mainzisegmap_num_tblocks_22584;
                        num_tblocks_22614 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_16658, segmap_tblock_sizze_22613), max_num_tblocks_24327)));
                        
                        int64_t segmap_tblock_sizze_22653;
                        
                        segmap_tblock_sizze_22653 = *ctx->tuning_params.mainzisegmap_tblock_sizze_22640;
                        
                        int64_t num_tblocks_22654;
                        int64_t max_num_tblocks_24328;
                        
                        max_num_tblocks_24328 = *ctx->tuning_params.mainzisegmap_num_tblocks_22642;
                        num_tblocks_22654 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027, segmap_tblock_sizze_22653), max_num_tblocks_24328)));
                        // main.fut:23:46-49
                        
                        int64_t tmp_21394 = add64((int64_t) 1, i_16715);
                        
                        // definitions.fut:46:5-48:18
                        if (memblock_alloc_device(ctx, &mem_23062, (int64_t) 24, "mem_23062")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23063, (int64_t) 8, "mem_23063")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23064, (int64_t) 8, "mem_23064")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23065, (int64_t) 24, "mem_23065")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23066, (int64_t) 0, "mem_23066")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23067, (int64_t) 0, "mem_23067")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23068, (int64_t) 8, "mem_23068")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23069, (int64_t) 0, "mem_23069")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23070, (int64_t) 0, "mem_23070")) {
                            err = 1;
                            goto cleanup;
                        }
                        // definitions.fut:46:5-55:34
                        {
                            err = gpu_kernel_mainzigpuseq_24329(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, num_qubits_14547, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, i_16715, tQ_mem_23047.mem, mem_23061.mem, mem_23062.mem, mem_23063.mem, mem_23064.mem, mem_23065.mem, mem_23066.mem, mem_23067.mem, mem_23068.mem, mem_23069.mem, mem_23070.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                        if (memblock_unref_device(ctx, &mem_23062, "mem_23062") != 0)
                            return 1;
                        
                        bool index_certs_21334 = 0;
                        
                        if (memblock_unref_device(ctx, &mem_23066, "mem_23066") != 0)
                            return 1;
                        
                        bool index_certs_21338 = 0;
                        
                        if (memblock_unref_device(ctx, &mem_23067, "mem_23067") != 0)
                            return 1;
                        
                        bool index_certs_21343 = 0;
                        
                        if (memblock_unref_device(ctx, &mem_23069, "mem_23069") != 0)
                            return 1;
                        
                        bool index_certs_21347 = 0;
                        
                        if (memblock_unref_device(ctx, &mem_23070, "mem_23070") != 0)
                            return 1;
                        // definitions.fut:46:5-58:18
                        if (memblock_alloc_device(ctx, &mem_23077, dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027, "mem_23077")) {
                            err = 1;
                            goto cleanup;
                        }
                        // definitions.fut:46:5-58:18
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t virt_num_tblocks_24335 = sext_i64_i32(sdiv_up64(arg_16658, segmap_tblock_sizze_22613));
                        
                        // definitions.fut:46:5-58:18
                        {
                            err = gpu_kernel_mainzisegmap_22618(ctx, num_tblocks_22614, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_22582, 1, 1, (int64_t) 0, arg_16658, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, num_tblocks_22614, virt_num_tblocks_24335, mem_23052.mem, mem_23061.mem, mem_23063.mem, mem_23064.mem, mem_23068.mem, mem_23077.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_unref_device(ctx, &mem_23063, "mem_23063") != 0)
                            return 1;
                        if (memblock_unref_device(ctx, &mem_23064, "mem_23064") != 0)
                            return 1;
                        if (memblock_unref_device(ctx, &mem_23068, "mem_23068") != 0)
                            return 1;
                        // definitions.fut:60:6-38
                        
                        bool acc_cert_21385;
                        
                        // definitions.fut:60:6-38
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t virt_num_tblocks_24348 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027, segmap_tblock_sizze_22653));
                        
                        // definitions.fut:60:6-38
                        {
                            err = gpu_kernel_mainzisegmap_22658(ctx, num_tblocks_22654, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_22640, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_16659, dzlz7bUZLztZRz20Utmpz20U3z7dUzg_17027, num_tblocks_22654, virt_num_tblocks_24348, mem_23052.mem, mem_23065.mem, mem_23077.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_unref_device(ctx, &mem_23065, "mem_23065") != 0)
                            return 1;
                        if (memblock_unref_device(ctx, &mem_23077, "mem_23077") != 0)
                            return 1;
                        loopres_f_res_f_res_f_res_17135 = tmp_21394;
                    } else {
                        // main.fut:25:26-29
                        
                        int64_t tmp_17201 = add64((int64_t) 1, i_16715);
                        
                        loopres_f_res_f_res_f_res_17135 = tmp_17201;
                    }
                    loopres_f_res_f_res_17082 = loopres_f_res_f_res_f_res_17135;
                }
                loopres_f_res_17029 = loopres_f_res_f_res_17082;
            }
            loopres_16728 = loopres_f_res_17029;
            loopres_16729 = rng_16716;
            loopres_16731 = measurement_count_16718;
        }
        // main.fut:8:13-16
        
        bool loop_cond_17202 = slt64(loopres_16728, n_14545);
        bool loop_while_tmp_23540 = loop_cond_17202;
        int64_t i_tmp_23542 = loopres_16728;
        int32_t rng_tmp_23543 = loopres_16729;
        int32_t measurement_count_tmp_23545 = loopres_16731;
        
        loop_while_16713 = loop_while_tmp_23540;
        i_16715 = i_tmp_23542;
        rng_16716 = rng_tmp_23543;
        measurement_count_16718 = measurement_count_tmp_23545;
    }
    simulate_res_16707 = loop_while_16713;
    simulate_res_16709 = i_16715;
    simulate_res_16710 = rng_16716;
    simulate_res_16712 = measurement_count_16718;
    if (memblock_unref_device(ctx, &mem_23052, "mem_23052") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_23061, "mem_23061") != 0)
        return 1;
    // main.fut:53:27-70
    // Trace: trace
    fprintf(ctx->log, "%s", "trace: ");
    for (int64_t nest_i_24361 = 0; nest_i_24361 < defunc_0_f_res_21395; nest_i_24361++) {
        int8_t read_res_24372;
        
        if ((err = gpu_scalar_from_device(ctx, "main.fut:53:27-70", &read_res_24372, mem_23053.mem, nest_i_24361 * sizeof(int8_t), sizeof(int8_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int8_t arr_elem_24362 = read_res_24372;
        
        fprintf(ctx->log, "%hhd%s", arr_elem_24362, " ");
    }
    fprintf(ctx->log, "%s", "\n");
    if (memblock_set_device(ctx, &mem_out_23452, &mem_23053, "mem_23053") != 0)
        return 1;
    prim_out_23453 = defunc_0_f_res_21395;
    if (memblock_set_device(ctx, &*mem_out_p_24363, &mem_out_23452, "mem_out_23452") != 0)
        return 1;
    *out_prim_out_24364 = prim_out_23453;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_23077, "mem_23077") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23070, "mem_23070") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23069, "mem_23069") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23068, "mem_23068") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23067, "mem_23067") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23066, "mem_23066") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23065, "mem_23065") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23064, "mem_23064") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23063, "mem_23063") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23062, "mem_23062") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23090, "mem_23090") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23083, "mem_23083") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23082, "mem_23082") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23081, "mem_23081") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23080, "mem_23080") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23079, "mem_23079") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23103, "mem_23103") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23096, "mem_23096") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23095, "mem_23095") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23094, "mem_23094") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23093, "mem_23093") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23092, "mem_23092") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23146, "mem_23146") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23144, "mem_23144") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_24170, "segred_tmp_mem_24170") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23143, "mem_23143") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23141, "mem_23141") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23132, "mem_23132") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23131, "mem_23131") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23159, "mem_23159") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_24080, "segred_tmp_mem_24080") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23440, "mem_23440") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_23358, "color_23358") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23189, "mem_23189") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23156, "mem_23156") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23192, "ext_mem_23192") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23128, "mem_23128") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23126, "mem_23126") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23124, "mem_23124") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23122, "mem_23122") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23119, "mem_23119") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23308, "mem_23308") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23248, "mem_23248") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23243, "mem_23243") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23246, "mem_23246") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23819, "segred_tmp_mem_23819") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23237, "mem_23237") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23235, "mem_23235") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23226, "mem_23226") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23251, "mem_23251") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23726, "segred_tmp_mem_23726") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23393, "mem_23393") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_23357, "color_23357") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23301, "mem_23301") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23290, "mem_23290") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23302, "ext_mem_23302") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23305, "ext_mem_23305") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23223, "mem_23223") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23210, "mem_23210") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23221, "mem_23221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23219, "mem_23219") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23215, "mem_23215") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23214, "mem_23214") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23213, "mem_23213") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23212, "mem_23212") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23211, "mem_23211") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23110, "mem_23110") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23564, "segred_tmp_mem_23564") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23562, "segred_tmp_mem_23562") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23109, "mem_23109") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23108, "mem_23108") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23106, "mem_23106") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23105, "mem_23105") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23061, "mem_23061") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23053, "mem_23053") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23052, "mem_23052") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23478, "segred_tmp_mem_23478") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23049, "mem_23049") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_23452, "mem_out_23452") != 0)
            return 1;
    }
    return err;
}

int futhark_entry_main(struct futhark_context *ctx, struct futhark_i8_1d **out0, const int32_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i64_1d *in4)
{
    int64_t n_14545 = (int64_t) 0;
    int32_t seed_14546 = 0;
    int64_t num_qubits_14547 = (int64_t) 0;
    int64_t prim_out_23453 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    
    struct memblock_device mem_out_23452;
    
    mem_out_23452.references = NULL;
    
    struct memblock_device tQ_mem_23047;
    
    tQ_mem_23047.references = NULL;
    
    struct memblock_device cQ_mem_23046;
    
    cQ_mem_23046.references = NULL;
    
    struct memblock_device gates_mem_23045;
    
    gates_mem_23045.references = NULL;
    seed_14546 = in0;
    num_qubits_14547 = in1;
    gates_mem_23045 = in2->mem;
    n_14545 = in2->shape[0];
    cQ_mem_23046 = in3->mem;
    n_14545 = in3->shape[0];
    tQ_mem_23047 = in4->mem;
    n_14545 = in4->shape[0];
    if (!(n_14545 == in2->shape[0] && (n_14545 == in3->shape[0] && n_14545 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_main(ctx, &mem_out_23452, &prim_out_23453, gates_mem_23045, cQ_mem_23046, tQ_mem_23047, n_14545, seed_14546, num_qubits_14547);
        if (ret == 0) {
            struct memblock_device counters_mem_23456 = ctx->constants->counters_mem_23456;
            struct memblock_device counters_mem_23560 = ctx->constants->counters_mem_23560;
            struct memblock_device counters_mem_23724 = ctx->constants->counters_mem_23724;
            struct memblock_device counters_mem_23821 = ctx->constants->counters_mem_23821;
            struct memblock_device counters_mem_24078 = ctx->constants->counters_mem_24078;
            struct memblock_device counters_mem_24172 = ctx->constants->counters_mem_24172;
            
            assert((*out0 = (struct futhark_i8_1d *) malloc(sizeof(struct futhark_i8_1d))) != NULL);
            (*out0)->mem = mem_out_23452;
            (*out0)->shape[0] = prim_out_23453;
        }
    }
    lock_unlock(&ctx->lock);
    return ret;
}
  
