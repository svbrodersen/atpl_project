// Generated by Futhark 0.25.24.
// git: 0bb3d37e788daf859346a635efd215ab37aa72f6
// Compiled with GHC 9.6.6.

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wunused-const-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#pragma clang diagnostic ignored "-Wunused-but-set-variable"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wunused-const-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *cfg);
void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_unified_memory(struct futhark_context_config *cfg, int flag);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
const char *futhark_context_config_get_program(struct futhark_context_config *cfg);
void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_i64_1d;
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0);
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data);
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
struct futhark_i8_1d;
struct futhark_i8_1d *futhark_new_i8_1d(struct futhark_context *ctx, const int8_t *data, int64_t dim0);
struct futhark_i8_1d *futhark_new_raw_i8_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr);
int futhark_values_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr, int8_t *data);
int futhark_index_i8_1d(struct futhark_context *ctx, int8_t *out, struct futhark_i8_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr);
const int64_t *futhark_shape_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr);
struct futhark_i8_2d;
struct futhark_i8_2d *futhark_new_i8_2d(struct futhark_context *ctx, const int8_t *data, int64_t dim0, int64_t dim1);
struct futhark_i8_2d *futhark_new_raw_i8_2d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0, int64_t dim1);
int futhark_free_i8_2d(struct futhark_context *ctx, struct futhark_i8_2d *arr);
int futhark_values_i8_2d(struct futhark_context *ctx, struct futhark_i8_2d *arr, int8_t *data);
int futhark_index_i8_2d(struct futhark_context *ctx, int8_t *out, struct futhark_i8_2d *arr, int64_t i0, int64_t i1);
CUdeviceptr futhark_values_raw_i8_2d(struct futhark_context *ctx, struct futhark_i8_2d *arr);
const int64_t *futhark_shape_i8_2d(struct futhark_context *ctx, struct futhark_i8_2d *arr);

// Opaque values



// Entry points
int futhark_entry_main(struct futhark_context *ctx, struct futhark_i8_1d **out0, const int32_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i64_1d *in4);
int futhark_entry_simple(struct futhark_context *ctx, struct futhark_i8_1d **out0, const int64_t in0, const struct futhark_i64_1d *in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3);
int futhark_entry_simulate(struct futhark_context *ctx, struct futhark_i8_2d **out0, struct futhark_i8_1d **out1, const int32_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i64_1d *in4);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
char *futhark_context_report(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cuda
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
#define SCALAR_FUN_ATTR static inline
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

static void str_builder_str(struct str_builder *b, const char *s) {
  size_t needed = strlen(s);
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  strcpy(b->str+b->used, s);
  b->used += needed;
}

static void str_builder_char(struct str_builder *b, char c) {
  size_t needed = 1;
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  b->str[b->used] = c;
  b->str[b->used+1] = 0;
  b->used += needed;
}

static void str_builder_json_str(struct str_builder* sb, const char* s) {
  str_builder_char(sb, '"');
  for (int j = 0; s[j]; j++) {
    char c = s[j];
    switch (c) {
    case '\n':
      str_builder_str(sb, "\\n");
      break;
    case '"':
      str_builder_str(sb, "\\\"");
      break;
    default:
      str_builder_char(sb, c);
    }
  }
  str_builder_char(sb, '"');
}

static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// Assumes NULL-terminated.
static char *strconcat(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
// Start of event_list.h

typedef int (*event_report_fn)(struct str_builder*, void*);

struct event {
  void* data;
  event_report_fn f;
  const char* name;
  char *description;
};

struct event_list {
  struct event *events;
  int num_events;
  int capacity;
};

static void event_list_init(struct event_list *l) {
  l->capacity = 100;
  l->num_events = 0;
  l->events = calloc(l->capacity, sizeof(struct event));
}

static void event_list_free(struct event_list *l) {
  free(l->events);
}

static void add_event_to_list(struct event_list *l,
                              const char* name,
                              char* description,
                              void* data,
                              event_report_fn f) {
  if (l->num_events == l->capacity) {
    l->capacity *= 2;
    l->events = realloc(l->events, l->capacity * sizeof(struct event));
  }
  l->events[l->num_events].name = name;
  l->events[l->num_events].description = description;
  l->events[l->num_events].data = data;
  l->events[l->num_events].f = f;
  l->num_events++;
}

static int report_events_in_list(struct event_list *l,
                                 struct str_builder* sb) {
  int ret = 0;
  for (int i = 0; i < l->num_events; i++) {
    if (i != 0) {
      str_builder_str(sb, ",");
    }
    str_builder_str(sb, "{\"name\":");
    str_builder_json_str(sb, l->events[i].name);
    str_builder_str(sb, ",\"description\":");
    str_builder_json_str(sb, l->events[i].description);
    free(l->events[i].description);
    if (l->events[i].f(sb, l->events[i].data) != 0) {
      ret = 1;
      break;
    }
    str_builder(sb, "}");
  }
  event_list_free(l);
  event_list_init(l);
  return ret;
}

// End of event_list.h
#include <getopt.h>
#include <ctype.h>
#include <inttypes.h>
static const char *entry_point = "main";
// Start of values.h.

//// Text I/O

typedef int (*writer)(FILE*, const void*);
typedef int (*bin_reader)(void*);
typedef int (*str_reader)(const char *, void*);

struct array_reader {
  char* elems;
  int64_t n_elems_space;
  int64_t elem_size;
  int64_t n_elems_used;
  int64_t *shape;
  str_reader elem_reader;
};

static void skipspaces(FILE *f) {
  int c;
  do {
    c = getc(f);
  } while (isspace(c));

  if (c != EOF) {
    ungetc(c, f);
  }
}

static int constituent(char c) {
  return isalnum(c) || c == '.' || c == '-' || c == '+' || c == '_';
}

// Produces an empty token only on EOF.
static void next_token(FILE *f, char *buf, int bufsize) {
 start:
  skipspaces(f);

  int i = 0;
  while (i < bufsize) {
    int c = getc(f);
    buf[i] = (char)c;

    if (c == EOF) {
      buf[i] = 0;
      return;
    } else if (c == '-' && i == 1 && buf[0] == '-') {
      // Line comment, so skip to end of line and start over.
      for (; c != '\n' && c != EOF; c = getc(f));
      goto start;
    } else if (!constituent((char)c)) {
      if (i == 0) {
        // We permit single-character tokens that are not
        // constituents; this lets things like ']' and ',' be
        // tokens.
        buf[i+1] = 0;
        return;
      } else {
        ungetc(c, f);
        buf[i] = 0;
        return;
      }
    }

    i++;
  }

  buf[bufsize-1] = 0;
}

static int next_token_is(FILE *f, char *buf, int bufsize, const char* expected) {
  next_token(f, buf, bufsize);
  return strcmp(buf, expected) == 0;
}

static void remove_underscores(char *buf) {
  char *w = buf;

  for (char *r = buf; *r; r++) {
    if (*r != '_') {
      *w++ = *r;
    }
  }

  *w++ = 0;
}

static int read_str_elem(char *buf, struct array_reader *reader) {
  int ret;
  if (reader->n_elems_used == reader->n_elems_space) {
    reader->n_elems_space *= 2;
    reader->elems = (char*) realloc(reader->elems,
                                    (size_t)(reader->n_elems_space * reader->elem_size));
  }

  ret = reader->elem_reader(buf, reader->elems + reader->n_elems_used * reader->elem_size);

  if (ret == 0) {
    reader->n_elems_used++;
  }

  return ret;
}

static int read_str_array_elems(FILE *f,
                                char *buf, int bufsize,
                                struct array_reader *reader, int64_t dims) {
  int ret = 1;
  int expect_elem = 1;
  char *knows_dimsize = (char*) calloc((size_t)dims, sizeof(char));
  int cur_dim = (int)dims-1;
  int64_t *elems_read_in_dim = (int64_t*) calloc((size_t)dims, sizeof(int64_t));

  while (1) {
    next_token(f, buf, bufsize);
    if (strcmp(buf, "]") == 0) {
      expect_elem = 0;
      if (knows_dimsize[cur_dim]) {
        if (reader->shape[cur_dim] != elems_read_in_dim[cur_dim]) {
          ret = 1;
          break;
        }
      } else {
        knows_dimsize[cur_dim] = 1;
        reader->shape[cur_dim] = elems_read_in_dim[cur_dim];
      }
      if (cur_dim == 0) {
        ret = 0;
        break;
      } else {
        cur_dim--;
        elems_read_in_dim[cur_dim]++;
      }
    } else if (!expect_elem && strcmp(buf, ",") == 0) {
      expect_elem = 1;
    } else if (expect_elem) {
      if (strcmp(buf, "[") == 0) {
        if (cur_dim == dims - 1) {
          ret = 1;
          break;
        }
        cur_dim++;
        elems_read_in_dim[cur_dim] = 0;
      } else if (cur_dim == dims - 1) {
        ret = read_str_elem(buf, reader);
        if (ret != 0) {
          break;
        }
        expect_elem = 0;
        elems_read_in_dim[cur_dim]++;
      } else {
        ret = 1;
        break;
      }
    } else {
      ret = 1;
      break;
    }
  }

  free(knows_dimsize);
  free(elems_read_in_dim);
  return ret;
}

static int read_str_empty_array(FILE *f, char *buf, int bufsize,
                                const char *type_name, int64_t *shape, int64_t dims) {
  if (strlen(buf) == 0) {
    // EOF
    return 1;
  }

  if (strcmp(buf, "empty") != 0) {
    return 1;
  }

  if (!next_token_is(f, buf, bufsize, "(")) {
    return 1;
  }

  for (int i = 0; i < dims; i++) {
    if (!next_token_is(f, buf, bufsize, "[")) {
      return 1;
    }

    next_token(f, buf, bufsize);

    if (sscanf(buf, "%"SCNu64, (uint64_t*)&shape[i]) != 1) {
      return 1;
    }

    if (!next_token_is(f, buf, bufsize, "]")) {
      return 1;
    }
  }

  if (!next_token_is(f, buf, bufsize, type_name)) {
    return 1;
  }


  if (!next_token_is(f, buf, bufsize, ")")) {
    return 1;
  }

  // Check whether the array really is empty.
  for (int i = 0; i < dims; i++) {
    if (shape[i] == 0) {
      return 0;
    }
  }

  // Not an empty array!
  return 1;
}

static int read_str_array(FILE *f,
                          int64_t elem_size, str_reader elem_reader,
                          const char *type_name,
                          void **data, int64_t *shape, int64_t dims) {
  int ret;
  struct array_reader reader;
  char buf[100];

  int dims_seen;
  for (dims_seen = 0; dims_seen < dims; dims_seen++) {
    if (!next_token_is(f, buf, sizeof(buf), "[")) {
      break;
    }
  }

  if (dims_seen == 0) {
    return read_str_empty_array(f, buf, sizeof(buf), type_name, shape, dims);
  }

  if (dims_seen != dims) {
    return 1;
  }

  reader.shape = shape;
  reader.n_elems_used = 0;
  reader.elem_size = elem_size;
  reader.n_elems_space = 16;
  reader.elems = (char*) realloc(*data, (size_t)(elem_size*reader.n_elems_space));
  reader.elem_reader = elem_reader;

  ret = read_str_array_elems(f, buf, sizeof(buf), &reader, dims);

  *data = reader.elems;

  return ret;
}

#define READ_STR(MACRO, PTR, SUFFIX)                                   \
  remove_underscores(buf);                                              \
  int j;                                                                \
  if (sscanf(buf, "%"MACRO"%n", (PTR*)dest, &j) == 1) {                 \
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, SUFFIX) == 0);     \
  } else {                                                              \
    return 1;                                                           \
  }

static int read_str_i8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNi8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(int8_t*)dest = (int8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "i8") == 0);
  } else {
    return 1;
  }
}

static int read_str_u8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNu8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(uint8_t*)dest = (uint8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "u8") == 0);
  } else {
    return 1;
  }
}

static int read_str_i16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "i16");
}

static int read_str_u16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "u16");
}

static int read_str_i32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "i32");
}

static int read_str_u32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "u32");
}

static int read_str_i64(char *buf, void* dest) {
  READ_STR(SCNi64, int64_t, "i64");
}

static int read_str_u64(char *buf, void* dest) {
  // FIXME: This is not correct, as SCNu64 only permits decimal
  // literals.  However, SCNi64 does not handle very large numbers
  // correctly (it's really for signed numbers, so that's fair).
  READ_STR(SCNu64, uint64_t, "u64");
}

static int read_str_f16(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f16.nan") == 0) {
    *(uint16_t*)dest = float2halfbits(NAN);
    return 0;
  } else if (strcmp(buf, "f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(INFINITY);
    return 0;
  } else if (strcmp(buf, "-f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(-INFINITY);
    return 0;
  } else {
    int j;
    float x;
    if (sscanf(buf, "%f%n", &x, &j) == 1) {
      if (strcmp(buf+j, "") == 0 || strcmp(buf+j, "f16") == 0) {
        *(uint16_t*)dest = float2halfbits(x);
        return 0;
      }
    }
    return 1;
  }
}

static int read_str_f32(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f32.nan") == 0) {
    *(float*)dest = (float)NAN;
    return 0;
  } else if (strcmp(buf, "f32.inf") == 0) {
    *(float*)dest = (float)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f32.inf") == 0) {
    *(float*)dest = (float)-INFINITY;
    return 0;
  } else {
    READ_STR("f", float, "f32");
  }
}

static int read_str_f64(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f64.nan") == 0) {
    *(double*)dest = (double)NAN;
    return 0;
  } else if (strcmp(buf, "f64.inf") == 0) {
    *(double*)dest = (double)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f64.inf") == 0) {
    *(double*)dest = (double)-INFINITY;
    return 0;
  } else {
    READ_STR("lf", double, "f64");
  }
}

static int read_str_bool(char *buf, void* dest) {
  if (strcmp(buf, "true") == 0) {
    *(char*)dest = 1;
    return 0;
  } else if (strcmp(buf, "false") == 0) {
    *(char*)dest = 0;
    return 0;
  } else {
    return 1;
  }
}

static int write_str_i8(FILE *out, int8_t *src) {
  return fprintf(out, "%hhdi8", *src);
}

static int write_str_u8(FILE *out, uint8_t *src) {
  return fprintf(out, "%hhuu8", *src);
}

static int write_str_i16(FILE *out, int16_t *src) {
  return fprintf(out, "%hdi16", *src);
}

static int write_str_u16(FILE *out, uint16_t *src) {
  return fprintf(out, "%huu16", *src);
}

static int write_str_i32(FILE *out, int32_t *src) {
  return fprintf(out, "%di32", *src);
}

static int write_str_u32(FILE *out, uint32_t *src) {
  return fprintf(out, "%uu32", *src);
}

static int write_str_i64(FILE *out, int64_t *src) {
  return fprintf(out, "%"PRIi64"i64", *src);
}

static int write_str_u64(FILE *out, uint64_t *src) {
  return fprintf(out, "%"PRIu64"u64", *src);
}

static int write_str_f16(FILE *out, uint16_t *src) {
  float x = halfbits2float(*src);
  if (isnan(x)) {
    return fprintf(out, "f16.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f16.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f16.inf");
  } else {
    return fprintf(out, "%.*ff16", FLT_DIG, x);
  }
}

static int write_str_f32(FILE *out, float *src) {
  float x = *src;
  if (isnan(x)) {
    return fprintf(out, "f32.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f32.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f32.inf");
  } else {
    return fprintf(out, "%.*ff32", FLT_DIG, x);
  }
}

static int write_str_f64(FILE *out, double *src) {
  double x = *src;
  if (isnan(x)) {
    return fprintf(out, "f64.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f64.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f64.inf");
  } else {
    return fprintf(out, "%.*ff64", DBL_DIG, x);
  }
}

static int write_str_bool(FILE *out, void *src) {
  return fprintf(out, *(char*)src ? "true" : "false");
}

//// Binary I/O

#define BINARY_FORMAT_VERSION 2
#define IS_BIG_ENDIAN (!*(unsigned char *)&(uint16_t){1})

static void flip_bytes(size_t elem_size, unsigned char *elem) {
  for (size_t j=0; j<elem_size/2; j++) {
    unsigned char head = elem[j];
    size_t tail_index = elem_size-1-j;
    elem[j] = elem[tail_index];
    elem[tail_index] = head;
  }
}

// On Windows we need to explicitly set the file mode to not mangle
// newline characters.  On *nix there is no difference.
#ifdef _WIN32
#include <io.h>
#include <fcntl.h>
static void set_binary_mode(FILE *f) {
  setmode(fileno(f), O_BINARY);
}
#else
static void set_binary_mode(FILE *f) {
  (void)f;
}
#endif

static int read_byte(FILE *f, void* dest) {
  size_t num_elems_read = fread(dest, 1, 1, f);
  return num_elems_read == 1 ? 0 : 1;
}

//// Types

struct primtype_info_t {
  const char binname[4]; // Used for parsing binary data.
  const char* type_name; // Same name as in Futhark.
  const int64_t size; // in bytes
  const writer write_str; // Write in text format.
  const str_reader read_str; // Read in text format.
};

static const struct primtype_info_t i8_info =
  {.binname = "  i8", .type_name = "i8",   .size = 1,
   .write_str = (writer)write_str_i8, .read_str = (str_reader)read_str_i8};
static const struct primtype_info_t i16_info =
  {.binname = " i16", .type_name = "i16",  .size = 2,
   .write_str = (writer)write_str_i16, .read_str = (str_reader)read_str_i16};
static const struct primtype_info_t i32_info =
  {.binname = " i32", .type_name = "i32",  .size = 4,
   .write_str = (writer)write_str_i32, .read_str = (str_reader)read_str_i32};
static const struct primtype_info_t i64_info =
  {.binname = " i64", .type_name = "i64",  .size = 8,
   .write_str = (writer)write_str_i64, .read_str = (str_reader)read_str_i64};
static const struct primtype_info_t u8_info =
  {.binname = "  u8", .type_name = "u8",   .size = 1,
   .write_str = (writer)write_str_u8, .read_str = (str_reader)read_str_u8};
static const struct primtype_info_t u16_info =
  {.binname = " u16", .type_name = "u16",  .size = 2,
   .write_str = (writer)write_str_u16, .read_str = (str_reader)read_str_u16};
static const struct primtype_info_t u32_info =
  {.binname = " u32", .type_name = "u32",  .size = 4,
   .write_str = (writer)write_str_u32, .read_str = (str_reader)read_str_u32};
static const struct primtype_info_t u64_info =
  {.binname = " u64", .type_name = "u64",  .size = 8,
   .write_str = (writer)write_str_u64, .read_str = (str_reader)read_str_u64};
static const struct primtype_info_t f16_info =
  {.binname = " f16", .type_name = "f16",  .size = 2,
   .write_str = (writer)write_str_f16, .read_str = (str_reader)read_str_f16};
static const struct primtype_info_t f32_info =
  {.binname = " f32", .type_name = "f32",  .size = 4,
   .write_str = (writer)write_str_f32, .read_str = (str_reader)read_str_f32};
static const struct primtype_info_t f64_info =
  {.binname = " f64", .type_name = "f64",  .size = 8,
   .write_str = (writer)write_str_f64, .read_str = (str_reader)read_str_f64};
static const struct primtype_info_t bool_info =
  {.binname = "bool", .type_name = "bool", .size = 1,
   .write_str = (writer)write_str_bool, .read_str = (str_reader)read_str_bool};

static const struct primtype_info_t* primtypes[] = {
  &i8_info, &i16_info, &i32_info, &i64_info,
  &u8_info, &u16_info, &u32_info, &u64_info,
  &f16_info, &f32_info, &f64_info,
  &bool_info,
  NULL // NULL-terminated
};

// General value interface.  All endian business taken care of at
// lower layers.

static int read_is_binary(FILE *f) {
  skipspaces(f);
  int c = getc(f);
  if (c == 'b') {
    int8_t bin_version;
    int ret = read_byte(f, &bin_version);

    if (ret != 0) { futhark_panic(1, "binary-input: could not read version.\n"); }

    if (bin_version != BINARY_FORMAT_VERSION) {
      futhark_panic(1, "binary-input: File uses version %i, but I only understand version %i.\n",
            bin_version, BINARY_FORMAT_VERSION);
    }

    return 1;
  }
  ungetc(c, f);
  return 0;
}

static const struct primtype_info_t* read_bin_read_type_enum(FILE *f) {
  char read_binname[4];

  int num_matched = fscanf(f, "%4c", read_binname);
  if (num_matched != 1) { futhark_panic(1, "binary-input: Couldn't read element type.\n"); }

  const struct primtype_info_t **type = primtypes;

  for (; *type != NULL; type++) {
    // I compare the 4 characters manually instead of using strncmp because
    // this allows any value to be used, also NULL bytes
    if (memcmp(read_binname, (*type)->binname, 4) == 0) {
      return *type;
    }
  }
  futhark_panic(1, "binary-input: Did not recognize the type '%s'.\n", read_binname);
  return NULL;
}

static void read_bin_ensure_scalar(FILE *f, const struct primtype_info_t *expected_type) {
  int8_t bin_dims;
  int ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != 0) {
    futhark_panic(1, "binary-input: Expected scalar (0 dimensions), but got array with %i dimensions.\n",
          bin_dims);
  }

  const struct primtype_info_t *bin_type = read_bin_read_type_enum(f);
  if (bin_type != expected_type) {
    futhark_panic(1, "binary-input: Expected scalar of type %s but got scalar of type %s.\n",
          expected_type->type_name,
          bin_type->type_name);
  }
}

//// High-level interface

static int read_bin_array(FILE *f,
                          const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  int ret;

  int8_t bin_dims;
  ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != dims) {
    futhark_panic(1, "binary-input: Expected %i dimensions, but got array with %i dimensions.\n",
          dims, bin_dims);
  }

  const struct primtype_info_t *bin_primtype = read_bin_read_type_enum(f);
  if (expected_type != bin_primtype) {
    futhark_panic(1, "binary-input: Expected %iD-array with element type '%s' but got %iD-array with element type '%s'.\n",
          dims, expected_type->type_name, dims, bin_primtype->type_name);
  }

  int64_t elem_count = 1;
  for (int i=0; i<dims; i++) {
    int64_t bin_shape;
    ret = (int)fread(&bin_shape, sizeof(bin_shape), 1, f);
    if (ret != 1) {
      futhark_panic(1, "binary-input: Couldn't read size for dimension %i of array.\n", i);
    }
    if (IS_BIG_ENDIAN) {
      flip_bytes(sizeof(bin_shape), (unsigned char*) &bin_shape);
    }
    elem_count *= bin_shape;
    shape[i] = bin_shape;
  }

  int64_t elem_size = expected_type->size;
  void* tmp = realloc(*data, (size_t)(elem_count * elem_size));
  if (tmp == NULL) {
    futhark_panic(1, "binary-input: Failed to allocate array of size %i.\n",
          elem_count * elem_size);
  }
  *data = tmp;

  int64_t num_elems_read = (int64_t)fread(*data, (size_t)elem_size, (size_t)elem_count, f);
  if (num_elems_read != elem_count) {
    futhark_panic(1, "binary-input: tried to read %i elements of an array, but only got %i elements.\n",
          elem_count, num_elems_read);
  }

  // If we're on big endian platform we must change all multibyte elements
  // from using little endian to big endian
  if (IS_BIG_ENDIAN && elem_size != 1) {
    flip_bytes((size_t)elem_size, (unsigned char*) *data);
  }

  return 0;
}

static int read_array(FILE *f, const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  if (!read_is_binary(f)) {
    return read_str_array(f, expected_type->size, (str_reader)expected_type->read_str, expected_type->type_name, data, shape, dims);
  } else {
    return read_bin_array(f, expected_type, data, shape, dims);
  }
}

static int end_of_input(FILE *f) {
  skipspaces(f);
  char token[2];
  next_token(f, token, sizeof(token));
  if (strcmp(token, "") == 0) {
    return 0;
  } else {
    return 1;
  }
}

static int write_str_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  if (rank==0) {
    elem_type->write_str(out, (const void*)data);
  } else {
    int64_t len = (int64_t)shape[0];
    int64_t slice_size = 1;

    int64_t elem_size = elem_type->size;
    for (int8_t i = 1; i < rank; i++) {
      slice_size *= shape[i];
    }

    if (len*slice_size == 0) {
      fprintf(out, "empty(");
      for (int64_t i = 0; i < rank; i++) {
        fprintf(out, "[%"PRIi64"]", shape[i]);
      }
      fprintf(out, "%s", elem_type->type_name);
      fprintf(out, ")");
    } else if (rank==1) {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        elem_type->write_str(out, (const void*) (data + i * elem_size));
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    } else {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        write_str_array(out, elem_type, data + i * slice_size * elem_size, shape+1, rank-1);
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    }
  }
  return 0;
}

static int write_bin_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  int64_t num_elems = 1;
  for (int64_t i = 0; i < rank; i++) {
    num_elems *= shape[i];
  }

  fputc('b', out);
  fputc((char)BINARY_FORMAT_VERSION, out);
  fwrite(&rank, sizeof(int8_t), 1, out);
  fwrite(elem_type->binname, 4, 1, out);
  if (shape != NULL) {
    fwrite(shape, sizeof(int64_t), (size_t)rank, out);
  }

  if (IS_BIG_ENDIAN) {
    for (int64_t i = 0; i < num_elems; i++) {
      const unsigned char *elem = data+i*elem_type->size;
      for (int64_t j = 0; j < elem_type->size; j++) {
        fwrite(&elem[elem_type->size-j], 1, 1, out);
      }
    }
  } else {
    fwrite(data, (size_t)elem_type->size, (size_t)num_elems, out);
  }

  return 0;
}

static int write_array(FILE *out, int write_binary,
                       const struct primtype_info_t *elem_type,
                       const void *data,
                       const int64_t *shape,
                       const int8_t rank) {
  if (write_binary) {
    return write_bin_array(out, elem_type, data, shape, rank);
  } else {
    return write_str_array(out, elem_type, data, shape, rank);
  }
}

static int read_scalar(FILE *f,
                       const struct primtype_info_t *expected_type, void *dest) {
  if (!read_is_binary(f)) {
    char buf[100];
    next_token(f, buf, sizeof(buf));
    return expected_type->read_str(buf, dest);
  } else {
    read_bin_ensure_scalar(f, expected_type);
    size_t elem_size = (size_t)expected_type->size;
    size_t num_elems_read = fread(dest, elem_size, 1, f);
    if (IS_BIG_ENDIAN) {
      flip_bytes(elem_size, (unsigned char*) dest);
    }
    return num_elems_read == 1 ? 0 : 1;
  }
}

static int write_scalar(FILE *out, int write_binary, const struct primtype_info_t *type, void *src) {
  if (write_binary) {
    return write_bin_array(out, type, src, NULL, 0);
  } else {
    return type->write_str(out, src);
  }
}

// End of values.h.

// Start of server.h.

// Forward declarations of things that we technically don't know until
// the application header file is included, but which we need.
struct futhark_context_config;
struct futhark_context;
char *futhark_context_get_error(struct futhark_context *ctx);
int futhark_context_sync(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value);
int futhark_get_tuning_param_count(void);
const char* futhark_get_tuning_param_name(int i);
const char* futhark_get_tuning_param_class(int i);

typedef int (*restore_fn)(const void*, FILE *, struct futhark_context*, void*);
typedef void (*store_fn)(const void*, FILE *, struct futhark_context*, void*);
typedef int (*free_fn)(const void*, struct futhark_context*, void*);
typedef int (*project_fn)(struct futhark_context*, void*, const void*);
typedef int (*new_fn)(struct futhark_context*, void**, const void*[]);

struct field {
  const char *name;
  const struct type *type;
  project_fn project;
};

struct record {
  int num_fields;
  const struct field* fields;
  new_fn new;
};

struct type {
  const char *name;
  restore_fn restore;
  store_fn store;
  free_fn free;
  const void *aux;
  const struct record *record;
};

int free_scalar(const void *aux, struct futhark_context *ctx, void *p) {
  (void)aux;
  (void)ctx;
  (void)p;
  // Nothing to do.
  return 0;
}

#define DEF_SCALAR_TYPE(T)                                      \
  int restore_##T(const void *aux, FILE *f,                     \
                  struct futhark_context *ctx, void *p) {       \
    (void)aux;                                                  \
    (void)ctx;                                                  \
    return read_scalar(f, &T##_info, p);                        \
  }                                                             \
                                                                \
  void store_##T(const void *aux, FILE *f,                      \
                 struct futhark_context *ctx, void *p) {        \
    (void)aux;                                                  \
    (void)ctx;                                                  \
    write_scalar(f, 1, &T##_info, p);                           \
  }                                                             \
                                                                \
  struct type type_##T =                                        \
    { .name = #T,                                               \
      .restore = restore_##T,                                   \
      .store = store_##T,                                       \
      .free = free_scalar                                       \
    }                                                           \

DEF_SCALAR_TYPE(i8);
DEF_SCALAR_TYPE(i16);
DEF_SCALAR_TYPE(i32);
DEF_SCALAR_TYPE(i64);
DEF_SCALAR_TYPE(u8);
DEF_SCALAR_TYPE(u16);
DEF_SCALAR_TYPE(u32);
DEF_SCALAR_TYPE(u64);
DEF_SCALAR_TYPE(f16);
DEF_SCALAR_TYPE(f32);
DEF_SCALAR_TYPE(f64);
DEF_SCALAR_TYPE(bool);

struct value {
  const struct type *type;
  union {
    void *v_ptr;
    int8_t  v_i8;
    int16_t v_i16;
    int32_t v_i32;
    int64_t v_i64;

    uint8_t  v_u8;
    uint16_t v_u16;
    uint32_t v_u32;
    uint64_t v_u64;

    uint16_t v_f16;
    float v_f32;
    double v_f64;

    bool v_bool;
  } value;
};

void* value_ptr(struct value *v) {
  if (v->type == &type_i8) {
    return &v->value.v_i8;
  }
  if (v->type == &type_i16) {
    return &v->value.v_i16;
  }
  if (v->type == &type_i32) {
    return &v->value.v_i32;
  }
  if (v->type == &type_i64) {
    return &v->value.v_i64;
  }
  if (v->type == &type_u8) {
    return &v->value.v_u8;
  }
  if (v->type == &type_u16) {
    return &v->value.v_u16;
  }
  if (v->type == &type_u32) {
    return &v->value.v_u32;
  }
  if (v->type == &type_u64) {
    return &v->value.v_u64;
  }
  if (v->type == &type_f16) {
    return &v->value.v_f16;
  }
  if (v->type == &type_f32) {
    return &v->value.v_f32;
  }
  if (v->type == &type_f64) {
    return &v->value.v_f64;
  }
  if (v->type == &type_bool) {
    return &v->value.v_bool;
  }
  return &v->value.v_ptr;
}

struct variable {
  // NULL name indicates free slot.  Name is owned by this struct.
  char *name;
  struct value value;
};

typedef int (*entry_point_fn)(struct futhark_context*, void**, void**);

struct entry_point {
  const char *name;
  entry_point_fn f;
  const char** tuning_params;
  const struct type **out_types;
  bool *out_unique;
  const struct type **in_types;
  bool *in_unique;
};

int entry_num_ins(struct entry_point *e) {
  int count = 0;
  while (e->in_types[count]) {
    count++;
  }
  return count;
}

int entry_num_outs(struct entry_point *e) {
  int count = 0;
  while (e->out_types[count]) {
    count++;
  }
  return count;
}

struct futhark_prog {
  // Last entry point identified by NULL name.
  struct entry_point *entry_points;
  // Last type identified by NULL name.
  const struct type **types;
};

struct server_state {
  struct futhark_prog prog;
  struct futhark_context_config *cfg;
  struct futhark_context *ctx;
  int variables_capacity;
  struct variable *variables;
};

struct variable* get_variable(struct server_state *s,
                              const char *name) {
  for (int i = 0; i < s->variables_capacity; i++) {
    if (s->variables[i].name != NULL &&
        strcmp(s->variables[i].name, name) == 0) {
      return &s->variables[i];
    }
  }

  return NULL;
}

struct variable* create_variable(struct server_state *s,
                                 const char *name,
                                 const struct type *type) {
  int found = -1;
  for (int i = 0; i < s->variables_capacity; i++) {
    if (found == -1 && s->variables[i].name == NULL) {
      found = i;
    } else if (s->variables[i].name != NULL &&
               strcmp(s->variables[i].name, name) == 0) {
      return NULL;
    }
  }

  if (found != -1) {
    // Found a free spot.
    s->variables[found].name = strdup(name);
    s->variables[found].value.type = type;
    return &s->variables[found];
  }

  // Need to grow the buffer.
  found = s->variables_capacity;
  s->variables_capacity *= 2;
  s->variables = realloc(s->variables,
                         s->variables_capacity * sizeof(struct variable));

  s->variables[found].name = strdup(name);
  s->variables[found].value.type = type;

  for (int i = found+1; i < s->variables_capacity; i++) {
    s->variables[i].name = NULL;
  }

  return &s->variables[found];
}

void drop_variable(struct variable *v) {
  free(v->name);
  v->name = NULL;
}

int arg_exists(const char *args[], int i) {
  return args[i] != NULL;
}

const char* get_arg(const char *args[], int i) {
  if (!arg_exists(args, i)) {
    futhark_panic(1, "Insufficient command args.\n");
  }
  return args[i];
}

const struct type* get_type(struct server_state *s, const char *name) {
  for (int i = 0; s->prog.types[i]; i++) {
    if (strcmp(s->prog.types[i]->name, name) == 0) {
      return s->prog.types[i];
    }
  }

  futhark_panic(1, "Unknown type %s\n", name);
  return NULL;
}

struct entry_point* get_entry_point(struct server_state *s, const char *name) {
  for (int i = 0; s->prog.entry_points[i].name; i++) {
    if (strcmp(s->prog.entry_points[i].name, name) == 0) {
      return &s->prog.entry_points[i];
    }
  }

  return NULL;
}

// Print the command-done marker, indicating that we are ready for
// more input.
void ok(void) {
  printf("%%%%%% OK\n");
  fflush(stdout);
}

// Print the failure marker.  Output is now an error message until the
// next ok().
void failure(void) {
  printf("%%%%%% FAILURE\n");
}

void error_check(struct server_state *s, int err) {
  if (err != 0) {
    failure();
    char *error = futhark_context_get_error(s->ctx);
    if (error != NULL) {
      puts(error);
    }
    free(error);
  }
}

void cmd_call(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);

  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_outs = entry_num_outs(e);
  int num_ins = entry_num_ins(e);
  // +1 to avoid zero-size arrays, which is UB.
  void* outs[num_outs+1];
  void* ins[num_ins+1];

  for (int i = 0; i < num_ins; i++) {
    const char *in_name = get_arg(args, 1+num_outs+i);
    struct variable *v = get_variable(s, in_name);
    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", in_name);
      return;
    }
    if (v->value.type != e->in_types[i]) {
      failure();
      printf("Wrong input type.  Expected %s, got %s.\n",
             e->in_types[i]->name, v->value.type->name);
      return;
    }
    ins[i] = value_ptr(&v->value);
  }

  for (int i = 0; i < num_outs; i++) {
    const char *out_name = get_arg(args, 1+i);
    struct variable *v = create_variable(s, out_name, e->out_types[i]);
    if (v == NULL) {
      failure();
      printf("Variable already exists: %s\n", out_name);
      return;
    }
    outs[i] = value_ptr(&v->value);
  }

  int64_t t_start = get_wall_time();
  int err = e->f(s->ctx, outs, ins);
  err |= futhark_context_sync(s->ctx);
  int64_t t_end = get_wall_time();
  long long int elapsed_usec = t_end - t_start;
  printf("runtime: %lld\n", elapsed_usec);

  error_check(s, err);
  if (err != 0) {
    // Need to uncreate the output variables, which would otherwise be left
    // in an uninitialised state.
    for (int i = 0; i < num_outs; i++) {
      const char *out_name = get_arg(args, 1+i);
      struct variable *v = get_variable(s, out_name);
      if (v) {
        drop_variable(v);
      }
    }
  }
}

void cmd_restore(struct server_state *s, const char *args[]) {
  const char *fname = get_arg(args, 0);

  FILE *f = fopen(fname, "rb");
  if (f == NULL) {
    failure();
    printf("Failed to open %s: %s\n", fname, strerror(errno));
    return;
  }

  int bad = 0;
  int values = 0;
  for (int i = 1; arg_exists(args, i); i+=2, values++) {
    const char *vname = get_arg(args, i);
    const char *type = get_arg(args, i+1);

    const struct type *t = get_type(s, type);
    struct variable *v = create_variable(s, vname, t);

    if (v == NULL) {
      bad = 1;
      failure();
      printf("Variable already exists: %s\n", vname);
      break;
    }

    errno = 0;
    if (t->restore(t->aux, f, s->ctx, value_ptr(&v->value)) != 0) {
      bad = 1;
      failure();
      printf("Failed to restore variable %s.\n"
             "Possibly malformed data in %s (errno: %s)\n",
             vname, fname, strerror(errno));
      drop_variable(v);
      break;
    }
  }

  if (!bad && end_of_input(f) != 0) {
    failure();
    printf("Expected EOF after reading %d values from %s\n",
           values, fname);
  }

  fclose(f);

  if (!bad) {
    int err = futhark_context_sync(s->ctx);
    error_check(s, err);
  }
}

void cmd_store(struct server_state *s, const char *args[]) {
  const char *fname = get_arg(args, 0);

  FILE *f = fopen(fname, "wb");
  if (f == NULL) {
    failure();
    printf("Failed to open %s: %s\n", fname, strerror(errno));
  } else {
    for (int i = 1; arg_exists(args, i); i++) {
      const char *vname = get_arg(args, i);
      struct variable *v = get_variable(s, vname);

      if (v == NULL) {
        failure();
        printf("Unknown variable: %s\n", vname);
        return;
      }

      const struct type *t = v->value.type;
      t->store(t->aux, f, s->ctx, value_ptr(&v->value));
    }
    fclose(f);
  }
}

void cmd_free(struct server_state *s, const char *args[]) {
  for (int i = 0; arg_exists(args, i); i++) {
    const char *name = get_arg(args, i);
    struct variable *v = get_variable(s, name);

    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", name);
      return;
    }

    const struct type *t = v->value.type;

    int err = t->free(t->aux, s->ctx, value_ptr(&v->value));
    error_check(s, err);
    drop_variable(v);
  }
}

void cmd_rename(struct server_state *s, const char *args[]) {
  const char *oldname = get_arg(args, 0);
  const char *newname = get_arg(args, 1);
  struct variable *old = get_variable(s, oldname);
  struct variable *new = get_variable(s, newname);

  if (old == NULL) {
    failure();
    printf("Unknown variable: %s\n", oldname);
    return;
  }

  if (new != NULL) {
    failure();
    printf("Variable already exists: %s\n", newname);
    return;
  }

  free(old->name);
  old->name = strdup(newname);
}

void cmd_inputs(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_ins = entry_num_ins(e);
  for (int i = 0; i < num_ins; i++) {
    if (e->in_unique[i]) {
      putchar('*');
    }
    puts(e->in_types[i]->name);
  }
}

void cmd_outputs(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_outs = entry_num_outs(e);
  for (int i = 0; i < num_outs; i++) {
    if (e->out_unique[i]) {
      putchar('*');
    }
    puts(e->out_types[i]->name);
  }
}

void cmd_clear(struct server_state *s, const char *args[]) {
  (void)args;
  int err = 0;
  for (int i = 0; i < s->variables_capacity; i++) {
    struct variable *v = &s->variables[i];
    if (v->name != NULL) {
      err |= v->value.type->free(v->value.type->aux, s->ctx, value_ptr(&v->value));
      drop_variable(v);
    }
  }
  err |= futhark_context_clear_caches(s->ctx);
  error_check(s, err);
}

void cmd_pause_profiling(struct server_state *s, const char *args[]) {
  (void)args;
  futhark_context_pause_profiling(s->ctx);
}

void cmd_unpause_profiling(struct server_state *s, const char *args[]) {
  (void)args;
  futhark_context_unpause_profiling(s->ctx);
}

void cmd_report(struct server_state *s, const char *args[]) {
  (void)args;
  char *report = futhark_context_report(s->ctx);
  if (report) {
    puts(report);
  } else {
    failure();
    report = futhark_context_get_error(s->ctx);
    if (report) {
      puts(report);
    } else {
      puts("Failed to produce profiling report.\n");
    }
  }
  free(report);
}

void cmd_set_tuning_param(struct server_state *s, const char *args[]) {
  const char *param = get_arg(args, 0);
  const char *val_s = get_arg(args, 1);
  size_t val = atol(val_s);
  int err = futhark_context_config_set_tuning_param(s->cfg, param, val);

  error_check(s, err);

  if (err != 0) {
    printf("Failed to set tuning parameter %s to %ld\n", param, (long)val);
  }
}

void cmd_tuning_params(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  const char **params = e->tuning_params;
  for (int i = 0; params[i] != NULL; i++) {
    printf("%s\n", params[i]);
  }
}

void cmd_tuning_param_class(struct server_state *s, const char *args[]) {
  (void)s;
  const char *param = get_arg(args, 0);

  int n = futhark_get_tuning_param_count();

  for (int i = 0; i < n; i++) {
    if (strcmp(futhark_get_tuning_param_name(i), param) == 0) {
      printf("%s\n", futhark_get_tuning_param_class(i));
      return;
    }
  }

  failure();
  printf("Unknown tuning parameter: %s\n", param);
}

void cmd_fields(struct server_state *s, const char *args[]) {
  const char *type = get_arg(args, 0);
  const struct type *t = get_type(s, type);
  const struct record *r = t->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  for (int i = 0; i < r->num_fields; i++) {
    const struct field f = r->fields[i];
    printf("%s %s\n", f.name, f.type->name);
  }
}

void cmd_project(struct server_state *s, const char *args[]) {
  const char *to_name = get_arg(args, 0);
  const char *from_name = get_arg(args, 1);
  const char *field_name = get_arg(args, 2);

  struct variable *from = get_variable(s, from_name);

  if (from == NULL) {
    failure();
    printf("Unknown variable: %s\n", from_name);
    return;
  }

  const struct type *from_type = from->value.type;
  const struct record *r = from_type->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  const struct field *field = NULL;
  for (int i = 0; i < r->num_fields; i++) {
    if (strcmp(r->fields[i].name, field_name) == 0) {
      field = &r->fields[i];
      break;
    }
  }

  if (field == NULL) {
    failure();
    printf("No such field\n");
  }

  struct variable *to = create_variable(s, to_name, field->type);

  if (to == NULL) {
    failure();
    printf("Variable already exists: %s\n", to_name);
    return;
  }

  field->project(s->ctx, value_ptr(&to->value), from->value.value.v_ptr);
}

void cmd_new(struct server_state *s, const char *args[]) {
  const char *to_name = get_arg(args, 0);
  const char *type_name = get_arg(args, 1);
  const struct type *type = get_type(s, type_name);
  struct variable *to = create_variable(s, to_name, type);

  if (to == NULL) {
    failure();
    printf("Variable already exists: %s\n", to_name);
    return;
  }

  const struct record* r = type->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  int num_args = 0;
  for (int i = 2; arg_exists(args, i); i++) {
    num_args++;
  }

  if (num_args != r->num_fields) {
    failure();
    printf("%d fields expected but %d values provided.\n", num_args, r->num_fields);
    return;
  }

  const void** value_ptrs = alloca(num_args * sizeof(void*));

  for (int i = 0; i < num_args; i++) {
    struct variable* v = get_variable(s, args[2+i]);

    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", args[2+i]);
      return;
    }

    if (strcmp(v->value.type->name, r->fields[i].type->name) != 0) {
      failure();
      printf("Field %s mismatch: expected type %s, got %s\n",
             r->fields[i].name, r->fields[i].type->name, v->value.type->name);
      return;
    }

    value_ptrs[i] = value_ptr(&v->value);
  }

  r->new(s->ctx, value_ptr(&to->value), value_ptrs);
}

void cmd_entry_points(struct server_state *s, const char *args[]) {
  (void)args;
  for (int i = 0; s->prog.entry_points[i].name; i++) {
    puts(s->prog.entry_points[i].name);
  }
}

void cmd_types(struct server_state *s, const char *args[]) {
  (void)args;
  for (int i = 0; s->prog.types[i] != NULL; i++) {
    puts(s->prog.types[i]->name);
  }
}

char *next_word(char **line) {
  char *p = *line;

  while (isspace(*p)) {
    p++;
  }

  if (*p == 0) {
    return NULL;
  }

  if (*p == '"') {
    char *save = p+1;
    // Skip ahead till closing quote.
    p++;

    while (*p && *p != '"') {
      p++;
    }

    if (*p == '"') {
      *p = 0;
      *line = p+1;
      return save;
    } else {
      return NULL;
    }
  } else {
    char *save = p;
    // Skip ahead till next whitespace.

    while (*p && !isspace(*p)) {
      p++;
    }

    if (*p) {
      *p = 0;
      *line = p+1;
    } else {
      *line = p;
    }
    return save;
  }
}

void process_line(struct server_state *s, char *line) {
  int max_num_tokens = 1000;
  const char* tokens[max_num_tokens];
  int num_tokens = 0;

  while ((tokens[num_tokens] = next_word(&line)) != NULL) {
    num_tokens++;
    if (num_tokens == max_num_tokens) {
      futhark_panic(1, "Line too long.\n");
    }
  }

  const char *command = tokens[0];

  if (command == NULL) {
    failure();
    printf("Empty line\n");
  } else if (strcmp(command, "call") == 0) {
    cmd_call(s, tokens+1);
  } else if (strcmp(command, "restore") == 0) {
    cmd_restore(s, tokens+1);
  } else if (strcmp(command, "store") == 0) {
    cmd_store(s, tokens+1);
  } else if (strcmp(command, "free") == 0) {
    cmd_free(s, tokens+1);
  } else if (strcmp(command, "rename") == 0) {
    cmd_rename(s, tokens+1);
  } else if (strcmp(command, "inputs") == 0) {
    cmd_inputs(s, tokens+1);
  } else if (strcmp(command, "outputs") == 0) {
    cmd_outputs(s, tokens+1);
  } else if (strcmp(command, "clear") == 0) {
    cmd_clear(s, tokens+1);
  } else if (strcmp(command, "pause_profiling") == 0) {
    cmd_pause_profiling(s, tokens+1);
  } else if (strcmp(command, "unpause_profiling") == 0) {
    cmd_unpause_profiling(s, tokens+1);
  } else if (strcmp(command, "report") == 0) {
    cmd_report(s, tokens+1);
  } else if (strcmp(command, "set_tuning_param") == 0) {
    cmd_set_tuning_param(s, tokens+1);
  } else if (strcmp(command, "tuning_params") == 0) {
    cmd_tuning_params(s, tokens+1);
  } else if (strcmp(command, "tuning_param_class") == 0) {
    cmd_tuning_param_class(s, tokens+1);
  } else if (strcmp(command, "fields") == 0) {
    cmd_fields(s, tokens+1);
  } else if (strcmp(command, "new") == 0) {
    cmd_new(s, tokens+1);
  } else if (strcmp(command, "project") == 0) {
    cmd_project(s, tokens+1);
  } else if (strcmp(command, "entry_points") == 0) {
    cmd_entry_points(s, tokens+1);
  } else if (strcmp(command, "types") == 0) {
    cmd_types(s, tokens+1);
  } else {
    futhark_panic(1, "Unknown command: %s\n", command);
  }
}

void run_server(struct futhark_prog *prog,
                struct futhark_context_config *cfg,
                struct futhark_context *ctx) {
  char *line = NULL;
  size_t buflen = 0;
  ssize_t linelen;

  struct server_state s = {
    .cfg = cfg,
    .ctx = ctx,
    .variables_capacity = 100,
    .prog = *prog
  };

  s.variables = malloc(s.variables_capacity * sizeof(struct variable));

  for (int i = 0; i < s.variables_capacity; i++) {
    s.variables[i].name = NULL;
  }

  ok();
  while ((linelen = getline(&line, &buflen, stdin)) > 0) {
    process_line(&s, line);
    ok();
  }

  free(s.variables);
  free(line);
}

// The aux struct lets us write generic method implementations without
// code duplication.

typedef void* (*array_new_fn)(struct futhark_context *, const void*, const int64_t*);
typedef const int64_t* (*array_shape_fn)(struct futhark_context*, void*);
typedef int (*array_values_fn)(struct futhark_context*, void*, void*);
typedef int (*array_free_fn)(struct futhark_context*, void*);

struct array_aux {
  int rank;
  const struct primtype_info_t* info;
  const char *name;
  array_new_fn new;
  array_shape_fn shape;
  array_values_fn values;
  array_free_fn free;
};

int restore_array(const struct array_aux *aux, FILE *f,
                  struct futhark_context *ctx, void *p) {
  void *data = NULL;
  int64_t shape[aux->rank];
  if (read_array(f, aux->info, &data, shape, aux->rank) != 0) {
    return 1;
  }

  void *arr = aux->new(ctx, data, shape);
  if (arr == NULL) {
    return 1;
  }
  int err = futhark_context_sync(ctx);
  *(void**)p = arr;
  free(data);
  return err;
}

void store_array(const struct array_aux *aux, FILE *f,
                 struct futhark_context *ctx, void *p) {
  void *arr = *(void**)p;
  const int64_t *shape = aux->shape(ctx, arr);
  int64_t size = sizeof(aux->info->size);
  for (int i = 0; i < aux->rank; i++) {
    size *= shape[i];
  }
  int32_t *data = malloc(size);
  assert(aux->values(ctx, arr, data) == 0);
  assert(futhark_context_sync(ctx) == 0);
  assert(write_array(f, 1, aux->info, data, shape, aux->rank) == 0);
  free(data);
}

int free_array(const struct array_aux *aux,
               struct futhark_context *ctx, void *p) {
  void *arr = *(void**)p;
  return aux->free(ctx, arr);
}

typedef void* (*opaque_restore_fn)(struct futhark_context*, void*);
typedef int (*opaque_store_fn)(struct futhark_context*, const void*, void **, size_t *);
typedef int (*opaque_free_fn)(struct futhark_context*, void*);

struct opaque_aux {
  opaque_restore_fn restore;
  opaque_store_fn store;
  opaque_free_fn free;
};

int restore_opaque(const struct opaque_aux *aux, FILE *f,
                   struct futhark_context *ctx, void *p) {
  // We have a problem: we need to load data from 'f', since the
  // restore function takes a pointer, but we don't know how much we
  // need (and cannot possibly).  So we do something hacky: we read
  // *all* of the file, pass all of the data to the restore function
  // (which doesn't care if there's extra at the end), then we compute
  // how much space the the object actually takes in serialised form
  // and rewind the file to that position.  The only downside is more IO.
  size_t start = ftell(f);
  size_t size;
  char *bytes = fslurp_file(f, &size);
  void *obj = aux->restore(ctx, bytes);
  free(bytes);
  if (obj != NULL) {
    *(void**)p = obj;
    size_t obj_size;
    (void)aux->store(ctx, obj, NULL, &obj_size);
    fseek(f, start+obj_size, SEEK_SET);
    return 0;
  } else {
    fseek(f, start, SEEK_SET);
    return 1;
  }
}

void store_opaque(const struct opaque_aux *aux, FILE *f,
                  struct futhark_context *ctx, void *p) {
  void *obj = *(void**)p;
  size_t obj_size;
  void *data = NULL;
  (void)aux->store(ctx, obj, &data, &obj_size);
  assert(futhark_context_sync(ctx) == 0);
  fwrite(data, sizeof(char), obj_size, f);
  free(data);
}

int free_opaque(const struct opaque_aux *aux,
                struct futhark_context *ctx, void *p) {
  void *obj = *(void**)p;
  return aux->free(ctx, obj);
}

// End of server.h.

// Start of tuning.h.


int is_blank_line_or_comment(const char *s) {
  size_t i = strspn(s, " \t\n");
  return s[i] == '\0' || // Line is blank.
         strncmp(s + i, "--", 2) == 0; // Line is comment.
}

static char* load_tuning_file(const char *fname,
                              void *cfg,
                              int (*set_tuning_param)(void*, const char*, size_t)) {
  const int max_line_len = 1024;
  char* line = (char*) malloc(max_line_len);

  FILE *f = fopen(fname, "r");

  if (f == NULL) {
    snprintf(line, max_line_len, "Cannot open file: %s", strerror(errno));
    return line;
  }

  int lineno = 0;
  while (fgets(line, max_line_len, f) != NULL) {
    lineno++;
    if (is_blank_line_or_comment(line)) {
      continue;
    }
    char *eql = strstr(line, "=");
    if (eql) {
      *eql = 0;
      char *endptr;
      int value = strtol(eql+1, &endptr, 10);
      if (*endptr && *endptr != '\n') {
        snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
                 lineno);
        return line;
      }
      if (set_tuning_param(cfg, line, (size_t)value) != 0) {
        char* err = (char*) malloc(max_line_len + 50);
        snprintf(err, max_line_len + 50, "Unknown name '%s' on line %d.", line, lineno);
        free(line);
        return err;
      }
    } else {
      snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
               lineno);
      return line;
    }
  }

  free(line);

  return NULL;
}

// End of tuning.h.

const struct type type_ZMZNZMZNi8;
const struct type type_ZMZNi64;
const struct type type_ZMZNi8;
void *futhark_new_i8_2d_wrap(struct futhark_context *ctx, const void *p, const int64_t *shape)
{
    return futhark_new_i8_2d(ctx, p, shape[0], shape[1]);
}
const struct array_aux type_ZMZNZMZNi8_aux = {.name ="[][]i8", .rank =2, .info =&i8_info, .new =(array_new_fn) futhark_new_i8_2d_wrap, .free =(array_free_fn) futhark_free_i8_2d, .shape =(array_shape_fn) futhark_shape_i8_2d, .values =(array_values_fn) futhark_values_i8_2d};
const struct type type_ZMZNZMZNi8 = {.name ="[][]i8", .restore =(restore_fn) restore_array, .store =(store_fn) store_array, .free =(free_fn) free_array, .aux =&type_ZMZNZMZNi8_aux};
void *futhark_new_i64_1d_wrap(struct futhark_context *ctx, const void *p, const int64_t *shape)
{
    return futhark_new_i64_1d(ctx, p, shape[0]);
}
const struct array_aux type_ZMZNi64_aux = {.name ="[]i64", .rank =1, .info =&i64_info, .new =(array_new_fn) futhark_new_i64_1d_wrap, .free =(array_free_fn) futhark_free_i64_1d, .shape =(array_shape_fn) futhark_shape_i64_1d, .values =(array_values_fn) futhark_values_i64_1d};
const struct type type_ZMZNi64 = {.name ="[]i64", .restore =(restore_fn) restore_array, .store =(store_fn) store_array, .free =(free_fn) free_array, .aux =&type_ZMZNi64_aux};
void *futhark_new_i8_1d_wrap(struct futhark_context *ctx, const void *p, const int64_t *shape)
{
    return futhark_new_i8_1d(ctx, p, shape[0]);
}
const struct array_aux type_ZMZNi8_aux = {.name ="[]i8", .rank =1, .info =&i8_info, .new =(array_new_fn) futhark_new_i8_1d_wrap, .free =(array_free_fn) futhark_free_i8_1d, .shape =(array_shape_fn) futhark_shape_i8_1d, .values =(array_values_fn) futhark_values_i8_1d};
const struct type type_ZMZNi8 = {.name ="[]i8", .restore =(restore_fn) restore_array, .store =(store_fn) store_array, .free =(free_fn) free_array, .aux =&type_ZMZNi8_aux};
const struct type *main_out_types[] = {&type_ZMZNi8, NULL};
bool main_out_unique[] = {false};
const struct type *main_in_types[] = {&type_i32, &type_i64, &type_ZMZNi64, &type_ZMZNi64, &type_ZMZNi64, NULL};
bool main_in_unique[] = {false, false, false, false, false};
const char *main_tuning_params[] = {"builtin#iota_i64.tblock_size_24193", "builtin#replicate_i8.tblock_size_23964", "simulate_8477.segmap_num_tblocks_21667", "simulate_8477.segmap_num_tblocks_21675", "simulate_8477.segmap_num_tblocks_21700", "simulate_8477.segmap_num_tblocks_22043", "simulate_8477.segmap_num_tblocks_22077", "simulate_8477.segmap_num_tblocks_22085", "simulate_8477.segmap_num_tblocks_22093", "simulate_8477.segmap_num_tblocks_22109", "simulate_8477.segmap_num_tblocks_22206", "simulate_8477.segmap_num_tblocks_22812", "simulate_8477.segmap_num_tblocks_22820", "simulate_8477.segmap_num_tblocks_22864", "simulate_8477.segmap_num_tblocks_22872", "simulate_8477.segmap_num_tblocks_22918", "simulate_8477.segmap_num_tblocks_22926", "simulate_8477.segmap_num_tblocks_22984", "simulate_8477.segmap_tblock_size_21568", "simulate_8477.segmap_tblock_size_21665", "simulate_8477.segmap_tblock_size_21673", "simulate_8477.segmap_tblock_size_21698", "simulate_8477.segmap_tblock_size_21856", "simulate_8477.segmap_tblock_size_21932", "simulate_8477.segmap_tblock_size_22041", "simulate_8477.segmap_tblock_size_22049", "simulate_8477.segmap_tblock_size_22075", "simulate_8477.segmap_tblock_size_22083", "simulate_8477.segmap_tblock_size_22091", "simulate_8477.segmap_tblock_size_22107", "simulate_8477.segmap_tblock_size_22204", "simulate_8477.segmap_tblock_size_22336", "simulate_8477.segmap_tblock_size_22409", "simulate_8477.segmap_tblock_size_22690", "simulate_8477.segmap_tblock_size_22751", "simulate_8477.segmap_tblock_size_22810", "simulate_8477.segmap_tblock_size_22818", "simulate_8477.segmap_tblock_size_22862", "simulate_8477.segmap_tblock_size_22870", "simulate_8477.segmap_tblock_size_22916", "simulate_8477.segmap_tblock_size_22924", "simulate_8477.segmap_tblock_size_22982", "simulate_8477.segred_num_tblocks_21547", "simulate_8477.segred_num_tblocks_21646", "simulate_8477.segred_num_tblocks_21879", "simulate_8477.segred_num_tblocks_22117", "simulate_8477.segred_num_tblocks_22359", "simulate_8477.segred_num_tblocks_22508", "simulate_8477.segred_num_tblocks_22718", "simulate_8477.segred_num_tblocks_22779", "simulate_8477.segred_num_tblocks_23833", "simulate_8477.segred_tblock_size_21545", "simulate_8477.segred_tblock_size_21644", "simulate_8477.segred_tblock_size_21877", "simulate_8477.segred_tblock_size_22115", "simulate_8477.segred_tblock_size_22357", "simulate_8477.segred_tblock_size_22506", "simulate_8477.segred_tblock_size_22716", "simulate_8477.segred_tblock_size_22777", "simulate_8477.segred_tblock_size_23835", "simulate_8477.segscan_num_tblocks_21657", "simulate_8477.segscan_num_tblocks_22099", "simulate_8477.segscan_tblock_size_21655", "simulate_8477.segscan_tblock_size_22097", "simulate_8477.suff_outer_par_0", "simulate_8477.suff_outer_par_2", "simulate_8477.suff_outer_par_3", "simulate_8477.suff_outer_par_4", "simulate_8477.suff_outer_screma_1", "simulate_8477.tblock_size_24367", "simulate_8477.tblock_size_24387", "simulate_8477.tblock_size_24407", NULL};
int call_main(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_i8_1d * *out0 = outs[0];
    int32_t in0 = *(int32_t *) ins[0];
    int64_t in1 = *(int64_t *) ins[1];
    struct futhark_i64_1d * in2 = *(struct futhark_i64_1d * *) ins[2];
    struct futhark_i64_1d * in3 = *(struct futhark_i64_1d * *) ins[3];
    struct futhark_i64_1d * in4 = *(struct futhark_i64_1d * *) ins[4];
    
    return futhark_entry_main(ctx, out0, in0, in1, in2, in3, in4);
}
const struct type *simple_out_types[] = {&type_ZMZNi8, NULL};
bool simple_out_unique[] = {false};
const struct type *simple_in_types[] = {&type_i64, &type_ZMZNi64, &type_ZMZNi64, &type_ZMZNi64, NULL};
bool simple_in_unique[] = {false, false, false, false};
const char *simple_tuning_params[] = {"builtin#iota_i64.tblock_size_24193", "builtin#replicate_i8.tblock_size_23964", "simulate_8477.segmap_num_tblocks_21667", "simulate_8477.segmap_num_tblocks_21675", "simulate_8477.segmap_num_tblocks_21700", "simulate_8477.segmap_num_tblocks_22043", "simulate_8477.segmap_num_tblocks_22077", "simulate_8477.segmap_num_tblocks_22085", "simulate_8477.segmap_num_tblocks_22093", "simulate_8477.segmap_num_tblocks_22109", "simulate_8477.segmap_num_tblocks_22206", "simulate_8477.segmap_num_tblocks_22812", "simulate_8477.segmap_num_tblocks_22820", "simulate_8477.segmap_num_tblocks_22864", "simulate_8477.segmap_num_tblocks_22872", "simulate_8477.segmap_num_tblocks_22918", "simulate_8477.segmap_num_tblocks_22926", "simulate_8477.segmap_num_tblocks_22984", "simulate_8477.segmap_tblock_size_21568", "simulate_8477.segmap_tblock_size_21665", "simulate_8477.segmap_tblock_size_21673", "simulate_8477.segmap_tblock_size_21698", "simulate_8477.segmap_tblock_size_21856", "simulate_8477.segmap_tblock_size_21932", "simulate_8477.segmap_tblock_size_22041", "simulate_8477.segmap_tblock_size_22049", "simulate_8477.segmap_tblock_size_22075", "simulate_8477.segmap_tblock_size_22083", "simulate_8477.segmap_tblock_size_22091", "simulate_8477.segmap_tblock_size_22107", "simulate_8477.segmap_tblock_size_22204", "simulate_8477.segmap_tblock_size_22336", "simulate_8477.segmap_tblock_size_22409", "simulate_8477.segmap_tblock_size_22690", "simulate_8477.segmap_tblock_size_22751", "simulate_8477.segmap_tblock_size_22810", "simulate_8477.segmap_tblock_size_22818", "simulate_8477.segmap_tblock_size_22862", "simulate_8477.segmap_tblock_size_22870", "simulate_8477.segmap_tblock_size_22916", "simulate_8477.segmap_tblock_size_22924", "simulate_8477.segmap_tblock_size_22982", "simulate_8477.segred_num_tblocks_21547", "simulate_8477.segred_num_tblocks_21646", "simulate_8477.segred_num_tblocks_21879", "simulate_8477.segred_num_tblocks_22117", "simulate_8477.segred_num_tblocks_22359", "simulate_8477.segred_num_tblocks_22508", "simulate_8477.segred_num_tblocks_22718", "simulate_8477.segred_num_tblocks_22779", "simulate_8477.segred_num_tblocks_23833", "simulate_8477.segred_tblock_size_21545", "simulate_8477.segred_tblock_size_21644", "simulate_8477.segred_tblock_size_21877", "simulate_8477.segred_tblock_size_22115", "simulate_8477.segred_tblock_size_22357", "simulate_8477.segred_tblock_size_22506", "simulate_8477.segred_tblock_size_22716", "simulate_8477.segred_tblock_size_22777", "simulate_8477.segred_tblock_size_23835", "simulate_8477.segscan_num_tblocks_21657", "simulate_8477.segscan_num_tblocks_22099", "simulate_8477.segscan_tblock_size_21655", "simulate_8477.segscan_tblock_size_22097", "simulate_8477.suff_outer_par_0", "simulate_8477.suff_outer_par_2", "simulate_8477.suff_outer_par_3", "simulate_8477.suff_outer_par_4", "simulate_8477.suff_outer_screma_1", "simulate_8477.tblock_size_24367", "simulate_8477.tblock_size_24387", "simulate_8477.tblock_size_24407", NULL};
int call_simple(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_i8_1d * *out0 = outs[0];
    int64_t in0 = *(int64_t *) ins[0];
    struct futhark_i64_1d * in1 = *(struct futhark_i64_1d * *) ins[1];
    struct futhark_i64_1d * in2 = *(struct futhark_i64_1d * *) ins[2];
    struct futhark_i64_1d * in3 = *(struct futhark_i64_1d * *) ins[3];
    
    return futhark_entry_simple(ctx, out0, in0, in1, in2, in3);
}
const struct type *simulate_out_types[] = {&type_ZMZNZMZNi8, &type_ZMZNi8, NULL};
bool simulate_out_unique[] = {false, false};
const struct type *simulate_in_types[] = {&type_i32, &type_i64, &type_ZMZNi64, &type_ZMZNi64, &type_ZMZNi64, NULL};
bool simulate_in_unique[] = {false, false, false, false, false};
const char *simulate_tuning_params[] = {"builtin#iota_i64.tblock_size_24193", "builtin#replicate_i8.tblock_size_23964", "simulate_8477.segmap_num_tblocks_21667", "simulate_8477.segmap_num_tblocks_21675", "simulate_8477.segmap_num_tblocks_21700", "simulate_8477.segmap_num_tblocks_22043", "simulate_8477.segmap_num_tblocks_22077", "simulate_8477.segmap_num_tblocks_22085", "simulate_8477.segmap_num_tblocks_22093", "simulate_8477.segmap_num_tblocks_22109", "simulate_8477.segmap_num_tblocks_22206", "simulate_8477.segmap_num_tblocks_22812", "simulate_8477.segmap_num_tblocks_22820", "simulate_8477.segmap_num_tblocks_22864", "simulate_8477.segmap_num_tblocks_22872", "simulate_8477.segmap_num_tblocks_22918", "simulate_8477.segmap_num_tblocks_22926", "simulate_8477.segmap_num_tblocks_22984", "simulate_8477.segmap_tblock_size_21568", "simulate_8477.segmap_tblock_size_21665", "simulate_8477.segmap_tblock_size_21673", "simulate_8477.segmap_tblock_size_21698", "simulate_8477.segmap_tblock_size_21856", "simulate_8477.segmap_tblock_size_21932", "simulate_8477.segmap_tblock_size_22041", "simulate_8477.segmap_tblock_size_22049", "simulate_8477.segmap_tblock_size_22075", "simulate_8477.segmap_tblock_size_22083", "simulate_8477.segmap_tblock_size_22091", "simulate_8477.segmap_tblock_size_22107", "simulate_8477.segmap_tblock_size_22204", "simulate_8477.segmap_tblock_size_22336", "simulate_8477.segmap_tblock_size_22409", "simulate_8477.segmap_tblock_size_22690", "simulate_8477.segmap_tblock_size_22751", "simulate_8477.segmap_tblock_size_22810", "simulate_8477.segmap_tblock_size_22818", "simulate_8477.segmap_tblock_size_22862", "simulate_8477.segmap_tblock_size_22870", "simulate_8477.segmap_tblock_size_22916", "simulate_8477.segmap_tblock_size_22924", "simulate_8477.segmap_tblock_size_22982", "simulate_8477.segred_num_tblocks_21547", "simulate_8477.segred_num_tblocks_21646", "simulate_8477.segred_num_tblocks_21879", "simulate_8477.segred_num_tblocks_22117", "simulate_8477.segred_num_tblocks_22359", "simulate_8477.segred_num_tblocks_22508", "simulate_8477.segred_num_tblocks_22718", "simulate_8477.segred_num_tblocks_22779", "simulate_8477.segred_num_tblocks_23833", "simulate_8477.segred_tblock_size_21545", "simulate_8477.segred_tblock_size_21644", "simulate_8477.segred_tblock_size_21877", "simulate_8477.segred_tblock_size_22115", "simulate_8477.segred_tblock_size_22357", "simulate_8477.segred_tblock_size_22506", "simulate_8477.segred_tblock_size_22716", "simulate_8477.segred_tblock_size_22777", "simulate_8477.segred_tblock_size_23835", "simulate_8477.segscan_num_tblocks_21657", "simulate_8477.segscan_num_tblocks_22099", "simulate_8477.segscan_tblock_size_21655", "simulate_8477.segscan_tblock_size_22097", "simulate_8477.suff_outer_par_0", "simulate_8477.suff_outer_par_2", "simulate_8477.suff_outer_par_3", "simulate_8477.suff_outer_par_4", "simulate_8477.suff_outer_screma_1", "simulate_8477.tblock_size_24367", "simulate_8477.tblock_size_24387", "simulate_8477.tblock_size_24407", NULL};
int call_simulate(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_i8_2d * *out0 = outs[0];
    struct futhark_i8_1d * *out1 = outs[1];
    int32_t in0 = *(int32_t *) ins[0];
    int64_t in1 = *(int64_t *) ins[1];
    struct futhark_i64_1d * in2 = *(struct futhark_i64_1d * *) ins[2];
    struct futhark_i64_1d * in3 = *(struct futhark_i64_1d * *) ins[3];
    struct futhark_i64_1d * in4 = *(struct futhark_i64_1d * *) ins[4];
    
    return futhark_entry_simulate(ctx, out0, out1, in0, in1, in2, in3, in4);
}
const struct type *types[] = {&type_i8, &type_i16, &type_i32, &type_i64, &type_u8, &type_u16, &type_u32, &type_u64, &type_f16, &type_f32, &type_f64, &type_bool, &type_ZMZNZMZNi8, &type_ZMZNi64, &type_ZMZNi8, NULL};
struct entry_point entry_points[] = {{.name ="main", .f =call_main, .tuning_params =main_tuning_params, .in_types =main_in_types, .out_types =main_out_types, .in_unique =main_in_unique, .out_unique =main_out_unique}, {.name ="simple", .f =call_simple, .tuning_params =simple_tuning_params, .in_types =simple_in_types, .out_types =simple_out_types, .in_unique =simple_in_unique, .out_unique =simple_out_unique}, {.name ="simulate", .f =call_simulate, .tuning_params =simulate_tuning_params, .in_types =simulate_in_types, .out_types =simulate_out_types, .in_unique =simulate_in_unique, .out_unique =simulate_out_unique}, {.name =NULL}};
struct futhark_prog prog = {.types =types, .entry_points =entry_points};
int parse_options(struct futhark_context_config *cfg, int argc, char *const argv[])
{
    int ch;
    static struct option long_options[] = {{"debugging", no_argument, NULL, 1}, {"log", no_argument, NULL, 2}, {"profile", no_argument, NULL, 3}, {"help", no_argument, NULL, 4}, {"print-params", no_argument, NULL, 5}, {"param", required_argument, NULL, 6}, {"tuning", required_argument, NULL, 7}, {"cache-file", required_argument, NULL, 8}, {"device", required_argument, NULL, 9}, {"default-thread-block-size", required_argument, NULL, 10}, {"default-grid-size", required_argument, NULL, 11}, {"default-group-size", required_argument, NULL, 12}, {"default-num-groups", required_argument, NULL, 13}, {"default-tile-size", required_argument, NULL, 14}, {"default-reg-tile-size", required_argument, NULL, 15}, {"default-registers", required_argument, NULL, 16}, {"default-cache", required_argument, NULL, 17}, {"default-threshold", required_argument, NULL, 18}, {"unified-memory", required_argument, NULL, 19}, {"dump-cuda", required_argument, NULL, 20}, {"load-cuda", required_argument, NULL, 21}, {"dump-ptx", required_argument, NULL, 22}, {"load-ptx", required_argument, NULL, 23}, {"nvrtc-option", required_argument, NULL, 24}, {0, 0, 0, 0}};
    static char *option_descriptions = "  -D/--debugging                  Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                        Print various low-overhead logging information while running.\n  -P/--profile                    Enable the collection of profiling information.\n  -h/--help                       Print help information and exit.\n  --print-params                  Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT              Set a tuning parameter to the given value.\n  --tuning FILE                   Read size=value assignments from the given file.\n  --cache-file FILE               Store program cache here.\n  -d/--device NAME                Use the first device whose name contains the given string.\n  --default-thread-block-size INT The default size of thread blocks that are launched.\n  --default-grid-size INT         The default number of thread blocks that are launched.\n  --default-group-size INT        Alias for --default-thread-block-size.\n  --default-num-groups INT        Alias for --default-num-thread-blocks.\n  --default-tile-size INT         The default tile size for two-dimensional tiling.\n  --default-reg-tile-size INT     The default register tile size for two-dimensional tiling.\n  --default-registers INT         The amount of register memory in bytes.\n  --default-cache INT             The amount of register memory in bytes.\n  --default-threshold INT         The default parallelism threshold.\n  --unified-memory INT            Whether to use unified memory\n  --dump-cuda FILE                Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE                Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE                 Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE                 Load PTX code from the indicated file.\n  --nvrtc-option OPT              Add an additional build option to the string passed to NVRTC.\n";
    
    while ((ch = getopt_long(argc, argv, ":DLPhd:", long_options, NULL)) != -1) {
        if (ch == 1 || ch == 'D')
            futhark_context_config_set_debugging(cfg, 1);
        if (ch == 2 || ch == 'L')
            futhark_context_config_set_logging(cfg, 1);
        if (ch == 3 || ch == 'P')
            futhark_context_config_set_profiling(cfg, 1);
        if (ch == 4 || ch == 'h') {
            printf("Usage: %s [OPTIONS]...\nOptions:\n\n%s\nFor more information, consult the Futhark User's Guide or the man pages.\n", fut_progname, option_descriptions);
            exit(0);
        }
        if (ch == 5) {
            int n = futhark_get_tuning_param_count();
            
            for (int i = 0; i < n; i++)
                printf("%s (%s)\n", futhark_get_tuning_param_name(i), futhark_get_tuning_param_class(i));
            exit(0);
        }
        if (ch == 6) {
            char *name = optarg;
            char *equals = strstr(optarg, "=");
            char *value_str = equals != NULL ? equals + 1 : optarg;
            int value = atoi(value_str);
            
            if (equals != NULL) {
                *equals = 0;
                if (futhark_context_config_set_tuning_param(cfg, name, value) != 0)
                    futhark_panic(1, "Unknown size: %s\n", name);
            } else
                futhark_panic(1, "Invalid argument for size option: %s\n", optarg);
        }
        if (ch == 7) {
            char *ret = load_tuning_file(optarg, cfg, (int (*)(void *, const char *, size_t)) futhark_context_config_set_tuning_param);
            
            if (ret != NULL)
                futhark_panic(1, "When loading tuning file '%s': %s\n", optarg, ret);
        }
        if (ch == 8)
            futhark_context_config_set_cache_file(cfg, optarg);
        if (ch == 9 || ch == 'd')
            futhark_context_config_set_device(cfg, optarg);
        if (ch == 10)
            futhark_context_config_set_default_thread_block_size(cfg, atoi(optarg));
        if (ch == 11)
            futhark_context_config_set_default_grid_size(cfg, atoi(optarg));
        if (ch == 12)
            futhark_context_config_set_default_group_size(cfg, atoi(optarg));
        if (ch == 13)
            futhark_context_config_set_default_num_groups(cfg, atoi(optarg));
        if (ch == 14)
            futhark_context_config_set_default_tile_size(cfg, atoi(optarg));
        if (ch == 15)
            futhark_context_config_set_default_reg_tile_size(cfg, atoi(optarg));
        if (ch == 16)
            futhark_context_config_set_default_registers(cfg, atoi(optarg));
        if (ch == 17)
            futhark_context_config_set_default_cache(cfg, atoi(optarg));
        if (ch == 18)
            futhark_context_config_set_default_threshold(cfg, atoi(optarg));
        if (ch == 19)
            futhark_context_config_set_unified_memory(cfg, atoi(optarg));
        if (ch == 20) {
            const char *prog = futhark_context_config_get_program(cfg);
            
            if (dump_file(optarg, prog, strlen(prog)) != 0) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            exit(0);
        }
        if (ch == 21) {
            size_t n;
            const char *s = slurp_file(optarg, &n);
            
            if (s == NULL) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            futhark_context_config_set_program(cfg, s);
        }
        if (ch == 22) {
            futhark_context_config_dump_ptx_to(cfg, optarg);
            entry_point = NULL;
        }
        if (ch == 23)
            futhark_context_config_load_ptx_from(cfg, optarg);
        if (ch == 24)
            futhark_context_config_add_nvrtc_option(cfg, optarg);
        if (ch == ':')
            futhark_panic(-1, "Missing argument for option %s\n", argv[optind - 1]);
        if (ch == '?') {
            fprintf(stderr, "Usage: %s [OPTIONS]...\nOptions:\n\n%s\n", fut_progname, "  -D/--debugging                  Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                        Print various low-overhead logging information while running.\n  -P/--profile                    Enable the collection of profiling information.\n  -h/--help                       Print help information and exit.\n  --print-params                  Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT              Set a tuning parameter to the given value.\n  --tuning FILE                   Read size=value assignments from the given file.\n  --cache-file FILE               Store program cache here.\n  -d/--device NAME                Use the first device whose name contains the given string.\n  --default-thread-block-size INT The default size of thread blocks that are launched.\n  --default-grid-size INT         The default number of thread blocks that are launched.\n  --default-group-size INT        Alias for --default-thread-block-size.\n  --default-num-groups INT        Alias for --default-num-thread-blocks.\n  --default-tile-size INT         The default tile size for two-dimensional tiling.\n  --default-reg-tile-size INT     The default register tile size for two-dimensional tiling.\n  --default-registers INT         The amount of register memory in bytes.\n  --default-cache INT             The amount of register memory in bytes.\n  --default-threshold INT         The default parallelism threshold.\n  --unified-memory INT            Whether to use unified memory\n  --dump-cuda FILE                Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE                Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE                 Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE                 Load PTX code from the indicated file.\n  --nvrtc-option OPT              Add an additional build option to the string passed to NVRTC.\n");
            futhark_panic(1, "Unknown option: %s\n", argv[optind - 1]);
        }
    }
    return optind;
}
int main(int argc, char **argv)
{
    fut_progname = argv[0];
    
    struct futhark_context_config *cfg = futhark_context_config_new();
    
    assert(cfg != NULL);
    
    int parsed_options = parse_options(cfg, argc, argv);
    
    argc -= parsed_options;
    argv += parsed_options;
    if (argc != 0)
        futhark_panic(1, "Excess non-option: %s\n", argv[0]);
    
    struct futhark_context *ctx = futhark_context_new(cfg);
    
    assert(ctx != NULL);
    futhark_context_set_logging_file(ctx, stdout);
    
    char *error = futhark_context_get_error(ctx);
    
    if (error != NULL)
        futhark_panic(1, "Error during context initialisation:\n%s", error);
    if (entry_point != NULL)
        run_server(&prog, cfg, ctx);
    futhark_context_free(ctx);
    futhark_context_config_free(cfg);
}

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);
SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);

SCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

SCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {
  return x;
}

SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {
  return x;
}

SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {
  return x;
}

SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

SCALAR_FUN_ATTR int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

SCALAR_FUN_ATTR int32_t abs32(int32_t x) {
  return abs(x);
}

SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) {
  return x / y;
}

SCALAR_FUN_ATTR float fadd32(float x, float y) {
  return x + y;
}

SCALAR_FUN_ATTR float fsub32(float x, float y) {
  return x - y;
}

SCALAR_FUN_ATTR float fmul32(float x, float y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt32(float x, float y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple32(float x, float y) {
  return x <= y;
}

SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x) {
  return fabs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

SCALAR_FUN_ATTR float fabs32(float x) {
  return abs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) {
  return x != 0;
}

SCALAR_FUN_ATTR float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) {
  return log(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1p(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return cosh(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinh(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanh(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acosh(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinh(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanh(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erf(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfc(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rint(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return round(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  int32_t xb = futrts_to_bits32(x);
  int32_t yb = futrts_to_bits32(y);
  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return logf(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2f(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10f(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1pf(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrtf(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return expf(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cosf(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sinf(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tanf(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acosf(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asinf(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atanf(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return coshf(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erff(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rintf(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floorf(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceilf(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexpf(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysignf(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);
SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return abs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return round(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0.0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {
  int64_t xb = futrts_to_bits64(x);
  int64_t yb = futrts_to_bits64(y);
  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return fabs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR double fpow64(double x, double y) {
  return pow(x, y);
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return log(x);
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return log2(x);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return log10(x);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  return log1p(x);
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return cosh(x);
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return sinh(x);
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return tanh(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  return acosh(x);
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  return asinh(x);
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  return atanh(x);
}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR double futrts_erf64(double x) {
  return erf(x);
}

SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  return erfc(x);
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return rint(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR bool futrts_isinf64(double x) {
  return isinf(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {
  return x + y;
}

SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {
  return x - y;
}

SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {
  return x <= y;
}

SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return abs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return log(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return log2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return log10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return cos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return sin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tan(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acos(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asin(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atan(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erf(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rint(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return floor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return hlog(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return hexp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return hcos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return hsin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tanf(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acosf(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asinf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atanf(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erff(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rintf(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs32(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

SCALAR_FUN_ATTR f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {
  return x;
}

SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {
  return x;
}

SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Log that a copy has occurred.
static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]);

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t m, int64_t n);

static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]);

static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]);

static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]);

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device counters_mem_23891;
    struct memblock_device counters_mem_23995;
    struct memblock_device counters_mem_24219;
    struct memblock_device counters_mem_24316;
    struct memblock_device counters_mem_24620;
    struct memblock_device counters_mem_24722;
    struct memblock_device counters_mem_24770;
    struct memblock_device counters_mem_24855;
    struct memblock_device counters_mem_24938;
    struct memblock_device global_dynid_mem_24078;
    struct memblock_device global_dynid_mem_24500;
};
struct tuning_params {
    int dummy;
    int64_t *builtinzhiota_i64zitblock_sizze_24193;
    int64_t *builtinzhreplicate_i32zitblock_sizze_23902;
    int64_t *builtinzhreplicate_i8zitblock_sizze_23964;
    int64_t *simulate_8477zisegmap_num_tblocks_21667;
    int64_t *simulate_8477zisegmap_num_tblocks_21675;
    int64_t *simulate_8477zisegmap_num_tblocks_21700;
    int64_t *simulate_8477zisegmap_num_tblocks_22043;
    int64_t *simulate_8477zisegmap_num_tblocks_22077;
    int64_t *simulate_8477zisegmap_num_tblocks_22085;
    int64_t *simulate_8477zisegmap_num_tblocks_22093;
    int64_t *simulate_8477zisegmap_num_tblocks_22109;
    int64_t *simulate_8477zisegmap_num_tblocks_22206;
    int64_t *simulate_8477zisegmap_num_tblocks_22812;
    int64_t *simulate_8477zisegmap_num_tblocks_22820;
    int64_t *simulate_8477zisegmap_num_tblocks_22864;
    int64_t *simulate_8477zisegmap_num_tblocks_22872;
    int64_t *simulate_8477zisegmap_num_tblocks_22918;
    int64_t *simulate_8477zisegmap_num_tblocks_22926;
    int64_t *simulate_8477zisegmap_num_tblocks_22984;
    int64_t *simulate_8477zisegmap_tblock_sizze_21568;
    int64_t *simulate_8477zisegmap_tblock_sizze_21665;
    int64_t *simulate_8477zisegmap_tblock_sizze_21673;
    int64_t *simulate_8477zisegmap_tblock_sizze_21698;
    int64_t *simulate_8477zisegmap_tblock_sizze_21856;
    int64_t *simulate_8477zisegmap_tblock_sizze_21932;
    int64_t *simulate_8477zisegmap_tblock_sizze_22041;
    int64_t *simulate_8477zisegmap_tblock_sizze_22049;
    int64_t *simulate_8477zisegmap_tblock_sizze_22075;
    int64_t *simulate_8477zisegmap_tblock_sizze_22083;
    int64_t *simulate_8477zisegmap_tblock_sizze_22091;
    int64_t *simulate_8477zisegmap_tblock_sizze_22107;
    int64_t *simulate_8477zisegmap_tblock_sizze_22204;
    int64_t *simulate_8477zisegmap_tblock_sizze_22336;
    int64_t *simulate_8477zisegmap_tblock_sizze_22409;
    int64_t *simulate_8477zisegmap_tblock_sizze_22690;
    int64_t *simulate_8477zisegmap_tblock_sizze_22751;
    int64_t *simulate_8477zisegmap_tblock_sizze_22810;
    int64_t *simulate_8477zisegmap_tblock_sizze_22818;
    int64_t *simulate_8477zisegmap_tblock_sizze_22862;
    int64_t *simulate_8477zisegmap_tblock_sizze_22870;
    int64_t *simulate_8477zisegmap_tblock_sizze_22916;
    int64_t *simulate_8477zisegmap_tblock_sizze_22924;
    int64_t *simulate_8477zisegmap_tblock_sizze_22982;
    int64_t *simulate_8477zisegred_num_tblocks_21547;
    int64_t *simulate_8477zisegred_num_tblocks_21646;
    int64_t *simulate_8477zisegred_num_tblocks_21879;
    int64_t *simulate_8477zisegred_num_tblocks_22117;
    int64_t *simulate_8477zisegred_num_tblocks_22359;
    int64_t *simulate_8477zisegred_num_tblocks_22508;
    int64_t *simulate_8477zisegred_num_tblocks_22718;
    int64_t *simulate_8477zisegred_num_tblocks_22779;
    int64_t *simulate_8477zisegred_num_tblocks_23833;
    int64_t *simulate_8477zisegred_tblock_sizze_21545;
    int64_t *simulate_8477zisegred_tblock_sizze_21644;
    int64_t *simulate_8477zisegred_tblock_sizze_21877;
    int64_t *simulate_8477zisegred_tblock_sizze_22115;
    int64_t *simulate_8477zisegred_tblock_sizze_22357;
    int64_t *simulate_8477zisegred_tblock_sizze_22506;
    int64_t *simulate_8477zisegred_tblock_sizze_22716;
    int64_t *simulate_8477zisegred_tblock_sizze_22777;
    int64_t *simulate_8477zisegred_tblock_sizze_23835;
    int64_t *simulate_8477zisegscan_num_tblocks_21657;
    int64_t *simulate_8477zisegscan_num_tblocks_22099;
    int64_t *simulate_8477zisegscan_tblock_sizze_21655;
    int64_t *simulate_8477zisegscan_tblock_sizze_22097;
    int64_t *simulate_8477zisuff_outer_par_0;
    int64_t *simulate_8477zisuff_outer_par_2;
    int64_t *simulate_8477zisuff_outer_par_3;
    int64_t *simulate_8477zisuff_outer_par_4;
    int64_t *simulate_8477zisuff_outer_screma_1;
    int64_t *simulate_8477zitblock_sizze_24367;
    int64_t *simulate_8477zitblock_sizze_24387;
    int64_t *simulate_8477zitblock_sizze_24407;
};
static const int num_tuning_params = 73;
static const char *tuning_param_names[] = {"builtin#iota_i64.tblock_size_24193", "builtin#replicate_i32.tblock_size_23902", "builtin#replicate_i8.tblock_size_23964", "simulate_8477.segmap_num_tblocks_21667", "simulate_8477.segmap_num_tblocks_21675", "simulate_8477.segmap_num_tblocks_21700", "simulate_8477.segmap_num_tblocks_22043", "simulate_8477.segmap_num_tblocks_22077", "simulate_8477.segmap_num_tblocks_22085", "simulate_8477.segmap_num_tblocks_22093", "simulate_8477.segmap_num_tblocks_22109", "simulate_8477.segmap_num_tblocks_22206", "simulate_8477.segmap_num_tblocks_22812", "simulate_8477.segmap_num_tblocks_22820", "simulate_8477.segmap_num_tblocks_22864", "simulate_8477.segmap_num_tblocks_22872", "simulate_8477.segmap_num_tblocks_22918", "simulate_8477.segmap_num_tblocks_22926", "simulate_8477.segmap_num_tblocks_22984", "simulate_8477.segmap_tblock_size_21568", "simulate_8477.segmap_tblock_size_21665", "simulate_8477.segmap_tblock_size_21673", "simulate_8477.segmap_tblock_size_21698", "simulate_8477.segmap_tblock_size_21856", "simulate_8477.segmap_tblock_size_21932", "simulate_8477.segmap_tblock_size_22041", "simulate_8477.segmap_tblock_size_22049", "simulate_8477.segmap_tblock_size_22075", "simulate_8477.segmap_tblock_size_22083", "simulate_8477.segmap_tblock_size_22091", "simulate_8477.segmap_tblock_size_22107", "simulate_8477.segmap_tblock_size_22204", "simulate_8477.segmap_tblock_size_22336", "simulate_8477.segmap_tblock_size_22409", "simulate_8477.segmap_tblock_size_22690", "simulate_8477.segmap_tblock_size_22751", "simulate_8477.segmap_tblock_size_22810", "simulate_8477.segmap_tblock_size_22818", "simulate_8477.segmap_tblock_size_22862", "simulate_8477.segmap_tblock_size_22870", "simulate_8477.segmap_tblock_size_22916", "simulate_8477.segmap_tblock_size_22924", "simulate_8477.segmap_tblock_size_22982", "simulate_8477.segred_num_tblocks_21547", "simulate_8477.segred_num_tblocks_21646", "simulate_8477.segred_num_tblocks_21879", "simulate_8477.segred_num_tblocks_22117", "simulate_8477.segred_num_tblocks_22359", "simulate_8477.segred_num_tblocks_22508", "simulate_8477.segred_num_tblocks_22718", "simulate_8477.segred_num_tblocks_22779", "simulate_8477.segred_num_tblocks_23833", "simulate_8477.segred_tblock_size_21545", "simulate_8477.segred_tblock_size_21644", "simulate_8477.segred_tblock_size_21877", "simulate_8477.segred_tblock_size_22115", "simulate_8477.segred_tblock_size_22357", "simulate_8477.segred_tblock_size_22506", "simulate_8477.segred_tblock_size_22716", "simulate_8477.segred_tblock_size_22777", "simulate_8477.segred_tblock_size_23835", "simulate_8477.segscan_num_tblocks_21657", "simulate_8477.segscan_num_tblocks_22099", "simulate_8477.segscan_tblock_size_21655", "simulate_8477.segscan_tblock_size_22097", "simulate_8477.suff_outer_par_0", "simulate_8477.suff_outer_par_2", "simulate_8477.suff_outer_par_3", "simulate_8477.suff_outer_par_4", "simulate_8477.suff_outer_screma_1", "simulate_8477.tblock_size_24367", "simulate_8477.tblock_size_24387", "simulate_8477.tblock_size_24407", NULL};
static const char *tuning_param_vars[] = {"builtinzhiota_i64zitblock_sizze_24193", "builtinzhreplicate_i32zitblock_sizze_23902", "builtinzhreplicate_i8zitblock_sizze_23964", "simulate_8477zisegmap_num_tblocks_21667", "simulate_8477zisegmap_num_tblocks_21675", "simulate_8477zisegmap_num_tblocks_21700", "simulate_8477zisegmap_num_tblocks_22043", "simulate_8477zisegmap_num_tblocks_22077", "simulate_8477zisegmap_num_tblocks_22085", "simulate_8477zisegmap_num_tblocks_22093", "simulate_8477zisegmap_num_tblocks_22109", "simulate_8477zisegmap_num_tblocks_22206", "simulate_8477zisegmap_num_tblocks_22812", "simulate_8477zisegmap_num_tblocks_22820", "simulate_8477zisegmap_num_tblocks_22864", "simulate_8477zisegmap_num_tblocks_22872", "simulate_8477zisegmap_num_tblocks_22918", "simulate_8477zisegmap_num_tblocks_22926", "simulate_8477zisegmap_num_tblocks_22984", "simulate_8477zisegmap_tblock_sizze_21568", "simulate_8477zisegmap_tblock_sizze_21665", "simulate_8477zisegmap_tblock_sizze_21673", "simulate_8477zisegmap_tblock_sizze_21698", "simulate_8477zisegmap_tblock_sizze_21856", "simulate_8477zisegmap_tblock_sizze_21932", "simulate_8477zisegmap_tblock_sizze_22041", "simulate_8477zisegmap_tblock_sizze_22049", "simulate_8477zisegmap_tblock_sizze_22075", "simulate_8477zisegmap_tblock_sizze_22083", "simulate_8477zisegmap_tblock_sizze_22091", "simulate_8477zisegmap_tblock_sizze_22107", "simulate_8477zisegmap_tblock_sizze_22204", "simulate_8477zisegmap_tblock_sizze_22336", "simulate_8477zisegmap_tblock_sizze_22409", "simulate_8477zisegmap_tblock_sizze_22690", "simulate_8477zisegmap_tblock_sizze_22751", "simulate_8477zisegmap_tblock_sizze_22810", "simulate_8477zisegmap_tblock_sizze_22818", "simulate_8477zisegmap_tblock_sizze_22862", "simulate_8477zisegmap_tblock_sizze_22870", "simulate_8477zisegmap_tblock_sizze_22916", "simulate_8477zisegmap_tblock_sizze_22924", "simulate_8477zisegmap_tblock_sizze_22982", "simulate_8477zisegred_num_tblocks_21547", "simulate_8477zisegred_num_tblocks_21646", "simulate_8477zisegred_num_tblocks_21879", "simulate_8477zisegred_num_tblocks_22117", "simulate_8477zisegred_num_tblocks_22359", "simulate_8477zisegred_num_tblocks_22508", "simulate_8477zisegred_num_tblocks_22718", "simulate_8477zisegred_num_tblocks_22779", "simulate_8477zisegred_num_tblocks_23833", "simulate_8477zisegred_tblock_sizze_21545", "simulate_8477zisegred_tblock_sizze_21644", "simulate_8477zisegred_tblock_sizze_21877", "simulate_8477zisegred_tblock_sizze_22115", "simulate_8477zisegred_tblock_sizze_22357", "simulate_8477zisegred_tblock_sizze_22506", "simulate_8477zisegred_tblock_sizze_22716", "simulate_8477zisegred_tblock_sizze_22777", "simulate_8477zisegred_tblock_sizze_23835", "simulate_8477zisegscan_num_tblocks_21657", "simulate_8477zisegscan_num_tblocks_22099", "simulate_8477zisegscan_tblock_sizze_21655", "simulate_8477zisegscan_tblock_sizze_22097", "simulate_8477zisuff_outer_par_0", "simulate_8477zisuff_outer_par_2", "simulate_8477zisuff_outer_par_3", "simulate_8477zisuff_outer_par_4", "simulate_8477zisuff_outer_screma_1", "simulate_8477zitblock_sizze_24367", "simulate_8477zitblock_sizze_24387", "simulate_8477zitblock_sizze_24407", NULL};
static const char *tuning_param_classes[] = {"thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(def, )", "threshold(def, !simulate_8477.suff_outer_screma_1)", "threshold(def, )", "threshold(def, )", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", NULL};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static const int max_failure_args = 2;
static const int f64_required = 0;
static const char *gpu_program[] = {"#define FUTHARK_CUDA\n// start of prelude.cu\n\n#define SCALAR_FUN_ATTR __device__ static inline\n#define FUTHARK_FUN_ATTR __device__ static\n#define FUTHARK_F64_ENABLED\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\n\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline __device__ int get_tblock_id(int d) {\n  switch (d) {\n  case 0: return blockIdx.x;\n  case 1: return blockIdx.y;\n  case 2: return blockIdx.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_num_tblocks(int d) {\n  switch(d) {\n  case 0: return gridDim.x;\n  case 1: return gridDim.y;\n  case 2: return gridDim.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x + blockIdx.x * blockDim.x;\n    case 1: return threadIdx.y + blockIdx.y * blockDim.y;\n    case 2: return threadIdx.z + blockIdx.z * blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_size(int d) {\n  switch (d) {\n    case 0: return gridDim.x * blockDim.x;\n    case 1: return gridDim.y * blockDim.y;\n    case 2: return gridDim.z * blockDim.z;\n    default: return 0;\n  }\n}\n\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline __device__ void barrier(int x) {\n  __syncthreads();\n}\nstatic inline __device__ void mem_fence_local() {\n  __threadfence_block();\n}\nstatic inline __device__ void mem_fence_global", "() {\n  __threadfence();\n}\n\nstatic inline __device__ void barrier_local() {\n  __syncthreads();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char shared_mem[];\n\n#define SHARED_MEM_PARAM\n#define FUTHARK_KERNEL extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define FUTHARK_KERNEL_SIZED(a,b,c) extern \"C\" __global__ __launch_bounds__(a*b*c)\n\n// End of prelude.cu\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0", "000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8",
                                    "000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24,", " 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2", "4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x37",
                                    "1B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x", "37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x", "37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x",
                                    "38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x", "384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, ", "0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, ",
                                    "0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, ", "0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000", ", 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000",
                                    ", 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000", ", 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x387620", "00, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1",
                                    "024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nSCALAR_FUN_ATTR uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nSCALAR_FUN_ATTR float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nSCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n/", "/ Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);\n\nSCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint", "8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALA",
                                    "R_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t q = x / ys;\n  int8_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t q = x / ys;\n  int16_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t q = x / ys;\n  int64_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y)", " {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int32_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) ", "{\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  ",
                                    "foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return", " y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = ", "x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t ",
                                    "y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {\n  return (uint8_t)(x << y);\n}\n\nS", "CALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult64(uint64_t x, uint64", "_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x",
                                    ") {\n  return x;\n}\n\nSCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nSCALAR_FUN_ATTR int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int32_t abs32(int32_t x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VER", "SION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return m", "ul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nSCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nSCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif ISPC\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nSCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR int",
                                    "32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }\nSCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t ", "a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return __clz(zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  retur", "n __clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return count_leading_zeros((int32_t)(uint8_t)x)-24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return count_leading_zeros((int32_t)(uint16_t)x)-16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return count_leading_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return count_leading_zeros(x);\n}\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1",
                                    ";\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return count_trailing_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return count_trailing_zeros(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nSCALAR_FUN_ATTR float fdiv32(float x, float y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR float fadd32(float x, float y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR float fsub32(float x, float y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR float fmul32(float x, float y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt32(float x, float y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, f", "loat y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nSCALAR_FUN_ATTR bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite32(float x) {\n  return !isnan(x) && !futrts_isinf32(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  };\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {", "\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f32_bool(float x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR float btof_bool_f32(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nSC",
                                    "ALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return futrts_log32(x) / log(2.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return futrts_log32(x) / log(10.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform float cbrtf(uniform float);\nSCALAR_FUN_ATTR float futrts_cbrt32(float", " x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return (exp(x)+exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return (exp(x)-exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return futrts_sinh32(x)/futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if(futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;\n    else return x + y;\n  }\n\n}\n\nextern \"C\" unmasked uniform float tgammaf(", "uniform float x);\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  int32_t xb = futrts_to_bits32(x);\n  int32_t yb = futrts_to_bits32(y);\n  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futr",
                                    "ts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return logf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1pf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return expf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  re", "turn rintf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafterf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexpf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysignf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fmaf(a, b, c);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  return intbits(x);\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  return floatbits(x);\n}\n#else\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nSCALAR_FUN_ATTR float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf64(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite64(float x) {\n  return !isnan(x) && !futrts_isinf64(x);\n}\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}", "\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return futrts_log64(x)/log(2.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return futrts_log64(x)/log(10.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform double cbrt(uniform double);\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(dou",
                                    "ble x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return (exp(x)+exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return (exp(x)-exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return futrts_sinh64(x)/futrts_cosh64(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nSCALAR_FUN_ATTR do", "uble futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nSCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int", "16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0.0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1.0 : 0.0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i);\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {\n  int64_t xb = futrts_to_bits64(x);\n  int64_t yb = futrts_to_bits64(y);\n  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#e",
                                    "lse\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  r", "eturn tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return fma(a, b, c);\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x", ") {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1 : 0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nSCALAR",
                                    "_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif ISPC\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because half\n// precision versions are not available.\n\nSCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nSCALAR", "_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\nSCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {\n  return x != (f16)0;\n}\n\nSCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifndef EMULATE_F16\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#elif ISPC\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#else // Assuming CUDA.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 ", "x, f16 y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf16(float x) {\n  return !futrts_isnan16(x) && futrts_isnan16(x - x);\n}\nSCALAR_FUN_ATTR bool futrts_isfinite16(float x) {\n  return !futrts_isnan16(x) && !futrts_isinf16(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n#endif\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return e",
                                    "rf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log16(x) / log(2.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log16(x) / log(10.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return (float16)sqrt((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return (float16)cos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return (float16)sin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return (float16)tan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return (float16)acos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return (float16)asin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return (float16)atan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  retu", "rn (exp(x)+exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return (exp(x)-exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_sinh16(x)/futrts_cosh16(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  float16 f = (1+x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return (float16)atan2((float)x, (float)y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return (float16)futrts_hypot32((float)x, (float)y);\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  f16 res = (f16)futrts_cbrt32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  f16 res = (f16)futrts_erf32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  f16 res = (f16)futrts_erfc32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return x - y * (float16)trunc((float) (x/y));\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return (float16)round((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return (float16)floor((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return (float16)ceil((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrt", "s_nextafter16(f16 x, f16 y) {\n  return (float16)futrts_nextafter32((float)x, (float) y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\n#else // Assume CUDA.\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return (f16)log1pf((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f1",
                                    "6 x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  varying int16_t y = *((varying int16_t * uniform)&x);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  varying f16 y = *((varying f16 * uniform)&x);\n  return y;\n}\n#else\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No native f16 - emulate.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nSC", "ALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return futrts_log1p_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return futrts_cbrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nSCA", "LAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return futrts_erf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return futrts_erfc32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return futrts_round32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nSCALAR_FUN_ATTR f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#endif\n\n#endif\n\nSCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {\n  retu",
                                    "rn x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {\n  return (f16) x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\n#if ISPC\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) ((float)x);\n}\n#else\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n#endif\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32", "_t *p, uint32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x);\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#el", "se\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  float ret;\n  asm volatile(\"atom.global.add.f32 %0,[%1],%2;\":\"=f\"(ret):\"l\"(p),\"f\"(x):\"memory\");\n  return ret;\n#elif defined(__opencl_c_ext_fp32_global_atomic_add)\n  // use hardware-supported atomic addition on some Intel GPUs\n  return atomic_fetch_add_explicit((volatile __global atomic_float*)p,\n                                   x,\n                                   memory_order_relaxed);\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f32)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f32(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  float old = x;\n  float ret;\n  while ((old=atomic_xchg(p, ret=atomic_xchg(p, 0.0f)+old))!=0.0f);\n  return ret;\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_shared((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile",
                                    " __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, ", "int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR uint", "64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x);\n\n#ifdef FUTHARK_F64_ENABLED\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x);\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val) {\n#if defined(F",
                                    "UTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  double ret;\n  asm volatile(\"atom.global.add.f64 %0,[%1],%2;\":\"=d\"(ret):\"l\"(p),\"d\"(x):\"memory\");\n  return ret;\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f64)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f64(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  union {int64_t i; double f;} old;\n  union {int64_t i; double f;} ret;\n  old.f = x;\n  while (1) {\n    ret.i = atom_xchg((volatile __global int64_t*)p, (int64_t)0);\n    ret.f += old.f;\n    old.i = atom_xchg((volatile __global int64_t*)p, ret.i);\n    if (old.i == 0) {\n      break;\n    }\n  }\n  return ret.f;\n#endif\n}\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  u", "nion { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do ", "{\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(v",
                                    "olatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\n// End of atomics.h\n// Start of transpose.cl\n\n#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME(SHARED_MEM_PARAM                              \\\n                          __global ELEM_TYPE *dst_mem,                  \\\n                          int64_t dst_offset,                           \\\n                          __global ELEM_TYPE *src_mem,                  \\\n                          int64_t src_offset,                           \\\n                          int32_t num_arrays,                           \\\n                          int32_t x_elems,                              \\\n                          int32_t y_elems,                              \\\n                          int32_t mulx,                                 \\\n                          int32_t muly,                                 \\\n                          int32_t repeat_1,                             \\\n                          int32_t repeat_2) {                           \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_g", "lobal_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = global_id_0;                                    \\\n      int32_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_in", "dex + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_height(SHARED_MEM_PARAM                 \\\n                                                __global ELEM_TYPE *dst_mem, \\\n                                                int64_t dst_offset,     \\\n                                                __global ELEM_TYPE *src_mem, \\\n                                                int64_t src_offset,     \\\n                                                int32_t num_arrays,     \\\n                                                int32_t x_elems,        \\\n                                                int32_t y_elems,        \\\n                                                int32_t mulx,           \\\n                                                int32_t muly,           \\\n                                                int32_t repeat_1,       \\\n ",
                                    "                                               int32_t repeat_2) {     \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index =                                                 \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(0) +                                               \\\n        get_local_id(1)%mulx * TR_BLOCK_DIM;                            \\\n      int32_t y_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;      \\\n      y_index =                                                         \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n", "        get_local_id(1) +                                               \\\n        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_width(SHARED_MEM_PARAM                  \\\n                                      __global ELEM_TYPE *dst_mem,      \\\n                                      int64_t dst_offset,               \\\n                                      __global ELEM_TYPE *src_mem,      \\\n                                      int64_t src_offset,               \\\n                                      int32_t num_arrays,               \\\n                                      int32_t x_elems,                  \\\n                                      int32_t y_elems,                  \\\n                                      int32_t mulx,                     \\\n                                      int32_t muly,                     \\\n                                      int32_t repeat_1,                 \\\n  ", "                                    int32_t repeat_2) {               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \\\n      int32_t y_index =                                                 \\\n        tblock_id_1 * TR_BLOCK_DIM * muly +                             \\\n        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM * muly +                     \\\n        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \\\n      y_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;      \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n ",
                                    "     if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_num_tblocks(2) * get_local_size(2);            \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_num_tblocks(1) * get_local_size(1);              \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \\\nvoid map_transpose_##NAME##_small(SHARED_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int32_t num_arrays,                   \\\n                                  int32_t x_elems,                      \\\n                                  int32_t y_elems,                      \\\n                                  int32_t mulx,                         \\\n                                  int32_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  ", "int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \\\n      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \\\n      int32_t y_index = global_id_0%y_elems;                            \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      int32_t index_out = x_index * y_elems + y_index;                  \\\n      if (global_id_0 < x_elems * y_elems * num_arrays) {               \\\n        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_", "PER_THREAD, 1)\\\nvoid map_transpose_##NAME##_large(SHARED_MEM_PARAM                      \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int64_t num_arrays,                   \\\n                                  int64_t x_elems,                      \\\n                                  int64_t y_elems,                      \\\n                                  int64_t mulx,                         \\\n                                  int64_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;             \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int64_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int64_t odata_offset = dst_offset + our_array_offset;             \\\n      int64_t idata_offset = src_offset + our_array_offset;             \\\n      int64_t x_index = global_id_0;                                    \\\n      int64_t y_index = tblock_id_1 * TR_TILE_DIM + get_loc",
                                    "al_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                      ", "                             \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n\nGEN_TRANSPOSE_KERNELS(1b, uint8_t)\nGEN_TRANSPOSE_KERNELS(2b, uint16_t)\nGEN_TRANSPOSE_KERNELS(4b, uint32_t)\nGEN_TRANSPOSE_KERNELS(8b, uint64_t)\n\n// End of transpose.cl\n// Start of copy.cl\n\n#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \\\nFUTHARK_KERNEL void lmad_copy_##NAME(SHARED_MEM_PARAM                   \\\n                               __global ELEM_TYPE *dst_mem,             \\\n                               int64_t dst_offset,                      \\\n                               __global ELEM_TYPE *src_mem,             \\\n                               int64_t src_offset,                      \\\n                               int64_t n,                               \\\n                               int r,                                   \\\n                               int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \\\n                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \\\n                               int64_t shape2, int64_t dst_stride2, int64_t src_stride2, \\\n                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \\\n                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \\\n                               int64_t shape5, int64_t dst_stride5, int64_t src_stride5, \\\n                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \\\n                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \\\n  int64_t gtid = get_global_id(0);                                      \\\n  int64_t remainder = gtid;                                             \\\n                                             ", "                           \\\n  if (gtid >= n) {                                                      \\\n    return;                                                             \\\n  }                                                                     \\\n                                                                        \\\n  if (r > 0) {                                                          \\\n    int64_t i = remainder % shape0;                                     \\\n    dst_offset += i * dst_stride0;                                      \\\n    src_offset += i * src_stride0;                                      \\\n    remainder /= shape0;                                                \\\n  }                                                                     \\\n  if (r > 1) {                                                          \\\n    int64_t i = remainder % shape1;                                     \\\n    dst_offset += i * dst_stride1;                                      \\\n    src_offset += i * src_stride1;                                      \\\n    remainder /= shape1;                                                \\\n  }                                                                     \\\n  if (r > 2) {                                                          \\\n    int64_t i = remainder % shape2;                                     \\\n    dst_offset += i * dst_stride2;                                      \\\n    src_offset += i * src_stride2;                                      \\\n    remainder /= shape2;                                                \\\n  }                                                                     \\\n  if (r > 3) {                                                          \\\n    int64_t i = remainder % shape3;                                     \\\n    dst_offset += i * dst_stride3;                                      \\\n    src_offset += i * src_stride3;                                      \\\n    remainder /= shape3;                       ",
                                    "                         \\\n  }                                                                     \\\n  if (r > 4) {                                                          \\\n    int64_t i = remainder % shape4;                                     \\\n    dst_offset += i * dst_stride4;                                      \\\n    src_offset += i * src_stride4;                                      \\\n    remainder /= shape4;                                                \\\n  }                                                                     \\\n  if (r > 5) {                                                          \\\n    int64_t i = remainder % shape5;                                     \\\n    dst_offset += i * dst_stride5;                                      \\\n    src_offset += i * src_stride5;                                      \\\n    remainder /= shape5;                                                \\\n  }                                                                     \\\n  if (r > 6) {                                                          \\\n    int64_t i = remainder % shape6;                                     \\\n    dst_offset += i * dst_stride6;                                      \\\n    src_offset += i * src_stride6;                                      \\\n    remainder /= shape6;                                                \\\n  }                                                                     \\\n  if (r > 7) {                                                          \\\n    int64_t i = remainder % shape7;                                     \\\n    dst_offset += i * dst_stride7;                                      \\\n    src_offset += i * src_stride7;                                      \\\n    remainder /= shape7;                                                \\\n  }                                                                     \\\n                                                                        \\\n  dst_mem[dst_offset] = src_mem[src_offset];     ", "                       \\\n}\n\nGEN_COPY_KERNEL(1b, uint8_t)\nGEN_COPY_KERNEL(2b, uint16_t)\nGEN_COPY_KERNEL(4b, uint32_t)\nGEN_COPY_KERNEL(8b, uint64_t)\n\n// End of copy.cl\n\n\n\nFUTHARK_KERNEL\nvoid builtinzhiota_i64ziiota_i64_24189(int64_t n_24185, int64_t x_24186, int64_t s_24187, int64_t virt_num_tblocks_24194, int64_t num_tblocks_24195, __global unsigned char *mem_24184)\n{\n    int32_t iota_ltid_24190;\n    int32_t tblock_sizze_24192;\n    int32_t iota_gid_24191;\n    int32_t iota_gtid_24189;\n    int32_t phys_tblock_id_24196;\n    int32_t iterations_24197;\n    \n    iota_ltid_24190 = get_local_id(0);\n    tblock_sizze_24192 = get_local_size(0);\n    iota_gid_24191 = get_tblock_id(0);\n    iota_gtid_24189 = iota_gid_24191 * tblock_sizze_24192 + iota_ltid_24190;\n    phys_tblock_id_24196 = get_tblock_id(0);\n    iterations_24197 = sdiv_up32(sext_i64_i32(virt_num_tblocks_24194) - phys_tblock_id_24196, sext_i64_i32(num_tblocks_24195));\n    for (int32_t i_24198 = 0; i_24198 < iterations_24197; i_24198++) {\n        int32_t virt_tblock_id_24199;\n        int64_t global_tid_24200;\n        \n        virt_tblock_id_24199 = phys_tblock_id_24196 + i_24198 * sext_i64_i32(num_tblocks_24195);\n        global_tid_24200 = sext_i32_i64(virt_tblock_id_24199) * sext_i32_i64(tblock_sizze_24192) + sext_i32_i64(iota_ltid_24190);\n        if (slt64(global_tid_24200, n_24185)) {\n            ((__global int64_t *) mem_24184)[global_tid_24200] = add64(mul64(global_tid_24200, s_24187), x_24186);\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i32zireplicate_23898(int64_t num_elems_23894, int32_t val_23895, int64_t replicate_n_23897, int64_t virt_num_tblocks_23903, int64_t num_tblocks_23904, __global unsigned char *mem_23893)\n{\n    int32_t replicate_ltid_23899;\n    int32_t tblock_sizze_23901;\n    int32_t replicate_gid_23900;\n    int32_t replicate_gtid_23898;\n    int32_t phys_tblock_id_23905;\n    int32_t iterations_23906", ";\n    \n    replicate_ltid_23899 = get_local_id(0);\n    tblock_sizze_23901 = get_local_size(0);\n    replicate_gid_23900 = get_tblock_id(0);\n    replicate_gtid_23898 = replicate_gid_23900 * tblock_sizze_23901 + replicate_ltid_23899;\n    phys_tblock_id_23905 = get_tblock_id(0);\n    iterations_23906 = sdiv_up32(sext_i64_i32(virt_num_tblocks_23903) - phys_tblock_id_23905, sext_i64_i32(num_tblocks_23904));\n    for (int32_t i_23907 = 0; i_23907 < iterations_23906; i_23907++) {\n        int32_t virt_tblock_id_23908;\n        int64_t global_tid_23909;\n        int64_t slice_23911;\n        int64_t rep_i_23910;\n        int64_t remnant_23912;\n        \n        virt_tblock_id_23908 = phys_tblock_id_23905 + i_23907 * sext_i64_i32(num_tblocks_23904);\n        global_tid_23909 = sext_i32_i64(virt_tblock_id_23908) * sext_i32_i64(tblock_sizze_23901) + sext_i32_i64(replicate_ltid_23899);\n        slice_23911 = num_elems_23894;\n        rep_i_23910 = global_tid_23909;\n        remnant_23912 = global_tid_23909 - rep_i_23910;\n        if (slt64(global_tid_23909, replicate_n_23897)) {\n            ((__global int32_t *) mem_23893)[rep_i_23910] = val_23895;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i8zireplicate_23960(int64_t num_elems_23956, int8_t val_23957, int64_t replicate_n_23959, int64_t virt_num_tblocks_23965, int64_t num_tblocks_23966, __global unsigned char *mem_23955)\n{\n    int32_t replicate_ltid_23961;\n    int32_t tblock_sizze_23963;\n    int32_t replicate_gid_23962;\n    int32_t replicate_gtid_23960;\n    int32_t phys_tblock_id_23967;\n    int32_t iterations_23968;\n    \n    replicate_ltid_23961 = get_local_id(0);\n    tblock_sizze_23963 = get_local_size(0);\n    replicate_gid_23962 = get_tblock_id(0);\n    replicate_gtid_23960 = replicate_gid_23962 * tblock_sizze_23963 + replicate_ltid_23961;\n    phys_tblock_id_23967 = get_tblock_id(0);\n    iterations_23968 = sdiv_up32(sext_i64_i32(virt_num_t",
                                    "blocks_23965) - phys_tblock_id_23967, sext_i64_i32(num_tblocks_23966));\n    for (int32_t i_23969 = 0; i_23969 < iterations_23968; i_23969++) {\n        int32_t virt_tblock_id_23970;\n        int64_t global_tid_23971;\n        int64_t slice_23973;\n        int64_t rep_i_23972;\n        int64_t remnant_23974;\n        \n        virt_tblock_id_23970 = phys_tblock_id_23967 + i_23969 * sext_i64_i32(num_tblocks_23966);\n        global_tid_23971 = sext_i32_i64(virt_tblock_id_23970) * sext_i32_i64(tblock_sizze_23963) + sext_i32_i64(replicate_ltid_23961);\n        slice_23973 = num_elems_23956;\n        rep_i_23972 = global_tid_23971;\n        remnant_23974 = global_tid_23971 - rep_i_23972;\n        if (slt64(global_tid_23971, replicate_n_23959)) {\n            ((__global int8_t *) mem_23955)[rep_i_23972] = val_23957;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zigpuseq_23981_dim1, 1, 1)\nvoid simulate_8477zigpuseq_23981(__global int *global_failure, int64_t i_15540, __global unsigned char *cQ_mem_23399, __global unsigned char *mem_23414)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23983;\n    int32_t tblock_sizze_23986;\n    int32_t wave_sizze_23985;\n    int32_t block_id_23984;\n    int32_t global_tid_23982;\n    int64_t tid_23981;\n    int64_t loopres_23151;\n    \n    local_tid_23983 = get_local_id(0);\n    tblock_sizze_23986 = get_local_size(0);\n    wave_sizze_23985 = LOCKSTEP_WIDTH;\n    block_id_23984 = get_tblock_id(0);\n    global_tid_23982 = block_id_23984 * tblock_sizze_23986 + local_tid_23983;\n    tid_23981 = sext_i32_i64(global_tid_23982);\n    loopres_23151 = ((__global int64_t *) cQ_mem_23399)[i_15540];\n    ((__global int64_t *) mem_23414)[(int64_t) 0] = loopres_23151;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zigpuseq_23988_dim1, 1, 1)\nvoid simulate_8477zigpuseq_23988(__global int *global_failure, int failure_is_an_option, __global int64", "_t *global_failure_args, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, __global unsigned char *mem_23414, __global unsigned char *mem_23458, __global unsigned char *mem_23459)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23990;\n    int32_t tblock_sizze_23993;\n    int32_t wave_sizze_23992;\n    int32_t block_id_23991;\n    int32_t global_tid_23989;\n    int64_t tid_23988;\n    int64_t loopres_23153;\n    bool x_23154;\n    bool y_23157;\n    bool bounds_check_23161;\n    bool index_certs_23165;\n    \n    local_tid_23990 = get_local_id(0);\n    tblock_sizze_23993 = get_local_size(0);\n    wave_sizze_23992 = LOCKSTEP_WIDTH;\n    block_id_23991 = get_tblock_id(0);\n    global_tid_23989 = block_id_23991 * tblock_sizze_23993 + local_tid_23990;\n    tid_23988 = sext_i32_i64(global_tid_23989);\n    loopres_23153 = ((__global int64_t *) mem_23414)[(int64_t) 0];\n    x_23154 = sle64((int64_t) 0, loopres_23153);\n    y_23157 = slt64(loopres_23153, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n    bounds_check_23161 = x_23154 && y_23157;\n    if (!bounds_check_23161) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {\n                global_failure_args[0] = (int64_t) loopres_23153;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                ;\n            }\n            return;\n        }\n    }\n    ((__global bool *) mem_23458)[(int64_t) 0] = bounds_check_23161;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zigpuseq_24049_dim1, 1, 1)\nvoid simulate_8477zigpuseq_24049(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, unsigned char cond_20883_bits, __global unsigned char *mem_23414, __global unsigned char *mem_23458, __global unsigned char *mem_23463)\n{\n    bool cond_20883 = cond_20883_b", "its;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24051;\n    int32_t tblock_sizze_24054;\n    int32_t wave_sizze_24053;\n    int32_t block_id_24052;\n    int32_t global_tid_24050;\n    int64_t tid_24049;\n    bool bounds_check_23168;\n    bool protect_assert_disj_23169;\n    int64_t loopres_23172;\n    bool index_certs_23173;\n    \n    local_tid_24051 = get_local_id(0);\n    tblock_sizze_24054 = get_local_size(0);\n    wave_sizze_24053 = LOCKSTEP_WIDTH;\n    block_id_24052 = get_tblock_id(0);\n    global_tid_24050 = block_id_24052 * tblock_sizze_24054 + local_tid_24051;\n    tid_24049 = sext_i32_i64(global_tid_24050);\n    bounds_check_23168 = ((__global bool *) mem_23458)[(int64_t) 0];\n    protect_assert_disj_23169 = cond_20883 || bounds_check_23168;\n    loopres_23172 = ((__global int64_t *) mem_23414)[(int64_t) 0];\n    if (!protect_assert_disj_23169) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 2) == -1) {\n                global_failure_args[0] = (int64_t) loopres_23172;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                ;\n            }\n            return;\n        }\n    }\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zigpuseq_24059_dim1, 1, 1)\nvoid simulate_8477zigpuseq_24059(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int8_t u64_res_21127, int64_t measurement_count_21335, __global unsigned char *mem_23405, __global unsigned char *mem_23406, __global unsigned char *mem_23414, __global unsigned char *mem_23461, __global unsigned char *mem_23652, __global unsigned char *mem_23653, __global unsigned char *mem_23654, __global unsigned char *mem_23655, __global unsigned char *mem_23656, __global unsigned char *mem_23657)\n{\n    if (*global_failure >= 0)\n       ",
                                    " return;\n    \n    int32_t local_tid_24061;\n    int32_t tblock_sizze_24064;\n    int32_t wave_sizze_24063;\n    int32_t block_id_24062;\n    int32_t global_tid_24060;\n    int64_t tid_24059;\n    int64_t defunc_0_f_res_23175;\n    bool x_23180;\n    bool y_23183;\n    bool bounds_check_23187;\n    bool index_certs_23191;\n    bool index_certs_23195;\n    int8_t zt_rhs_23198;\n    int8_t zp_rhs_23201;\n    int64_t tmp_23208;\n    int64_t loopres_23212;\n    int64_t zeze_rhs_23213;\n    \n    local_tid_24061 = get_local_id(0);\n    tblock_sizze_24064 = get_local_size(0);\n    wave_sizze_24063 = LOCKSTEP_WIDTH;\n    block_id_24062 = get_tblock_id(0);\n    global_tid_24060 = block_id_24062 * tblock_sizze_24064 + local_tid_24061;\n    tid_24059 = sext_i32_i64(global_tid_24060);\n    defunc_0_f_res_23175 = ((__global int64_t *) mem_23461)[(int64_t) 0];\n    x_23180 = sle64((int64_t) 0, defunc_0_f_res_23175);\n    y_23183 = slt64(defunc_0_f_res_23175, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n    bounds_check_23187 = x_23180 && y_23183;\n    if (!bounds_check_23187) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 3) == -1) {\n                global_failure_args[0] = (int64_t) defunc_0_f_res_23175;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                ;\n            }\n            return;\n        }\n    }\n    if (!bounds_check_23187) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 4) == -1) {\n                global_failure_args[0] = (int64_t) defunc_0_f_res_23175;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                ;\n            }\n            return;\n        }\n    }\n    zt_rhs_23198 = ((__global int8_t *) mem_23405)[defunc_0_f_res_23175 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + arg_15490];\n    zp_rhs_23201 = mul8((int8_t) 2, zt_rhs_23198);\n    tmp_2", "3208 = sub64(defunc_0_f_res_23175, num_qubits_15486);\n    loopres_23212 = ((__global int64_t *) mem_23414)[(int64_t) 0];\n    zeze_rhs_23213 = add64(num_qubits_15486, loopres_23212);\n    ((__global int64_t *) mem_23652)[(int64_t) 0] = defunc_0_f_res_23175;\n    ((__global int8_t *) mem_23655)[(int64_t) 0] = zp_rhs_23201;\n    ((__global int64_t *) mem_23656)[(int64_t) 0] = tmp_23208;\n    ((__global int64_t *) mem_23657)[(int64_t) 0] = zeze_rhs_23213;\n    ((__global int8_t *) mem_23406)[measurement_count_21335] = u64_res_21127;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zigpuseq_24609_dim1, 1, 1)\nvoid simulate_8477zigpuseq_24609(__global int *global_failure, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, __global unsigned char *mem_23405, __global unsigned char *mem_23473)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24611;\n    int32_t tblock_sizze_24614;\n    int32_t wave_sizze_24613;\n    int32_t block_id_24612;\n    int32_t global_tid_24610;\n    int64_t tid_24609;\n    int8_t zt_rhs_23218;\n    int8_t zp_lhs_23221;\n    \n    local_tid_24611 = get_local_id(0);\n    tblock_sizze_24614 = get_local_size(0);\n    wave_sizze_24613 = LOCKSTEP_WIDTH;\n    block_id_24612 = get_tblock_id(0);\n    global_tid_24610 = block_id_24612 * tblock_sizze_24614 + local_tid_24611;\n    tid_24609 = sext_i32_i64(global_tid_24610);\n    zt_rhs_23218 = ((__global int8_t *) mem_23405)[arg_15490 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + arg_15490];\n    zp_lhs_23221 = mul8((int8_t) 2, zt_rhs_23218);\n    ((__global int8_t *) mem_23473)[(int64_t) 0] = zp_lhs_23221;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zigpuseq_24656_dim1, 1, 1)\nvoid simulate_8477zigpuseq_24656(__global int *global_failure, int64_t measurement_count_21335, __global unsigned char *mem_23406, __global unsigned char *mem_23568)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_ti", "d_24658;\n    int32_t tblock_sizze_24661;\n    int32_t wave_sizze_24660;\n    int32_t block_id_24659;\n    int32_t global_tid_24657;\n    int64_t tid_24656;\n    int8_t defunc_0_reduce_res_23224;\n    \n    local_tid_24658 = get_local_id(0);\n    tblock_sizze_24661 = get_local_size(0);\n    wave_sizze_24660 = LOCKSTEP_WIDTH;\n    block_id_24659 = get_tblock_id(0);\n    global_tid_24657 = block_id_24659 * tblock_sizze_24661 + local_tid_24658;\n    tid_24656 = sext_i32_i64(global_tid_24657);\n    defunc_0_reduce_res_23224 = ((__global int8_t *) mem_23568)[(int64_t) 0];\n    ((__global int8_t *) mem_23406)[measurement_count_21335] = defunc_0_reduce_res_23224;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zigpuseq_24803_dim1, 1, 1)\nvoid simulate_8477zigpuseq_24803(__global int *global_failure, int64_t measurement_count_21335, __global unsigned char *mem_23406, __global unsigned char *mem_23541)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24805;\n    int32_t tblock_sizze_24808;\n    int32_t wave_sizze_24807;\n    int32_t block_id_24806;\n    int32_t global_tid_24804;\n    int64_t tid_24803;\n    int8_t defunc_0_reduce_res_23228;\n    \n    local_tid_24805 = get_local_id(0);\n    tblock_sizze_24808 = get_local_size(0);\n    wave_sizze_24807 = LOCKSTEP_WIDTH;\n    block_id_24806 = get_tblock_id(0);\n    global_tid_24804 = block_id_24806 * tblock_sizze_24808 + local_tid_24805;\n    tid_24803 = sext_i32_i64(global_tid_24804);\n    defunc_0_reduce_res_23228 = ((__global int8_t *) mem_23541)[(int64_t) 0];\n    ((__global int8_t *) mem_23406)[measurement_count_21335] = defunc_0_reduce_res_23228;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zigpuseq_24991_dim1, 1, 1)\nvoid simulate_8477zigpuseq_24991(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, __global unsigned char *mem_23414",
                                    ", __global unsigned char *mem_23445, __global unsigned char *mem_23446, __global unsigned char *mem_23447, __global unsigned char *mem_23448, __global unsigned char *mem_23449)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24993;\n    int32_t tblock_sizze_24996;\n    int32_t wave_sizze_24995;\n    int32_t block_id_24994;\n    int32_t global_tid_24992;\n    int64_t tid_24991;\n    int64_t loopres_23235;\n    int64_t tmp_23236;\n    bool y_23243;\n    bool x_23246;\n    bool bounds_check_23250;\n    bool index_certs_23254;\n    bool y_23257;\n    bool x_23260;\n    bool bounds_check_23264;\n    bool index_certs_23268;\n    \n    local_tid_24993 = get_local_id(0);\n    tblock_sizze_24996 = get_local_size(0);\n    wave_sizze_24995 = LOCKSTEP_WIDTH;\n    block_id_24994 = get_tblock_id(0);\n    global_tid_24992 = block_id_24994 * tblock_sizze_24996 + local_tid_24993;\n    tid_24991 = sext_i32_i64(global_tid_24992);\n    loopres_23235 = ((__global int64_t *) mem_23414)[(int64_t) 0];\n    tmp_23236 = add64(num_qubits_15486, loopres_23235);\n    ((__global int64_t *) mem_23445)[(int64_t) 0] = arg_15490;\n    ((__global int64_t *) mem_23445)[(int64_t) 1] = loopres_23235;\n    ((__global int64_t *) mem_23445)[(int64_t) 2] = tmp_23236;\n    y_23243 = slt64(tmp_23236, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n    x_23246 = sle64((int64_t) 0, tmp_23236);\n    bounds_check_23250 = y_23243 && x_23246;\n    if (!bounds_check_23250) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 33) == -1) {\n                global_failure_args[0] = (int64_t) tmp_23236;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                ;\n            }\n            return;\n        }\n    }\n    y_23257 = slt64(loopres_23235, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n    x_23260 = sle64((int64_t) 0, loopres_23235);\n    bounds_check_23264 = y_23257 && x_23260;\n    if (!b", "ounds_check_23264) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 34) == -1) {\n                global_failure_args[0] = (int64_t) loopres_23235;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                ;\n            }\n            return;\n        }\n    }\n    ((__global int64_t *) mem_23446)[(int64_t) 0] = tmp_23236;\n    for (int64_t i_0 = 0; i_0 < (int64_t) 3; i_0++) {\n        ((__global int64_t *) mem_23447)[i_0] = ((__global int64_t *) mem_23445)[i_0];\n    }\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zigpuseq_25025_dim1, 1, 1)\nvoid simulate_8477zigpuseq_25025(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, __global unsigned char *mem_23414, __global unsigned char *mem_23432, __global unsigned char *mem_23433, __global unsigned char *mem_23434, __global unsigned char *mem_23435, __global unsigned char *mem_23436)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_25027;\n    int32_t tblock_sizze_25030;\n    int32_t wave_sizze_25029;\n    int32_t block_id_25028;\n    int32_t global_tid_25026;\n    int64_t tid_25025;\n    int64_t loopres_23272;\n    int64_t tmp_23273;\n    bool y_23279;\n    bool x_23282;\n    bool bounds_check_23286;\n    bool index_certs_23290;\n    bool y_23293;\n    bool x_23296;\n    bool bounds_check_23300;\n    bool index_certs_23304;\n    \n    local_tid_25027 = get_local_id(0);\n    tblock_sizze_25030 = get_local_size(0);\n    wave_sizze_25029 = LOCKSTEP_WIDTH;\n    block_id_25028 = get_tblock_id(0);\n    global_tid_25026 = block_id_25028 * tblock_sizze_25030 + local_tid_25027;\n    tid_25025 = sext_i32_i64(global_tid_25026);\n    loopres_23272 = ((__global int64_t *) mem_23414)[(int64_t) 0];\n    tmp_23273 = add64(num_qubits_15486, loopres_23272);\n    ((__glo", "bal int64_t *) mem_23432)[(int64_t) 0] = arg_15490;\n    ((__global int64_t *) mem_23432)[(int64_t) 1] = tmp_23273;\n    y_23279 = slt64(tmp_23273, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n    x_23282 = sle64((int64_t) 0, tmp_23273);\n    bounds_check_23286 = y_23279 && x_23282;\n    if (!bounds_check_23286) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 36) == -1) {\n                global_failure_args[0] = (int64_t) tmp_23273;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                ;\n            }\n            return;\n        }\n    }\n    y_23293 = slt64(loopres_23272, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n    x_23296 = sle64((int64_t) 0, loopres_23272);\n    bounds_check_23300 = y_23293 && x_23296;\n    if (!bounds_check_23300) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 37) == -1) {\n                global_failure_args[0] = (int64_t) loopres_23272;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                ;\n            }\n            return;\n        }\n    }\n    ((__global int64_t *) mem_23433)[(int64_t) 0] = tmp_23273;\n    for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n        ((__global int64_t *) mem_23434)[i_0] = ((__global int64_t *) mem_23432)[i_0];\n    }\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zigpuseq_25059_dim1, 1, 1)\nvoid simulate_8477zigpuseq_25059(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t i_15540, __global unsigned char *tQ_mem_23400, __global unsigned char *mem_23414, __global unsigned char *mem_23415, __global unsigned char *mem_23416, __global unsigned char *mem_23417, __global unsigned char *mem_23418",
                                    ", __global unsigned char *mem_23419, __global unsigned char *mem_23420, __global unsigned char *mem_23421, __global unsigned char *mem_23422, __global unsigned char *mem_23423)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_25061;\n    int32_t tblock_sizze_25064;\n    int32_t wave_sizze_25063;\n    int32_t block_id_25062;\n    int32_t global_tid_25060;\n    int64_t tid_25059;\n    int64_t loopres_23308;\n    int64_t loopres_23310;\n    int64_t tmp_23311;\n    bool y_23318;\n    bool x_23321;\n    bool bounds_check_23325;\n    bool index_certs_23329;\n    bool y_23332;\n    bool x_23335;\n    bool bounds_check_23339;\n    bool index_certs_23343;\n    int64_t zzib_23346;\n    bool y_23349;\n    bool x_23352;\n    bool bounds_check_23356;\n    bool index_certs_23360;\n    bool y_23363;\n    bool x_23366;\n    bool bounds_check_23370;\n    bool index_certs_23374;\n    \n    local_tid_25061 = get_local_id(0);\n    tblock_sizze_25064 = get_local_size(0);\n    wave_sizze_25063 = LOCKSTEP_WIDTH;\n    block_id_25062 = get_tblock_id(0);\n    global_tid_25060 = block_id_25062 * tblock_sizze_25064 + local_tid_25061;\n    tid_25059 = sext_i32_i64(global_tid_25060);\n    loopres_23308 = ((__global int64_t *) tQ_mem_23400)[i_15540];\n    loopres_23310 = ((__global int64_t *) mem_23414)[(int64_t) 0];\n    tmp_23311 = add64(num_qubits_15486, loopres_23310);\n    ((__global int64_t *) mem_23415)[(int64_t) 0] = arg_15490;\n    ((__global int64_t *) mem_23415)[(int64_t) 1] = loopres_23308;\n    ((__global int64_t *) mem_23415)[(int64_t) 2] = tmp_23311;\n    y_23318 = slt64(loopres_23308, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n    x_23321 = sle64((int64_t) 0, loopres_23308);\n    bounds_check_23325 = y_23318 && x_23321;\n    if (!bounds_check_23325) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 39) == -1) {\n                global_failure_args[0] = (int64_t) loopres_23308;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLzt", "ZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                ;\n            }\n            return;\n        }\n    }\n    y_23332 = slt64(loopres_23310, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n    x_23335 = sle64((int64_t) 0, loopres_23310);\n    bounds_check_23339 = y_23332 && x_23335;\n    if (!bounds_check_23339) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 40) == -1) {\n                global_failure_args[0] = (int64_t) loopres_23310;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                ;\n            }\n            return;\n        }\n    }\n    zzib_23346 = add64(num_qubits_15486, loopres_23308);\n    y_23349 = slt64(zzib_23346, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n    x_23352 = sle64((int64_t) 0, zzib_23346);\n    bounds_check_23356 = y_23349 && x_23352;\n    if (!bounds_check_23356) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 41) == -1) {\n                global_failure_args[0] = (int64_t) zzib_23346;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                ;\n            }\n            return;\n        }\n    }\n    y_23363 = slt64(tmp_23311, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n    x_23366 = sle64((int64_t) 0, tmp_23311);\n    bounds_check_23370 = y_23363 && x_23366;\n    if (!bounds_check_23370) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 42) == -1) {\n                global_failure_args[0] = (int64_t) tmp_23311;\n                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                ;\n            }\n            return;\n        }\n    }\n    ((__global int64_t *) mem_23416)[(int64_t) 0] = loopres_23308;\n    ((__global int64_t *) mem_23417)[(int64_t) 0] = tmp_23311;\n    for (int64_t i_0 = 0; i_0 < (int64_t)", " 3; i_0++) {\n        ((__global int64_t *) mem_23418)[i_0] = ((__global int64_t *) mem_23415)[i_0];\n    }\n    ((__global int64_t *) mem_23421)[(int64_t) 0] = zzib_23346;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid simulate_8477zireplicate_24363(int64_t arg_15490, int64_t m_20948, int64_t replicate_n_24362, int64_t virt_num_tblocks_24368, int64_t num_tblocks_24369, __global unsigned char *mem_23665, __global unsigned char *mem_23689)\n{\n    int32_t replicate_ltid_24364;\n    int32_t tblock_sizze_24366;\n    int32_t replicate_gid_24365;\n    int32_t replicate_gtid_24363;\n    int32_t phys_tblock_id_24370;\n    int32_t iterations_24371;\n    \n    replicate_ltid_24364 = get_local_id(0);\n    tblock_sizze_24366 = get_local_size(0);\n    replicate_gid_24365 = get_tblock_id(0);\n    replicate_gtid_24363 = replicate_gid_24365 * tblock_sizze_24366 + replicate_ltid_24364;\n    phys_tblock_id_24370 = get_tblock_id(0);\n    iterations_24371 = sdiv_up32(sext_i64_i32(virt_num_tblocks_24368) - phys_tblock_id_24370, sext_i64_i32(num_tblocks_24369));\n    for (int32_t i_24372 = 0; i_24372 < iterations_24371; i_24372++) {\n        int32_t virt_tblock_id_24373;\n        int64_t global_tid_24374;\n        int64_t slice_24377;\n        int64_t slice_24378;\n        int64_t rep_i_24375;\n        int64_t remnant_24379;\n        int64_t rep_i_24376;\n        int64_t remnant_24380;\n        \n        virt_tblock_id_24373 = phys_tblock_id_24370 + i_24372 * sext_i64_i32(num_tblocks_24369);\n        global_tid_24374 = sext_i32_i64(virt_tblock_id_24373) * sext_i32_i64(tblock_sizze_24366) + sext_i32_i64(replicate_ltid_24364);\n        slice_24377 = m_20948;\n        slice_24378 = arg_15490 * slice_24377;\n        rep_i_24375 = squot64(global_tid_24374, slice_24377);\n        remnant_24379 = global_tid_24374 - rep_i_24375 * slice_24377;\n        rep_i_24376 = remnant_24379;\n        remnant_24380 = remnant_24379 - rep_i_24376;\n        if (slt64(global_tid_24374, replicate_n_24362)) {\n            int64_t tmp_24381 = ((__",
                                    "global int64_t *) mem_23665)[rep_i_24376];\n            \n            ((__global int64_t *) mem_23689)[rep_i_24375 * m_20948 + rep_i_24376] = tmp_24381;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid simulate_8477zireplicate_24383(int64_t arg_15490, int64_t m_20948, int64_t replicate_n_24382, int64_t virt_num_tblocks_24388, int64_t num_tblocks_24389, __global unsigned char *mem_23665, __global unsigned char *mem_23689)\n{\n    int32_t replicate_ltid_24384;\n    int32_t tblock_sizze_24386;\n    int32_t replicate_gid_24385;\n    int32_t replicate_gtid_24383;\n    int32_t phys_tblock_id_24390;\n    int32_t iterations_24391;\n    \n    replicate_ltid_24384 = get_local_id(0);\n    tblock_sizze_24386 = get_local_size(0);\n    replicate_gid_24385 = get_tblock_id(0);\n    replicate_gtid_24383 = replicate_gid_24385 * tblock_sizze_24386 + replicate_ltid_24384;\n    phys_tblock_id_24390 = get_tblock_id(0);\n    iterations_24391 = sdiv_up32(sext_i64_i32(virt_num_tblocks_24388) - phys_tblock_id_24390, sext_i64_i32(num_tblocks_24389));\n    for (int32_t i_24392 = 0; i_24392 < iterations_24391; i_24392++) {\n        int32_t virt_tblock_id_24393;\n        int64_t global_tid_24394;\n        int64_t slice_24397;\n        int64_t slice_24398;\n        int64_t rep_i_24395;\n        int64_t remnant_24399;\n        int64_t rep_i_24396;\n        int64_t remnant_24400;\n        \n        virt_tblock_id_24393 = phys_tblock_id_24390 + i_24392 * sext_i64_i32(num_tblocks_24389);\n        global_tid_24394 = sext_i32_i64(virt_tblock_id_24393) * sext_i32_i64(tblock_sizze_24386) + sext_i32_i64(replicate_ltid_24384);\n        slice_24397 = m_20948;\n        slice_24398 = slice_24397;\n        rep_i_24395 = squot64(global_tid_24394, slice_24397);\n        remnant_24399 = global_tid_24394 - rep_i_24395 * slice_24397;\n        rep_i_24396 = remnant_24399;\n        remnant_24400 = remnant_24399 - rep_i_24396;\n        if (slt64(global_tid_24394, replicate_n_", "24382)) {\n            int64_t tmp_24401 = ((__global int64_t *) mem_23665)[rep_i_24396];\n            \n            ((__global int64_t *) mem_23689)[m_20948 * arg_15490 + (rep_i_24395 * m_20948 + rep_i_24396)] = tmp_24401;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid simulate_8477zireplicate_24403(int64_t m_20948, int64_t replicate_n_24402, int64_t virt_num_tblocks_24408, int64_t num_tblocks_24409, __global unsigned char *mem_23680, __global unsigned char *mem_23686)\n{\n    int32_t replicate_ltid_24404;\n    int32_t tblock_sizze_24406;\n    int32_t replicate_gid_24405;\n    int32_t replicate_gtid_24403;\n    int32_t phys_tblock_id_24410;\n    int32_t iterations_24411;\n    \n    replicate_ltid_24404 = get_local_id(0);\n    tblock_sizze_24406 = get_local_size(0);\n    replicate_gid_24405 = get_tblock_id(0);\n    replicate_gtid_24403 = replicate_gid_24405 * tblock_sizze_24406 + replicate_ltid_24404;\n    phys_tblock_id_24410 = get_tblock_id(0);\n    iterations_24411 = sdiv_up32(sext_i64_i32(virt_num_tblocks_24408) - phys_tblock_id_24410, sext_i64_i32(num_tblocks_24409));\n    for (int32_t i_24412 = 0; i_24412 < iterations_24411; i_24412++) {\n        int32_t virt_tblock_id_24413;\n        int64_t global_tid_24414;\n        int64_t slice_24417;\n        int64_t slice_24418;\n        int64_t rep_i_24415;\n        int64_t remnant_24419;\n        int64_t rep_i_24416;\n        int64_t remnant_24420;\n        \n        virt_tblock_id_24413 = phys_tblock_id_24410 + i_24412 * sext_i64_i32(num_tblocks_24409);\n        global_tid_24414 = sext_i32_i64(virt_tblock_id_24413) * sext_i32_i64(tblock_sizze_24406) + sext_i32_i64(replicate_ltid_24404);\n        slice_24417 = m_20948;\n        slice_24418 = slice_24417;\n        rep_i_24415 = squot64(global_tid_24414, slice_24417);\n        remnant_24419 = global_tid_24414 - rep_i_24415 * slice_24417;\n        rep_i_24416 = remnant_24419;\n        remnant_24420 = remnant_24419 - rep_i_2441", "6;\n        if (slt64(global_tid_24414, replicate_n_24402)) {\n            int8_t tmp_24421 = ((__global int8_t *) mem_23680)[rep_i_24416];\n            \n            ((__global int8_t *) mem_23686)[rep_i_24415 * m_20948 + rep_i_24416] = tmp_24421;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_21631_dim1, 1, 1)\nvoid simulate_8477zisegmap_21631(__global int *global_failure, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, __global unsigned char *mem_23405)\n{\n    #define segmap_tblock_sizze_21626 (simulate_8477zisegmap_21631zisegmap_tblock_sizze_21626)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23946;\n    int32_t tblock_sizze_23949;\n    int32_t wave_sizze_23948;\n    int32_t block_id_23947;\n    int32_t global_tid_23945;\n    int64_t phys_tid_21631;\n    int64_t global_tid_23950;\n    int64_t slice_23951;\n    int64_t slice_23952;\n    int64_t gtid_21629;\n    int64_t remnant_23953;\n    int64_t gtid_21630;\n    int64_t remnant_23954;\n    \n    local_tid_23946 = get_local_id(0);\n    tblock_sizze_23949 = get_local_size(0);\n    wave_sizze_23948 = LOCKSTEP_WIDTH;\n    block_id_23947 = get_tblock_id(0);\n    global_tid_23945 = block_id_23947 * tblock_sizze_23949 + local_tid_23946;\n    phys_tid_21631 = sext_i32_i64(global_tid_23945);\n    global_tid_23950 = sext_i32_i64(block_id_23947) * segmap_tblock_sizze_21626 + sext_i32_i64(local_tid_23946);\n    slice_23951 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n    slice_23952 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 * slice_23951;\n    gtid_21629 = squot64(global_tid_23950, slice_23951);\n    remnant_23953 = global_tid_23950 - gtid_21629 * slice_23951;\n    gtid_21630 = remnant_23953;\n    remnant_23954 = remnant_23953 - gtid_21630;\n    if (slt64(gtid_21629, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491) && slt6",
                                    "4(gtid_21630, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) {\n        bool index_primexp_23115;\n        bool cond_21635;\n        bool x_21636;\n        bool y_21637;\n        bool cond_21638;\n        int8_t lifted_lambda_res_21639;\n        \n        index_primexp_23115 = gtid_21629 == arg_15490;\n        cond_21635 = gtid_21630 == arg_15490;\n        x_21636 = !cond_21635;\n        y_21637 = x_21636 && index_primexp_23115;\n        cond_21638 = cond_21635 || y_21637;\n        if (cond_21638) {\n            lifted_lambda_res_21639 = (int8_t) 0;\n        } else {\n            bool cond_21640;\n            int8_t lifted_lambda_res_f_res_21641;\n            \n            cond_21640 = gtid_21629 == gtid_21630;\n            lifted_lambda_res_f_res_21641 = btoi_bool_i8(cond_21640);\n            lifted_lambda_res_21639 = lifted_lambda_res_f_res_21641;\n        }\n        ((__global int8_t *) mem_23405)[gtid_21629 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + gtid_21630] = lifted_lambda_res_21639;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_21626\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_21663_dim1, 1, 1)\nvoid simulate_8477zisegmap_21663(__global int *global_failure, int64_t arg_15490, int64_t m_20948, int64_t num_tblocks_21668, int32_t virt_num_tblocks_24201, __global unsigned char *mem_23661, __global unsigned char *mem_23663, __global unsigned char *mem_23665)\n{\n    #define segmap_tblock_sizze_21666 (simulate_8477zisegmap_21663zisegmap_tblock_sizze_21666)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24203;\n    int32_t tblock_sizze_24206;\n    int32_t wave_sizze_24205;\n    int32_t block_id_24204;\n    int32_t global_tid_24202;\n    int64_t phys_tid_21663;\n    int32_t phys_tblock_id_24207;\n    int32_t iterations_24208;\n    \n    local_tid_24203 = get_local_id(0);\n    tblock_sizze_24206 = get_local_size(0);\n    wave_sizze_24205 = LOCKSTEP_WIDTH;\n    block_id_24204 = get_tblock_id(0);\n    global_tid_24202", " = block_id_24204 * tblock_sizze_24206 + local_tid_24203;\n    phys_tid_21663 = sext_i32_i64(global_tid_24202);\n    phys_tblock_id_24207 = get_tblock_id(0);\n    iterations_24208 = sdiv_up32(virt_num_tblocks_24201 - phys_tblock_id_24207, sext_i64_i32(num_tblocks_21668));\n    for (int32_t i_24209 = 0; i_24209 < iterations_24208; i_24209++) {\n        int32_t virt_tblock_id_24210;\n        int64_t global_tid_24211;\n        int64_t slice_24212;\n        int64_t write_i_21662;\n        int64_t remnant_24213;\n        \n        virt_tblock_id_24210 = phys_tblock_id_24207 + i_24209 * sext_i64_i32(num_tblocks_21668);\n        global_tid_24211 = sext_i32_i64(virt_tblock_id_24210) * segmap_tblock_sizze_21666 + sext_i32_i64(local_tid_24203);\n        slice_24212 = arg_15490;\n        write_i_21662 = global_tid_24211;\n        remnant_24213 = global_tid_24211 - write_i_21662;\n        if (slt64(write_i_21662, arg_15490)) {\n            int64_t eta_p_20962;\n            bool cond_20965;\n            int64_t lifted_lambda_res_20966;\n            \n            eta_p_20962 = ((__global int64_t *) mem_23663)[write_i_21662];\n            cond_20965 = eta_p_20962 == (int64_t) 1;\n            if (cond_20965) {\n                int64_t eta_p_20963;\n                int64_t lifted_lambda_res_t_res_20967;\n                \n                eta_p_20963 = ((__global int64_t *) mem_23661)[write_i_21662];\n                lifted_lambda_res_t_res_20967 = sub64(eta_p_20963, (int64_t) 1);\n                lifted_lambda_res_20966 = lifted_lambda_res_t_res_20967;\n            } else {\n                lifted_lambda_res_20966 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_20966) && slt64(lifted_lambda_res_20966, m_20948)) {\n                ((__global int64_t *) mem_23665)[lifted_lambda_res_20966] = write_i_21662;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_21666\n}\nFUTHARK_KERNEL_SIZED(", "simulate_8477zisegmap_21689_dim1, 1, 1)\nvoid simulate_8477zisegmap_21689(__global int *global_failure, int64_t num_qubits_15486, int64_t num_tblocks_21685, int32_t virt_num_tblocks_24169, __global unsigned char *mem_23651)\n{\n    #define segmap_tblock_sizze_21684 (simulate_8477zisegmap_21689zisegmap_tblock_sizze_21684)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24171;\n    int32_t tblock_sizze_24174;\n    int32_t wave_sizze_24173;\n    int32_t block_id_24172;\n    int32_t global_tid_24170;\n    int64_t phys_tid_21689;\n    int32_t phys_tblock_id_24175;\n    int32_t iterations_24176;\n    \n    local_tid_24171 = get_local_id(0);\n    tblock_sizze_24174 = get_local_size(0);\n    wave_sizze_24173 = LOCKSTEP_WIDTH;\n    block_id_24172 = get_tblock_id(0);\n    global_tid_24170 = block_id_24172 * tblock_sizze_24174 + local_tid_24171;\n    phys_tid_21689 = sext_i32_i64(global_tid_24170);\n    phys_tblock_id_24175 = get_tblock_id(0);\n    iterations_24176 = sdiv_up32(virt_num_tblocks_24169 - phys_tblock_id_24175, sext_i64_i32(num_tblocks_21685));\n    for (int32_t i_24177 = 0; i_24177 < iterations_24176; i_24177++) {\n        int32_t virt_tblock_id_24178;\n        int64_t global_tid_24179;\n        int64_t slice_24180;\n        int64_t gtid_21688;\n        int64_t remnant_24181;\n        \n        virt_tblock_id_24178 = phys_tblock_id_24175 + i_24177 * sext_i64_i32(num_tblocks_21685);\n        global_tid_24179 = sext_i32_i64(virt_tblock_id_24178) * segmap_tblock_sizze_21684 + sext_i32_i64(local_tid_24171);\n        slice_24180 = num_qubits_15486;\n        gtid_21688 = global_tid_24179;\n        remnant_24181 = global_tid_24179 - gtid_21688;\n        if (slt64(gtid_21688, num_qubits_15486)) {\n            int64_t tmp_21691;\n            int64_t mem_23641[(int64_t) 2];\n            \n            tmp_21691 = add64(num_qubits_15486, gtid_21688);\n            mem_23641[(int64_t) 0] = gtid_21688;\n            mem_23641[(int64_t) 1] = tmp_21691;\n            for (int64_t i_0 = 0; i_0 < (",
                                    "int64_t) 2; i_0++) {\n                ((__global int64_t *) mem_23651)[gtid_21688 + i_0 * num_qubits_15486] = mem_23641[i_0];\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_21684\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_21774_dim1, 1, 1)\nvoid simulate_8477zisegmap_21774(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_20948, int64_t num_tblocks_21769, int64_t num_threads_23824, int64_t ctx_23865, int32_t virt_num_tblocks_24252, __global unsigned char *mem_23405, __global unsigned char *mem_23652, __global unsigned char *mem_23655, __global unsigned char *mem_23665, __global unsigned char *mem_23694, __global unsigned char *mem_23734, __global unsigned char *mem_23744, __global unsigned char *color_23821)\n{\n    #define segmap_tblock_sizze_21768 (simulate_8477zisegmap_21774zisegmap_tblock_sizze_21768)\n    \n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24254;\n    int32_t tblock_sizze_24257;\n    int32_t wave_sizze_24256;\n    int32_t block_id_24255;\n    int32_t global_tid_24253;\n    int64_t phys_tid_21774;\n    int32_t phys_tblock_id_24258;\n    int32_t iterations_24259;\n    \n    local_tid_24254 = get_local_id(0);\n    tblock_sizze_24257 = get_local_size(0);\n    wave_sizze_24256 = LOCKSTEP_WIDTH;\n    block_id_24255 = get_tblock_id(0);\n    global_tid_24253 = block_id_24255 * tblock_sizze_24257 + local_tid_24254;\n    phys_tid_21774 = sext_i32_i64(global_tid_24253);\n    phys_tblock_id_24258 = get_tblock_id(0);\n    iterations_24259 = sdiv_up32(virt_num_tblocks_24252 - phys_tblock_id_24258, sext", "_i64_i32(num_tblocks_21769));\n    for (int32_t i_24260 = 0; i_24260 < iterations_24259; i_24260++) {\n        int32_t virt_tblock_id_24261;\n        int64_t global_tid_24262;\n        int64_t slice_24263;\n        int64_t gtid_21773;\n        int64_t remnant_24264;\n        \n        virt_tblock_id_24261 = phys_tblock_id_24258 + i_24260 * sext_i64_i32(num_tblocks_21769);\n        global_tid_24262 = sext_i32_i64(virt_tblock_id_24261) * segmap_tblock_sizze_21768 + sext_i32_i64(local_tid_24254);\n        slice_24263 = m_20948;\n        gtid_21773 = global_tid_24262;\n        remnant_24264 = global_tid_24262 - gtid_21773;\n        if (slt64(gtid_21773, m_20948)) {\n            int64_t eta_p_21775;\n            bool x_21776;\n            bool y_21777;\n            bool bounds_check_21778;\n            bool index_certs_21779;\n            bool index_certs_21822;\n            int64_t defunc_0_f_res_23203;\n            int8_t zp_rhs_23204;\n            int8_t mem_23702[(int64_t) 2];\n            int8_t defunc_0_f_res_21780;\n            int8_t redout_23117;\n            int8_t zt_rhs_21823;\n            int8_t zp_lhs_21824;\n            int8_t zp_lhs_21825;\n            int8_t zv_lhs_21826;\n            int8_t res_21827;\n            bool cond_21828;\n            bool cond_neg_21829;\n            int8_t v_21830;\n            int64_t mem_23716[(int64_t) 1];\n            int8_t mem_23720[(int64_t) 1];\n            int64_t tmp_offs_24270;\n            int64_t tmp_offs_24271;\n            \n            eta_p_21775 = ((__global int64_t *) mem_23665)[gtid_21773];\n            x_21776 = sle64((int64_t) 0, eta_p_21775);\n            y_21777 = slt64(eta_p_21775, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n            bounds_check_21778 = x_21776 && y_21777;\n            if (!bounds_check_21778) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 8) == -1) {\n                        global_failure_args[0] = (int64_t) eta_p_21775;\n                        global_fail", "ure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            if (!bounds_check_21778) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 9) == -1) {\n                        global_failure_args[0] = (int64_t) eta_p_21775;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            defunc_0_f_res_23203 = ((__global int64_t *) mem_23652)[(int64_t) 0];\n            zp_rhs_23204 = ((__global int8_t *) mem_23655)[(int64_t) 0];\n            redout_23117 = (int8_t) 0;\n            for (int64_t i_23119 = 0; i_23119 < num_qubits_15486; i_23119++) {\n                int64_t g_arg3_21786;\n                bool x_21787;\n                bool y_21788;\n                bool bounds_check_21789;\n                bool index_certs_21790;\n                bool y_21793;\n                bool index_certs_21795;\n                int8_t g_arg3_21791;\n                int8_t g_arg2_21796;\n                int8_t g_arg1_21797;\n                int8_t g_arg0_21798;\n                bool cond_21799;\n                bool cond_t_res_21800;\n                bool x_21801;\n                int8_t g_res_21802;\n                int8_t tmp_21819;\n                int8_t tmp_21820;\n                int8_t defunc_0_op_res_21784;\n                int8_t redout_tmp_24265;\n                \n                g_arg3_21786 = add64(num_qubits_15486, i_23119);\n                x_21787 = sle64((int64_t) 0, g_arg3_21786);\n                y_21788 = slt64(g_arg3_21786, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                bounds_check_21789 = x_21787 && y_217",
                                    "88;\n                if (!bounds_check_21789) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 10) == -1) {\n                            global_failure_args[0] = (int64_t) g_arg3_21786;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                y_21793 = slt64(i_23119, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                if (!y_21793) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 11) == -1) {\n                            global_failure_args[0] = (int64_t) i_23119;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                g_arg3_21791 = ((__global int8_t *) mem_23405)[eta_p_21775 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + g_arg3_21786];\n                g_arg2_21796 = ((__global int8_t *) mem_23405)[eta_p_21775 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + i_23119];\n                g_arg1_21797 = ((__global int8_t *) mem_23405)[defunc_0_f_res_23203 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + g_arg3_21786];\n                g_arg0_21798 = ((__global int8_t *) mem_23405)[defunc_0_f_res_23203 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + i_23119];\n                cond_21799 = g_arg0_21798 == g_arg2_21796;\n                cond_t_res_21800 = g_arg0_21798 == (int8_t) 0;\n                x_21801 = cond_21799 && cond_t_res_21800;\n                i", "f (x_21801) {\n                    g_res_21802 = (int8_t) 0;\n                } else {\n                    bool cond_t_res_21803;\n                    bool x_21804;\n                    int8_t g_res_f_res_21805;\n                    \n                    cond_t_res_21803 = g_arg0_21798 == (int8_t) 1;\n                    x_21804 = cond_21799 && cond_t_res_21803;\n                    if (x_21804) {\n                        int8_t g_res_f_res_t_res_21806 = sub8(g_arg3_21791, g_arg1_21797);\n                        \n                        g_res_f_res_21805 = g_res_f_res_t_res_21806;\n                    } else {\n                        bool cond_t_res_21807;\n                        bool x_21808;\n                        int8_t g_res_f_res_f_res_21809;\n                        \n                        cond_t_res_21807 = g_arg2_21796 == (int8_t) 0;\n                        x_21808 = cond_t_res_21803 && cond_t_res_21807;\n                        if (x_21808) {\n                            int8_t zm_lhs_21810;\n                            int8_t zt_rhs_21811;\n                            int8_t g_res_f_res_f_res_t_res_21812;\n                            \n                            zm_lhs_21810 = mul8((int8_t) 2, g_arg1_21797);\n                            zt_rhs_21811 = sub8(zm_lhs_21810, (int8_t) 1);\n                            g_res_f_res_f_res_t_res_21812 = mul8(g_arg3_21791, zt_rhs_21811);\n                            g_res_f_res_f_res_21809 = g_res_f_res_f_res_t_res_21812;\n                        } else {\n                            bool cond_t_res_21813;\n                            bool x_21814;\n                            int8_t g_res_f_res_f_res_f_res_21815;\n                            \n                            cond_t_res_21813 = g_arg2_21796 == (int8_t) 1;\n                            x_21814 = cond_t_res_21800 && cond_t_res_21813;\n                            if (x_21814) {\n                                int8_t zm_rhs_21816;\n                                int8_t zt_rhs_21817;\n  ", "                              int8_t g_res_f_res_f_res_f_res_t_res_21818;\n                                \n                                zm_rhs_21816 = mul8((int8_t) 2, g_arg3_21791);\n                                zt_rhs_21817 = sub8((int8_t) 1, zm_rhs_21816);\n                                g_res_f_res_f_res_f_res_t_res_21818 = mul8(g_arg1_21797, zt_rhs_21817);\n                                g_res_f_res_f_res_f_res_21815 = g_res_f_res_f_res_f_res_t_res_21818;\n                            } else {\n                                g_res_f_res_f_res_f_res_21815 = (int8_t) 0;\n                            }\n                            g_res_f_res_f_res_21809 = g_res_f_res_f_res_f_res_21815;\n                        }\n                        g_res_f_res_21805 = g_res_f_res_f_res_21809;\n                    }\n                    g_res_21802 = g_res_f_res_21805;\n                }\n                tmp_21819 = g_arg2_21796 ^ g_arg0_21798;\n                tmp_21820 = g_arg3_21791 ^ g_arg1_21797;\n                mem_23702[(int64_t) 0] = tmp_21819;\n                mem_23702[(int64_t) 1] = tmp_21820;\n                defunc_0_op_res_21784 = add8(g_res_21802, redout_23117);\n                for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                    ((__global int8_t *) mem_23694)[phys_tid_21774 + i_23119 * ctx_23865 + i_0 * num_threads_23824] = mem_23702[i_0];\n                }\n                redout_tmp_24265 = defunc_0_op_res_21784;\n                redout_23117 = redout_tmp_24265;\n            }\n            defunc_0_f_res_21780 = redout_23117;\n            zt_rhs_21823 = ((__global int8_t *) mem_23405)[eta_p_21775 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + arg_15490];\n            zp_lhs_21824 = mul8((int8_t) 2, zt_rhs_21823);\n            zp_lhs_21825 = add8(zp_lhs_21824, zp_rhs_23204);\n            zv_lhs_21826 = add8(defunc_0_f_res_21780, zp_lhs_21825);\n            res_21827 = smod8(zv_lhs_21826, (int8_t) 4);\n            cond_21828 = res_21827 == ",
                                    "(int8_t) 0;\n            cond_neg_21829 = !cond_21828;\n            v_21830 = btoi_bool_i8(cond_neg_21829);\n            for (int64_t nest_i_24267 = 0; nest_i_24267 < arg_15490; nest_i_24267++) {\n                ((__global int64_t *) mem_23734)[gtid_21773 + nest_i_24267 * m_20948] = eta_p_21775;\n            }\n            for (int64_t i_0 = 0; i_0 < num_qubits_15486; i_0++) {\n                for (int64_t i_1 = 0; i_1 < (int64_t) 2; i_1++) {\n                    ((__global int8_t *) color_23821)[phys_tid_21774 + (i_0 * (num_threads_23824 * (int64_t) 2) + i_1 * num_threads_23824)] = ((__global int8_t *) mem_23694)[phys_tid_21774 + (i_0 * ctx_23865 + i_1 * num_threads_23824)];\n                }\n            }\n            for (int64_t nest_i_24268 = 0; nest_i_24268 < (int64_t) 1; nest_i_24268++) {\n                mem_23716[nest_i_24268] = eta_p_21775;\n            }\n            for (int64_t nest_i_24269 = 0; nest_i_24269 < (int64_t) 1; nest_i_24269++) {\n                mem_23720[nest_i_24269] = v_21830;\n            }\n            tmp_offs_24270 = (int64_t) 0;\n            if (!((gtid_21773 + m_20948 * tmp_offs_24270) == gtid_21773)) {\n                for (int64_t i_0 = 0; i_0 < arg_15490; i_0++) {\n                    ((__global int64_t *) mem_23734)[gtid_21773 + m_20948 * tmp_offs_24270 + i_0 * m_20948] = ((__global int64_t *) mem_23734)[gtid_21773 + i_0 * m_20948];\n                }\n            }\n            tmp_offs_24270 += arg_15490;\n            for (int64_t i_0 = 0; i_0 < (int64_t) 1; i_0++) {\n                ((__global int64_t *) mem_23734)[gtid_21773 + m_20948 * tmp_offs_24270 + i_0 * m_20948] = mem_23716[i_0];\n            }\n            tmp_offs_24270 += (int64_t) 1;\n            tmp_offs_24271 = (int64_t) 0;\n            for (int64_t i_0 = 0; i_0 < arg_15490; i_0++) {\n                ((__global int8_t *) mem_23744)[gtid_21773 + m_20948 * tmp_offs_24271 + i_0 * m_20948] = ((__global int8_t *) color_23821)[phys_tid_21774 + i_0 * num_threads_23824];\n            }\n            ", "tmp_offs_24271 += arg_15490;\n            for (int64_t i_0 = 0; i_0 < (int64_t) 1; i_0++) {\n                ((__global int8_t *) mem_23744)[gtid_21773 + m_20948 * tmp_offs_24271 + i_0 * m_20948] = mem_23720[i_0];\n            }\n            tmp_offs_24271 += (int64_t) 1;\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_21768\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_21948_dim1, 1, 1)\nvoid simulate_8477zisegmap_21948(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_20948, __global unsigned char *mem_23665, __global unsigned char *mem_23668, __global unsigned char *mem_23680)\n{\n    #define segmap_tblock_sizze_21943 (simulate_8477zisegmap_21948zisegmap_tblock_sizze_21943)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24274;\n    int32_t tblock_sizze_24277;\n    int32_t wave_sizze_24276;\n    int32_t block_id_24275;\n    int32_t global_tid_24273;\n    int64_t phys_tid_21948;\n    int64_t global_tid_24278;\n    int64_t slice_24279;\n    int64_t gtid_21947;\n    int64_t remnant_24280;\n    \n    local_tid_24274 = get_local_id(0);\n    tblock_sizze_24277 = get_local_size(0);\n    wave_sizze_24276 = LOCKSTEP_WIDTH;\n    block_id_24275 = get_tblock_id(0);\n    global_tid_24273 = block_id_24275 * tblock_sizze_24277 + local_tid_24274;\n    phys_tid_21948 = sext_i32_i64(global_tid_24273);\n    global_tid_24278 = sext_i32_i64(block_id_24275) * segmap_tblock_sizze_21943 + sext_i32_i64(local_tid_24274);\n    slice_24279 = m_20948;\n    gtid_21947 = global_tid_24278;\n    remnant_24280 = global_tid_24278 - gtid_21947;\n    if (slt64(gtid_21947, m_20948)) {\n        int64_t eta_p_21949;\n        bool x_21950;\n        bool y_21951;\n      ", "  bool bounds_check_21952;\n        bool index_certs_21953;\n        \n        eta_p_21949 = ((__global int64_t *) mem_23665)[gtid_21947];\n        x_21950 = sle64((int64_t) 0, eta_p_21949);\n        y_21951 = slt64(eta_p_21949, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n        bounds_check_21952 = x_21950 && y_21951;\n        if (!bounds_check_21952) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 12) == -1) {\n                    global_failure_args[0] = (int64_t) eta_p_21949;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                    ;\n                }\n                return;\n            }\n        }\n        ((__global bool *) mem_23680)[gtid_21947] = bounds_check_21952;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_21943\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22011_dim1, 1, 1)\nvoid simulate_8477zisegmap_22011(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_20948, __global unsigned char *mem_23405, __global unsigned char *mem_23655, __global unsigned char *mem_23665, __global unsigned char *mem_23675, __global unsigned char *mem_23680)\n{\n    #define segmap_tblock_sizze_22007 (simulate_8477zisegmap_22011zisegmap_tblock_sizze_22007)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24355;\n    int32_t tblock_sizze_24358;\n    int32_t wave_sizze_24357;\n    int32_t block_id_24356;\n    int32_t global_tid_24354;\n    int64_t phys_tid_22011;\n    int64_t global_tid_24359;\n    int64_t slice_24360;\n    int64_t gtid_22010;\n    int64_t remnant_24361;\n    \n    local_tid_24355 = get_local_id(0);\n    tblock_sizze_24358 = get_local_size(0);\n    wave_sizze_24357 = LOCKSTEP_WIDTH;\n    block_id_24356 = get_tblock_id(0);\n    global_tid_24354 = block_id_24356 * tb",
                                    "lock_sizze_24358 + local_tid_24355;\n    phys_tid_22011 = sext_i32_i64(global_tid_24354);\n    global_tid_24359 = sext_i32_i64(block_id_24356) * segmap_tblock_sizze_22007 + sext_i32_i64(local_tid_24355);\n    slice_24360 = m_20948;\n    gtid_22010 = global_tid_24359;\n    remnant_24361 = global_tid_24359 - gtid_22010;\n    if (slt64(gtid_22010, m_20948)) {\n        int64_t eta_p_22012;\n        bool bounds_check_22013;\n        bool index_certs_22015;\n        int8_t zp_rhs_23206;\n        int8_t defunc_0_f_res_22014;\n        int8_t zt_rhs_22016;\n        int8_t zp_lhs_22017;\n        int8_t zp_lhs_22018;\n        int8_t zv_lhs_22019;\n        int8_t res_22020;\n        bool cond_22021;\n        bool cond_neg_22022;\n        int8_t v_22023;\n        \n        eta_p_22012 = ((__global int64_t *) mem_23665)[gtid_22010];\n        bounds_check_22013 = ((__global bool *) mem_23680)[gtid_22010];\n        if (!bounds_check_22013) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 17) == -1) {\n                    global_failure_args[0] = (int64_t) eta_p_22012;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                    ;\n                }\n                return;\n            }\n        }\n        zp_rhs_23206 = ((__global int8_t *) mem_23655)[(int64_t) 0];\n        defunc_0_f_res_22014 = ((__global int8_t *) mem_23675)[gtid_22010];\n        zt_rhs_22016 = ((__global int8_t *) mem_23405)[eta_p_22012 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + arg_15490];\n        zp_lhs_22017 = mul8((int8_t) 2, zt_rhs_22016);\n        zp_lhs_22018 = add8(zp_lhs_22017, zp_rhs_23206);\n        zv_lhs_22019 = add8(defunc_0_f_res_22014, zp_lhs_22018);\n        res_22020 = smod8(zv_lhs_22019, (int8_t) 4);\n        cond_22021 = res_22020 == (int8_t) 0;\n        cond_neg_22022 = !cond_22021;\n        v_22023 = btoi_bool_i8(cond_neg_22022);\n        ((__global int8_t *) mem_23680)[gtid_22010] = v_2202", "3;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22007\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22039_dim1, 1, 1)\nvoid simulate_8477zisegmap_22039(__global int *global_failure, int64_t num_qubits_15486, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_20948, int64_t dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20972, int64_t num_tblocks_22044, int64_t ext_23745, int64_t ext_23746, int32_t virt_num_tblocks_24426, __global unsigned char *mem_23405, __global unsigned char *mem_23651, __global unsigned char *ext_mem_23747, __global unsigned char *ext_mem_23748)\n{\n    #define segmap_tblock_sizze_22042 (simulate_8477zisegmap_22039zisegmap_tblock_sizze_22042)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24428;\n    int32_t tblock_sizze_24431;\n    int32_t wave_sizze_24430;\n    int32_t block_id_24429;\n    int32_t global_tid_24427;\n    int64_t phys_tid_22039;\n    int32_t phys_tblock_id_24432;\n    int32_t iterations_24433;\n    \n    local_tid_24428 = get_local_id(0);\n    tblock_sizze_24431 = get_local_size(0);\n    wave_sizze_24430 = LOCKSTEP_WIDTH;\n    block_id_24429 = get_tblock_id(0);\n    global_tid_24427 = block_id_24429 * tblock_sizze_24431 + local_tid_24428;\n    phys_tid_22039 = sext_i32_i64(global_tid_24427);\n    phys_tblock_id_24432 = get_tblock_id(0);\n    iterations_24433 = sdiv_up32(virt_num_tblocks_24426 - phys_tblock_id_24432, sext_i64_i32(num_tblocks_22044));\n    for (int32_t i_24434 = 0; i_24434 < iterations_24433; i_24434++) {\n        int32_t virt_tblock_id_24435;\n        int64_t global_tid_24436;\n        int64_t slice_24437;\n        int64_t write_i_22038;\n        int64_t remnant_24438;\n        \n        virt_tblock_id_24435 = phys_tblock_id_24432 + i_24434 * sext_i64_i32(num_tblocks_22044);\n        global_tid_24436 = sext_i32_i64(virt_tblock_id_24435) * segmap_tblock_sizze_22042 + sext_i32_i64(local_tid_24428);\n        slice_244", "37 = dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20972;\n        write_i_22038 = global_tid_24436;\n        remnant_24438 = global_tid_24436 - write_i_22038;\n        if (slt64(write_i_22038, dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20972)) {\n            int64_t new_index_22993;\n            int64_t binop_y_22995;\n            int64_t new_index_22996;\n            int64_t write_index_21087;\n            bool index_concat_cmp_23006;\n            int64_t index_concat_branch_23010;\n            int8_t write_value_21089;\n            \n            new_index_22993 = squot64(write_i_22038, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n            binop_y_22995 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 * new_index_22993;\n            new_index_22996 = write_i_22038 - binop_y_22995;\n            write_index_21087 = ((__global int64_t *) ext_mem_23748)[new_index_22993 + new_index_22996 * m_20948];\n            index_concat_cmp_23006 = sle64(arg_15490, new_index_22996);\n            if (index_concat_cmp_23006) {\n                index_concat_branch_23010 = arg_15490;\n            } else {\n                int64_t new_index_23107;\n                int64_t binop_y_23109;\n                int64_t new_index_23110;\n                int64_t index_concat_23009;\n                \n                new_index_23107 = squot64(new_index_22996, (int64_t) 2);\n                binop_y_23109 = (int64_t) 2 * new_index_23107;\n                new_index_23110 = new_index_22996 - binop_y_23109;\n                index_concat_23009 = ((__global int64_t *) mem_23651)[new_index_23107 + new_index_23110 * num_qubits_15486];\n                index_concat_branch_23010 = index_concat_23009;\n            }\n            write_value_21089 = ((__global int8_t *) ext_mem_23747)[new_index_22993 * ext_23746 + new_index_22996 * ext_23745];\n            if ((sle64((int64_t) 0, write_index_21087) && slt64(write_index_21087, dzl",
                                    "z7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) && (sle64((int64_t) 0, index_concat_branch_23010) && slt64(index_concat_branch_23010, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491))) {\n                ((__global int8_t *) mem_23405)[write_index_21087 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + index_concat_branch_23010] = write_value_21089;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22042\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22065_dim1, 1, 1)\nvoid simulate_8477zisegmap_22065(__global int *global_failure, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, __global unsigned char *mem_23405, __global unsigned char *mem_23652, __global unsigned char *mem_23751)\n{\n    #define segmap_tblock_sizze_22061 (simulate_8477zisegmap_22065zisegmap_tblock_sizze_22061)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24441;\n    int32_t tblock_sizze_24444;\n    int32_t wave_sizze_24443;\n    int32_t block_id_24442;\n    int32_t global_tid_24440;\n    int64_t phys_tid_22065;\n    int64_t global_tid_24445;\n    int64_t slice_24446;\n    int64_t gtid_22064;\n    int64_t remnant_24447;\n    \n    local_tid_24441 = get_local_id(0);\n    tblock_sizze_24444 = get_local_size(0);\n    wave_sizze_24443 = LOCKSTEP_WIDTH;\n    block_id_24442 = get_tblock_id(0);\n    global_tid_24440 = block_id_24442 * tblock_sizze_24444 + local_tid_24441;\n    phys_tid_22065 = sext_i32_i64(global_tid_24440);\n    global_tid_24445 = sext_i32_i64(block_id_24442) * segmap_tblock_sizze_22061 + sext_i32_i64(local_tid_24441);\n    slice_24446 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n    gtid_22064 = global_tid_24445;\n    remnant_24447 = global_tid_24445 - gtid_22064;\n    if (slt64(gtid_22064, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) {\n        int64_t defunc_0_f_res_23210", ";\n        int8_t lifted_lambda_res_22071;\n        \n        defunc_0_f_res_23210 = ((__global int64_t *) mem_23652)[(int64_t) 0];\n        lifted_lambda_res_22071 = ((__global int8_t *) mem_23405)[defunc_0_f_res_23210 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + gtid_22064];\n        ((__global int8_t *) mem_23751)[gtid_22064] = lifted_lambda_res_22071;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22061\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22073_dim1, 1, 1)\nvoid simulate_8477zisegmap_22073(__global int *global_failure, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t num_tblocks_22078, int32_t virt_num_tblocks_24448, __global unsigned char *mem_23405, __global unsigned char *mem_23656, __global unsigned char *mem_23751)\n{\n    #define segmap_tblock_sizze_22076 (simulate_8477zisegmap_22073zisegmap_tblock_sizze_22076)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24450;\n    int32_t tblock_sizze_24453;\n    int32_t wave_sizze_24452;\n    int32_t block_id_24451;\n    int32_t global_tid_24449;\n    int64_t phys_tid_22073;\n    int32_t phys_tblock_id_24454;\n    int32_t iterations_24455;\n    \n    local_tid_24450 = get_local_id(0);\n    tblock_sizze_24453 = get_local_size(0);\n    wave_sizze_24452 = LOCKSTEP_WIDTH;\n    block_id_24451 = get_tblock_id(0);\n    global_tid_24449 = block_id_24451 * tblock_sizze_24453 + local_tid_24450;\n    phys_tid_22073 = sext_i32_i64(global_tid_24449);\n    phys_tblock_id_24454 = get_tblock_id(0);\n    iterations_24455 = sdiv_up32(virt_num_tblocks_24448 - phys_tblock_id_24454, sext_i64_i32(num_tblocks_22078));\n    for (int32_t i_24456 = 0; i_24456 < iterations_24455; i_24456++) {\n        int32_t virt_tblock_id_24457;\n        int64_t global_tid_24458;\n        int64_t slice_24459;\n        int64_t write_i_22072;\n        int64_t remnant_24460;\n        \n        virt_tblock_id_24457 = phys_tblock_id_24454 + i_24456 * sext_i64_i32(num_tblocks_22078);\n     ", "   global_tid_24458 = sext_i32_i64(virt_tblock_id_24457) * segmap_tblock_sizze_22076 + sext_i32_i64(local_tid_24450);\n        slice_24459 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n        write_i_22072 = global_tid_24458;\n        remnant_24460 = global_tid_24458 - write_i_22072;\n        if (slt64(write_i_22072, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) {\n            int64_t tmp_23211;\n            int8_t write_value_21109;\n            \n            tmp_23211 = ((__global int64_t *) mem_23656)[(int64_t) 0];\n            write_value_21109 = ((__global int8_t *) mem_23751)[write_i_22072];\n            if ((sle64((int64_t) 0, tmp_23211) && slt64(tmp_23211, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) && (sle64((int64_t) 0, write_i_22072) && slt64(write_i_22072, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491))) {\n                ((__global int8_t *) mem_23405)[tmp_23211 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + write_i_22072] = write_value_21109;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22076\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22081_dim1, 1, 1)\nvoid simulate_8477zisegmap_22081(__global int *global_failure, int64_t num_qubits_15486, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int8_t u64_res_21127, int64_t num_tblocks_22086, int32_t virt_num_tblocks_24461, __global unsigned char *mem_23405, __global unsigned char *mem_23652, __global unsigned char *mem_23657)\n{\n    #define segmap_tblock_sizze_22084 (simulate_8477zisegmap_22081zisegmap_tblock_sizze_22084)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24463;\n    int32_t tblock_sizze_24466;\n    int32_t wave_sizze_24465;\n    int32_t block_id_24464;\n    int32_t global_tid_24462;\n    int64_t phys_tid_22081;\n    int32_t phys_tblock_id_24467;\n    int32",
                                    "_t iterations_24468;\n    \n    local_tid_24463 = get_local_id(0);\n    tblock_sizze_24466 = get_local_size(0);\n    wave_sizze_24465 = LOCKSTEP_WIDTH;\n    block_id_24464 = get_tblock_id(0);\n    global_tid_24462 = block_id_24464 * tblock_sizze_24466 + local_tid_24463;\n    phys_tid_22081 = sext_i32_i64(global_tid_24462);\n    phys_tblock_id_24467 = get_tblock_id(0);\n    iterations_24468 = sdiv_up32(virt_num_tblocks_24461 - phys_tblock_id_24467, sext_i64_i32(num_tblocks_22086));\n    for (int32_t i_24469 = 0; i_24469 < iterations_24468; i_24469++) {\n        int32_t virt_tblock_id_24470;\n        int64_t global_tid_24471;\n        int64_t slice_24472;\n        int64_t write_i_22080;\n        int64_t remnant_24473;\n        \n        virt_tblock_id_24470 = phys_tblock_id_24467 + i_24469 * sext_i64_i32(num_tblocks_22086);\n        global_tid_24471 = sext_i32_i64(virt_tblock_id_24470) * segmap_tblock_sizze_22084 + sext_i32_i64(local_tid_24463);\n        slice_24472 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n        write_i_22080 = global_tid_24471;\n        remnant_24473 = global_tid_24471 - write_i_22080;\n        if (slt64(write_i_22080, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) {\n            int64_t defunc_0_f_res_23215;\n            int64_t zeze_rhs_23216;\n            bool cond_21131;\n            int8_t lifted_lambda_res_21132;\n            \n            defunc_0_f_res_23215 = ((__global int64_t *) mem_23652)[(int64_t) 0];\n            zeze_rhs_23216 = ((__global int64_t *) mem_23657)[(int64_t) 0];\n            cond_21131 = write_i_22080 == zeze_rhs_23216;\n            if (cond_21131) {\n                lifted_lambda_res_21132 = (int8_t) 1;\n            } else {\n                int64_t zeze_rhs_21133;\n                bool cond_21134;\n                int8_t lifted_lambda_res_f_res_21135;\n                \n                zeze_rhs_21133 = mul64((int64_t) 2, num_qubits_15486);\n                cond_21134 = write_i_22080 == zeze_rhs_21133;\n          ", "      if (cond_21134) {\n                    lifted_lambda_res_f_res_21135 = u64_res_21127;\n                } else {\n                    lifted_lambda_res_f_res_21135 = (int8_t) 0;\n                }\n                lifted_lambda_res_21132 = lifted_lambda_res_f_res_21135;\n            }\n            if ((sle64((int64_t) 0, defunc_0_f_res_23215) && slt64(defunc_0_f_res_23215, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) && (sle64((int64_t) 0, write_i_22080) && slt64(write_i_22080, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491))) {\n                ((__global int8_t *) mem_23405)[defunc_0_f_res_23215 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + write_i_22080] = lifted_lambda_res_21132;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22084\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22089_dim1, 1, 1)\nvoid simulate_8477zisegmap_22089(__global int *global_failure, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t num_tblocks_22094, int32_t virt_num_tblocks_24474, __global unsigned char *mem_23405)\n{\n    #define segmap_tblock_sizze_22092 (simulate_8477zisegmap_22089zisegmap_tblock_sizze_22092)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24476;\n    int32_t tblock_sizze_24479;\n    int32_t wave_sizze_24478;\n    int32_t block_id_24477;\n    int32_t global_tid_24475;\n    int64_t phys_tid_22089;\n    int32_t phys_tblock_id_24480;\n    int32_t iterations_24481;\n    \n    local_tid_24476 = get_local_id(0);\n    tblock_sizze_24479 = get_local_size(0);\n    wave_sizze_24478 = LOCKSTEP_WIDTH;\n    block_id_24477 = get_tblock_id(0);\n    global_tid_24475 = block_id_24477 * tblock_sizze_24479 + local_tid_24476;\n    phys_tid_22089 = sext_i32_i64(global_tid_24475);\n    phys_tblock_id_24480 = get_tblock_id(0);\n    iterations_24481 = sdiv_up32(virt_num_tblocks_2", "4474 - phys_tblock_id_24480, sext_i64_i32(num_tblocks_22094));\n    for (int32_t i_24482 = 0; i_24482 < iterations_24481; i_24482++) {\n        int32_t virt_tblock_id_24483;\n        int64_t global_tid_24484;\n        int64_t slice_24485;\n        int64_t write_i_22088;\n        int64_t remnant_24486;\n        \n        virt_tblock_id_24483 = phys_tblock_id_24480 + i_24482 * sext_i64_i32(num_tblocks_22094);\n        global_tid_24484 = sext_i32_i64(virt_tblock_id_24483) * segmap_tblock_sizze_22092 + sext_i32_i64(local_tid_24476);\n        slice_24485 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n        write_i_22088 = global_tid_24484;\n        remnant_24486 = global_tid_24484 - write_i_22088;\n        if (slt64(write_i_22088, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) {\n            if ((sle64((int64_t) 0, arg_15490) && slt64(arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) && (sle64((int64_t) 0, write_i_22088) && slt64(write_i_22088, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491))) {\n                ((__global int8_t *) mem_23405)[arg_15490 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + write_i_22088] = (int8_t) 0;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22092\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22105_dim1, 1, 1)\nvoid simulate_8477zisegmap_22105(__global int *global_failure, int64_t num_qubits_15486, int64_t m_21170, int64_t num_tblocks_22110, int32_t virt_num_tblocks_24589, __global unsigned char *mem_23467, __global unsigned char *mem_23469, __global unsigned char *mem_23471)\n{\n    #define segmap_tblock_sizze_22108 (simulate_8477zisegmap_22105zisegmap_tblock_sizze_22108)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24591;\n    int32_t tblock_sizze_24594;\n    int32_t wave_sizze_24593;\n    int32_t block_id_24592;\n    int32_t",
                                    " global_tid_24590;\n    int64_t phys_tid_22105;\n    int32_t phys_tblock_id_24595;\n    int32_t iterations_24596;\n    \n    local_tid_24591 = get_local_id(0);\n    tblock_sizze_24594 = get_local_size(0);\n    wave_sizze_24593 = LOCKSTEP_WIDTH;\n    block_id_24592 = get_tblock_id(0);\n    global_tid_24590 = block_id_24592 * tblock_sizze_24594 + local_tid_24591;\n    phys_tid_22105 = sext_i32_i64(global_tid_24590);\n    phys_tblock_id_24595 = get_tblock_id(0);\n    iterations_24596 = sdiv_up32(virt_num_tblocks_24589 - phys_tblock_id_24595, sext_i64_i32(num_tblocks_22110));\n    for (int32_t i_24597 = 0; i_24597 < iterations_24596; i_24597++) {\n        int32_t virt_tblock_id_24598;\n        int64_t global_tid_24599;\n        int64_t slice_24600;\n        int64_t write_i_22104;\n        int64_t remnant_24601;\n        \n        virt_tblock_id_24598 = phys_tblock_id_24595 + i_24597 * sext_i64_i32(num_tblocks_22110);\n        global_tid_24599 = sext_i32_i64(virt_tblock_id_24598) * segmap_tblock_sizze_22108 + sext_i32_i64(local_tid_24591);\n        slice_24600 = num_qubits_15486;\n        write_i_22104 = global_tid_24599;\n        remnant_24601 = global_tid_24599 - write_i_22104;\n        if (slt64(write_i_22104, num_qubits_15486)) {\n            int64_t eta_p_21184;\n            bool cond_21187;\n            int64_t lifted_lambda_res_21188;\n            \n            eta_p_21184 = ((__global int64_t *) mem_23469)[write_i_22104];\n            cond_21187 = eta_p_21184 == (int64_t) 1;\n            if (cond_21187) {\n                int64_t eta_p_21185;\n                int64_t lifted_lambda_res_t_res_21189;\n                \n                eta_p_21185 = ((__global int64_t *) mem_23467)[write_i_22104];\n                lifted_lambda_res_t_res_21189 = sub64(eta_p_21185, (int64_t) 1);\n                lifted_lambda_res_21188 = lifted_lambda_res_t_res_21189;\n            } else {\n                lifted_lambda_res_21188 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21188) && sl", "t64(lifted_lambda_res_21188, m_21170)) {\n                ((__global int64_t *) mem_23471)[lifted_lambda_res_21188] = write_i_22104;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22108\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22528_dim1, 1, 1)\nvoid simulate_8477zisegmap_22528(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_21170, int64_t num_tblocks_22522, int32_t virt_num_tblocks_24662, __global unsigned char *mem_23405, __global unsigned char *mem_23471, __global unsigned char *mem_23473, __global unsigned char *mem_23496, __global unsigned char *mem_23512, __global unsigned char *mem_23522, __global unsigned char *mem_23532)\n{\n    #define segmap_tblock_sizze_22521 (simulate_8477zisegmap_22528zisegmap_tblock_sizze_22521)\n    \n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24664;\n    int32_t tblock_sizze_24667;\n    int32_t wave_sizze_24666;\n    int32_t block_id_24665;\n    int32_t global_tid_24663;\n    int64_t phys_tid_22528;\n    int32_t phys_tblock_id_24668;\n    int32_t iterations_24669;\n    \n    local_tid_24664 = get_local_id(0);\n    tblock_sizze_24667 = get_local_size(0);\n    wave_sizze_24666 = LOCKSTEP_WIDTH;\n    block_id_24665 = get_tblock_id(0);\n    global_tid_24663 = block_id_24665 * tblock_sizze_24667 + local_tid_24664;\n    phys_tid_22528 = sext_i32_i64(global_tid_24663);\n    phys_tblock_id_24668 = get_tblock_id(0);\n    iterations_24669 = sdiv_up32(virt_num_tblocks_24662 - phys_tblock_id_24668, sext_i64_i32(num_tblocks_22522));\n    for (int32_t i_24670 = 0; i_24670 < iterat", "ions_24669; i_24670++) {\n        int32_t virt_tblock_id_24671;\n        int64_t global_tid_24672;\n        int64_t slice_24673;\n        int64_t gtid_22527;\n        int64_t remnant_24674;\n        \n        virt_tblock_id_24671 = phys_tblock_id_24668 + i_24670 * sext_i64_i32(num_tblocks_22522);\n        global_tid_24672 = sext_i32_i64(virt_tblock_id_24671) * segmap_tblock_sizze_22521 + sext_i32_i64(local_tid_24664);\n        slice_24673 = m_21170;\n        gtid_22527 = global_tid_24672;\n        remnant_24674 = global_tid_24672 - gtid_22527;\n        if (slt64(gtid_22527, m_21170)) {\n            int64_t eta_p_22529;\n            int64_t idx_22530;\n            bool x_22531;\n            bool y_22532;\n            bool bounds_check_22533;\n            bool index_certs_22534;\n            bool index_certs_22575;\n            int8_t zp_lhs_23226;\n            int8_t defunc_0_f_res_22535;\n            int8_t redout_23131;\n            int8_t zt_rhs_22576;\n            int8_t zp_rhs_22577;\n            int8_t zp_lhs_22578;\n            int8_t zv_lhs_22579;\n            int8_t res_22580;\n            bool cond_22581;\n            bool cond_neg_22582;\n            int8_t phase_contrib_22583;\n            \n            eta_p_22529 = ((__global int64_t *) mem_23471)[gtid_22527];\n            idx_22530 = add64(num_qubits_15486, eta_p_22529);\n            x_22531 = sle64((int64_t) 0, idx_22530);\n            y_22532 = slt64(idx_22530, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n            bounds_check_22533 = x_22531 && y_22532;\n            if (!bounds_check_22533) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 23) == -1) {\n                        global_failure_args[0] = (int64_t) idx_22530;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n          ",
                                    "      }\n            }\n            if (!bounds_check_22533) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 24) == -1) {\n                        global_failure_args[0] = (int64_t) idx_22530;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            zp_lhs_23226 = ((__global int8_t *) mem_23473)[(int64_t) 0];\n            redout_23131 = (int8_t) 0;\n            for (int64_t i_23134 = 0; i_23134 < num_qubits_15486; i_23134++) {\n                int64_t g_arg3_22542;\n                bool x_22543;\n                bool y_22544;\n                bool bounds_check_22545;\n                bool index_certs_22546;\n                bool y_22549;\n                bool index_certs_22551;\n                int8_t g_arg2_22552;\n                int8_t g_arg0_22554;\n                bool cond_22555;\n                bool cond_t_res_22556;\n                bool x_22557;\n                int8_t g_res_22558;\n                int8_t defunc_0_op_res_22540;\n                int8_t redout_tmp_24675;\n                \n                g_arg3_22542 = add64(num_qubits_15486, i_23134);\n                x_22543 = sle64((int64_t) 0, g_arg3_22542);\n                y_22544 = slt64(g_arg3_22542, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                bounds_check_22545 = x_22543 && y_22544;\n                if (!bounds_check_22545) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 25) == -1) {\n                            global_failure_args[0] = (int64_t) g_arg3_22542;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                            ;\n                        }\n                        loca", "l_failure = 1;\n                        goto error_0;\n                    }\n                }\n                y_22549 = slt64(i_23134, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                if (!y_22549) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 26) == -1) {\n                            global_failure_args[0] = (int64_t) i_23134;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                g_arg2_22552 = ((__global int8_t *) mem_23405)[arg_15490 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + i_23134];\n                g_arg0_22554 = ((__global int8_t *) mem_23496)[idx_22530 + i_23134 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491];\n                cond_22555 = g_arg0_22554 == g_arg2_22552;\n                cond_t_res_22556 = g_arg0_22554 == (int8_t) 0;\n                x_22557 = cond_22555 && cond_t_res_22556;\n                if (x_22557) {\n                    g_res_22558 = (int8_t) 0;\n                } else {\n                    int8_t g_arg3_22547;\n                    int8_t g_arg1_22553;\n                    bool cond_t_res_22559;\n                    bool x_22560;\n                    int8_t g_res_f_res_22561;\n                    \n                    g_arg3_22547 = ((__global int8_t *) mem_23405)[arg_15490 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + g_arg3_22542];\n                    g_arg1_22553 = ((__global int8_t *) mem_23496)[idx_22530 + g_arg3_22542 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491];\n                    cond_t_res_22559 = g_arg0_22554 == (int8_t) 1;\n                    x_22560 = cond_22555 && cond_t_res_22559;\n                    if ", "(x_22560) {\n                        int8_t g_res_f_res_t_res_22562 = sub8(g_arg3_22547, g_arg1_22553);\n                        \n                        g_res_f_res_22561 = g_res_f_res_t_res_22562;\n                    } else {\n                        bool cond_t_res_22563;\n                        bool x_22564;\n                        int8_t g_res_f_res_f_res_22565;\n                        \n                        cond_t_res_22563 = g_arg2_22552 == (int8_t) 0;\n                        x_22564 = cond_t_res_22559 && cond_t_res_22563;\n                        if (x_22564) {\n                            int8_t zm_lhs_22566;\n                            int8_t zt_rhs_22567;\n                            int8_t g_res_f_res_f_res_t_res_22568;\n                            \n                            zm_lhs_22566 = mul8((int8_t) 2, g_arg1_22553);\n                            zt_rhs_22567 = sub8(zm_lhs_22566, (int8_t) 1);\n                            g_res_f_res_f_res_t_res_22568 = mul8(g_arg3_22547, zt_rhs_22567);\n                            g_res_f_res_f_res_22565 = g_res_f_res_f_res_t_res_22568;\n                        } else {\n                            bool cond_t_res_22569;\n                            bool x_22570;\n                            int8_t g_res_f_res_f_res_f_res_22571;\n                            \n                            cond_t_res_22569 = g_arg2_22552 == (int8_t) 1;\n                            x_22570 = cond_t_res_22556 && cond_t_res_22569;\n                            if (x_22570) {\n                                int8_t zm_rhs_22572;\n                                int8_t zt_rhs_22573;\n                                int8_t g_res_f_res_f_res_f_res_t_res_22574;\n                                \n                                zm_rhs_22572 = mul8((int8_t) 2, g_arg3_22547);\n                                zt_rhs_22573 = sub8((int8_t) 1, zm_rhs_22572);\n                                g_res_f_res_f_res_f_res_t_res_22574 = mul8(g_arg1_22553, zt_rhs_22573);\n            ",
                                    "                    g_res_f_res_f_res_f_res_22571 = g_res_f_res_f_res_f_res_t_res_22574;\n                            } else {\n                                g_res_f_res_f_res_f_res_22571 = (int8_t) 0;\n                            }\n                            g_res_f_res_f_res_22565 = g_res_f_res_f_res_f_res_22571;\n                        }\n                        g_res_f_res_22561 = g_res_f_res_f_res_22565;\n                    }\n                    g_res_22558 = g_res_f_res_22561;\n                }\n                defunc_0_op_res_22540 = add8(g_res_22558, redout_23131);\n                for (int64_t i_0 = 0; i_0 < (int64_t) 1; i_0++) {\n                    ((__global int8_t *) mem_23532)[gtid_22527 + m_21170 * i_23134 + i_0 * m_21170] = ((__global int8_t *) mem_23496)[idx_22530 + dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 * g_arg3_22542 + i_0 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491];\n                }\n                for (int64_t i_0 = 0; i_0 < (int64_t) 1; i_0++) {\n                    ((__global int8_t *) mem_23522)[gtid_22527 + m_21170 * i_23134 + i_0 * m_21170] = ((__global int8_t *) mem_23496)[idx_22530 + dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 * i_23134 + i_0 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491];\n                }\n                redout_tmp_24675 = defunc_0_op_res_22540;\n                redout_23131 = redout_tmp_24675;\n            }\n            defunc_0_f_res_22535 = redout_23131;\n            zt_rhs_22576 = ((__global int8_t *) mem_23405)[idx_22530 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + arg_15490];\n            zp_rhs_22577 = mul8((int8_t) 2, zt_rhs_22576);\n            zp_lhs_22578 = add8(zp_rhs_22577, zp_lhs_23226);\n            zv_lhs_22579 = add8(defunc_0_f_res_22535, zp_lhs_22578);\n            res_22580 = smod8(zv_lhs_22579, (int8_t) 4);\n            cond_22581 = res_22580 == (int8_t) 0;\n            cond_neg_22582 = !cond_22581;\n    ", "        phase_contrib_22583 = btoi_bool_i8(cond_neg_22582);\n            ((__global int8_t *) mem_23512)[gtid_22527] = phase_contrib_22583;\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22521\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22591_dim1, 1, 1)\nvoid simulate_8477zisegmap_22591(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_21170, __global unsigned char *mem_23471, __global unsigned char *mem_23475, __global unsigned char *mem_23477, __global unsigned char *mem_23486)\n{\n    #define segmap_tblock_sizze_22585 (simulate_8477zisegmap_22591zisegmap_tblock_sizze_22585)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24680;\n    int32_t tblock_sizze_24683;\n    int32_t wave_sizze_24682;\n    int32_t block_id_24681;\n    int32_t global_tid_24679;\n    int64_t phys_tid_22591;\n    int64_t global_tid_24684;\n    int64_t slice_24685;\n    int64_t gtid_22590;\n    int64_t remnant_24686;\n    \n    local_tid_24680 = get_local_id(0);\n    tblock_sizze_24683 = get_local_size(0);\n    wave_sizze_24682 = LOCKSTEP_WIDTH;\n    block_id_24681 = get_tblock_id(0);\n    global_tid_24679 = block_id_24681 * tblock_sizze_24683 + local_tid_24680;\n    phys_tid_22591 = sext_i32_i64(global_tid_24679);\n    global_tid_24684 = sext_i32_i64(block_id_24681) * segmap_tblock_sizze_22585 + sext_i32_i64(local_tid_24680);\n    slice_24685 = m_21170;\n    gtid_22590 = global_tid_24684;\n    remnant_24686 = global_tid_24684 - gtid_22590;\n    if (slt64(gtid_22590, m_21170)) {\n        int64_t eta_p_22592;\n        int64_t idx_22593;\n        bool x_22594;\n        bool y_22595;\n        bool bounds_check_22596;\n        bool in", "dex_certs_22597;\n        \n        eta_p_22592 = ((__global int64_t *) mem_23471)[gtid_22590];\n        idx_22593 = add64(num_qubits_15486, eta_p_22592);\n        x_22594 = sle64((int64_t) 0, idx_22593);\n        y_22595 = slt64(idx_22593, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n        bounds_check_22596 = x_22594 && y_22595;\n        if (!bounds_check_22596) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 27) == -1) {\n                    global_failure_args[0] = (int64_t) idx_22593;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                    ;\n                }\n                return;\n            }\n        }\n        ((__global int64_t *) mem_23477)[gtid_22590] = idx_22593;\n        ((__global bool *) mem_23486)[gtid_22590] = bounds_check_22596;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22585\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22653_dim1, 1, 1)\nvoid simulate_8477zisegmap_22653(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_21170, __global unsigned char *mem_23405, __global unsigned char *mem_23473, __global unsigned char *mem_23477, __global unsigned char *mem_23480, __global unsigned char *mem_23486)\n{\n    #define segmap_tblock_sizze_22649 (simulate_8477zisegmap_22653zisegmap_tblock_sizze_22649)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24761;\n    int32_t tblock_sizze_24764;\n    int32_t wave_sizze_24763;\n    int32_t block_id_24762;\n    int32_t global_tid_24760;\n    int64_t phys_tid_22653;\n    int64_t global_tid_24765;\n    int64_t slice_24766;\n    int64_t gtid_22652;\n    int64_t remnant_24767;\n    \n    local_tid_24761 = get_local_id(0);\n    tblock_sizze_24764 = get_local_size(0);\n    wave_sizze_24763 = LOCKSTEP_WIDTH;\n    b",
                                    "lock_id_24762 = get_tblock_id(0);\n    global_tid_24760 = block_id_24762 * tblock_sizze_24764 + local_tid_24761;\n    phys_tid_22653 = sext_i32_i64(global_tid_24760);\n    global_tid_24765 = sext_i32_i64(block_id_24762) * segmap_tblock_sizze_22649 + sext_i32_i64(local_tid_24761);\n    slice_24766 = m_21170;\n    gtid_22652 = global_tid_24765;\n    remnant_24767 = global_tid_24765 - gtid_22652;\n    if (slt64(gtid_22652, m_21170)) {\n        int64_t idx_22654;\n        bool bounds_check_22655;\n        bool index_certs_22657;\n        int8_t zp_lhs_23227;\n        int8_t defunc_0_f_res_22656;\n        int8_t zt_rhs_22658;\n        int8_t zp_rhs_22659;\n        int8_t zp_lhs_22660;\n        int8_t zv_lhs_22661;\n        int8_t res_22662;\n        bool cond_22663;\n        bool cond_neg_22664;\n        int8_t phase_contrib_22665;\n        \n        idx_22654 = ((__global int64_t *) mem_23477)[gtid_22652];\n        bounds_check_22655 = ((__global bool *) mem_23486)[gtid_22652];\n        if (!bounds_check_22655) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 32) == -1) {\n                    global_failure_args[0] = (int64_t) idx_22654;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                    ;\n                }\n                return;\n            }\n        }\n        zp_lhs_23227 = ((__global int8_t *) mem_23473)[(int64_t) 0];\n        defunc_0_f_res_22656 = ((__global int8_t *) mem_23480)[gtid_22652];\n        zt_rhs_22658 = ((__global int8_t *) mem_23405)[idx_22654 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + arg_15490];\n        zp_rhs_22659 = mul8((int8_t) 2, zt_rhs_22658);\n        zp_lhs_22660 = add8(zp_rhs_22659, zp_lhs_23227);\n        zv_lhs_22661 = add8(defunc_0_f_res_22656, zp_lhs_22660);\n        res_22662 = smod8(zv_lhs_22661, (int8_t) 4);\n        cond_22663 = res_22662 == (int8_t) 0;\n        cond_neg_22664 = !cond_22663;\n        phase_contrib_22665 ", "= btoi_bool_i8(cond_neg_22664);\n        ((__global int8_t *) mem_23486)[gtid_22652] = phase_contrib_22665;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22649\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22706_dim1, 1, 1)\nvoid simulate_8477zisegmap_22706(__global int *global_failure, int64_t num_qubits_15486, int64_t m_21170, int64_t ext_23601, int64_t ext_23602, __global unsigned char *ext_mem_23603, __global unsigned char *mem_23618)\n{\n    #define segmap_tblock_sizze_22702 (simulate_8477zisegmap_22706zisegmap_tblock_sizze_22702)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24812;\n    int32_t tblock_sizze_24815;\n    int32_t wave_sizze_24814;\n    int32_t block_id_24813;\n    int32_t global_tid_24811;\n    int64_t phys_tid_22706;\n    int64_t global_tid_24816;\n    int64_t slice_24817;\n    int64_t gtid_22705;\n    int64_t remnant_24818;\n    \n    local_tid_24812 = get_local_id(0);\n    tblock_sizze_24815 = get_local_size(0);\n    wave_sizze_24814 = LOCKSTEP_WIDTH;\n    block_id_24813 = get_tblock_id(0);\n    global_tid_24811 = block_id_24813 * tblock_sizze_24815 + local_tid_24812;\n    phys_tid_22706 = sext_i32_i64(global_tid_24811);\n    global_tid_24816 = sext_i32_i64(block_id_24813) * segmap_tblock_sizze_22702 + sext_i32_i64(local_tid_24812);\n    slice_24817 = num_qubits_15486;\n    gtid_22705 = global_tid_24816;\n    remnant_24818 = global_tid_24816 - gtid_22705;\n    if (slt64(gtid_22705, num_qubits_15486)) {\n        int8_t defunc_0_reduce_res_22708;\n        int8_t redout_23137 = (int8_t) 0;\n        \n        for (int64_t i_23138 = 0; i_23138 < m_21170; i_23138++) {\n            int8_t x_22712;\n            int8_t defunc_0_op_res_22711;\n            int8_t redout_tmp_24819;\n            \n            x_22712 = ((__global int8_t *) ext_mem_23603)[i_23138 * ext_23602 + gtid_22705 * ext_23601];\n            defunc_0_op_res_22711 = x_22712 ^ redout_23137;\n            redout_tmp_24819 = defunc_0_op_res_22711;\n            redout_23137 = redout", "_tmp_24819;\n        }\n        defunc_0_reduce_res_22708 = redout_23137;\n        ((__global int8_t *) mem_23618)[gtid_22705] = defunc_0_reduce_res_22708;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22702\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22767_dim1, 1, 1)\nvoid simulate_8477zisegmap_22767(__global int *global_failure, int64_t num_qubits_15486, int64_t m_21170, int64_t ext_23601, int64_t ext_23602, __global unsigned char *ext_mem_23600, __global unsigned char *mem_23633)\n{\n    #define segmap_tblock_sizze_22763 (simulate_8477zisegmap_22767zisegmap_tblock_sizze_22763)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24895;\n    int32_t tblock_sizze_24898;\n    int32_t wave_sizze_24897;\n    int32_t block_id_24896;\n    int32_t global_tid_24894;\n    int64_t phys_tid_22767;\n    int64_t global_tid_24899;\n    int64_t slice_24900;\n    int64_t gtid_22766;\n    int64_t remnant_24901;\n    \n    local_tid_24895 = get_local_id(0);\n    tblock_sizze_24898 = get_local_size(0);\n    wave_sizze_24897 = LOCKSTEP_WIDTH;\n    block_id_24896 = get_tblock_id(0);\n    global_tid_24894 = block_id_24896 * tblock_sizze_24898 + local_tid_24895;\n    phys_tid_22767 = sext_i32_i64(global_tid_24894);\n    global_tid_24899 = sext_i32_i64(block_id_24896) * segmap_tblock_sizze_22763 + sext_i32_i64(local_tid_24895);\n    slice_24900 = num_qubits_15486;\n    gtid_22766 = global_tid_24899;\n    remnant_24901 = global_tid_24899 - gtid_22766;\n    if (slt64(gtid_22766, num_qubits_15486)) {\n        int8_t defunc_0_reduce_res_22769;\n        int8_t redout_23139 = (int8_t) 0;\n        \n        for (int64_t i_23140 = 0; i_23140 < m_21170; i_23140++) {\n            int8_t x_22773;\n            int8_t defunc_0_op_res_22772;\n            int8_t redout_tmp_24902;\n            \n            x_22773 = ((__global int8_t *) ext_mem_23600)[i_23140 * ext_23602 + gtid_22766 * ext_23601];\n            defunc_0_op_res_22772 = x_22773 ^ redout_23139;\n            redout_tmp_24902 = defunc_0_o",
                                    "p_res_22772;\n            redout_23139 = redout_tmp_24902;\n        }\n        defunc_0_reduce_res_22769 = redout_23139;\n        ((__global int8_t *) mem_23633)[gtid_22766] = defunc_0_reduce_res_22769;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22763\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22808_dim1, 1, 1)\nvoid simulate_8477zisegmap_22808(__global int *global_failure, int64_t num_qubits_15486, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t conc_tmp_21320, int64_t measurement_count_21335, int64_t num_tblocks_22813, int32_t virt_num_tblocks_24976, __global unsigned char *mem_23405, __global unsigned char *mem_23406, __global unsigned char *ext_mem_23619, __global unsigned char *ext_mem_23634)\n{\n    #define segmap_tblock_sizze_22811 (simulate_8477zisegmap_22808zisegmap_tblock_sizze_22811)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24978;\n    int32_t tblock_sizze_24981;\n    int32_t wave_sizze_24980;\n    int32_t block_id_24979;\n    int32_t global_tid_24977;\n    int64_t phys_tid_22808;\n    int32_t phys_tblock_id_24982;\n    int32_t iterations_24983;\n    \n    local_tid_24978 = get_local_id(0);\n    tblock_sizze_24981 = get_local_size(0);\n    wave_sizze_24980 = LOCKSTEP_WIDTH;\n    block_id_24979 = get_tblock_id(0);\n    global_tid_24977 = block_id_24979 * tblock_sizze_24981 + local_tid_24978;\n    phys_tid_22808 = sext_i32_i64(global_tid_24977);\n    phys_tblock_id_24982 = get_tblock_id(0);\n    iterations_24983 = sdiv_up32(virt_num_tblocks_24976 - phys_tblock_id_24982, sext_i64_i32(num_tblocks_22813));\n    for (int32_t i_24984 = 0; i_24984 < iterations_24983; i_24984++) {\n        int32_t virt_tblock_id_24985;\n        int64_t global_tid_24986;\n        int64_t slice_24987;\n        int64_t write_i_22807;\n        int64_t remnant_24988;\n        \n        virt_tblock_id_24985 = phys_tblock_id_24982 + i_24984 * sext_i64_i32(num_tblocks_22813);\n        global_tid_24986 = sext_i32_i", "64(virt_tblock_id_24985) * segmap_tblock_sizze_22811 + sext_i32_i64(local_tid_24978);\n        slice_24987 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n        write_i_22807 = global_tid_24986;\n        remnant_24988 = global_tid_24986 - write_i_22807;\n        if (slt64(write_i_22807, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) {\n            bool index_concat_cmp_23032;\n            int64_t index_concat_branch_23036;\n            bool index_concat_cmp_23022;\n            int8_t index_concat_branch_23030;\n            \n            index_concat_cmp_23032 = sle64(arg_15490, write_i_22807);\n            if (index_concat_cmp_23032) {\n                index_concat_branch_23036 = arg_15490;\n            } else {\n                index_concat_branch_23036 = write_i_22807;\n            }\n            index_concat_cmp_23022 = sle64(conc_tmp_21320, write_i_22807);\n            if (index_concat_cmp_23022) {\n                int8_t defunc_0_reduce_res_23231 = ((__global int8_t *) mem_23406)[measurement_count_21335];\n                \n                index_concat_branch_23030 = defunc_0_reduce_res_23231;\n            } else {\n                bool index_concat_cmp_23025;\n                int8_t index_concat_branch_23029;\n                \n                index_concat_cmp_23025 = sle64(num_qubits_15486, write_i_22807);\n                if (index_concat_cmp_23025) {\n                    int64_t index_concat_i_23026;\n                    int8_t index_concat_23027;\n                    \n                    index_concat_i_23026 = sub64(write_i_22807, num_qubits_15486);\n                    index_concat_23027 = ((__global int8_t *) ext_mem_23634)[index_concat_i_23026];\n                    index_concat_branch_23029 = index_concat_23027;\n                } else {\n                    int8_t index_concat_23028 = ((__global int8_t *) ext_mem_23619)[write_i_22807];\n                    \n                    index_concat_branch_23029 = index_concat_23028;\n                }\n  ", "              index_concat_branch_23030 = index_concat_branch_23029;\n            }\n            if ((sle64((int64_t) 0, arg_15490) && slt64(arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) && (sle64((int64_t) 0, index_concat_branch_23036) && slt64(index_concat_branch_23036, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491))) {\n                ((__global int8_t *) mem_23405)[arg_15490 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + index_concat_branch_23036] = index_concat_branch_23030;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22811\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22847_dim1, 1, 1)\nvoid simulate_8477zisegmap_22847(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t num_tblocks_22843, int32_t virt_num_tblocks_24997, __global unsigned char *mem_23405, __global unsigned char *mem_23414, __global unsigned char *mem_23446, __global unsigned char *mem_23456)\n{\n    #define segmap_tblock_sizze_22842 (simulate_8477zisegmap_22847zisegmap_tblock_sizze_22842)\n    \n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24999;\n    int32_t tblock_sizze_25002;\n    int32_t wave_sizze_25001;\n    int32_t block_id_25000;\n    int32_t global_tid_24998;\n    int64_t phys_tid_22847;\n    int32_t phys_tblock_id_25003;\n    int32_t iterations_25004;\n    \n    local_tid_24999 = get_local_id(0);\n    tblock_sizze_25002 = get_local_size(0);\n    wave_sizze_25001 = LOCKSTEP_WIDTH;\n    block_id_25000 = get_tblock_id(0);\n    global_tid_24998 = block_id_25000 * tblock_sizze_25002 + lo",
                                    "cal_tid_24999;\n    phys_tid_22847 = sext_i32_i64(global_tid_24998);\n    phys_tblock_id_25003 = get_tblock_id(0);\n    iterations_25004 = sdiv_up32(virt_num_tblocks_24997 - phys_tblock_id_25003, sext_i64_i32(num_tblocks_22843));\n    for (int32_t i_25005 = 0; i_25005 < iterations_25004; i_25005++) {\n        int32_t virt_tblock_id_25006;\n        int64_t global_tid_25007;\n        int64_t slice_25008;\n        int64_t gtid_22846;\n        int64_t remnant_25009;\n        \n        virt_tblock_id_25006 = phys_tblock_id_25003 + i_25005 * sext_i64_i32(num_tblocks_22843);\n        global_tid_25007 = sext_i32_i64(virt_tblock_id_25006) * segmap_tblock_sizze_22842 + sext_i32_i64(local_tid_24999);\n        slice_25008 = arg_15490;\n        gtid_22846 = global_tid_25007;\n        remnant_25009 = global_tid_25007 - gtid_22846;\n        if (slt64(gtid_22846, arg_15490)) {\n            bool y_22850;\n            bool index_certs_22852;\n            int64_t loopres_23270;\n            int64_t tmp_23271;\n            int8_t ri_22853;\n            int8_t xia_22854;\n            int8_t zzia_22855;\n            int8_t zc_rhs_22856;\n            int8_t tmp_22857;\n            int8_t mem_23454[(int64_t) 3];\n            \n            y_22850 = slt64(gtid_22846, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n            if (!y_22850) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 35) == -1) {\n                        global_failure_args[0] = (int64_t) gtid_22846;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            loopres_23270 = ((__global int64_t *) mem_23414)[(int64_t) 0];\n            tmp_23271 = ((__global int64_t *) mem_23446)[(int64_t) 0];\n            ri_22853 = ((__global int8_t *) mem_23405)[gtid_22846 * dzlz7bUZ", "LzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + arg_15490];\n            xia_22854 = ((__global int8_t *) mem_23405)[gtid_22846 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + loopres_23270];\n            zzia_22855 = ((__global int8_t *) mem_23405)[gtid_22846 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + tmp_23271];\n            zc_rhs_22856 = mul8(xia_22854, zzia_22855);\n            tmp_22857 = ri_22853 ^ zc_rhs_22856;\n            mem_23454[(int64_t) 0] = tmp_22857;\n            mem_23454[(int64_t) 1] = zzia_22855;\n            mem_23454[(int64_t) 2] = xia_22854;\n            for (int64_t i_0 = 0; i_0 < (int64_t) 3; i_0++) {\n                ((__global int8_t *) mem_23456)[gtid_22846 * (int64_t) 3 + i_0] = mem_23454[i_0];\n            }\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22842\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22860_dim1, 1, 1)\nvoid simulate_8477zisegmap_22860(__global int *global_failure, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255, int64_t num_tblocks_22865, int32_t virt_num_tblocks_25010, __global unsigned char *mem_23405, __global unsigned char *mem_23447, __global unsigned char *mem_23456)\n{\n    #define segmap_tblock_sizze_22863 (simulate_8477zisegmap_22860zisegmap_tblock_sizze_22863)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_25012;\n    int32_t tblock_sizze_25015;\n    int32_t wave_sizze_25014;\n    int32_t block_id_25013;\n    int32_t global_tid_25011;\n    int64_t phys_tid_22860;\n    int32_t phys_tblock_id_25016;\n    int32_t iterations_25017;\n    \n    local_tid_25012 = get_local_id(0);\n    tblock_sizze_25015 = get_local_size(0);\n    wave_sizze_25014 = LOCKSTEP_WIDTH;\n    blo", "ck_id_25013 = get_tblock_id(0);\n    global_tid_25011 = block_id_25013 * tblock_sizze_25015 + local_tid_25012;\n    phys_tid_22860 = sext_i32_i64(global_tid_25011);\n    phys_tblock_id_25016 = get_tblock_id(0);\n    iterations_25017 = sdiv_up32(virt_num_tblocks_25010 - phys_tblock_id_25016, sext_i64_i32(num_tblocks_22865));\n    for (int32_t i_25018 = 0; i_25018 < iterations_25017; i_25018++) {\n        int32_t virt_tblock_id_25019;\n        int64_t global_tid_25020;\n        int64_t slice_25021;\n        int64_t write_i_22859;\n        int64_t remnant_25022;\n        \n        virt_tblock_id_25019 = phys_tblock_id_25016 + i_25018 * sext_i64_i32(num_tblocks_22865);\n        global_tid_25020 = sext_i32_i64(virt_tblock_id_25019) * segmap_tblock_sizze_22863 + sext_i32_i64(local_tid_25012);\n        slice_25021 = dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255;\n        write_i_22859 = global_tid_25020;\n        remnant_25022 = global_tid_25020 - write_i_22859;\n        if (slt64(write_i_22859, dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255)) {\n            int64_t new_index_23053;\n            int64_t binop_y_23059;\n            int64_t new_index_23060;\n            int64_t write_index_21393;\n            int8_t write_value_21394;\n            \n            new_index_23053 = squot64(write_i_22859, (int64_t) 3);\n            binop_y_23059 = (int64_t) 3 * new_index_23053;\n            new_index_23060 = write_i_22859 - binop_y_23059;\n            write_index_21393 = ((__global int64_t *) mem_23447)[new_index_23060];\n            write_value_21394 = ((__global int8_t *) mem_23456)[new_index_23053 * (int64_t) 3 + new_index_23060];\n            if ((sle64((int64_t) 0, new_index_23053) && slt64(new_index_23053, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) && (sle64((int64_t) 0, write_index_21393) && slt64(write_index_21393, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491))) {\n                ((__global int8_t *) mem_23405)[new_index_23053 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZR",
                                    "z20U1z7dUzg_15491 + write_index_21393] = write_value_21394;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22863\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22900_dim1, 1, 1)\nvoid simulate_8477zisegmap_22900(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t num_tblocks_22896, int32_t virt_num_tblocks_25031, __global unsigned char *mem_23405, __global unsigned char *mem_23414, __global unsigned char *mem_23433, __global unsigned char *mem_23443)\n{\n    #define segmap_tblock_sizze_22895 (simulate_8477zisegmap_22900zisegmap_tblock_sizze_22895)\n    \n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_25033;\n    int32_t tblock_sizze_25036;\n    int32_t wave_sizze_25035;\n    int32_t block_id_25034;\n    int32_t global_tid_25032;\n    int64_t phys_tid_22900;\n    int32_t phys_tblock_id_25037;\n    int32_t iterations_25038;\n    \n    local_tid_25033 = get_local_id(0);\n    tblock_sizze_25036 = get_local_size(0);\n    wave_sizze_25035 = LOCKSTEP_WIDTH;\n    block_id_25034 = get_tblock_id(0);\n    global_tid_25032 = block_id_25034 * tblock_sizze_25036 + local_tid_25033;\n    phys_tid_22900 = sext_i32_i64(global_tid_25032);\n    phys_tblock_id_25037 = get_tblock_id(0);\n    iterations_25038 = sdiv_up32(virt_num_tblocks_25031 - phys_tblock_id_25037, sext_i64_i32(num_tblocks_22896));\n    for (int32_t i_25039 = 0; i_25039 < iterations_25038; i_25039++) {\n        int32_t virt_tblock_id_25040;\n        int64_t global_tid_25041;\n        int64_t slice_25042;\n        int64_t gtid_22899;\n        int64_t remnant_25043;\n        \n        virt_tblock_id_250", "40 = phys_tblock_id_25037 + i_25039 * sext_i64_i32(num_tblocks_22896);\n        global_tid_25041 = sext_i32_i64(virt_tblock_id_25040) * segmap_tblock_sizze_22895 + sext_i32_i64(local_tid_25033);\n        slice_25042 = arg_15490;\n        gtid_22899 = global_tid_25041;\n        remnant_25043 = global_tid_25041 - gtid_22899;\n        if (slt64(gtid_22899, arg_15490)) {\n            bool y_22903;\n            bool index_certs_22905;\n            int64_t loopres_23306;\n            int64_t tmp_23307;\n            int8_t ri_22906;\n            int8_t xia_22907;\n            int8_t zzia_22908;\n            int8_t zc_rhs_22909;\n            int8_t tmp_22910;\n            int8_t tmp_22911;\n            int8_t mem_23441[(int64_t) 2];\n            \n            y_22903 = slt64(gtid_22899, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n            if (!y_22903) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 38) == -1) {\n                        global_failure_args[0] = (int64_t) gtid_22899;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            loopres_23306 = ((__global int64_t *) mem_23414)[(int64_t) 0];\n            tmp_23307 = ((__global int64_t *) mem_23433)[(int64_t) 0];\n            ri_22906 = ((__global int8_t *) mem_23405)[gtid_22899 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + arg_15490];\n            xia_22907 = ((__global int8_t *) mem_23405)[gtid_22899 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + loopres_23306];\n            zzia_22908 = ((__global int8_t *) mem_23405)[gtid_22899 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + tmp_23307];\n            zc_rhs_22909 = mul8(xia_22907, zzia_22908);\n            tmp_22910 = ri_22906 ^ zc_", "rhs_22909;\n            tmp_22911 = xia_22907 ^ zzia_22908;\n            mem_23441[(int64_t) 0] = tmp_22910;\n            mem_23441[(int64_t) 1] = tmp_22911;\n            for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                ((__global int8_t *) mem_23443)[gtid_22899 * (int64_t) 2 + i_0] = mem_23441[i_0];\n            }\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22895\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22914_dim1, 1, 1)\nvoid simulate_8477zisegmap_22914(__global int *global_failure, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t dzlz7bUZLztZRz20Utmpz20U2z7dUzg_16359, int64_t num_tblocks_22919, int32_t virt_num_tblocks_25044, __global unsigned char *mem_23405, __global unsigned char *mem_23434, __global unsigned char *mem_23443)\n{\n    #define segmap_tblock_sizze_22917 (simulate_8477zisegmap_22914zisegmap_tblock_sizze_22917)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_25046;\n    int32_t tblock_sizze_25049;\n    int32_t wave_sizze_25048;\n    int32_t block_id_25047;\n    int32_t global_tid_25045;\n    int64_t phys_tid_22914;\n    int32_t phys_tblock_id_25050;\n    int32_t iterations_25051;\n    \n    local_tid_25046 = get_local_id(0);\n    tblock_sizze_25049 = get_local_size(0);\n    wave_sizze_25048 = LOCKSTEP_WIDTH;\n    block_id_25047 = get_tblock_id(0);\n    global_tid_25045 = block_id_25047 * tblock_sizze_25049 + local_tid_25046;\n    phys_tid_22914 = sext_i32_i64(global_tid_25045);\n    phys_tblock_id_25050 = get_tblock_id(0);\n    iterations_25051 = sdiv_up32(virt_num_tblocks_25044 - phys_tblock_id_25050, sext_i64_i32(num_tblocks_22919));\n    for (int32_t i_25052 = 0; i_25052 < iterations_25051; i_25052++) {\n        int32_t virt_tblock_id_25053;\n        int64_t global_tid_25054;",
                                    "\n        int64_t slice_25055;\n        int64_t write_i_22913;\n        int64_t remnant_25056;\n        \n        virt_tblock_id_25053 = phys_tblock_id_25050 + i_25052 * sext_i64_i32(num_tblocks_22919);\n        global_tid_25054 = sext_i32_i64(virt_tblock_id_25053) * segmap_tblock_sizze_22917 + sext_i32_i64(local_tid_25046);\n        slice_25055 = dzlz7bUZLztZRz20Utmpz20U2z7dUzg_16359;\n        write_i_22913 = global_tid_25054;\n        remnant_25056 = global_tid_25054 - write_i_22913;\n        if (slt64(write_i_22913, dzlz7bUZLztZRz20Utmpz20U2z7dUzg_16359)) {\n            int64_t new_index_23069;\n            int64_t binop_y_23075;\n            int64_t new_index_23076;\n            int64_t write_index_21454;\n            int8_t write_value_21455;\n            \n            new_index_23069 = squot64(write_i_22913, (int64_t) 2);\n            binop_y_23075 = (int64_t) 2 * new_index_23069;\n            new_index_23076 = write_i_22913 - binop_y_23075;\n            write_index_21454 = ((__global int64_t *) mem_23434)[new_index_23076];\n            write_value_21455 = ((__global int8_t *) mem_23443)[new_index_23069 * (int64_t) 2 + new_index_23076];\n            if ((sle64((int64_t) 0, new_index_23069) && slt64(new_index_23069, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) && (sle64((int64_t) 0, write_index_21454) && slt64(write_index_21454, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491))) {\n                ((__global int8_t *) mem_23405)[new_index_23069 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + write_index_21454] = write_value_21455;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22917\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22960_dim1, 1, 1)\nvoid simulate_8477zisegmap_22960(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2", "z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t num_tblocks_22956, int32_t virt_num_tblocks_25065, __global unsigned char *mem_23405, __global unsigned char *mem_23414, __global unsigned char *mem_23416, __global unsigned char *mem_23417, __global unsigned char *mem_23421, __global unsigned char *mem_23430)\n{\n    #define segmap_tblock_sizze_22955 (simulate_8477zisegmap_22960zisegmap_tblock_sizze_22955)\n    \n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_25067;\n    int32_t tblock_sizze_25070;\n    int32_t wave_sizze_25069;\n    int32_t block_id_25068;\n    int32_t global_tid_25066;\n    int64_t phys_tid_22960;\n    int32_t phys_tblock_id_25071;\n    int32_t iterations_25072;\n    \n    local_tid_25067 = get_local_id(0);\n    tblock_sizze_25070 = get_local_size(0);\n    wave_sizze_25069 = LOCKSTEP_WIDTH;\n    block_id_25068 = get_tblock_id(0);\n    global_tid_25066 = block_id_25068 * tblock_sizze_25070 + local_tid_25067;\n    phys_tid_22960 = sext_i32_i64(global_tid_25066);\n    phys_tblock_id_25071 = get_tblock_id(0);\n    iterations_25072 = sdiv_up32(virt_num_tblocks_25065 - phys_tblock_id_25071, sext_i64_i32(num_tblocks_22956));\n    for (int32_t i_25073 = 0; i_25073 < iterations_25072; i_25073++) {\n        int32_t virt_tblock_id_25074;\n        int64_t global_tid_25075;\n        int64_t slice_25076;\n        int64_t gtid_22959;\n        int64_t remnant_25077;\n        \n        virt_tblock_id_25074 = phys_tblock_id_25071 + i_25073 * sext_i64_i32(num_tblocks_22956);\n        global_tid_25075 = sext_i32_i64(virt_tblock_id_25074) * segmap_tblock_sizze_22955 + sext_i32_i64(local_tid_25067);\n        slice_25076 = arg_15490;\n        gtid_22959 = global_tid_25075;\n        remnant_25077 = global_tid_25075 - gtid_22959;\n        if (slt64(gtid_22959, arg_15490)) {\n            bool y_22963;\n   ", "         bool index_certs_22965;\n            int64_t loopres_23376;\n            int64_t loopres_23377;\n            int64_t tmp_23378;\n            int64_t zzib_23379;\n            int8_t zzia_22966;\n            int8_t zzib_22967;\n            int8_t xia_22968;\n            int8_t xib_22969;\n            int8_t ri_22970;\n            int8_t zt_lhs_22971;\n            int8_t zc_lhs_22972;\n            int8_t zt_rhs_22973;\n            int8_t zc_rhs_22974;\n            int8_t tmp_22975;\n            int8_t tmp_22976;\n            int8_t tmp_22977;\n            int8_t mem_23428[(int64_t) 3];\n            \n            y_22963 = slt64(gtid_22959, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n            if (!y_22963) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 43) == -1) {\n                        global_failure_args[0] = (int64_t) gtid_22959;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                        ;\n                    }\n                    local_failure = 1;\n                    goto error_0;\n                }\n            }\n            loopres_23376 = ((__global int64_t *) mem_23414)[(int64_t) 0];\n            loopres_23377 = ((__global int64_t *) mem_23416)[(int64_t) 0];\n            tmp_23378 = ((__global int64_t *) mem_23417)[(int64_t) 0];\n            zzib_23379 = ((__global int64_t *) mem_23421)[(int64_t) 0];\n            zzia_22966 = ((__global int8_t *) mem_23405)[gtid_22959 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + tmp_23378];\n            zzib_22967 = ((__global int8_t *) mem_23405)[gtid_22959 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + zzib_23379];\n            xia_22968 = ((__global int8_t *) mem_23405)[gtid_22959 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + loopres_23376];\n            xib_22969 = ((__global int8_t *) mem_23405)[gtid_22959 * dzlz7bUZLzpZ",
                                    "Rz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + loopres_23377];\n            ri_22970 = ((__global int8_t *) mem_23405)[gtid_22959 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + arg_15490];\n            zt_lhs_22971 = mul8(zzib_22967, xia_22968);\n            zc_lhs_22972 = zzia_22966 ^ xib_22969;\n            zt_rhs_22973 = (int8_t) 1 ^ zc_lhs_22972;\n            zc_rhs_22974 = mul8(zt_lhs_22971, zt_rhs_22973);\n            tmp_22975 = ri_22970 ^ zc_rhs_22974;\n            tmp_22976 = xia_22968 ^ xib_22969;\n            tmp_22977 = zzia_22966 ^ zzib_22967;\n            mem_23428[(int64_t) 0] = tmp_22975;\n            mem_23428[(int64_t) 1] = tmp_22976;\n            mem_23428[(int64_t) 2] = tmp_22977;\n            for (int64_t i_0 = 0; i_0 < (int64_t) 3; i_0++) {\n                ((__global int8_t *) mem_23430)[gtid_22959 * (int64_t) 3 + i_0] = mem_23428[i_0];\n            }\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22955\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegmap_22980_dim1, 1, 1)\nvoid simulate_8477zisegmap_22980(__global int *global_failure, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255, int64_t num_tblocks_22985, int32_t virt_num_tblocks_25078, __global unsigned char *mem_23405, __global unsigned char *mem_23418, __global unsigned char *mem_23430)\n{\n    #define segmap_tblock_sizze_22983 (simulate_8477zisegmap_22980zisegmap_tblock_sizze_22983)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_25080;\n    int32_t tblock_sizze_25083;\n    int32_t wave_sizze_25082;\n    int32_t block_id_25081;\n    int32_t global_tid_25079;\n    int64_t phys_tid_22980;\n    int32_t phys_tblock_id_25084;\n    int32_t iterations_25085;\n    \n    local_tid_25080 =", " get_local_id(0);\n    tblock_sizze_25083 = get_local_size(0);\n    wave_sizze_25082 = LOCKSTEP_WIDTH;\n    block_id_25081 = get_tblock_id(0);\n    global_tid_25079 = block_id_25081 * tblock_sizze_25083 + local_tid_25080;\n    phys_tid_22980 = sext_i32_i64(global_tid_25079);\n    phys_tblock_id_25084 = get_tblock_id(0);\n    iterations_25085 = sdiv_up32(virt_num_tblocks_25078 - phys_tblock_id_25084, sext_i64_i32(num_tblocks_22985));\n    for (int32_t i_25086 = 0; i_25086 < iterations_25085; i_25086++) {\n        int32_t virt_tblock_id_25087;\n        int64_t global_tid_25088;\n        int64_t slice_25089;\n        int64_t write_i_22979;\n        int64_t remnant_25090;\n        \n        virt_tblock_id_25087 = phys_tblock_id_25084 + i_25086 * sext_i64_i32(num_tblocks_22985);\n        global_tid_25088 = sext_i32_i64(virt_tblock_id_25087) * segmap_tblock_sizze_22983 + sext_i32_i64(local_tid_25080);\n        slice_25089 = dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255;\n        write_i_22979 = global_tid_25088;\n        remnant_25090 = global_tid_25088 - write_i_22979;\n        if (slt64(write_i_22979, dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255)) {\n            int64_t new_index_23085;\n            int64_t binop_y_23091;\n            int64_t new_index_23092;\n            int64_t write_index_21533;\n            int8_t write_value_21534;\n            \n            new_index_23085 = squot64(write_i_22979, (int64_t) 3);\n            binop_y_23091 = (int64_t) 3 * new_index_23085;\n            new_index_23092 = write_i_22979 - binop_y_23091;\n            write_index_21533 = ((__global int64_t *) mem_23418)[new_index_23092];\n            write_value_21534 = ((__global int8_t *) mem_23430)[new_index_23085 * (int64_t) 3 + new_index_23092];\n            if ((sle64((int64_t) 0, new_index_23085) && slt64(new_index_23085, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491)) && (sle64((int64_t) 0, write_index_21533) && slt64(write_index_21533, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491))) {\n    ", "            ((__global int8_t *) mem_23405)[new_index_23085 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + write_index_21533] = write_value_21534;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22983\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegred_large_21963_dim1, 1, 1)\nvoid simulate_8477zisegred_large_21963(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_20948, int64_t num_tblocks_21957, int64_t blocks_per_segment_24310, int64_t q_24311, int64_t num_virtblocks_24312, int64_t threads_per_segment_24313, __global unsigned char *mem_23405, __global unsigned char *mem_23652, __global unsigned char *mem_23665, __global unsigned char *mem_23668, __global unsigned char *mem_23675, __global unsigned char *mem_23678, __global unsigned char *segred_tmp_mem_24314, __global unsigned char *counters_mem_24316)\n{\n    #define segred_tblock_sizze_21956 (simulate_8477zisegred_large_21963zisegred_tblock_sizze_21956)\n    #define chunk_sizze_24281 (simulate_8477zisegred_large_21963zichunk_sizze_24281)\n    \n    volatile __local unsigned char *sync_arr_mem_24325_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_24325_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i8_mem_24323_backing_0 = &shared_mem[sync_arr_mem_24325_backing_1_offset];\n    const int64_t red_arr_i8_mem_24323_backing_0_offset = sync_arr_mem_24325_backing_1_offset + (segred_tblock_sizze_21956 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_21956, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_",
                                    "t local_tid_24319;\n    int32_t tblock_sizze_24322;\n    int32_t wave_sizze_24321;\n    int32_t block_id_24320;\n    int32_t global_tid_24318;\n    int64_t phys_tid_21963;\n    __local unsigned char *red_arr_i8_mem_24323;\n    __local unsigned char *sync_arr_mem_24325;\n    int32_t phys_tblock_id_24327;\n    int32_t iterations_24328;\n    \n    local_tid_24319 = get_local_id(0);\n    tblock_sizze_24322 = get_local_size(0);\n    wave_sizze_24321 = LOCKSTEP_WIDTH;\n    block_id_24320 = get_tblock_id(0);\n    global_tid_24318 = block_id_24320 * tblock_sizze_24322 + local_tid_24319;\n    phys_tid_21963 = sext_i32_i64(global_tid_24318);\n    red_arr_i8_mem_24323 = (__local unsigned char *) red_arr_i8_mem_24323_backing_0;\n    sync_arr_mem_24325 = (__local unsigned char *) sync_arr_mem_24325_backing_1;\n    phys_tblock_id_24327 = get_tblock_id(0);\n    iterations_24328 = sdiv_up32(sext_i64_i32(num_virtblocks_24312) - phys_tblock_id_24327, sext_i64_i32(num_tblocks_21957));\n    for (int32_t i_24329 = 0; i_24329 < iterations_24328; i_24329++) {\n        int32_t virt_tblock_id_24330;\n        int64_t flat_segment_id_24331;\n        int64_t global_tid_24332;\n        int64_t slice_24333;\n        int64_t gtid_21961;\n        int64_t remnant_24334;\n        int64_t gtid_21962;\n        int8_t eta_p_block_res_acc_24335;\n        int8_t eta_p_21964;\n        int8_t eta_p_21965;\n        int64_t tblock_id_in_segment_24339;\n        int64_t block_base_offset_24340;\n        int32_t offset_24343;\n        int32_t skip_waves_24344;\n        int8_t eta_p_24336;\n        int8_t eta_p_24337;\n        \n        virt_tblock_id_24330 = phys_tblock_id_24327 + i_24329 * sext_i64_i32(num_tblocks_21957);\n        flat_segment_id_24331 = squot64(sext_i32_i64(virt_tblock_id_24330), blocks_per_segment_24310);\n        global_tid_24332 = srem64(sext_i32_i64(virt_tblock_id_24330) * segred_tblock_sizze_21956 + sext_i32_i64(local_tid_24319), threads_per_segment_24313);\n        slice_24333 = m_20948;\n        gtid_21961 = flat_segment_id_243", "31;\n        remnant_24334 = flat_segment_id_24331 - gtid_21961;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_24335 = (int8_t) 0;\n        }\n        tblock_id_in_segment_24339 = squot64(global_tid_24332, segred_tblock_sizze_21956);\n        block_base_offset_24340 = tblock_id_in_segment_24339 * q_24311 * segred_tblock_sizze_21956;\n        for (int64_t i_24341 = 0; i_24341 < q_24311; i_24341++) {\n            int64_t block_offset_24342 = block_base_offset_24340 + i_24341 * segred_tblock_sizze_21956;\n            \n            gtid_21962 = global_tid_24332 + threads_per_segment_24313 * i_24341;\n            if (slt64(gtid_21962, num_qubits_15486)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        bool index_certs_21968 = 0;\n                        int64_t g_arg3_21970 = add64(num_qubits_15486, gtid_21962);\n                        bool x_21971 = sle64((int64_t) 0, g_arg3_21970);\n                        bool y_21972 = slt64(g_arg3_21970, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                        bool bounds_check_21973 = x_21971 && y_21972;\n                        bool index_certs_21974;\n                        \n                        if (!bounds_check_21973) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 15) == -1) {\n                                    global_failure_args[0] = (int64_t) g_arg3_21970;\n                                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        bool y_21977 = slt64(", "gtid_21962, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                        bool index_certs_21979;\n                        \n                        if (!y_21977) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 16) == -1) {\n                                    global_failure_args[0] = (int64_t) gtid_21962;\n                                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        int64_t defunc_0_f_res_23205 = ((__global int64_t *) mem_23652)[(int64_t) 0];\n                        int64_t eta_p_21967 = ((__global int64_t *) mem_23665)[gtid_21961];\n                        int8_t g_arg3_21975 = ((__global int8_t *) mem_23405)[eta_p_21967 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + g_arg3_21970];\n                        int8_t g_arg2_21980 = ((__global int8_t *) mem_23405)[eta_p_21967 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + gtid_21962];\n                        int8_t g_arg1_21981 = ((__global int8_t *) mem_23405)[defunc_0_f_res_23205 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + g_arg3_21970];\n                        int8_t g_arg0_21982 = ((__global int8_t *) mem_23405)[defunc_0_f_res_23205 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + gtid_21962];\n                        bool cond_21983 = g_arg0_21982 == g_arg2_21980;\n                        bool cond_t_res_21984 = g_arg0_21982 == (int8_t) 0;\n                        bool x_21985 = cond_21983 && cond_t_res_21984;\n                        int8_t g_res_21986;\n                        \n                        if ",
                                    "(x_21985) {\n                            g_res_21986 = (int8_t) 0;\n                        } else {\n                            bool cond_t_res_21987 = g_arg0_21982 == (int8_t) 1;\n                            bool x_21988 = cond_21983 && cond_t_res_21987;\n                            int8_t g_res_f_res_21989;\n                            \n                            if (x_21988) {\n                                int8_t g_res_f_res_t_res_21990 = sub8(g_arg3_21975, g_arg1_21981);\n                                \n                                g_res_f_res_21989 = g_res_f_res_t_res_21990;\n                            } else {\n                                bool cond_t_res_21991 = g_arg2_21980 == (int8_t) 0;\n                                bool x_21992 = cond_t_res_21987 && cond_t_res_21991;\n                                int8_t g_res_f_res_f_res_21993;\n                                \n                                if (x_21992) {\n                                    int8_t zm_lhs_21994 = mul8((int8_t) 2, g_arg1_21981);\n                                    int8_t zt_rhs_21995 = sub8(zm_lhs_21994, (int8_t) 1);\n                                    int8_t g_res_f_res_f_res_t_res_21996 = mul8(g_arg3_21975, zt_rhs_21995);\n                                    \n                                    g_res_f_res_f_res_21993 = g_res_f_res_f_res_t_res_21996;\n                                } else {\n                                    bool cond_t_res_21997 = g_arg2_21980 == (int8_t) 1;\n                                    bool x_21998 = cond_t_res_21984 && cond_t_res_21997;\n                                    int8_t g_res_f_res_f_res_f_res_21999;\n                                    \n                                    if (x_21998) {\n                                        int8_t zm_rhs_22000 = mul8((int8_t) 2, g_arg3_21975);\n                                        int8_t zt_rhs_22001 = sub8((int8_t) 1, zm_rhs_22000);\n                                        int8_t g_res_f_res_f_res_f_res_t_r", "es_22002 = mul8(g_arg1_21981, zt_rhs_22001);\n                                        \n                                        g_res_f_res_f_res_f_res_21999 = g_res_f_res_f_res_f_res_t_res_22002;\n                                    } else {\n                                        g_res_f_res_f_res_f_res_21999 = (int8_t) 0;\n                                    }\n                                    g_res_f_res_f_res_21993 = g_res_f_res_f_res_f_res_21999;\n                                }\n                                g_res_f_res_21989 = g_res_f_res_f_res_21993;\n                            }\n                            g_res_21986 = g_res_f_res_21989;\n                        }\n                        \n                        int8_t tmp_22003 = g_arg2_21980 ^ g_arg0_21982;\n                        int8_t tmp_22004 = g_arg3_21975 ^ g_arg1_21981;\n                        int8_t mem_23674[(int64_t) 2];\n                        \n                        mem_23674[(int64_t) 0] = tmp_22003;\n                        mem_23674[(int64_t) 1] = tmp_22004;\n                        // write map-out result(s)\n                        {\n                            for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                                ((__global int8_t *) mem_23678)[gtid_21961 * ((int64_t) 2 * num_qubits_15486) + gtid_21962 * (int64_t) 2 + i_0] = mem_23674[i_0];\n                            }\n                        }\n                        // load accumulator(s)\n                        {\n                            eta_p_21964 = eta_p_block_res_acc_24335;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_21965 = g_res_21986;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            int8_t defunc_0_op_res_21966 = add8(eta_p_21964, eta_p_21965);\n                            \n                            // store in accumulator(s", ")\n                            {\n                                eta_p_block_res_acc_24335 = defunc_0_op_res_21966;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int8_t *) red_arr_i8_mem_24323)[sext_i32_i64(local_tid_24319)] = eta_p_block_res_acc_24335;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_24344 = 1;\n        offset_24343 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_24319, sext_i64_i32(segred_tblock_sizze_21956))) {\n                eta_p_24336 = ((__local int8_t *) red_arr_i8_mem_24323)[sext_i32_i64(local_tid_24319 + offset_24343)];\n            }\n        }\n        offset_24343 = 1;\n        while (slt32(offset_24343, wave_sizze_24321)) {\n            if (slt32(local_tid_24319 + offset_24343, sext_i64_i32(segred_tblock_sizze_21956)) && ((local_tid_24319 - squot32(local_tid_24319, wave_sizze_24321) * wave_sizze_24321) & (2 * offset_24343 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_24337 = ((volatile __local int8_t *) red_arr_i8_mem_24323)[sext_i32_i64(local_tid_24319 + offset_24343)];\n                }\n                // apply reduction operation\n                {\n                    int8_t defunc_0_op_res_24338 = add8(eta_p_24336, eta_p_24337);\n                    \n                    eta_p_24336 = defunc_0_op_res_24338;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int8_t *) red_arr_i8_mem_24323)[sext_i32_i64(local_tid_24319)] = eta_p_24336;\n                }\n            }\n            offset_24343 *= 2;\n        }\n        while (slt32(",
                                    "skip_waves_24344, squot32(sext_i64_i32(segred_tblock_sizze_21956) + wave_sizze_24321 - 1, wave_sizze_24321))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_24343 = skip_waves_24344 * wave_sizze_24321;\n            if (slt32(local_tid_24319 + offset_24343, sext_i64_i32(segred_tblock_sizze_21956)) && ((local_tid_24319 - squot32(local_tid_24319, wave_sizze_24321) * wave_sizze_24321) == 0 && (squot32(local_tid_24319, wave_sizze_24321) & (2 * skip_waves_24344 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_24337 = ((__local int8_t *) red_arr_i8_mem_24323)[sext_i32_i64(local_tid_24319 + offset_24343)];\n                }\n                // apply reduction operation\n                {\n                    int8_t defunc_0_op_res_24338 = add8(eta_p_24336, eta_p_24337);\n                    \n                    eta_p_24336 = defunc_0_op_res_24338;\n                }\n                // write result of operation\n                {\n                    ((__local int8_t *) red_arr_i8_mem_24323)[sext_i32_i64(local_tid_24319)] = eta_p_24336;\n                }\n            }\n            skip_waves_24344 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_24319) == (int64_t) 0) {\n                eta_p_block_res_acc_24335 = eta_p_24336;\n            } else {\n                eta_p_block_res_acc_24335 = (int8_t) 0;\n            }\n        }\n        if (blocks_per_segment_24310 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_24319 == 0) {\n                    ((__global int8_t *) mem_23675)[gtid_21961] = eta_p_block_res_acc_24335;\n                }\n            }\n        } else {\n            int32_t old_counter_24345;\n            bool is_last_block_24346;\n            \n            // first thread in block save", "s block result to global memory\n            {\n                if (local_tid_24319 == 0) {\n                    ((__global int8_t *) segred_tmp_mem_24314)[sext_i32_i64(virt_tblock_id_24330)] = eta_p_block_res_acc_24335;\n                    mem_fence_global();\n                    old_counter_24345 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24316)[srem64(flat_segment_id_24331, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_24325)[(int64_t) 0] = old_counter_24345 == sext_i64_i32(blocks_per_segment_24310 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_24346 = ((__local bool *) sync_arr_mem_24325)[(int64_t) 0];\n            if (is_last_block_24346) {\n                if (local_tid_24319 == 0) {\n                    old_counter_24345 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24316)[srem64(flat_segment_id_24331, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_24310));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_24347 = sdiv_up64(blocks_per_segment_24310, segred_tblock_sizze_21956);\n                    \n                    eta_p_21964 = (int8_t) 0;\n                    for (int64_t i_24348 = 0; i_24348 < read_per_thread_24347; i_24348++) {\n                        int64_t block_res_id_24349 = sext_i32_i64(local_tid_24319) * read_per_thread_24347 + i_24348;\n                        int64_t index_of_block_res_24350 = flat_segment_id_24331 * blocks_per_segment_24310 + block_res_id_24349;\n                        \n                        if (slt64(block_res_id_24349, blocks_per_segment_24310)) {\n                            eta_p_21965 = ((__global int8_t *) segred_tmp_mem_24314)[index_of_block_res_24350];\n                            \n                            int8_t defunc_0_op_res_21966 = add8(eta_p_21964, eta_p", "_21965);\n                            \n                            eta_p_21964 = defunc_0_op_res_21966;\n                        }\n                    }\n                }\n                ((__local int8_t *) red_arr_i8_mem_24323)[sext_i32_i64(local_tid_24319)] = eta_p_21964;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_24351;\n                    int32_t skip_waves_24352 = 1;\n                    int8_t eta_p_24336;\n                    int8_t eta_p_24337;\n                    \n                    offset_24351 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_24319, sext_i64_i32(segred_tblock_sizze_21956))) {\n                            eta_p_24336 = ((__local int8_t *) red_arr_i8_mem_24323)[sext_i32_i64(local_tid_24319 + offset_24351)];\n                        }\n                    }\n                    offset_24351 = 1;\n                    while (slt32(offset_24351, wave_sizze_24321)) {\n                        if (slt32(local_tid_24319 + offset_24351, sext_i64_i32(segred_tblock_sizze_21956)) && ((local_tid_24319 - squot32(local_tid_24319, wave_sizze_24321) * wave_sizze_24321) & (2 * offset_24351 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_24337 = ((volatile __local int8_t *) red_arr_i8_mem_24323)[sext_i32_i64(local_tid_24319 + offset_24351)];\n                            }\n                            // apply reduction operation\n                            {\n                                int8_t defunc_0_op_res_24338 = add8(eta_p_24336, eta_p_24337);\n                                \n                                eta_p_24336 = defunc_0_op_res_24338;\n                            }\n                            // write result of operation\n                            {\n                              ",
                                    "  ((volatile __local int8_t *) red_arr_i8_mem_24323)[sext_i32_i64(local_tid_24319)] = eta_p_24336;\n                            }\n                        }\n                        offset_24351 *= 2;\n                    }\n                    while (slt32(skip_waves_24352, squot32(sext_i64_i32(segred_tblock_sizze_21956) + wave_sizze_24321 - 1, wave_sizze_24321))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_24351 = skip_waves_24352 * wave_sizze_24321;\n                        if (slt32(local_tid_24319 + offset_24351, sext_i64_i32(segred_tblock_sizze_21956)) && ((local_tid_24319 - squot32(local_tid_24319, wave_sizze_24321) * wave_sizze_24321) == 0 && (squot32(local_tid_24319, wave_sizze_24321) & (2 * skip_waves_24352 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_24337 = ((__local int8_t *) red_arr_i8_mem_24323)[sext_i32_i64(local_tid_24319 + offset_24351)];\n                            }\n                            // apply reduction operation\n                            {\n                                int8_t defunc_0_op_res_24338 = add8(eta_p_24336, eta_p_24337);\n                                \n                                eta_p_24336 = defunc_0_op_res_24338;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int8_t *) red_arr_i8_mem_24323)[sext_i32_i64(local_tid_24319)] = eta_p_24336;\n                            }\n                        }\n                        skip_waves_24352 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_24319 == 0) {\n                            ((__global int8_t *) mem_23675)[gtid_21961] = eta_p_24336;\n                        }\n                    }\n       ", "         }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_21956\n    #undef chunk_sizze_24281\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegred_large_22608_dim1, 1, 1)\nvoid simulate_8477zisegred_large_22608(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_21170, int64_t num_tblocks_22601, int64_t blocks_per_segment_24716, int64_t q_24717, int64_t num_virtblocks_24718, int64_t threads_per_segment_24719, __global unsigned char *mem_23405, __global unsigned char *mem_23475, __global unsigned char *mem_23477, __global unsigned char *mem_23480, __global unsigned char *mem_23482, __global unsigned char *mem_23484, __global unsigned char *segred_tmp_mem_24720, __global unsigned char *counters_mem_24722)\n{\n    #define segred_tblock_sizze_22600 (simulate_8477zisegred_large_22608zisegred_tblock_sizze_22600)\n    #define chunk_sizze_24687 (simulate_8477zisegred_large_22608zichunk_sizze_24687)\n    \n    volatile __local unsigned char *sync_arr_mem_24731_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_24731_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i8_mem_24729_backing_0 = &shared_mem[sync_arr_mem_24731_backing_1_offset];\n    const int64_t red_arr_i8_mem_24729_backing_0_offset = sync_arr_mem_24731_backing_1_offset + (segred_tblock_sizze_22600 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22600, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24725;\n    int32_t tblock_sizze_24728;\n    int32_t wave_sizze_24727;\n    int32_t block_id_24726;\n", "    int32_t global_tid_24724;\n    int64_t phys_tid_22608;\n    __local unsigned char *red_arr_i8_mem_24729;\n    __local unsigned char *sync_arr_mem_24731;\n    int32_t phys_tblock_id_24733;\n    int32_t iterations_24734;\n    \n    local_tid_24725 = get_local_id(0);\n    tblock_sizze_24728 = get_local_size(0);\n    wave_sizze_24727 = LOCKSTEP_WIDTH;\n    block_id_24726 = get_tblock_id(0);\n    global_tid_24724 = block_id_24726 * tblock_sizze_24728 + local_tid_24725;\n    phys_tid_22608 = sext_i32_i64(global_tid_24724);\n    red_arr_i8_mem_24729 = (__local unsigned char *) red_arr_i8_mem_24729_backing_0;\n    sync_arr_mem_24731 = (__local unsigned char *) sync_arr_mem_24731_backing_1;\n    phys_tblock_id_24733 = get_tblock_id(0);\n    iterations_24734 = sdiv_up32(sext_i64_i32(num_virtblocks_24718) - phys_tblock_id_24733, sext_i64_i32(num_tblocks_22601));\n    for (int32_t i_24735 = 0; i_24735 < iterations_24734; i_24735++) {\n        int32_t virt_tblock_id_24736;\n        int64_t flat_segment_id_24737;\n        int64_t global_tid_24738;\n        int64_t slice_24739;\n        int64_t gtid_22606;\n        int64_t remnant_24740;\n        int64_t gtid_22607;\n        int8_t eta_p_block_res_acc_24741;\n        int8_t eta_p_22609;\n        int8_t eta_p_22610;\n        int64_t tblock_id_in_segment_24745;\n        int64_t block_base_offset_24746;\n        int32_t offset_24749;\n        int32_t skip_waves_24750;\n        int8_t eta_p_24742;\n        int8_t eta_p_24743;\n        \n        virt_tblock_id_24736 = phys_tblock_id_24733 + i_24735 * sext_i64_i32(num_tblocks_22601);\n        flat_segment_id_24737 = squot64(sext_i32_i64(virt_tblock_id_24736), blocks_per_segment_24716);\n        global_tid_24738 = srem64(sext_i32_i64(virt_tblock_id_24736) * segred_tblock_sizze_22600 + sext_i32_i64(local_tid_24725), threads_per_segment_24719);\n        slice_24739 = m_21170;\n        gtid_22606 = flat_segment_id_24737;\n        remnant_24740 = flat_segment_id_24737 - gtid_22606;\n        // ne-initialise the outer (per-block",
                                    ") accumulator(s)\n        {\n            eta_p_block_res_acc_24741 = (int8_t) 0;\n        }\n        tblock_id_in_segment_24745 = squot64(global_tid_24738, segred_tblock_sizze_22600);\n        block_base_offset_24746 = tblock_id_in_segment_24745 * q_24717 * segred_tblock_sizze_22600;\n        for (int64_t i_24747 = 0; i_24747 < q_24717; i_24747++) {\n            int64_t block_offset_24748 = block_base_offset_24746 + i_24747 * segred_tblock_sizze_22600;\n            \n            gtid_22607 = global_tid_24738 + threads_per_segment_24719 * i_24747;\n            if (slt64(gtid_22607, num_qubits_15486)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        bool index_certs_22613 = 0;\n                        int64_t g_arg3_22615 = add64(num_qubits_15486, gtid_22607);\n                        bool x_22616 = sle64((int64_t) 0, g_arg3_22615);\n                        bool y_22617 = slt64(g_arg3_22615, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                        bool bounds_check_22618 = x_22616 && y_22617;\n                        bool index_certs_22619;\n                        \n                        if (!bounds_check_22618) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 30) == -1) {\n                                    global_failure_args[0] = (int64_t) g_arg3_22615;\n                                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        bool y_22622 = slt64(gtid_22607, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                        bool in", "dex_certs_22624;\n                        \n                        if (!y_22622) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 31) == -1) {\n                                    global_failure_args[0] = (int64_t) gtid_22607;\n                                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        int64_t idx_22612 = ((__global int64_t *) mem_23477)[gtid_22606];\n                        int8_t g_arg2_22625 = ((__global int8_t *) mem_23405)[arg_15490 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + gtid_22607];\n                        int8_t g_arg1_22626 = ((__global int8_t *) mem_23405)[idx_22612 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + g_arg3_22615];\n                        int8_t g_arg0_22627 = ((__global int8_t *) mem_23405)[idx_22612 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + gtid_22607];\n                        bool cond_22628 = g_arg0_22627 == g_arg2_22625;\n                        bool cond_t_res_22629 = g_arg0_22627 == (int8_t) 0;\n                        bool x_22630 = cond_22628 && cond_t_res_22629;\n                        int8_t g_res_22631;\n                        \n                        if (x_22630) {\n                            g_res_22631 = (int8_t) 0;\n                        } else {\n                            int8_t g_arg3_22620 = ((__global int8_t *) mem_23405)[arg_15490 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + g_arg3_22615];\n                            bool cond_t_res_22632 = g_arg0_22627 == (int8_t) 1;\n                            bool x_22633 = cond_22628 &&", " cond_t_res_22632;\n                            int8_t g_res_f_res_22634;\n                            \n                            if (x_22633) {\n                                int8_t g_res_f_res_t_res_22635 = sub8(g_arg3_22620, g_arg1_22626);\n                                \n                                g_res_f_res_22634 = g_res_f_res_t_res_22635;\n                            } else {\n                                bool cond_t_res_22636 = g_arg2_22625 == (int8_t) 0;\n                                bool x_22637 = cond_t_res_22632 && cond_t_res_22636;\n                                int8_t g_res_f_res_f_res_22638;\n                                \n                                if (x_22637) {\n                                    int8_t zm_lhs_22639 = mul8((int8_t) 2, g_arg1_22626);\n                                    int8_t zt_rhs_22640 = sub8(zm_lhs_22639, (int8_t) 1);\n                                    int8_t g_res_f_res_f_res_t_res_22641 = mul8(g_arg3_22620, zt_rhs_22640);\n                                    \n                                    g_res_f_res_f_res_22638 = g_res_f_res_f_res_t_res_22641;\n                                } else {\n                                    bool cond_t_res_22642 = g_arg2_22625 == (int8_t) 1;\n                                    bool x_22643 = cond_t_res_22629 && cond_t_res_22642;\n                                    int8_t g_res_f_res_f_res_f_res_22644;\n                                    \n                                    if (x_22643) {\n                                        int8_t zm_rhs_22645 = mul8((int8_t) 2, g_arg3_22620);\n                                        int8_t zt_rhs_22646 = sub8((int8_t) 1, zm_rhs_22645);\n                                        int8_t g_res_f_res_f_res_f_res_t_res_22647 = mul8(g_arg1_22626, zt_rhs_22646);\n                                        \n                                        g_res_f_res_f_res_f_res_22644 = g_res_f_res_f_res_f_res_t_res_22647;\n                                    } el",
                                    "se {\n                                        g_res_f_res_f_res_f_res_22644 = (int8_t) 0;\n                                    }\n                                    g_res_f_res_f_res_22638 = g_res_f_res_f_res_f_res_22644;\n                                }\n                                g_res_f_res_22634 = g_res_f_res_f_res_22638;\n                            }\n                            g_res_22631 = g_res_f_res_22634;\n                        }\n                        // write map-out result(s)\n                        {\n                            ((__global int8_t *) mem_23482)[gtid_22606 * num_qubits_15486 + gtid_22607] = g_arg1_22626;\n                            ((__global int8_t *) mem_23484)[gtid_22606 * num_qubits_15486 + gtid_22607] = g_arg0_22627;\n                        }\n                        // load accumulator(s)\n                        {\n                            eta_p_22609 = eta_p_block_res_acc_24741;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_22610 = g_res_22631;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            int8_t defunc_0_op_res_22611 = add8(eta_p_22609, eta_p_22610);\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_24741 = defunc_0_op_res_22611;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int8_t *) red_arr_i8_mem_24729)[sext_i32_i64(local_tid_24725)] = eta_p_block_res_acc_24741;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n   ", "     skip_waves_24750 = 1;\n        offset_24749 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_24725, sext_i64_i32(segred_tblock_sizze_22600))) {\n                eta_p_24742 = ((__local int8_t *) red_arr_i8_mem_24729)[sext_i32_i64(local_tid_24725 + offset_24749)];\n            }\n        }\n        offset_24749 = 1;\n        while (slt32(offset_24749, wave_sizze_24727)) {\n            if (slt32(local_tid_24725 + offset_24749, sext_i64_i32(segred_tblock_sizze_22600)) && ((local_tid_24725 - squot32(local_tid_24725, wave_sizze_24727) * wave_sizze_24727) & (2 * offset_24749 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_24743 = ((volatile __local int8_t *) red_arr_i8_mem_24729)[sext_i32_i64(local_tid_24725 + offset_24749)];\n                }\n                // apply reduction operation\n                {\n                    int8_t defunc_0_op_res_24744 = add8(eta_p_24742, eta_p_24743);\n                    \n                    eta_p_24742 = defunc_0_op_res_24744;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int8_t *) red_arr_i8_mem_24729)[sext_i32_i64(local_tid_24725)] = eta_p_24742;\n                }\n            }\n            offset_24749 *= 2;\n        }\n        while (slt32(skip_waves_24750, squot32(sext_i64_i32(segred_tblock_sizze_22600) + wave_sizze_24727 - 1, wave_sizze_24727))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_24749 = skip_waves_24750 * wave_sizze_24727;\n            if (slt32(local_tid_24725 + offset_24749, sext_i64_i32(segred_tblock_sizze_22600)) && ((local_tid_24725 - squot32(local_tid_24725, wave_sizze_24727) * wave_sizze_24727) == 0 && (squot32(local_tid_24725, wave_sizze_24727) & (2 * skip_waves_24750 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_24743 = ((__local int8_t *) red_arr_i8_mem_24729)[sext_i32_i64", "(local_tid_24725 + offset_24749)];\n                }\n                // apply reduction operation\n                {\n                    int8_t defunc_0_op_res_24744 = add8(eta_p_24742, eta_p_24743);\n                    \n                    eta_p_24742 = defunc_0_op_res_24744;\n                }\n                // write result of operation\n                {\n                    ((__local int8_t *) red_arr_i8_mem_24729)[sext_i32_i64(local_tid_24725)] = eta_p_24742;\n                }\n            }\n            skip_waves_24750 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_24725) == (int64_t) 0) {\n                eta_p_block_res_acc_24741 = eta_p_24742;\n            } else {\n                eta_p_block_res_acc_24741 = (int8_t) 0;\n            }\n        }\n        if (blocks_per_segment_24716 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_24725 == 0) {\n                    ((__global int8_t *) mem_23480)[gtid_22606] = eta_p_block_res_acc_24741;\n                }\n            }\n        } else {\n            int32_t old_counter_24751;\n            bool is_last_block_24752;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_24725 == 0) {\n                    ((__global int8_t *) segred_tmp_mem_24720)[sext_i32_i64(virt_tblock_id_24736)] = eta_p_block_res_acc_24741;\n                    mem_fence_global();\n                    old_counter_24751 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24722)[srem64(flat_segment_id_24737, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_24731)[(int64_t) 0] = old_counter_24751 == sext_i64_i32(blocks_per_segment_24716 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLO",
                                    "BAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_24752 = ((__local bool *) sync_arr_mem_24731)[(int64_t) 0];\n            if (is_last_block_24752) {\n                if (local_tid_24725 == 0) {\n                    old_counter_24751 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24722)[srem64(flat_segment_id_24737, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_24716));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_24753 = sdiv_up64(blocks_per_segment_24716, segred_tblock_sizze_22600);\n                    \n                    eta_p_22609 = (int8_t) 0;\n                    for (int64_t i_24754 = 0; i_24754 < read_per_thread_24753; i_24754++) {\n                        int64_t block_res_id_24755 = sext_i32_i64(local_tid_24725) * read_per_thread_24753 + i_24754;\n                        int64_t index_of_block_res_24756 = flat_segment_id_24737 * blocks_per_segment_24716 + block_res_id_24755;\n                        \n                        if (slt64(block_res_id_24755, blocks_per_segment_24716)) {\n                            eta_p_22610 = ((__global int8_t *) segred_tmp_mem_24720)[index_of_block_res_24756];\n                            \n                            int8_t defunc_0_op_res_22611 = add8(eta_p_22609, eta_p_22610);\n                            \n                            eta_p_22609 = defunc_0_op_res_22611;\n                        }\n                    }\n                }\n                ((__local int8_t *) red_arr_i8_mem_24729)[sext_i32_i64(local_tid_24725)] = eta_p_22609;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_24757;\n                    int32_t skip_waves_24758 = 1;\n                    int8_t eta_p_24742;\n                    int8_t eta_p_24743;\n                    \n                    offset_24757 = 0;\n                  ", "  // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_24725, sext_i64_i32(segred_tblock_sizze_22600))) {\n                            eta_p_24742 = ((__local int8_t *) red_arr_i8_mem_24729)[sext_i32_i64(local_tid_24725 + offset_24757)];\n                        }\n                    }\n                    offset_24757 = 1;\n                    while (slt32(offset_24757, wave_sizze_24727)) {\n                        if (slt32(local_tid_24725 + offset_24757, sext_i64_i32(segred_tblock_sizze_22600)) && ((local_tid_24725 - squot32(local_tid_24725, wave_sizze_24727) * wave_sizze_24727) & (2 * offset_24757 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_24743 = ((volatile __local int8_t *) red_arr_i8_mem_24729)[sext_i32_i64(local_tid_24725 + offset_24757)];\n                            }\n                            // apply reduction operation\n                            {\n                                int8_t defunc_0_op_res_24744 = add8(eta_p_24742, eta_p_24743);\n                                \n                                eta_p_24742 = defunc_0_op_res_24744;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int8_t *) red_arr_i8_mem_24729)[sext_i32_i64(local_tid_24725)] = eta_p_24742;\n                            }\n                        }\n                        offset_24757 *= 2;\n                    }\n                    while (slt32(skip_waves_24758, squot32(sext_i64_i32(segred_tblock_sizze_22600) + wave_sizze_24727 - 1, wave_sizze_24727))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_24757 = skip_waves_24758 * wave_sizze_24727;\n                        if (slt32(local_tid_24725 + offset_24757, sext_i64_i32(segred_tblock_sizze_22600)) && ((local_tid_24725 - squot32(l", "ocal_tid_24725, wave_sizze_24727) * wave_sizze_24727) == 0 && (squot32(local_tid_24725, wave_sizze_24727) & (2 * skip_waves_24758 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_24743 = ((__local int8_t *) red_arr_i8_mem_24729)[sext_i32_i64(local_tid_24725 + offset_24757)];\n                            }\n                            // apply reduction operation\n                            {\n                                int8_t defunc_0_op_res_24744 = add8(eta_p_24742, eta_p_24743);\n                                \n                                eta_p_24742 = defunc_0_op_res_24744;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int8_t *) red_arr_i8_mem_24729)[sext_i32_i64(local_tid_24725)] = eta_p_24742;\n                            }\n                        }\n                        skip_waves_24758 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_24725 == 0) {\n                            ((__global int8_t *) mem_23480)[gtid_22606] = eta_p_24742;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_22600\n    #undef chunk_sizze_24687\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegred_large_22739_dim1, 1, 1)\nvoid simulate_8477zisegred_large_22739(__global int *global_failure, int64_t num_qubits_15486, int64_t m_21170, int64_t num_tblocks_22734, int64_t blocks_per_segment_24849, int64_t q_24850, int64_t num_virtblocks_24851, int64_t threads_per_segment_24852, __global unsigned char *mem_23614, __global unsigned char *mem_23616, __global unsigned char *segred_tmp_mem_24853",
                                    ", __global unsigned char *counters_mem_24855)\n{\n    #define segred_tblock_sizze_22733 (simulate_8477zisegred_large_22739zisegred_tblock_sizze_22733)\n    #define chunk_sizze_24820 (simulate_8477zisegred_large_22739zichunk_sizze_24820)\n    \n    volatile __local unsigned char *sync_arr_mem_24864_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_24864_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i8_mem_24862_backing_0 = &shared_mem[sync_arr_mem_24864_backing_1_offset];\n    const int64_t red_arr_i8_mem_24862_backing_0_offset = sync_arr_mem_24864_backing_1_offset + (segred_tblock_sizze_22733 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22733, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24858;\n    int32_t tblock_sizze_24861;\n    int32_t wave_sizze_24860;\n    int32_t block_id_24859;\n    int32_t global_tid_24857;\n    int64_t phys_tid_22739;\n    __local unsigned char *red_arr_i8_mem_24862;\n    __local unsigned char *sync_arr_mem_24864;\n    int32_t phys_tblock_id_24866;\n    int32_t iterations_24867;\n    \n    local_tid_24858 = get_local_id(0);\n    tblock_sizze_24861 = get_local_size(0);\n    wave_sizze_24860 = LOCKSTEP_WIDTH;\n    block_id_24859 = get_tblock_id(0);\n    global_tid_24857 = block_id_24859 * tblock_sizze_24861 + local_tid_24858;\n    phys_tid_22739 = sext_i32_i64(global_tid_24857);\n    red_arr_i8_mem_24862 = (__local unsigned char *) red_arr_i8_mem_24862_backing_0;\n    sync_arr_mem_24864 = (__local unsigned char *) sync_arr_mem_24864_backing_1;\n    phys_tblock_id_24866 = get_tblock_id(0);\n    iterations_24867 = sdiv_up32(sext_i64_i32(num_virtblocks_24851) - phys_tblock_id_24866, sext_i64_i32(num_tblocks_22734));\n    for (int32_t i_24868 = 0; i_24868 < iterations_24867; i_24868++) {\n        int32_t virt_tblock_id_24869;\n        int64_t flat_segment_id_24870;\n        int64_t global_tid_24871;\n        int64_t slice_24872;\n        int64_t gtid_22737;\n        int64_t remna", "nt_24873;\n        int64_t gtid_22738;\n        int8_t eta_p_block_res_acc_24874;\n        int8_t eta_p_22740;\n        int8_t eta_p_22741;\n        int64_t tblock_id_in_segment_24878;\n        int64_t block_base_offset_24879;\n        int32_t offset_24882;\n        int32_t skip_waves_24883;\n        int8_t eta_p_24875;\n        int8_t eta_p_24876;\n        \n        virt_tblock_id_24869 = phys_tblock_id_24866 + i_24868 * sext_i64_i32(num_tblocks_22734);\n        flat_segment_id_24870 = squot64(sext_i32_i64(virt_tblock_id_24869), blocks_per_segment_24849);\n        global_tid_24871 = srem64(sext_i32_i64(virt_tblock_id_24869) * segred_tblock_sizze_22733 + sext_i32_i64(local_tid_24858), threads_per_segment_24852);\n        slice_24872 = num_qubits_15486;\n        gtid_22737 = flat_segment_id_24870;\n        remnant_24873 = flat_segment_id_24870 - gtid_22737;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_24874 = (int8_t) 0;\n        }\n        tblock_id_in_segment_24878 = squot64(global_tid_24871, segred_tblock_sizze_22733);\n        block_base_offset_24879 = tblock_id_in_segment_24878 * q_24850 * segred_tblock_sizze_22733;\n        for (int64_t i_24880 = 0; i_24880 < q_24850; i_24880++) {\n            int64_t block_offset_24881 = block_base_offset_24879 + i_24880 * segred_tblock_sizze_22733;\n            \n            gtid_22738 = global_tid_24871 + threads_per_segment_24852 * i_24880;\n            if (slt64(gtid_22738, m_21170)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        int8_t x_22744 = ((__global int8_t *) mem_23614)[gtid_22738 + gtid_22737 * m_21170];\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_22740 = eta_p_block_res_acc_24874;\n                        }\n                        // load next value(s)\n                        {\n                ", "            eta_p_22741 = x_22744;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            int8_t defunc_0_op_res_22742 = eta_p_22740 ^ eta_p_22741;\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_24874 = defunc_0_op_res_22742;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int8_t *) red_arr_i8_mem_24862)[sext_i32_i64(local_tid_24858)] = eta_p_block_res_acc_24874;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_24883 = 1;\n        offset_24882 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_24858, sext_i64_i32(segred_tblock_sizze_22733))) {\n                eta_p_24875 = ((__local int8_t *) red_arr_i8_mem_24862)[sext_i32_i64(local_tid_24858 + offset_24882)];\n            }\n        }\n        offset_24882 = 1;\n        while (slt32(offset_24882, wave_sizze_24860)) {\n            if (slt32(local_tid_24858 + offset_24882, sext_i64_i32(segred_tblock_sizze_22733)) && ((local_tid_24858 - squot32(local_tid_24858, wave_sizze_24860) * wave_sizze_24860) & (2 * offset_24882 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_24876 = ((volatile __local int8_t *) red_arr_i8_mem_24862)[sext_i32_i64(local_tid_24858 + offset_24882)];\n                }\n                // apply reduction operation\n                {\n                    int8_t defunc_0_op_res_24877 = eta_p_24875 ^ eta_p_24876;\n                    \n                    eta_p_24875 = defunc_0_op_res_24877;\n                }\n                // write result of operation\n                {\n               ",
                                    "     ((volatile __local int8_t *) red_arr_i8_mem_24862)[sext_i32_i64(local_tid_24858)] = eta_p_24875;\n                }\n            }\n            offset_24882 *= 2;\n        }\n        while (slt32(skip_waves_24883, squot32(sext_i64_i32(segred_tblock_sizze_22733) + wave_sizze_24860 - 1, wave_sizze_24860))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_24882 = skip_waves_24883 * wave_sizze_24860;\n            if (slt32(local_tid_24858 + offset_24882, sext_i64_i32(segred_tblock_sizze_22733)) && ((local_tid_24858 - squot32(local_tid_24858, wave_sizze_24860) * wave_sizze_24860) == 0 && (squot32(local_tid_24858, wave_sizze_24860) & (2 * skip_waves_24883 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_24876 = ((__local int8_t *) red_arr_i8_mem_24862)[sext_i32_i64(local_tid_24858 + offset_24882)];\n                }\n                // apply reduction operation\n                {\n                    int8_t defunc_0_op_res_24877 = eta_p_24875 ^ eta_p_24876;\n                    \n                    eta_p_24875 = defunc_0_op_res_24877;\n                }\n                // write result of operation\n                {\n                    ((__local int8_t *) red_arr_i8_mem_24862)[sext_i32_i64(local_tid_24858)] = eta_p_24875;\n                }\n            }\n            skip_waves_24883 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_24858) == (int64_t) 0) {\n                eta_p_block_res_acc_24874 = eta_p_24875;\n            } else {\n                eta_p_block_res_acc_24874 = (int8_t) 0;\n            }\n        }\n        if (blocks_per_segment_24849 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_24858 == 0) {\n                    ((__global int8_t *) mem_23616)[gtid_22737] = eta_p_block_res_", "acc_24874;\n                }\n            }\n        } else {\n            int32_t old_counter_24884;\n            bool is_last_block_24885;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_24858 == 0) {\n                    ((__global int8_t *) segred_tmp_mem_24853)[sext_i32_i64(virt_tblock_id_24869)] = eta_p_block_res_acc_24874;\n                    mem_fence_global();\n                    old_counter_24884 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24855)[srem64(flat_segment_id_24870, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_24864)[(int64_t) 0] = old_counter_24884 == sext_i64_i32(blocks_per_segment_24849 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_24885 = ((__local bool *) sync_arr_mem_24864)[(int64_t) 0];\n            if (is_last_block_24885) {\n                if (local_tid_24858 == 0) {\n                    old_counter_24884 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24855)[srem64(flat_segment_id_24870, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_24849));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_24886 = sdiv_up64(blocks_per_segment_24849, segred_tblock_sizze_22733);\n                    \n                    eta_p_22740 = (int8_t) 0;\n                    for (int64_t i_24887 = 0; i_24887 < read_per_thread_24886; i_24887++) {\n                        int64_t block_res_id_24888 = sext_i32_i64(local_tid_24858) * read_per_thread_24886 + i_24887;\n                        int64_t index_of_block_res_24889 = flat_segment_id_24870 * blocks_per_segment_24849 + block_res_id_24888;\n                        \n                        if (slt64(block_res_id_24888, blocks_per_segment_24849)) {\n                            eta_", "p_22741 = ((__global int8_t *) segred_tmp_mem_24853)[index_of_block_res_24889];\n                            \n                            int8_t defunc_0_op_res_22742 = eta_p_22740 ^ eta_p_22741;\n                            \n                            eta_p_22740 = defunc_0_op_res_22742;\n                        }\n                    }\n                }\n                ((__local int8_t *) red_arr_i8_mem_24862)[sext_i32_i64(local_tid_24858)] = eta_p_22740;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_24890;\n                    int32_t skip_waves_24891 = 1;\n                    int8_t eta_p_24875;\n                    int8_t eta_p_24876;\n                    \n                    offset_24890 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_24858, sext_i64_i32(segred_tblock_sizze_22733))) {\n                            eta_p_24875 = ((__local int8_t *) red_arr_i8_mem_24862)[sext_i32_i64(local_tid_24858 + offset_24890)];\n                        }\n                    }\n                    offset_24890 = 1;\n                    while (slt32(offset_24890, wave_sizze_24860)) {\n                        if (slt32(local_tid_24858 + offset_24890, sext_i64_i32(segred_tblock_sizze_22733)) && ((local_tid_24858 - squot32(local_tid_24858, wave_sizze_24860) * wave_sizze_24860) & (2 * offset_24890 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_24876 = ((volatile __local int8_t *) red_arr_i8_mem_24862)[sext_i32_i64(local_tid_24858 + offset_24890)];\n                            }\n                            // apply reduction operation\n                            {\n                                int8_t defunc_0_op_res_24877 = eta_p_24875 ^ eta_p_24876;\n                                \n                                eta",
                                    "_p_24875 = defunc_0_op_res_24877;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int8_t *) red_arr_i8_mem_24862)[sext_i32_i64(local_tid_24858)] = eta_p_24875;\n                            }\n                        }\n                        offset_24890 *= 2;\n                    }\n                    while (slt32(skip_waves_24891, squot32(sext_i64_i32(segred_tblock_sizze_22733) + wave_sizze_24860 - 1, wave_sizze_24860))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_24890 = skip_waves_24891 * wave_sizze_24860;\n                        if (slt32(local_tid_24858 + offset_24890, sext_i64_i32(segred_tblock_sizze_22733)) && ((local_tid_24858 - squot32(local_tid_24858, wave_sizze_24860) * wave_sizze_24860) == 0 && (squot32(local_tid_24858, wave_sizze_24860) & (2 * skip_waves_24891 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_24876 = ((__local int8_t *) red_arr_i8_mem_24862)[sext_i32_i64(local_tid_24858 + offset_24890)];\n                            }\n                            // apply reduction operation\n                            {\n                                int8_t defunc_0_op_res_24877 = eta_p_24875 ^ eta_p_24876;\n                                \n                                eta_p_24875 = defunc_0_op_res_24877;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int8_t *) red_arr_i8_mem_24862)[sext_i32_i64(local_tid_24858)] = eta_p_24875;\n                            }\n                        }\n                        skip_waves_24891 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                  ", "      if (local_tid_24858 == 0) {\n                            ((__global int8_t *) mem_23616)[gtid_22737] = eta_p_24875;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_22733\n    #undef chunk_sizze_24820\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegred_large_22800_dim1, 1, 1)\nvoid simulate_8477zisegred_large_22800(__global int *global_failure, int64_t num_qubits_15486, int64_t m_21170, int64_t num_tblocks_22795, int64_t blocks_per_segment_24932, int64_t q_24933, int64_t num_virtblocks_24934, int64_t threads_per_segment_24935, __global unsigned char *mem_23629, __global unsigned char *mem_23631, __global unsigned char *segred_tmp_mem_24936, __global unsigned char *counters_mem_24938)\n{\n    #define segred_tblock_sizze_22794 (simulate_8477zisegred_large_22800zisegred_tblock_sizze_22794)\n    #define chunk_sizze_24903 (simulate_8477zisegred_large_22800zichunk_sizze_24903)\n    \n    volatile __local unsigned char *sync_arr_mem_24947_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_24947_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i8_mem_24945_backing_0 = &shared_mem[sync_arr_mem_24947_backing_1_offset];\n    const int64_t red_arr_i8_mem_24945_backing_0_offset = sync_arr_mem_24947_backing_1_offset + (segred_tblock_sizze_22794 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22794, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24941;\n    int32_t tblock_sizze_24944;\n    int32_t wave_sizze_24943;\n    int32_t block_id_24942;\n    int32_t global_tid_24940;\n    int64_t phys_tid_22800;\n    __local unsigned char *red_arr_i8_mem_24945;\n    __local unsigned char *sync_arr_mem_24947;\n    int32_t phys_tblock_id_24949;\n    int32_t iterations_24950;\n    \n    local_tid_24941 = get_local_id(0);\n    tblock_sizze_24944 = get_local_size(", "0);\n    wave_sizze_24943 = LOCKSTEP_WIDTH;\n    block_id_24942 = get_tblock_id(0);\n    global_tid_24940 = block_id_24942 * tblock_sizze_24944 + local_tid_24941;\n    phys_tid_22800 = sext_i32_i64(global_tid_24940);\n    red_arr_i8_mem_24945 = (__local unsigned char *) red_arr_i8_mem_24945_backing_0;\n    sync_arr_mem_24947 = (__local unsigned char *) sync_arr_mem_24947_backing_1;\n    phys_tblock_id_24949 = get_tblock_id(0);\n    iterations_24950 = sdiv_up32(sext_i64_i32(num_virtblocks_24934) - phys_tblock_id_24949, sext_i64_i32(num_tblocks_22795));\n    for (int32_t i_24951 = 0; i_24951 < iterations_24950; i_24951++) {\n        int32_t virt_tblock_id_24952;\n        int64_t flat_segment_id_24953;\n        int64_t global_tid_24954;\n        int64_t slice_24955;\n        int64_t gtid_22798;\n        int64_t remnant_24956;\n        int64_t gtid_22799;\n        int8_t eta_p_block_res_acc_24957;\n        int8_t eta_p_22801;\n        int8_t eta_p_22802;\n        int64_t tblock_id_in_segment_24961;\n        int64_t block_base_offset_24962;\n        int32_t offset_24965;\n        int32_t skip_waves_24966;\n        int8_t eta_p_24958;\n        int8_t eta_p_24959;\n        \n        virt_tblock_id_24952 = phys_tblock_id_24949 + i_24951 * sext_i64_i32(num_tblocks_22795);\n        flat_segment_id_24953 = squot64(sext_i32_i64(virt_tblock_id_24952), blocks_per_segment_24932);\n        global_tid_24954 = srem64(sext_i32_i64(virt_tblock_id_24952) * segred_tblock_sizze_22794 + sext_i32_i64(local_tid_24941), threads_per_segment_24935);\n        slice_24955 = num_qubits_15486;\n        gtid_22798 = flat_segment_id_24953;\n        remnant_24956 = flat_segment_id_24953 - gtid_22798;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_24957 = (int8_t) 0;\n        }\n        tblock_id_in_segment_24961 = squot64(global_tid_24954, segred_tblock_sizze_22794);\n        block_base_offset_24962 = tblock_id_in_segment_24961 * q_24933 * segred_tblock_sizze_22794;\n        for (",
                                    "int64_t i_24963 = 0; i_24963 < q_24933; i_24963++) {\n            int64_t block_offset_24964 = block_base_offset_24962 + i_24963 * segred_tblock_sizze_22794;\n            \n            gtid_22799 = global_tid_24954 + threads_per_segment_24935 * i_24963;\n            if (slt64(gtid_22799, m_21170)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        int8_t x_22805 = ((__global int8_t *) mem_23629)[gtid_22799 + gtid_22798 * m_21170];\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_22801 = eta_p_block_res_acc_24957;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_22802 = x_22805;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            int8_t defunc_0_op_res_22803 = eta_p_22801 ^ eta_p_22802;\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_24957 = defunc_0_op_res_22803;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int8_t *) red_arr_i8_mem_24945)[sext_i32_i64(local_tid_24941)] = eta_p_block_res_acc_24957;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_24966 = 1;\n        offset_24965 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_24941, sext_i64_i32(segred_tblock_sizze_22794))) {\n                eta_p_24958 = ((__local int8_t *) red_arr_i8_mem_24945)[sext_i32_i64(local_tid_24941 + offset_24965)];\n            }\n        }\n        ", "offset_24965 = 1;\n        while (slt32(offset_24965, wave_sizze_24943)) {\n            if (slt32(local_tid_24941 + offset_24965, sext_i64_i32(segred_tblock_sizze_22794)) && ((local_tid_24941 - squot32(local_tid_24941, wave_sizze_24943) * wave_sizze_24943) & (2 * offset_24965 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_24959 = ((volatile __local int8_t *) red_arr_i8_mem_24945)[sext_i32_i64(local_tid_24941 + offset_24965)];\n                }\n                // apply reduction operation\n                {\n                    int8_t defunc_0_op_res_24960 = eta_p_24958 ^ eta_p_24959;\n                    \n                    eta_p_24958 = defunc_0_op_res_24960;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int8_t *) red_arr_i8_mem_24945)[sext_i32_i64(local_tid_24941)] = eta_p_24958;\n                }\n            }\n            offset_24965 *= 2;\n        }\n        while (slt32(skip_waves_24966, squot32(sext_i64_i32(segred_tblock_sizze_22794) + wave_sizze_24943 - 1, wave_sizze_24943))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_24965 = skip_waves_24966 * wave_sizze_24943;\n            if (slt32(local_tid_24941 + offset_24965, sext_i64_i32(segred_tblock_sizze_22794)) && ((local_tid_24941 - squot32(local_tid_24941, wave_sizze_24943) * wave_sizze_24943) == 0 && (squot32(local_tid_24941, wave_sizze_24943) & (2 * skip_waves_24966 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_24959 = ((__local int8_t *) red_arr_i8_mem_24945)[sext_i32_i64(local_tid_24941 + offset_24965)];\n                }\n                // apply reduction operation\n                {\n                    int8_t defunc_0_op_res_24960 = eta_p_24958 ^ eta_p_24959;\n                    \n                    eta_p_24958 = defunc_0_op_res_24960;\n                }\n                // write result of operation\n                {\n       ", "             ((__local int8_t *) red_arr_i8_mem_24945)[sext_i32_i64(local_tid_24941)] = eta_p_24958;\n                }\n            }\n            skip_waves_24966 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_24941) == (int64_t) 0) {\n                eta_p_block_res_acc_24957 = eta_p_24958;\n            } else {\n                eta_p_block_res_acc_24957 = (int8_t) 0;\n            }\n        }\n        if (blocks_per_segment_24932 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_24941 == 0) {\n                    ((__global int8_t *) mem_23631)[gtid_22798] = eta_p_block_res_acc_24957;\n                }\n            }\n        } else {\n            int32_t old_counter_24967;\n            bool is_last_block_24968;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_24941 == 0) {\n                    ((__global int8_t *) segred_tmp_mem_24936)[sext_i32_i64(virt_tblock_id_24952)] = eta_p_block_res_acc_24957;\n                    mem_fence_global();\n                    old_counter_24967 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24938)[srem64(flat_segment_id_24953, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_24947)[(int64_t) 0] = old_counter_24967 == sext_i64_i32(blocks_per_segment_24932 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_24968 = ((__local bool *) sync_arr_mem_24947)[(int64_t) 0];\n            if (is_last_block_24968) {\n                if (local_tid_24941 == 0) {\n                    old_counter_24967 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24938)[srem64(flat_segment_id_24953, (int64_t) 20480)],",
                                    " (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_24932));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_24969 = sdiv_up64(blocks_per_segment_24932, segred_tblock_sizze_22794);\n                    \n                    eta_p_22801 = (int8_t) 0;\n                    for (int64_t i_24970 = 0; i_24970 < read_per_thread_24969; i_24970++) {\n                        int64_t block_res_id_24971 = sext_i32_i64(local_tid_24941) * read_per_thread_24969 + i_24970;\n                        int64_t index_of_block_res_24972 = flat_segment_id_24953 * blocks_per_segment_24932 + block_res_id_24971;\n                        \n                        if (slt64(block_res_id_24971, blocks_per_segment_24932)) {\n                            eta_p_22802 = ((__global int8_t *) segred_tmp_mem_24936)[index_of_block_res_24972];\n                            \n                            int8_t defunc_0_op_res_22803 = eta_p_22801 ^ eta_p_22802;\n                            \n                            eta_p_22801 = defunc_0_op_res_22803;\n                        }\n                    }\n                }\n                ((__local int8_t *) red_arr_i8_mem_24945)[sext_i32_i64(local_tid_24941)] = eta_p_22801;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_24973;\n                    int32_t skip_waves_24974 = 1;\n                    int8_t eta_p_24958;\n                    int8_t eta_p_24959;\n                    \n                    offset_24973 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_24941, sext_i64_i32(segred_tblock_sizze_22794))) {\n                            eta_p_24958 = ((__local int8_t *) red_arr_i8_mem_24945)[sext_i32_i64(local_tid_24941 + offset_24973)];\n                        }\n                    }\n                    of", "fset_24973 = 1;\n                    while (slt32(offset_24973, wave_sizze_24943)) {\n                        if (slt32(local_tid_24941 + offset_24973, sext_i64_i32(segred_tblock_sizze_22794)) && ((local_tid_24941 - squot32(local_tid_24941, wave_sizze_24943) * wave_sizze_24943) & (2 * offset_24973 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_24959 = ((volatile __local int8_t *) red_arr_i8_mem_24945)[sext_i32_i64(local_tid_24941 + offset_24973)];\n                            }\n                            // apply reduction operation\n                            {\n                                int8_t defunc_0_op_res_24960 = eta_p_24958 ^ eta_p_24959;\n                                \n                                eta_p_24958 = defunc_0_op_res_24960;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int8_t *) red_arr_i8_mem_24945)[sext_i32_i64(local_tid_24941)] = eta_p_24958;\n                            }\n                        }\n                        offset_24973 *= 2;\n                    }\n                    while (slt32(skip_waves_24974, squot32(sext_i64_i32(segred_tblock_sizze_22794) + wave_sizze_24943 - 1, wave_sizze_24943))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_24973 = skip_waves_24974 * wave_sizze_24943;\n                        if (slt32(local_tid_24941 + offset_24973, sext_i64_i32(segred_tblock_sizze_22794)) && ((local_tid_24941 - squot32(local_tid_24941, wave_sizze_24943) * wave_sizze_24943) == 0 && (squot32(local_tid_24941, wave_sizze_24943) & (2 * skip_waves_24974 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_24959 = ((__local int8_t *) red_arr_i8_mem_24945)[sext_i32_i64(local_tid_24941 + offset_24973)];\n               ", "             }\n                            // apply reduction operation\n                            {\n                                int8_t defunc_0_op_res_24960 = eta_p_24958 ^ eta_p_24959;\n                                \n                                eta_p_24958 = defunc_0_op_res_24960;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int8_t *) red_arr_i8_mem_24945)[sext_i32_i64(local_tid_24941)] = eta_p_24958;\n                            }\n                        }\n                        skip_waves_24974 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_24941 == 0) {\n                            ((__global int8_t *) mem_23631)[gtid_22798] = eta_p_24958;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_22794\n    #undef chunk_sizze_24903\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegred_nonseg_21553_dim1, 1, 1)\nvoid simulate_8477zisegred_nonseg_21553(__global int *global_failure, int64_t n_15484, int64_t num_tblocks_21548, int64_t num_threads_23915, __global unsigned char *gates_mem_23398, __global unsigned char *mem_23402, __global unsigned char *counters_mem_23891, __global unsigned char *segred_tmp_mem_23913)\n{\n    #define segred_tblock_sizze_21546 (simulate_8477zisegred_nonseg_21553zisegred_tblock_sizze_21546)\n    #define chunk_sizze_23890 (simulate_8477zisegred_nonseg_21553zichunk_sizze_23890)\n    \n    volatile __local unsigned char *sync_arr_mem_23923_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_23923_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_23921_backing_0 = &shared_mem[sync_arr_mem_23923",
                                    "_backing_1_offset];\n    const int64_t red_arr_i64_mem_23921_backing_0_offset = sync_arr_mem_23923_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_21546 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_21546, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23917;\n    int32_t tblock_sizze_23920;\n    int32_t wave_sizze_23919;\n    int32_t block_id_23918;\n    int32_t global_tid_23916;\n    int64_t phys_tid_21553;\n    __local unsigned char *red_arr_i64_mem_23921;\n    __local unsigned char *sync_arr_mem_23923;\n    int64_t dummy_21551;\n    int64_t gtid_21552;\n    int64_t q_23925;\n    int64_t eta_p_block_res_acc_23926;\n    int64_t eta_p_16093;\n    int64_t eta_p_16094;\n    int64_t tblock_id_in_segment_23930;\n    int64_t block_base_offset_23931;\n    int32_t offset_23934;\n    int32_t skip_waves_23935;\n    int64_t eta_p_23927;\n    int64_t eta_p_23928;\n    int32_t old_counter_23936;\n    bool is_last_block_23937;\n    \n    local_tid_23917 = get_local_id(0);\n    tblock_sizze_23920 = get_local_size(0);\n    wave_sizze_23919 = LOCKSTEP_WIDTH;\n    block_id_23918 = get_tblock_id(0);\n    global_tid_23916 = block_id_23918 * tblock_sizze_23920 + local_tid_23917;\n    phys_tid_21553 = sext_i32_i64(global_tid_23916);\n    red_arr_i64_mem_23921 = (__local unsigned char *) red_arr_i64_mem_23921_backing_0;\n    sync_arr_mem_23923 = (__local unsigned char *) sync_arr_mem_23923_backing_1;\n    dummy_21551 = (int64_t) 0;\n    gtid_21552 = (int64_t) 0;\n    q_23925 = sdiv_up64(n_15484, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_21546 * num_tblocks_21548)) * chunk_sizze_23890);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        eta_p_block_res_acc_23926 = (int64_t) 0;\n    }\n    tblock_id_in_segment_23930 = squot64(phys_tid_21553, segred_tblock_sizze_21546);\n    block_base_offset_23931 = tblock_id_in_segment_23930 * q_23925 * segred_tblock_sizze_21546;\n    for (int64_t i_23932 = 0; i_23932 < q_23925; i_239", "32++) {\n        int64_t block_offset_23933 = block_base_offset_23931 + i_23932 * segred_tblock_sizze_21546;\n        \n        gtid_21552 = phys_tid_21553 + num_threads_23915 * i_23932;\n        if (slt64(gtid_21552, n_15484)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n                    int64_t eta_p_17643 = ((__global int64_t *) gates_mem_23398)[gtid_21552];\n                    bool cond_17644 = eta_p_17643 == (int64_t) 0;\n                    int64_t lifted_lambda_res_17645 = btoi_bool_i64(cond_17644);\n                    \n                    // load accumulator(s)\n                    {\n                        eta_p_16093 = eta_p_block_res_acc_23926;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_16094 = lifted_lambda_res_17645;\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int64_t defunc_0_op_res_16095 = add64(eta_p_16093, eta_p_16094);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_23926 = defunc_0_op_res_16095;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local int64_t *) red_arr_i64_mem_23921)[sext_i32_i64(local_tid_23917)] = eta_p_block_res_acc_23926;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_23935 = 1;\n    offset_23934 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_23917, sext_i64_i32(segred_tblock_sizze_21546))) {\n            eta_p_23927 = ((__local int64_t *) red_arr_i64_mem_23921)[sext_i32_i64(local_tid_23917 + offset_23934)];\n        }\n    }\n    offset_23934 = 1;\n    while (slt32(offset_23934, wave_sizze_23919)) {\n      ", "  if (slt32(local_tid_23917 + offset_23934, sext_i64_i32(segred_tblock_sizze_21546)) && ((local_tid_23917 - squot32(local_tid_23917, wave_sizze_23919) * wave_sizze_23919) & (2 * offset_23934 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_23928 = ((volatile __local int64_t *) red_arr_i64_mem_23921)[sext_i32_i64(local_tid_23917 + offset_23934)];\n            }\n            // apply reduction operation\n            {\n                int64_t defunc_0_op_res_23929 = add64(eta_p_23927, eta_p_23928);\n                \n                eta_p_23927 = defunc_0_op_res_23929;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_i64_mem_23921)[sext_i32_i64(local_tid_23917)] = eta_p_23927;\n            }\n        }\n        offset_23934 *= 2;\n    }\n    while (slt32(skip_waves_23935, squot32(sext_i64_i32(segred_tblock_sizze_21546) + wave_sizze_23919 - 1, wave_sizze_23919))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_23934 = skip_waves_23935 * wave_sizze_23919;\n        if (slt32(local_tid_23917 + offset_23934, sext_i64_i32(segred_tblock_sizze_21546)) && ((local_tid_23917 - squot32(local_tid_23917, wave_sizze_23919) * wave_sizze_23919) == 0 && (squot32(local_tid_23917, wave_sizze_23919) & (2 * skip_waves_23935 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_23928 = ((__local int64_t *) red_arr_i64_mem_23921)[sext_i32_i64(local_tid_23917 + offset_23934)];\n            }\n            // apply reduction operation\n            {\n                int64_t defunc_0_op_res_23929 = add64(eta_p_23927, eta_p_23928);\n                \n                eta_p_23927 = defunc_0_op_res_23929;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_i64_mem_23921)[sext_i32_i64(local_tid_23917)] = eta_p_23927;\n            }\n        }\n        skip_waves_23935 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n  ",
                                    "  barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_23917) == (int64_t) 0) {\n            eta_p_block_res_acc_23926 = eta_p_23927;\n        } else {\n            eta_p_block_res_acc_23926 = (int64_t) 0;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_23917 == 0) {\n            ((__global int64_t *) segred_tmp_mem_23913)[sext_i32_i64(block_id_23918)] = eta_p_block_res_acc_23926;\n            mem_fence_global();\n            old_counter_23936 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23891)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_23923)[(int64_t) 0] = old_counter_23936 == sext_i64_i32(num_tblocks_21548 - (int64_t) 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_23937 = ((__local bool *) sync_arr_mem_23923)[(int64_t) 0];\n    if (is_last_block_23937) {\n        if (local_tid_23917 == 0) {\n            old_counter_23936 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23891)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_21548));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_23938 = sdiv_up64(num_tblocks_21548, segred_tblock_sizze_21546);\n            \n            eta_p_16093 = (int64_t) 0;\n            for (int64_t i_23939 = 0; i_23939 < read_per_thread_23938; i_23939++) {\n                int64_t block_res_id_23940 = sext_i32_i64(local_tid_23917) * read_per_thread_23938 + i_23939;\n                int64_t index_of_block_res_23941 = block_res_id_23940;\n                \n                if (slt64(block_res_id_23940, num_tblocks_21548)) {\n                    eta_p_16094 = ((__global int64_t *) segred_tmp_mem_23913)[index_of_block_res_23941];\n                    \n                    int64_t defunc_0_op_res_16095 = add64(eta_p_16093, eta_p_16094);\n                    \n       ", "             eta_p_16093 = defunc_0_op_res_16095;\n                }\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_23921)[sext_i32_i64(local_tid_23917)] = eta_p_16093;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_23942;\n            int32_t skip_waves_23943 = 1;\n            int64_t eta_p_23927;\n            int64_t eta_p_23928;\n            \n            offset_23942 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_23917, sext_i64_i32(segred_tblock_sizze_21546))) {\n                    eta_p_23927 = ((__local int64_t *) red_arr_i64_mem_23921)[sext_i32_i64(local_tid_23917 + offset_23942)];\n                }\n            }\n            offset_23942 = 1;\n            while (slt32(offset_23942, wave_sizze_23919)) {\n                if (slt32(local_tid_23917 + offset_23942, sext_i64_i32(segred_tblock_sizze_21546)) && ((local_tid_23917 - squot32(local_tid_23917, wave_sizze_23919) * wave_sizze_23919) & (2 * offset_23942 - 1)) == 0) {\n                    // read array element\n                    {\n                        eta_p_23928 = ((volatile __local int64_t *) red_arr_i64_mem_23921)[sext_i32_i64(local_tid_23917 + offset_23942)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t defunc_0_op_res_23929 = add64(eta_p_23927, eta_p_23928);\n                        \n                        eta_p_23927 = defunc_0_op_res_23929;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local int64_t *) red_arr_i64_mem_23921)[sext_i32_i64(local_tid_23917)] = eta_p_23927;\n                    }\n                }\n                offset_23942 *= 2;\n            }\n            while (slt32(skip_waves_23943, squot32(sext_i64_i32(segred_tblock_sizze_21546) + wave_sizze_23919 - 1, wave_sizze_23919))", ") {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_23942 = skip_waves_23943 * wave_sizze_23919;\n                if (slt32(local_tid_23917 + offset_23942, sext_i64_i32(segred_tblock_sizze_21546)) && ((local_tid_23917 - squot32(local_tid_23917, wave_sizze_23919) * wave_sizze_23919) == 0 && (squot32(local_tid_23917, wave_sizze_23919) & (2 * skip_waves_23943 - 1)) == 0)) {\n                    // read array element\n                    {\n                        eta_p_23928 = ((__local int64_t *) red_arr_i64_mem_23921)[sext_i32_i64(local_tid_23917 + offset_23942)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t defunc_0_op_res_23929 = add64(eta_p_23927, eta_p_23928);\n                        \n                        eta_p_23927 = defunc_0_op_res_23929;\n                    }\n                    // write result of operation\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_23921)[sext_i32_i64(local_tid_23917)] = eta_p_23927;\n                    }\n                }\n                skip_waves_23943 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_23917 == 0) {\n                    ((__global int64_t *) mem_23402)[(int64_t) 0] = eta_p_23927;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_21546\n    #undef chunk_sizze_23890\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegred_nonseg_21653_dim1, 1, 1)\nvoid simulate_8477zisegred_nonseg_21653(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t distance_17135, int64_t num_tblocks_21647, int64_t num_threads_24001, __global unsigned char *mem_23405, __global unsigned char *mem_23414, __global unsig",
                                    "ned char *mem_23461, __global unsigned char *mem_23462, __global unsigned char *counters_mem_23995, __global unsigned char *segred_tmp_mem_23997, __global unsigned char *segred_tmp_mem_23999)\n{\n    #define segred_tblock_sizze_21645 (simulate_8477zisegred_nonseg_21653zisegred_tblock_sizze_21645)\n    #define chunk_sizze_23994 (simulate_8477zisegred_nonseg_21653zichunk_sizze_23994)\n    \n    volatile __local unsigned char *sync_arr_mem_24011_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_24011_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i8_mem_24009_backing_1 = &shared_mem[sync_arr_mem_24011_backing_2_offset];\n    const int64_t red_arr_i8_mem_24009_backing_1_offset = sync_arr_mem_24011_backing_2_offset + (segred_tblock_sizze_21645 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_21645, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i64_mem_24007_backing_0 = &shared_mem[red_arr_i8_mem_24009_backing_1_offset];\n    const int64_t red_arr_i64_mem_24007_backing_0_offset = red_arr_i8_mem_24009_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_21645 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_21645, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24003;\n    int32_t tblock_sizze_24006;\n    int32_t wave_sizze_24005;\n    int32_t block_id_24004;\n    int32_t global_tid_24002;\n    int64_t phys_tid_21653;\n    __local unsigned char *red_arr_i64_mem_24007;\n    __local unsigned char *red_arr_i8_mem_24009;\n    __local unsigned char *sync_arr_mem_24011;\n    int64_t dummy_21651;\n    int64_t gtid_21652;\n    int64_t q_24013;\n    int64_t eta_p_block_res_acc_24014;\n    int8_t eta_p_block_res_acc_24015;\n    int64_t eta_p_20855;\n    int8_t eta_p_20856;\n    int64_t eta_p_208", "57;\n    int8_t eta_p_20858;\n    int64_t tblock_id_in_segment_24032;\n    int64_t block_base_offset_24033;\n    int32_t offset_24036;\n    int32_t skip_waves_24037;\n    int64_t eta_p_24016;\n    int8_t eta_p_24017;\n    int64_t eta_p_24018;\n    int8_t eta_p_24019;\n    int32_t old_counter_24038;\n    bool is_last_block_24039;\n    \n    local_tid_24003 = get_local_id(0);\n    tblock_sizze_24006 = get_local_size(0);\n    wave_sizze_24005 = LOCKSTEP_WIDTH;\n    block_id_24004 = get_tblock_id(0);\n    global_tid_24002 = block_id_24004 * tblock_sizze_24006 + local_tid_24003;\n    phys_tid_21653 = sext_i32_i64(global_tid_24002);\n    red_arr_i64_mem_24007 = (__local unsigned char *) red_arr_i64_mem_24007_backing_0;\n    red_arr_i8_mem_24009 = (__local unsigned char *) red_arr_i8_mem_24009_backing_1;\n    sync_arr_mem_24011 = (__local unsigned char *) sync_arr_mem_24011_backing_2;\n    dummy_21651 = (int64_t) 0;\n    gtid_21652 = (int64_t) 0;\n    q_24013 = sdiv_up64(distance_17135, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_21645 * num_tblocks_21647)) * chunk_sizze_23994);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        eta_p_block_res_acc_24014 = (int64_t) 0;\n        eta_p_block_res_acc_24015 = (int8_t) 0;\n    }\n    tblock_id_in_segment_24032 = squot64(phys_tid_21653, segred_tblock_sizze_21645);\n    block_base_offset_24033 = tblock_id_in_segment_24032 * q_24013 * segred_tblock_sizze_21645;\n    for (int64_t i_24034 = 0; i_24034 < q_24013; i_24034++) {\n        int64_t block_offset_24035 = block_base_offset_24033 + i_24034 * segred_tblock_sizze_21645;\n        \n        gtid_21652 = phys_tid_21653 + num_threads_24001 * i_24034;\n        if (slt64(gtid_21652, distance_17135)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n                    int64_t index_primexp_23052 = add64(num_qubits_15486, gtid_21652);\n                    bool x_20872 = sle64((int64_t) 0, index_primexp_23052);\n                    bool y_2", "0873 = slt64(index_primexp_23052, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                    bool bounds_check_20874 = x_20872 && y_20873;\n                    bool index_certs_20875;\n                    \n                    if (!bounds_check_20874) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                                global_failure_args[0] = (int64_t) index_primexp_23052;\n                                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int64_t loopres_23167 = ((__global int64_t *) mem_23414)[(int64_t) 0];\n                    int8_t tmp_20876 = ((__global int8_t *) mem_23405)[index_primexp_23052 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + loopres_23167];\n                    \n                    // load accumulator(s)\n                    {\n                        eta_p_20855 = eta_p_block_res_acc_24014;\n                        eta_p_20856 = eta_p_block_res_acc_24015;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_20857 = index_primexp_23052;\n                        eta_p_20858 = tmp_20876;\n                    }\n                    // apply reduction operator(s)\n                    {\n                        bool cond_20859 = eta_p_20856 == (int8_t) 1;\n                        bool cond_t_res_20860 = eta_p_20858 == (int8_t) 1;\n                        bool x_20861 = cond_20859 && cond_t_res_20860;\n                        int64_t lifted_lambda_res_20862;\n                        int8_t lifted_lambda_res_20863;\n                        \n                        if (x_20861) {\n ",
                                    "                           bool cond_20864 = sle64(eta_p_20855, eta_p_20857);\n                            int64_t lifted_lambda_res_t_res_20865;\n                            \n                            if (cond_20864) {\n                                lifted_lambda_res_t_res_20865 = eta_p_20855;\n                            } else {\n                                lifted_lambda_res_t_res_20865 = eta_p_20857;\n                            }\n                            \n                            int8_t lifted_lambda_res_t_res_20866;\n                            \n                            if (cond_20864) {\n                                lifted_lambda_res_t_res_20866 = eta_p_20856;\n                            } else {\n                                lifted_lambda_res_t_res_20866 = eta_p_20858;\n                            }\n                            lifted_lambda_res_20862 = lifted_lambda_res_t_res_20865;\n                            lifted_lambda_res_20863 = lifted_lambda_res_t_res_20866;\n                        } else {\n                            int64_t lifted_lambda_res_f_res_20867;\n                            int8_t lifted_lambda_res_f_res_20868;\n                            \n                            if (cond_20859) {\n                                lifted_lambda_res_f_res_20867 = eta_p_20855;\n                                lifted_lambda_res_f_res_20868 = eta_p_20856;\n                            } else {\n                                int64_t lifted_lambda_res_f_res_f_res_20869;\n                                \n                                if (cond_t_res_20860) {\n                                    lifted_lambda_res_f_res_f_res_20869 = eta_p_20857;\n                                } else {\n                                    lifted_lambda_res_f_res_f_res_20869 = (int64_t) 0;\n                                }\n                                \n                                int8_t lifted_lambda_res_f_res_f_res_20870;\n                                \n         ", "                       if (cond_t_res_20860) {\n                                    lifted_lambda_res_f_res_f_res_20870 = eta_p_20858;\n                                } else {\n                                    lifted_lambda_res_f_res_f_res_20870 = (int8_t) 0;\n                                }\n                                lifted_lambda_res_f_res_20867 = lifted_lambda_res_f_res_f_res_20869;\n                                lifted_lambda_res_f_res_20868 = lifted_lambda_res_f_res_f_res_20870;\n                            }\n                            lifted_lambda_res_20862 = lifted_lambda_res_f_res_20867;\n                            lifted_lambda_res_20863 = lifted_lambda_res_f_res_20868;\n                        }\n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_24014 = lifted_lambda_res_20862;\n                            eta_p_block_res_acc_24015 = lifted_lambda_res_20863;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_failure)\n        return;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local int64_t *) red_arr_i64_mem_24007)[sext_i32_i64(local_tid_24003)] = eta_p_block_res_acc_24014;\n        ((__local int8_t *) red_arr_i8_mem_24009)[sext_i32_i64(local_tid_24003)] = eta_p_block_res_acc_24015;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_24037 = 1;\n    offset_24036 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_24003, sext_i64_i32(segred_tblock_sizze_21645))) {\n            eta_p_24016 = ((__local int64_t *) red_arr_i64_mem_24007)[sext_i32_i64(local_tid_24003 + offset_24036)];\n            eta_p_24017 = ((__local int8_t *) red_arr_i8_mem_24009)[sext_i32_i64(local_tid_24003 + offset_24036)];\n        }\n    }\n    offset_24036 = 1;\n    while (slt32(offs", "et_24036, wave_sizze_24005)) {\n        if (slt32(local_tid_24003 + offset_24036, sext_i64_i32(segred_tblock_sizze_21645)) && ((local_tid_24003 - squot32(local_tid_24003, wave_sizze_24005) * wave_sizze_24005) & (2 * offset_24036 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_24018 = ((volatile __local int64_t *) red_arr_i64_mem_24007)[sext_i32_i64(local_tid_24003 + offset_24036)];\n                eta_p_24019 = ((volatile __local int8_t *) red_arr_i8_mem_24009)[sext_i32_i64(local_tid_24003 + offset_24036)];\n            }\n            // apply reduction operation\n            {\n                bool cond_24020 = eta_p_24017 == (int8_t) 1;\n                bool cond_t_res_24021 = eta_p_24019 == (int8_t) 1;\n                bool x_24022 = cond_24020 && cond_t_res_24021;\n                int64_t lifted_lambda_res_24023;\n                int8_t lifted_lambda_res_24024;\n                \n                if (x_24022) {\n                    bool cond_24025 = sle64(eta_p_24016, eta_p_24018);\n                    int64_t lifted_lambda_res_t_res_24026;\n                    \n                    if (cond_24025) {\n                        lifted_lambda_res_t_res_24026 = eta_p_24016;\n                    } else {\n                        lifted_lambda_res_t_res_24026 = eta_p_24018;\n                    }\n                    \n                    int8_t lifted_lambda_res_t_res_24027;\n                    \n                    if (cond_24025) {\n                        lifted_lambda_res_t_res_24027 = eta_p_24017;\n                    } else {\n                        lifted_lambda_res_t_res_24027 = eta_p_24019;\n                    }\n                    lifted_lambda_res_24023 = lifted_lambda_res_t_res_24026;\n                    lifted_lambda_res_24024 = lifted_lambda_res_t_res_24027;\n                } else {\n                    int64_t lifted_lambda_res_f_res_24028;\n                    int8_t lifted_lambda_res_f_res_24029;\n                    \n                    if (c",
                                    "ond_24020) {\n                        lifted_lambda_res_f_res_24028 = eta_p_24016;\n                        lifted_lambda_res_f_res_24029 = eta_p_24017;\n                    } else {\n                        int64_t lifted_lambda_res_f_res_f_res_24030;\n                        \n                        if (cond_t_res_24021) {\n                            lifted_lambda_res_f_res_f_res_24030 = eta_p_24018;\n                        } else {\n                            lifted_lambda_res_f_res_f_res_24030 = (int64_t) 0;\n                        }\n                        \n                        int8_t lifted_lambda_res_f_res_f_res_24031;\n                        \n                        if (cond_t_res_24021) {\n                            lifted_lambda_res_f_res_f_res_24031 = eta_p_24019;\n                        } else {\n                            lifted_lambda_res_f_res_f_res_24031 = (int8_t) 0;\n                        }\n                        lifted_lambda_res_f_res_24028 = lifted_lambda_res_f_res_f_res_24030;\n                        lifted_lambda_res_f_res_24029 = lifted_lambda_res_f_res_f_res_24031;\n                    }\n                    lifted_lambda_res_24023 = lifted_lambda_res_f_res_24028;\n                    lifted_lambda_res_24024 = lifted_lambda_res_f_res_24029;\n                }\n                eta_p_24016 = lifted_lambda_res_24023;\n                eta_p_24017 = lifted_lambda_res_24024;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_i64_mem_24007)[sext_i32_i64(local_tid_24003)] = eta_p_24016;\n                ((volatile __local int8_t *) red_arr_i8_mem_24009)[sext_i32_i64(local_tid_24003)] = eta_p_24017;\n            }\n        }\n        offset_24036 *= 2;\n    }\n    while (slt32(skip_waves_24037, squot32(sext_i64_i32(segred_tblock_sizze_21645) + wave_sizze_24005 - 1, wave_sizze_24005))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_24036 = skip_waves_24037 * wave_sizze_24005;\n        ", "if (slt32(local_tid_24003 + offset_24036, sext_i64_i32(segred_tblock_sizze_21645)) && ((local_tid_24003 - squot32(local_tid_24003, wave_sizze_24005) * wave_sizze_24005) == 0 && (squot32(local_tid_24003, wave_sizze_24005) & (2 * skip_waves_24037 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_24018 = ((__local int64_t *) red_arr_i64_mem_24007)[sext_i32_i64(local_tid_24003 + offset_24036)];\n                eta_p_24019 = ((__local int8_t *) red_arr_i8_mem_24009)[sext_i32_i64(local_tid_24003 + offset_24036)];\n            }\n            // apply reduction operation\n            {\n                bool cond_24020 = eta_p_24017 == (int8_t) 1;\n                bool cond_t_res_24021 = eta_p_24019 == (int8_t) 1;\n                bool x_24022 = cond_24020 && cond_t_res_24021;\n                int64_t lifted_lambda_res_24023;\n                int8_t lifted_lambda_res_24024;\n                \n                if (x_24022) {\n                    bool cond_24025 = sle64(eta_p_24016, eta_p_24018);\n                    int64_t lifted_lambda_res_t_res_24026;\n                    \n                    if (cond_24025) {\n                        lifted_lambda_res_t_res_24026 = eta_p_24016;\n                    } else {\n                        lifted_lambda_res_t_res_24026 = eta_p_24018;\n                    }\n                    \n                    int8_t lifted_lambda_res_t_res_24027;\n                    \n                    if (cond_24025) {\n                        lifted_lambda_res_t_res_24027 = eta_p_24017;\n                    } else {\n                        lifted_lambda_res_t_res_24027 = eta_p_24019;\n                    }\n                    lifted_lambda_res_24023 = lifted_lambda_res_t_res_24026;\n                    lifted_lambda_res_24024 = lifted_lambda_res_t_res_24027;\n                } else {\n                    int64_t lifted_lambda_res_f_res_24028;\n                    int8_t lifted_lambda_res_f_res_24029;\n                    \n                    if (c", "ond_24020) {\n                        lifted_lambda_res_f_res_24028 = eta_p_24016;\n                        lifted_lambda_res_f_res_24029 = eta_p_24017;\n                    } else {\n                        int64_t lifted_lambda_res_f_res_f_res_24030;\n                        \n                        if (cond_t_res_24021) {\n                            lifted_lambda_res_f_res_f_res_24030 = eta_p_24018;\n                        } else {\n                            lifted_lambda_res_f_res_f_res_24030 = (int64_t) 0;\n                        }\n                        \n                        int8_t lifted_lambda_res_f_res_f_res_24031;\n                        \n                        if (cond_t_res_24021) {\n                            lifted_lambda_res_f_res_f_res_24031 = eta_p_24019;\n                        } else {\n                            lifted_lambda_res_f_res_f_res_24031 = (int8_t) 0;\n                        }\n                        lifted_lambda_res_f_res_24028 = lifted_lambda_res_f_res_f_res_24030;\n                        lifted_lambda_res_f_res_24029 = lifted_lambda_res_f_res_f_res_24031;\n                    }\n                    lifted_lambda_res_24023 = lifted_lambda_res_f_res_24028;\n                    lifted_lambda_res_24024 = lifted_lambda_res_f_res_24029;\n                }\n                eta_p_24016 = lifted_lambda_res_24023;\n                eta_p_24017 = lifted_lambda_res_24024;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_i64_mem_24007)[sext_i32_i64(local_tid_24003)] = eta_p_24016;\n                ((__local int8_t *) red_arr_i8_mem_24009)[sext_i32_i64(local_tid_24003)] = eta_p_24017;\n            }\n        }\n        skip_waves_24037 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_24003) == (int64_t) 0) {\n            eta_p_block_res_acc_24014 = eta_p_24016;\n   ",
                                    "         eta_p_block_res_acc_24015 = eta_p_24017;\n        } else {\n            eta_p_block_res_acc_24014 = (int64_t) 0;\n            eta_p_block_res_acc_24015 = (int8_t) 0;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_24003 == 0) {\n            ((__global int64_t *) segred_tmp_mem_23997)[sext_i32_i64(block_id_24004)] = eta_p_block_res_acc_24014;\n            mem_fence_global();\n            ((__global int8_t *) segred_tmp_mem_23999)[sext_i32_i64(block_id_24004)] = eta_p_block_res_acc_24015;\n            mem_fence_global();\n            old_counter_24038 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23995)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_24011)[(int64_t) 0] = old_counter_24038 == sext_i64_i32(num_tblocks_21647 - (int64_t) 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_24039 = ((__local bool *) sync_arr_mem_24011)[(int64_t) 0];\n    if (is_last_block_24039) {\n        if (local_tid_24003 == 0) {\n            old_counter_24038 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23995)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_21647));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_24040 = sdiv_up64(num_tblocks_21647, segred_tblock_sizze_21645);\n            \n            eta_p_20855 = (int64_t) 0;\n            eta_p_20856 = (int8_t) 0;\n            for (int64_t i_24041 = 0; i_24041 < read_per_thread_24040; i_24041++) {\n                int64_t block_res_id_24042 = sext_i32_i64(local_tid_24003) * read_per_thread_24040 + i_24041;\n                int64_t index_of_block_res_24043 = block_res_id_24042;\n                \n                if (slt64(block_res_id_24042, num_tblocks_21647)) {\n                    eta_p_20857 = ((__global int64_t *) segred_tmp_mem_23997)[index_of_block_res_24043];\n                    eta_p_20858 = ((__global int8_t *) seg", "red_tmp_mem_23999)[index_of_block_res_24043];\n                    \n                    bool cond_20859 = eta_p_20856 == (int8_t) 1;\n                    bool cond_t_res_20860 = eta_p_20858 == (int8_t) 1;\n                    bool x_20861 = cond_20859 && cond_t_res_20860;\n                    int64_t lifted_lambda_res_20862;\n                    int8_t lifted_lambda_res_20863;\n                    \n                    if (x_20861) {\n                        bool cond_20864 = sle64(eta_p_20855, eta_p_20857);\n                        int64_t lifted_lambda_res_t_res_20865;\n                        \n                        if (cond_20864) {\n                            lifted_lambda_res_t_res_20865 = eta_p_20855;\n                        } else {\n                            lifted_lambda_res_t_res_20865 = eta_p_20857;\n                        }\n                        \n                        int8_t lifted_lambda_res_t_res_20866;\n                        \n                        if (cond_20864) {\n                            lifted_lambda_res_t_res_20866 = eta_p_20856;\n                        } else {\n                            lifted_lambda_res_t_res_20866 = eta_p_20858;\n                        }\n                        lifted_lambda_res_20862 = lifted_lambda_res_t_res_20865;\n                        lifted_lambda_res_20863 = lifted_lambda_res_t_res_20866;\n                    } else {\n                        int64_t lifted_lambda_res_f_res_20867;\n                        int8_t lifted_lambda_res_f_res_20868;\n                        \n                        if (cond_20859) {\n                            lifted_lambda_res_f_res_20867 = eta_p_20855;\n                            lifted_lambda_res_f_res_20868 = eta_p_20856;\n                        } else {\n                            int64_t lifted_lambda_res_f_res_f_res_20869;\n                            \n                            if (cond_t_res_20860) {\n                                lifted_lambda_res_f_res_f_res_20869 = eta_p_20857;\n ", "                           } else {\n                                lifted_lambda_res_f_res_f_res_20869 = (int64_t) 0;\n                            }\n                            \n                            int8_t lifted_lambda_res_f_res_f_res_20870;\n                            \n                            if (cond_t_res_20860) {\n                                lifted_lambda_res_f_res_f_res_20870 = eta_p_20858;\n                            } else {\n                                lifted_lambda_res_f_res_f_res_20870 = (int8_t) 0;\n                            }\n                            lifted_lambda_res_f_res_20867 = lifted_lambda_res_f_res_f_res_20869;\n                            lifted_lambda_res_f_res_20868 = lifted_lambda_res_f_res_f_res_20870;\n                        }\n                        lifted_lambda_res_20862 = lifted_lambda_res_f_res_20867;\n                        lifted_lambda_res_20863 = lifted_lambda_res_f_res_20868;\n                    }\n                    eta_p_20855 = lifted_lambda_res_20862;\n                    eta_p_20856 = lifted_lambda_res_20863;\n                }\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_24007)[sext_i32_i64(local_tid_24003)] = eta_p_20855;\n        ((__local int8_t *) red_arr_i8_mem_24009)[sext_i32_i64(local_tid_24003)] = eta_p_20856;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_24044;\n            int32_t skip_waves_24045 = 1;\n            int64_t eta_p_24016;\n            int8_t eta_p_24017;\n            int64_t eta_p_24018;\n            int8_t eta_p_24019;\n            \n            offset_24044 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_24003, sext_i64_i32(segred_tblock_sizze_21645))) {\n                    eta_p_24016 = ((__local int64_t *) red_arr_i64_mem_24007)[sext_i32_i64(local_tid_24003 + offset_24044)];\n                    eta_p_24017 = ((__local int8_t *) ",
                                    "red_arr_i8_mem_24009)[sext_i32_i64(local_tid_24003 + offset_24044)];\n                }\n            }\n            offset_24044 = 1;\n            while (slt32(offset_24044, wave_sizze_24005)) {\n                if (slt32(local_tid_24003 + offset_24044, sext_i64_i32(segred_tblock_sizze_21645)) && ((local_tid_24003 - squot32(local_tid_24003, wave_sizze_24005) * wave_sizze_24005) & (2 * offset_24044 - 1)) == 0) {\n                    // read array element\n                    {\n                        eta_p_24018 = ((volatile __local int64_t *) red_arr_i64_mem_24007)[sext_i32_i64(local_tid_24003 + offset_24044)];\n                        eta_p_24019 = ((volatile __local int8_t *) red_arr_i8_mem_24009)[sext_i32_i64(local_tid_24003 + offset_24044)];\n                    }\n                    // apply reduction operation\n                    {\n                        bool cond_24020 = eta_p_24017 == (int8_t) 1;\n                        bool cond_t_res_24021 = eta_p_24019 == (int8_t) 1;\n                        bool x_24022 = cond_24020 && cond_t_res_24021;\n                        int64_t lifted_lambda_res_24023;\n                        int8_t lifted_lambda_res_24024;\n                        \n                        if (x_24022) {\n                            bool cond_24025 = sle64(eta_p_24016, eta_p_24018);\n                            int64_t lifted_lambda_res_t_res_24026;\n                            \n                            if (cond_24025) {\n                                lifted_lambda_res_t_res_24026 = eta_p_24016;\n                            } else {\n                                lifted_lambda_res_t_res_24026 = eta_p_24018;\n                            }\n                            \n                            int8_t lifted_lambda_res_t_res_24027;\n                            \n                            if (cond_24025) {\n                                lifted_lambda_res_t_res_24027 = eta_p_24017;\n                            } else {\n                                lifted_la", "mbda_res_t_res_24027 = eta_p_24019;\n                            }\n                            lifted_lambda_res_24023 = lifted_lambda_res_t_res_24026;\n                            lifted_lambda_res_24024 = lifted_lambda_res_t_res_24027;\n                        } else {\n                            int64_t lifted_lambda_res_f_res_24028;\n                            int8_t lifted_lambda_res_f_res_24029;\n                            \n                            if (cond_24020) {\n                                lifted_lambda_res_f_res_24028 = eta_p_24016;\n                                lifted_lambda_res_f_res_24029 = eta_p_24017;\n                            } else {\n                                int64_t lifted_lambda_res_f_res_f_res_24030;\n                                \n                                if (cond_t_res_24021) {\n                                    lifted_lambda_res_f_res_f_res_24030 = eta_p_24018;\n                                } else {\n                                    lifted_lambda_res_f_res_f_res_24030 = (int64_t) 0;\n                                }\n                                \n                                int8_t lifted_lambda_res_f_res_f_res_24031;\n                                \n                                if (cond_t_res_24021) {\n                                    lifted_lambda_res_f_res_f_res_24031 = eta_p_24019;\n                                } else {\n                                    lifted_lambda_res_f_res_f_res_24031 = (int8_t) 0;\n                                }\n                                lifted_lambda_res_f_res_24028 = lifted_lambda_res_f_res_f_res_24030;\n                                lifted_lambda_res_f_res_24029 = lifted_lambda_res_f_res_f_res_24031;\n                            }\n                            lifted_lambda_res_24023 = lifted_lambda_res_f_res_24028;\n                            lifted_lambda_res_24024 = lifted_lambda_res_f_res_24029;\n                        }\n                        eta_p_24016 = lifte", "d_lambda_res_24023;\n                        eta_p_24017 = lifted_lambda_res_24024;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local int64_t *) red_arr_i64_mem_24007)[sext_i32_i64(local_tid_24003)] = eta_p_24016;\n                        ((volatile __local int8_t *) red_arr_i8_mem_24009)[sext_i32_i64(local_tid_24003)] = eta_p_24017;\n                    }\n                }\n                offset_24044 *= 2;\n            }\n            while (slt32(skip_waves_24045, squot32(sext_i64_i32(segred_tblock_sizze_21645) + wave_sizze_24005 - 1, wave_sizze_24005))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_24044 = skip_waves_24045 * wave_sizze_24005;\n                if (slt32(local_tid_24003 + offset_24044, sext_i64_i32(segred_tblock_sizze_21645)) && ((local_tid_24003 - squot32(local_tid_24003, wave_sizze_24005) * wave_sizze_24005) == 0 && (squot32(local_tid_24003, wave_sizze_24005) & (2 * skip_waves_24045 - 1)) == 0)) {\n                    // read array element\n                    {\n                        eta_p_24018 = ((__local int64_t *) red_arr_i64_mem_24007)[sext_i32_i64(local_tid_24003 + offset_24044)];\n                        eta_p_24019 = ((__local int8_t *) red_arr_i8_mem_24009)[sext_i32_i64(local_tid_24003 + offset_24044)];\n                    }\n                    // apply reduction operation\n                    {\n                        bool cond_24020 = eta_p_24017 == (int8_t) 1;\n                        bool cond_t_res_24021 = eta_p_24019 == (int8_t) 1;\n                        bool x_24022 = cond_24020 && cond_t_res_24021;\n                        int64_t lifted_lambda_res_24023;\n                        int8_t lifted_lambda_res_24024;\n                        \n                        if (x_24022) {\n                            bool cond_24025 = sle64(eta_p_24016, eta_p_24018);\n                            int64_t lifted_lambda_res_t_res_24026;\n             ",
                                    "               \n                            if (cond_24025) {\n                                lifted_lambda_res_t_res_24026 = eta_p_24016;\n                            } else {\n                                lifted_lambda_res_t_res_24026 = eta_p_24018;\n                            }\n                            \n                            int8_t lifted_lambda_res_t_res_24027;\n                            \n                            if (cond_24025) {\n                                lifted_lambda_res_t_res_24027 = eta_p_24017;\n                            } else {\n                                lifted_lambda_res_t_res_24027 = eta_p_24019;\n                            }\n                            lifted_lambda_res_24023 = lifted_lambda_res_t_res_24026;\n                            lifted_lambda_res_24024 = lifted_lambda_res_t_res_24027;\n                        } else {\n                            int64_t lifted_lambda_res_f_res_24028;\n                            int8_t lifted_lambda_res_f_res_24029;\n                            \n                            if (cond_24020) {\n                                lifted_lambda_res_f_res_24028 = eta_p_24016;\n                                lifted_lambda_res_f_res_24029 = eta_p_24017;\n                            } else {\n                                int64_t lifted_lambda_res_f_res_f_res_24030;\n                                \n                                if (cond_t_res_24021) {\n                                    lifted_lambda_res_f_res_f_res_24030 = eta_p_24018;\n                                } else {\n                                    lifted_lambda_res_f_res_f_res_24030 = (int64_t) 0;\n                                }\n                                \n                                int8_t lifted_lambda_res_f_res_f_res_24031;\n                                \n                                if (cond_t_res_24021) {\n                                    lifted_lambda_res_f_res_f_res_24031 = eta_p_24019;\n                        ", "        } else {\n                                    lifted_lambda_res_f_res_f_res_24031 = (int8_t) 0;\n                                }\n                                lifted_lambda_res_f_res_24028 = lifted_lambda_res_f_res_f_res_24030;\n                                lifted_lambda_res_f_res_24029 = lifted_lambda_res_f_res_f_res_24031;\n                            }\n                            lifted_lambda_res_24023 = lifted_lambda_res_f_res_24028;\n                            lifted_lambda_res_24024 = lifted_lambda_res_f_res_24029;\n                        }\n                        eta_p_24016 = lifted_lambda_res_24023;\n                        eta_p_24017 = lifted_lambda_res_24024;\n                    }\n                    // write result of operation\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_24007)[sext_i32_i64(local_tid_24003)] = eta_p_24016;\n                        ((__local int8_t *) red_arr_i8_mem_24009)[sext_i32_i64(local_tid_24003)] = eta_p_24017;\n                    }\n                }\n                skip_waves_24045 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_24003 == 0) {\n                    ((__global int64_t *) mem_23461)[(int64_t) 0] = eta_p_24016;\n                    ((__global int8_t *) mem_23462)[(int64_t) 0] = eta_p_24017;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_21645\n    #undef chunk_sizze_23994\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegred_nonseg_22135_dim1, 1, 1)\nvoid simulate_8477zisegred_nonseg_22135(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_21170, int64_t num_tblocks_22128, int64_t num_threads_23870, int64_t num_threads_24624, __global unsigned", " char *mem_23405, __global unsigned char *mem_23471, __global unsigned char *mem_23473, __global unsigned char *mem_23552, __global unsigned char *mem_23568, __global unsigned char *mem_23582, __global unsigned char *mem_23596, __global unsigned char *color_23822, __global unsigned char *color_23823, __global unsigned char *counters_mem_24620, __global unsigned char *segred_tmp_mem_24622)\n{\n    #define segred_tblock_sizze_22127 (simulate_8477zisegred_nonseg_22135zisegred_tblock_sizze_22127)\n    #define chunk_sizze_24619 (simulate_8477zisegred_nonseg_22135zichunk_sizze_24619)\n    \n    volatile __local unsigned char *sync_arr_mem_24632_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_24632_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i8_mem_24630_backing_0 = &shared_mem[sync_arr_mem_24632_backing_1_offset];\n    const int64_t red_arr_i8_mem_24630_backing_0_offset = sync_arr_mem_24632_backing_1_offset + (segred_tblock_sizze_22127 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22127, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24626;\n    int32_t tblock_sizze_24629;\n    int32_t wave_sizze_24628;\n    int32_t block_id_24627;\n    int32_t global_tid_24625;\n    int64_t phys_tid_22135;\n    __local unsigned char *red_arr_i8_mem_24630;\n    __local unsigned char *sync_arr_mem_24632;\n    int64_t dummy_22133;\n    int64_t gtid_22134;\n    int64_t q_24634;\n    int8_t eta_p_block_res_acc_24635;\n    int8_t eta_p_22136;\n    int8_t eta_p_22137;\n    int64_t tblock_id_in_segment_24639;\n    int64_t block_base_offset_24640;\n    int32_t offset_24646;\n    int32_t skip_waves_24647;\n    int8_t eta_p_24636;\n    int8_t eta_p_24637;\n    int32_t old_counter_24648;\n    bool is_last_block_24649;\n    \n    local_tid_24626 = get_",
                                    "local_id(0);\n    tblock_sizze_24629 = get_local_size(0);\n    wave_sizze_24628 = LOCKSTEP_WIDTH;\n    block_id_24627 = get_tblock_id(0);\n    global_tid_24625 = block_id_24627 * tblock_sizze_24629 + local_tid_24626;\n    phys_tid_22135 = sext_i32_i64(global_tid_24625);\n    red_arr_i8_mem_24630 = (__local unsigned char *) red_arr_i8_mem_24630_backing_0;\n    sync_arr_mem_24632 = (__local unsigned char *) sync_arr_mem_24632_backing_1;\n    dummy_22133 = (int64_t) 0;\n    gtid_22134 = (int64_t) 0;\n    q_24634 = sdiv_up64(m_21170, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_22127 * num_tblocks_22128)) * chunk_sizze_24619);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        eta_p_block_res_acc_24635 = (int8_t) 0;\n    }\n    tblock_id_in_segment_24639 = squot64(phys_tid_22135, segred_tblock_sizze_22127);\n    block_base_offset_24640 = tblock_id_in_segment_24639 * q_24634 * segred_tblock_sizze_22127;\n    for (int64_t i_24641 = 0; i_24641 < q_24634; i_24641++) {\n        int64_t block_offset_24642 = block_base_offset_24640 + i_24641 * segred_tblock_sizze_22127;\n        \n        gtid_22134 = phys_tid_22135 + num_threads_24624 * i_24641;\n        if (slt64(gtid_22134, m_21170)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n                    int64_t eta_p_22139 = ((__global int64_t *) mem_23471)[gtid_22134];\n                    int64_t idx_22140 = add64(num_qubits_15486, eta_p_22139);\n                    bool x_22141 = sle64((int64_t) 0, idx_22140);\n                    bool y_22142 = slt64(idx_22140, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                    bool bounds_check_22143 = x_22141 && y_22142;\n                    bool index_certs_22144;\n                    \n                    if (!bounds_check_22143) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 19) == -1) {\n                                global_failure_", "args[0] = (int64_t) idx_22140;\n                                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    bool index_certs_22185;\n                    \n                    if (!bounds_check_22143) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 20) == -1) {\n                                global_failure_args[0] = (int64_t) idx_22140;\n                                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int8_t zp_lhs_23223 = ((__global int8_t *) mem_23473)[(int64_t) 0];\n                    int8_t defunc_0_f_res_22145;\n                    int8_t redout_23123 = (int8_t) 0;\n                    \n                    for (int64_t i_23126 = 0; i_23126 < num_qubits_15486; i_23126++) {\n                        int64_t g_arg3_22152 = add64(num_qubits_15486, i_23126);\n                        bool x_22153 = sle64((int64_t) 0, g_arg3_22152);\n                        bool y_22154 = slt64(g_arg3_22152, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                        bool bounds_check_22155 = x_22153 && y_22154;\n                        bool index_certs_22156;\n                        \n                        if (!bounds_check_22155) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 21) == -1) {\n                                    global_failure_args[0", "] = (int64_t) g_arg3_22152;\n                                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        bool y_22159 = slt64(i_23126, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                        bool index_certs_22161;\n                        \n                        if (!y_22159) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 22) == -1) {\n                                    global_failure_args[0] = (int64_t) i_23126;\n                                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        int8_t g_arg2_22162 = ((__global int8_t *) mem_23405)[arg_15490 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + i_23126];\n                        int8_t g_arg0_22164 = ((__global int8_t *) mem_23552)[idx_22140 + i_23126 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491];\n                        bool cond_22165 = g_arg0_22164 == g_arg2_22162;\n                        bool cond_t_res_22166 = g_arg0_22164 == (int8_t) 0;\n                        bool x_22167 = cond_22165 && cond_t_res_22166;\n                        int8_t g_res_22168;\n                        \n                        if (x_22167) {\n                            g_res_22168 = (int8_t) 0;\n                        } else {\n                ",
                                    "            int8_t g_arg3_22157 = ((__global int8_t *) mem_23405)[arg_15490 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + g_arg3_22152];\n                            int8_t g_arg1_22163 = ((__global int8_t *) mem_23552)[idx_22140 + g_arg3_22152 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491];\n                            bool cond_t_res_22169 = g_arg0_22164 == (int8_t) 1;\n                            bool x_22170 = cond_22165 && cond_t_res_22169;\n                            int8_t g_res_f_res_22171;\n                            \n                            if (x_22170) {\n                                int8_t g_res_f_res_t_res_22172 = sub8(g_arg3_22157, g_arg1_22163);\n                                \n                                g_res_f_res_22171 = g_res_f_res_t_res_22172;\n                            } else {\n                                bool cond_t_res_22173 = g_arg2_22162 == (int8_t) 0;\n                                bool x_22174 = cond_t_res_22169 && cond_t_res_22173;\n                                int8_t g_res_f_res_f_res_22175;\n                                \n                                if (x_22174) {\n                                    int8_t zm_lhs_22176 = mul8((int8_t) 2, g_arg1_22163);\n                                    int8_t zt_rhs_22177 = sub8(zm_lhs_22176, (int8_t) 1);\n                                    int8_t g_res_f_res_f_res_t_res_22178 = mul8(g_arg3_22157, zt_rhs_22177);\n                                    \n                                    g_res_f_res_f_res_22175 = g_res_f_res_f_res_t_res_22178;\n                                } else {\n                                    bool cond_t_res_22179 = g_arg2_22162 == (int8_t) 1;\n                                    bool x_22180 = cond_t_res_22166 && cond_t_res_22179;\n                                    int8_t g_res_f_res_f_res_f_res_22181;\n                                    \n                                    if (x_22180) {\n                           ", "             int8_t zm_rhs_22182 = mul8((int8_t) 2, g_arg3_22157);\n                                        int8_t zt_rhs_22183 = sub8((int8_t) 1, zm_rhs_22182);\n                                        int8_t g_res_f_res_f_res_f_res_t_res_22184 = mul8(g_arg1_22163, zt_rhs_22183);\n                                        \n                                        g_res_f_res_f_res_f_res_22181 = g_res_f_res_f_res_f_res_t_res_22184;\n                                    } else {\n                                        g_res_f_res_f_res_f_res_22181 = (int8_t) 0;\n                                    }\n                                    g_res_f_res_f_res_22175 = g_res_f_res_f_res_f_res_22181;\n                                }\n                                g_res_f_res_22171 = g_res_f_res_f_res_22175;\n                            }\n                            g_res_22168 = g_res_f_res_22171;\n                        }\n                        \n                        int8_t defunc_0_op_res_22150 = add8(g_res_22168, redout_23123);\n                        \n                        for (int64_t i_0 = 0; i_0 < (int64_t) 1; i_0++) {\n                            ((__global int8_t *) color_23823)[phys_tid_22135 + num_threads_23870 * i_23126 + i_0 * num_threads_23870] = ((__global int8_t *) mem_23552)[idx_22140 + dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 * g_arg3_22152 + i_0 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491];\n                        }\n                        for (int64_t i_0 = 0; i_0 < (int64_t) 1; i_0++) {\n                            ((__global int8_t *) color_23822)[phys_tid_22135 + num_threads_23870 * i_23126 + i_0 * num_threads_23870] = ((__global int8_t *) mem_23552)[idx_22140 + dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 * i_23126 + i_0 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491];\n                        }\n                        \n                        int8_t redout_tmp_24643 = defunc_0", "_op_res_22150;\n                        \n                        redout_23123 = redout_tmp_24643;\n                    }\n                    defunc_0_f_res_22145 = redout_23123;\n                    \n                    int8_t zt_rhs_22186 = ((__global int8_t *) mem_23405)[idx_22140 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + arg_15490];\n                    int8_t zp_rhs_22187 = mul8((int8_t) 2, zt_rhs_22186);\n                    int8_t zp_lhs_22188 = add8(zp_rhs_22187, zp_lhs_23223);\n                    int8_t zv_lhs_22189 = add8(defunc_0_f_res_22145, zp_lhs_22188);\n                    int8_t res_22190 = smod8(zv_lhs_22189, (int8_t) 4);\n                    bool cond_22191 = res_22190 == (int8_t) 0;\n                    bool cond_neg_22192 = !cond_22191;\n                    int8_t phase_contrib_22193 = btoi_bool_i8(cond_neg_22192);\n                    \n                    // write map-out result(s)\n                    {\n                        for (int64_t i_0 = 0; i_0 < num_qubits_15486; i_0++) {\n                            ((__global int8_t *) mem_23582)[dummy_22133 * m_21170 + gtid_22134 + i_0 * m_21170] = ((__global int8_t *) color_23822)[phys_tid_22135 + i_0 * num_threads_23870];\n                        }\n                        for (int64_t i_0 = 0; i_0 < num_qubits_15486; i_0++) {\n                            ((__global int8_t *) mem_23596)[dummy_22133 * m_21170 + gtid_22134 + i_0 * m_21170] = ((__global int8_t *) color_23823)[phys_tid_22135 + i_0 * num_threads_23870];\n                        }\n                    }\n                    // load accumulator(s)\n                    {\n                        eta_p_22136 = eta_p_block_res_acc_24635;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_22137 = phase_contrib_22193;\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int8_t defunc_0_op_res_22138 = eta_p_2",
                                    "2136 ^ eta_p_22137;\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_24635 = defunc_0_op_res_22138;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_failure)\n        return;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local int8_t *) red_arr_i8_mem_24630)[sext_i32_i64(local_tid_24626)] = eta_p_block_res_acc_24635;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_24647 = 1;\n    offset_24646 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_24626, sext_i64_i32(segred_tblock_sizze_22127))) {\n            eta_p_24636 = ((__local int8_t *) red_arr_i8_mem_24630)[sext_i32_i64(local_tid_24626 + offset_24646)];\n        }\n    }\n    offset_24646 = 1;\n    while (slt32(offset_24646, wave_sizze_24628)) {\n        if (slt32(local_tid_24626 + offset_24646, sext_i64_i32(segred_tblock_sizze_22127)) && ((local_tid_24626 - squot32(local_tid_24626, wave_sizze_24628) * wave_sizze_24628) & (2 * offset_24646 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_24637 = ((volatile __local int8_t *) red_arr_i8_mem_24630)[sext_i32_i64(local_tid_24626 + offset_24646)];\n            }\n            // apply reduction operation\n            {\n                int8_t defunc_0_op_res_24638 = eta_p_24636 ^ eta_p_24637;\n                \n                eta_p_24636 = defunc_0_op_res_24638;\n            }\n            // write result of operation\n            {\n                ((volatile __local int8_t *) red_arr_i8_mem_24630)[sext_i32_i64(local_tid_24626)] = eta_p_24636;\n            }\n        }\n        offset_24646 *= 2;\n    }\n    while (slt32(skip_waves_24647, squot32(sext_i64_i32(segred_tblock_sizze_22127) + wave_sizze_24628 - 1, wave_sizze_24", "628))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_24646 = skip_waves_24647 * wave_sizze_24628;\n        if (slt32(local_tid_24626 + offset_24646, sext_i64_i32(segred_tblock_sizze_22127)) && ((local_tid_24626 - squot32(local_tid_24626, wave_sizze_24628) * wave_sizze_24628) == 0 && (squot32(local_tid_24626, wave_sizze_24628) & (2 * skip_waves_24647 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_24637 = ((__local int8_t *) red_arr_i8_mem_24630)[sext_i32_i64(local_tid_24626 + offset_24646)];\n            }\n            // apply reduction operation\n            {\n                int8_t defunc_0_op_res_24638 = eta_p_24636 ^ eta_p_24637;\n                \n                eta_p_24636 = defunc_0_op_res_24638;\n            }\n            // write result of operation\n            {\n                ((__local int8_t *) red_arr_i8_mem_24630)[sext_i32_i64(local_tid_24626)] = eta_p_24636;\n            }\n        }\n        skip_waves_24647 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_24626) == (int64_t) 0) {\n            eta_p_block_res_acc_24635 = eta_p_24636;\n        } else {\n            eta_p_block_res_acc_24635 = (int8_t) 0;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_24626 == 0) {\n            ((__global int8_t *) segred_tmp_mem_24622)[sext_i32_i64(block_id_24627)] = eta_p_block_res_acc_24635;\n            mem_fence_global();\n            old_counter_24648 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24620)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_24632)[(int64_t) 0] = old_counter_24648 == sext_i64_i32(num_tblocks_22128 - (int64_t) 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_24649 = ((__local bool *) sync_arr_mem_24632)[(int64_t) 0];\n    if (is_last_b", "lock_24649) {\n        if (local_tid_24626 == 0) {\n            old_counter_24648 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24620)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_22128));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_24650 = sdiv_up64(num_tblocks_22128, segred_tblock_sizze_22127);\n            \n            eta_p_22136 = (int8_t) 0;\n            for (int64_t i_24651 = 0; i_24651 < read_per_thread_24650; i_24651++) {\n                int64_t block_res_id_24652 = sext_i32_i64(local_tid_24626) * read_per_thread_24650 + i_24651;\n                int64_t index_of_block_res_24653 = block_res_id_24652;\n                \n                if (slt64(block_res_id_24652, num_tblocks_22128)) {\n                    eta_p_22137 = ((__global int8_t *) segred_tmp_mem_24622)[index_of_block_res_24653];\n                    \n                    int8_t defunc_0_op_res_22138 = eta_p_22136 ^ eta_p_22137;\n                    \n                    eta_p_22136 = defunc_0_op_res_22138;\n                }\n            }\n        }\n        ((__local int8_t *) red_arr_i8_mem_24630)[sext_i32_i64(local_tid_24626)] = eta_p_22136;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_24654;\n            int32_t skip_waves_24655 = 1;\n            int8_t eta_p_24636;\n            int8_t eta_p_24637;\n            \n            offset_24654 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_24626, sext_i64_i32(segred_tblock_sizze_22127))) {\n                    eta_p_24636 = ((__local int8_t *) red_arr_i8_mem_24630)[sext_i32_i64(local_tid_24626 + offset_24654)];\n                }\n            }\n            offset_24654 = 1;\n            while (slt32(offset_24654, wave_sizze_24628)) {\n                if (slt32(local_tid_24626 + offset_24654, sext_i64_i32(segred_tblock_sizze_22127)) && ((local_tid_24626",
                                    " - squot32(local_tid_24626, wave_sizze_24628) * wave_sizze_24628) & (2 * offset_24654 - 1)) == 0) {\n                    // read array element\n                    {\n                        eta_p_24637 = ((volatile __local int8_t *) red_arr_i8_mem_24630)[sext_i32_i64(local_tid_24626 + offset_24654)];\n                    }\n                    // apply reduction operation\n                    {\n                        int8_t defunc_0_op_res_24638 = eta_p_24636 ^ eta_p_24637;\n                        \n                        eta_p_24636 = defunc_0_op_res_24638;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local int8_t *) red_arr_i8_mem_24630)[sext_i32_i64(local_tid_24626)] = eta_p_24636;\n                    }\n                }\n                offset_24654 *= 2;\n            }\n            while (slt32(skip_waves_24655, squot32(sext_i64_i32(segred_tblock_sizze_22127) + wave_sizze_24628 - 1, wave_sizze_24628))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_24654 = skip_waves_24655 * wave_sizze_24628;\n                if (slt32(local_tid_24626 + offset_24654, sext_i64_i32(segred_tblock_sizze_22127)) && ((local_tid_24626 - squot32(local_tid_24626, wave_sizze_24628) * wave_sizze_24628) == 0 && (squot32(local_tid_24626, wave_sizze_24628) & (2 * skip_waves_24655 - 1)) == 0)) {\n                    // read array element\n                    {\n                        eta_p_24637 = ((__local int8_t *) red_arr_i8_mem_24630)[sext_i32_i64(local_tid_24626 + offset_24654)];\n                    }\n                    // apply reduction operation\n                    {\n                        int8_t defunc_0_op_res_24638 = eta_p_24636 ^ eta_p_24637;\n                        \n                        eta_p_24636 = defunc_0_op_res_24638;\n                    }\n                    // write result of operation\n                    {\n                        ((__local int8_t *) red_arr_i8_mem_24630", ")[sext_i32_i64(local_tid_24626)] = eta_p_24636;\n                    }\n                }\n                skip_waves_24655 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_24626 == 0) {\n                    ((__global int8_t *) mem_23568)[(int64_t) 0] = eta_p_24636;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_22127\n    #undef chunk_sizze_24619\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegred_nonseg_22676_dim1, 1, 1)\nvoid simulate_8477zisegred_nonseg_22676(__global int *global_failure, int64_t m_21170, int64_t num_tblocks_22671, int64_t num_threads_24774, __global unsigned char *ext_mem_23539, __global unsigned char *mem_23541, __global unsigned char *counters_mem_24770, __global unsigned char *segred_tmp_mem_24772)\n{\n    #define segred_tblock_sizze_22670 (simulate_8477zisegred_nonseg_22676zisegred_tblock_sizze_22670)\n    #define chunk_sizze_24769 (simulate_8477zisegred_nonseg_22676zichunk_sizze_24769)\n    \n    volatile __local unsigned char *sync_arr_mem_24782_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_24782_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i8_mem_24780_backing_0 = &shared_mem[sync_arr_mem_24782_backing_1_offset];\n    const int64_t red_arr_i8_mem_24780_backing_0_offset = sync_arr_mem_24782_backing_1_offset + (segred_tblock_sizze_22670 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22670, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24776;\n    int32_t tblock_sizze_24779;\n    int32_t wave_sizze_24778;\n    int32_t block_id_24777;\n    int32_t global_tid_24775;\n    int64_t phys_tid_22676;\n    __local unsigned char *red_arr_i8_mem_24780;\n    __local unsigned char *sync_arr_mem_24782;\n    int64_t dummy_22674;\n    int64_t gtid_22675;\n    int64_t q_24784;\n    int8_t eta_p_block_res_acc_24785;\n", "    int8_t eta_p_22677;\n    int8_t eta_p_22678;\n    int64_t tblock_id_in_segment_24789;\n    int64_t block_base_offset_24790;\n    int32_t offset_24793;\n    int32_t skip_waves_24794;\n    int8_t eta_p_24786;\n    int8_t eta_p_24787;\n    int32_t old_counter_24795;\n    bool is_last_block_24796;\n    \n    local_tid_24776 = get_local_id(0);\n    tblock_sizze_24779 = get_local_size(0);\n    wave_sizze_24778 = LOCKSTEP_WIDTH;\n    block_id_24777 = get_tblock_id(0);\n    global_tid_24775 = block_id_24777 * tblock_sizze_24779 + local_tid_24776;\n    phys_tid_22676 = sext_i32_i64(global_tid_24775);\n    red_arr_i8_mem_24780 = (__local unsigned char *) red_arr_i8_mem_24780_backing_0;\n    sync_arr_mem_24782 = (__local unsigned char *) sync_arr_mem_24782_backing_1;\n    dummy_22674 = (int64_t) 0;\n    gtid_22675 = (int64_t) 0;\n    q_24784 = sdiv_up64(m_21170, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_22670 * num_tblocks_22671)) * chunk_sizze_24769);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        eta_p_block_res_acc_24785 = (int8_t) 0;\n    }\n    tblock_id_in_segment_24789 = squot64(phys_tid_22676, segred_tblock_sizze_22670);\n    block_base_offset_24790 = tblock_id_in_segment_24789 * q_24784 * segred_tblock_sizze_22670;\n    for (int64_t i_24791 = 0; i_24791 < q_24784; i_24791++) {\n        int64_t block_offset_24792 = block_base_offset_24790 + i_24791 * segred_tblock_sizze_22670;\n        \n        gtid_22675 = phys_tid_22676 + num_threads_24774 * i_24791;\n        if (slt64(gtid_22675, m_21170)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n                    int8_t x_22680 = ((__global int8_t *) ext_mem_23539)[gtid_22675];\n                    \n                    // load accumulator(s)\n                    {\n                        eta_p_22677 = eta_p_block_res_acc_24785;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_22678 = x_22680;\n ",
                                    "                   }\n                    // apply reduction operator(s)\n                    {\n                        int8_t defunc_0_op_res_22679 = eta_p_22677 ^ eta_p_22678;\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_24785 = defunc_0_op_res_22679;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local int8_t *) red_arr_i8_mem_24780)[sext_i32_i64(local_tid_24776)] = eta_p_block_res_acc_24785;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_24794 = 1;\n    offset_24793 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_24776, sext_i64_i32(segred_tblock_sizze_22670))) {\n            eta_p_24786 = ((__local int8_t *) red_arr_i8_mem_24780)[sext_i32_i64(local_tid_24776 + offset_24793)];\n        }\n    }\n    offset_24793 = 1;\n    while (slt32(offset_24793, wave_sizze_24778)) {\n        if (slt32(local_tid_24776 + offset_24793, sext_i64_i32(segred_tblock_sizze_22670)) && ((local_tid_24776 - squot32(local_tid_24776, wave_sizze_24778) * wave_sizze_24778) & (2 * offset_24793 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_24787 = ((volatile __local int8_t *) red_arr_i8_mem_24780)[sext_i32_i64(local_tid_24776 + offset_24793)];\n            }\n            // apply reduction operation\n            {\n                int8_t defunc_0_op_res_24788 = eta_p_24786 ^ eta_p_24787;\n                \n                eta_p_24786 = defunc_0_op_res_24788;\n            }\n            // write result of operation\n            {\n                ((volatile __local int8_t *) red_arr_i8_mem_24780)[sext_i32_i64(local_tid_24776)] = eta_p_24786;\n            }\n        }\n        offset_24793 *= 2;\n    }\n    while (slt32(skip_waves_24794, squot32(sext_i64_i", "32(segred_tblock_sizze_22670) + wave_sizze_24778 - 1, wave_sizze_24778))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_24793 = skip_waves_24794 * wave_sizze_24778;\n        if (slt32(local_tid_24776 + offset_24793, sext_i64_i32(segred_tblock_sizze_22670)) && ((local_tid_24776 - squot32(local_tid_24776, wave_sizze_24778) * wave_sizze_24778) == 0 && (squot32(local_tid_24776, wave_sizze_24778) & (2 * skip_waves_24794 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_24787 = ((__local int8_t *) red_arr_i8_mem_24780)[sext_i32_i64(local_tid_24776 + offset_24793)];\n            }\n            // apply reduction operation\n            {\n                int8_t defunc_0_op_res_24788 = eta_p_24786 ^ eta_p_24787;\n                \n                eta_p_24786 = defunc_0_op_res_24788;\n            }\n            // write result of operation\n            {\n                ((__local int8_t *) red_arr_i8_mem_24780)[sext_i32_i64(local_tid_24776)] = eta_p_24786;\n            }\n        }\n        skip_waves_24794 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_24776) == (int64_t) 0) {\n            eta_p_block_res_acc_24785 = eta_p_24786;\n        } else {\n            eta_p_block_res_acc_24785 = (int8_t) 0;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_24776 == 0) {\n            ((__global int8_t *) segred_tmp_mem_24772)[sext_i32_i64(block_id_24777)] = eta_p_block_res_acc_24785;\n            mem_fence_global();\n            old_counter_24795 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24770)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_24782)[(int64_t) 0] = old_counter_24795 == sext_i64_i32(num_tblocks_22671 - (int64_t) 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_24796 = ((", "__local bool *) sync_arr_mem_24782)[(int64_t) 0];\n    if (is_last_block_24796) {\n        if (local_tid_24776 == 0) {\n            old_counter_24795 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24770)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_22671));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_24797 = sdiv_up64(num_tblocks_22671, segred_tblock_sizze_22670);\n            \n            eta_p_22677 = (int8_t) 0;\n            for (int64_t i_24798 = 0; i_24798 < read_per_thread_24797; i_24798++) {\n                int64_t block_res_id_24799 = sext_i32_i64(local_tid_24776) * read_per_thread_24797 + i_24798;\n                int64_t index_of_block_res_24800 = block_res_id_24799;\n                \n                if (slt64(block_res_id_24799, num_tblocks_22671)) {\n                    eta_p_22678 = ((__global int8_t *) segred_tmp_mem_24772)[index_of_block_res_24800];\n                    \n                    int8_t defunc_0_op_res_22679 = eta_p_22677 ^ eta_p_22678;\n                    \n                    eta_p_22677 = defunc_0_op_res_22679;\n                }\n            }\n        }\n        ((__local int8_t *) red_arr_i8_mem_24780)[sext_i32_i64(local_tid_24776)] = eta_p_22677;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_24801;\n            int32_t skip_waves_24802 = 1;\n            int8_t eta_p_24786;\n            int8_t eta_p_24787;\n            \n            offset_24801 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_24776, sext_i64_i32(segred_tblock_sizze_22670))) {\n                    eta_p_24786 = ((__local int8_t *) red_arr_i8_mem_24780)[sext_i32_i64(local_tid_24776 + offset_24801)];\n                }\n            }\n            offset_24801 = 1;\n            while (slt32(offset_24801, wave_sizze_24778)) {\n                if (slt32(local_tid_24776 + offset_2",
                                    "4801, sext_i64_i32(segred_tblock_sizze_22670)) && ((local_tid_24776 - squot32(local_tid_24776, wave_sizze_24778) * wave_sizze_24778) & (2 * offset_24801 - 1)) == 0) {\n                    // read array element\n                    {\n                        eta_p_24787 = ((volatile __local int8_t *) red_arr_i8_mem_24780)[sext_i32_i64(local_tid_24776 + offset_24801)];\n                    }\n                    // apply reduction operation\n                    {\n                        int8_t defunc_0_op_res_24788 = eta_p_24786 ^ eta_p_24787;\n                        \n                        eta_p_24786 = defunc_0_op_res_24788;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local int8_t *) red_arr_i8_mem_24780)[sext_i32_i64(local_tid_24776)] = eta_p_24786;\n                    }\n                }\n                offset_24801 *= 2;\n            }\n            while (slt32(skip_waves_24802, squot32(sext_i64_i32(segred_tblock_sizze_22670) + wave_sizze_24778 - 1, wave_sizze_24778))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_24801 = skip_waves_24802 * wave_sizze_24778;\n                if (slt32(local_tid_24776 + offset_24801, sext_i64_i32(segred_tblock_sizze_22670)) && ((local_tid_24776 - squot32(local_tid_24776, wave_sizze_24778) * wave_sizze_24778) == 0 && (squot32(local_tid_24776, wave_sizze_24778) & (2 * skip_waves_24802 - 1)) == 0)) {\n                    // read array element\n                    {\n                        eta_p_24787 = ((__local int8_t *) red_arr_i8_mem_24780)[sext_i32_i64(local_tid_24776 + offset_24801)];\n                    }\n                    // apply reduction operation\n                    {\n                        int8_t defunc_0_op_res_24788 = eta_p_24786 ^ eta_p_24787;\n                        \n                        eta_p_24786 = defunc_0_op_res_24788;\n                    }\n                    // write result of operation\n                   ", " {\n                        ((__local int8_t *) red_arr_i8_mem_24780)[sext_i32_i64(local_tid_24776)] = eta_p_24786;\n                    }\n                }\n                skip_waves_24802 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_24776 == 0) {\n                    ((__global int8_t *) mem_23541)[(int64_t) 0] = eta_p_24786;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_22670\n    #undef chunk_sizze_24769\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegred_nonseg_23843_dim1, 1, 1)\nvoid simulate_8477zisegred_nonseg_23843(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_20948, int64_t num_threads_24223, __global unsigned char *mem_23665, __global unsigned char *mem_23858, __global unsigned char *counters_mem_24219, __global unsigned char *segred_tmp_mem_24221)\n{\n    #define segred_num_tblocks_23834 (simulate_8477zisegred_nonseg_23843zisegred_num_tblocks_23834)\n    #define segred_tblock_sizze_23836 (simulate_8477zisegred_nonseg_23843zisegred_tblock_sizze_23836)\n    #define chunk_sizze_24218 (simulate_8477zisegred_nonseg_23843zichunk_sizze_24218)\n    \n    volatile __local unsigned char *sync_arr_mem_24231_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_24231_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_24229_backing_0 = &shared_mem[sync_arr_mem_24231_backing_1_offset];\n    const int64_t red_arr_i64_mem_24229_backing_0_offset = sync_arr_mem_24231_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_23836 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_23836, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_f", "ailure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24225;\n    int32_t tblock_sizze_24228;\n    int32_t wave_sizze_24227;\n    int32_t block_id_24226;\n    int32_t global_tid_24224;\n    int64_t phys_tid_23843;\n    __local unsigned char *red_arr_i64_mem_24229;\n    __local unsigned char *sync_arr_mem_24231;\n    int64_t dummy_23841;\n    int64_t gtid_23842;\n    int64_t q_24233;\n    int64_t x_block_res_acc_24234;\n    int64_t x_23844;\n    int64_t y_23845;\n    int64_t tblock_id_in_segment_24238;\n    int64_t block_base_offset_24239;\n    int32_t offset_24242;\n    int32_t skip_waves_24243;\n    int64_t x_24235;\n    int64_t y_24236;\n    int32_t old_counter_24244;\n    bool is_last_block_24245;\n    \n    local_tid_24225 = get_local_id(0);\n    tblock_sizze_24228 = get_local_size(0);\n    wave_sizze_24227 = LOCKSTEP_WIDTH;\n    block_id_24226 = get_tblock_id(0);\n    global_tid_24224 = block_id_24226 * tblock_sizze_24228 + local_tid_24225;\n    phys_tid_23843 = sext_i32_i64(global_tid_24224);\n    red_arr_i64_mem_24229 = (__local unsigned char *) red_arr_i64_mem_24229_backing_0;\n    sync_arr_mem_24231 = (__local unsigned char *) sync_arr_mem_24231_backing_1;\n    dummy_23841 = (int64_t) 0;\n    gtid_23842 = (int64_t) 0;\n    q_24233 = sdiv_up64(m_20948, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_23836 * segred_num_tblocks_23834)) * chunk_sizze_24218);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        x_block_res_acc_24234 = (int64_t) 0;\n    }\n    tblock_id_in_segment_24238 = squot64(phys_tid_23843, segred_tblock_sizze_23836);\n    block_base_offset_24239 = tblock_id_in_segment_24238 * q_24233 * segred_tblock_sizze_23836;\n    for (int64_t i_24240 = 0; i_24240 < q_24233; i_24240++) {\n        int64_t block_offset_24241 = block_base_offset_24239 + i_24240 * segred_tblock_sizze_23836;\n        \n        gtid_23842 = phys_tid_23843 + num_threads_24223 * i_24240;\n        if (slt64",
                                    "(gtid_23842, m_20948)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n                    int64_t eta_p_23848 = ((__global int64_t *) mem_23665)[gtid_23842];\n                    bool x_23849 = sle64((int64_t) 0, eta_p_23848);\n                    bool y_23850 = slt64(eta_p_23848, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                    bool bounds_check_23851 = x_23849 && y_23850;\n                    bool index_certs_23852;\n                    \n                    if (!bounds_check_23851) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 7) == -1) {\n                                global_failure_args[0] = (int64_t) eta_p_23848;\n                                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int64_t bytes_23853 = (int64_t) 2 * num_qubits_15486;\n                    \n                    // load accumulator(s)\n                    {\n                        x_23844 = x_block_res_acc_24234;\n                    }\n                    // load next value(s)\n                    {\n                        y_23845 = bytes_23853;\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int64_t zz_23846 = smax64(x_23844, y_23845);\n                        \n                        // store in accumulator(s)\n                        {\n                            x_block_res_acc_24234 = zz_23846;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_failure)\n        return;\n ", "   barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local int64_t *) red_arr_i64_mem_24229)[sext_i32_i64(local_tid_24225)] = x_block_res_acc_24234;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_24243 = 1;\n    offset_24242 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_24225, sext_i64_i32(segred_tblock_sizze_23836))) {\n            x_24235 = ((__local int64_t *) red_arr_i64_mem_24229)[sext_i32_i64(local_tid_24225 + offset_24242)];\n        }\n    }\n    offset_24242 = 1;\n    while (slt32(offset_24242, wave_sizze_24227)) {\n        if (slt32(local_tid_24225 + offset_24242, sext_i64_i32(segred_tblock_sizze_23836)) && ((local_tid_24225 - squot32(local_tid_24225, wave_sizze_24227) * wave_sizze_24227) & (2 * offset_24242 - 1)) == 0) {\n            // read array element\n            {\n                y_24236 = ((volatile __local int64_t *) red_arr_i64_mem_24229)[sext_i32_i64(local_tid_24225 + offset_24242)];\n            }\n            // apply reduction operation\n            {\n                int64_t zz_24237 = smax64(x_24235, y_24236);\n                \n                x_24235 = zz_24237;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_i64_mem_24229)[sext_i32_i64(local_tid_24225)] = x_24235;\n            }\n        }\n        offset_24242 *= 2;\n    }\n    while (slt32(skip_waves_24243, squot32(sext_i64_i32(segred_tblock_sizze_23836) + wave_sizze_24227 - 1, wave_sizze_24227))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_24242 = skip_waves_24243 * wave_sizze_24227;\n        if (slt32(local_tid_24225 + offset_24242, sext_i64_i32(segred_tblock_sizze_23836)) && ((local_tid_24225 - squot32(local_tid_24225, wave_sizze_24227) * wave_sizze_24227) == 0 && (squot32(local_tid_24225, wave_sizze_24227) & (2 * skip_waves_24243 - 1)) == 0)) {\n            // read array element\n            {\n  ", "              y_24236 = ((__local int64_t *) red_arr_i64_mem_24229)[sext_i32_i64(local_tid_24225 + offset_24242)];\n            }\n            // apply reduction operation\n            {\n                int64_t zz_24237 = smax64(x_24235, y_24236);\n                \n                x_24235 = zz_24237;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_i64_mem_24229)[sext_i32_i64(local_tid_24225)] = x_24235;\n            }\n        }\n        skip_waves_24243 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_24225) == (int64_t) 0) {\n            x_block_res_acc_24234 = x_24235;\n        } else {\n            x_block_res_acc_24234 = (int64_t) 0;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_24225 == 0) {\n            ((__global int64_t *) segred_tmp_mem_24221)[sext_i32_i64(block_id_24226)] = x_block_res_acc_24234;\n            mem_fence_global();\n            old_counter_24244 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24219)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_24231)[(int64_t) 0] = old_counter_24244 == sext_i64_i32(segred_num_tblocks_23834 - (int64_t) 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_24245 = ((__local bool *) sync_arr_mem_24231)[(int64_t) 0];\n    if (is_last_block_24245) {\n        if (local_tid_24225 == 0) {\n            old_counter_24244 = atomic_add_i32_global(&((volatile __global int *) counters_mem_24219)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - segred_num_tblocks_23834));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_24246 = sdiv_up64(segred_num_tblocks_23834, segred_tblock_sizze_23836);\n            \n            x_23844 = (int64_t) 0;\n            for (int64",
                                    "_t i_24247 = 0; i_24247 < read_per_thread_24246; i_24247++) {\n                int64_t block_res_id_24248 = sext_i32_i64(local_tid_24225) * read_per_thread_24246 + i_24247;\n                int64_t index_of_block_res_24249 = block_res_id_24248;\n                \n                if (slt64(block_res_id_24248, segred_num_tblocks_23834)) {\n                    y_23845 = ((__global int64_t *) segred_tmp_mem_24221)[index_of_block_res_24249];\n                    \n                    int64_t zz_23846 = smax64(x_23844, y_23845);\n                    \n                    x_23844 = zz_23846;\n                }\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_24229)[sext_i32_i64(local_tid_24225)] = x_23844;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_24250;\n            int32_t skip_waves_24251 = 1;\n            int64_t x_24235;\n            int64_t y_24236;\n            \n            offset_24250 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_24225, sext_i64_i32(segred_tblock_sizze_23836))) {\n                    x_24235 = ((__local int64_t *) red_arr_i64_mem_24229)[sext_i32_i64(local_tid_24225 + offset_24250)];\n                }\n            }\n            offset_24250 = 1;\n            while (slt32(offset_24250, wave_sizze_24227)) {\n                if (slt32(local_tid_24225 + offset_24250, sext_i64_i32(segred_tblock_sizze_23836)) && ((local_tid_24225 - squot32(local_tid_24225, wave_sizze_24227) * wave_sizze_24227) & (2 * offset_24250 - 1)) == 0) {\n                    // read array element\n                    {\n                        y_24236 = ((volatile __local int64_t *) red_arr_i64_mem_24229)[sext_i32_i64(local_tid_24225 + offset_24250)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t zz_24237 = smax64(x_24235, y_24236);\n                        \n      ", "                  x_24235 = zz_24237;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local int64_t *) red_arr_i64_mem_24229)[sext_i32_i64(local_tid_24225)] = x_24235;\n                    }\n                }\n                offset_24250 *= 2;\n            }\n            while (slt32(skip_waves_24251, squot32(sext_i64_i32(segred_tblock_sizze_23836) + wave_sizze_24227 - 1, wave_sizze_24227))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_24250 = skip_waves_24251 * wave_sizze_24227;\n                if (slt32(local_tid_24225 + offset_24250, sext_i64_i32(segred_tblock_sizze_23836)) && ((local_tid_24225 - squot32(local_tid_24225, wave_sizze_24227) * wave_sizze_24227) == 0 && (squot32(local_tid_24225, wave_sizze_24227) & (2 * skip_waves_24251 - 1)) == 0)) {\n                    // read array element\n                    {\n                        y_24236 = ((__local int64_t *) red_arr_i64_mem_24229)[sext_i32_i64(local_tid_24225 + offset_24250)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t zz_24237 = smax64(x_24235, y_24236);\n                        \n                        x_24235 = zz_24237;\n                    }\n                    // write result of operation\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_24229)[sext_i32_i64(local_tid_24225)] = x_24235;\n                    }\n                }\n                skip_waves_24251 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_24225 == 0) {\n                    ((__global int64_t *) mem_23858)[(int64_t) 0] = x_24235;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_num_tblocks_23834\n    #undef segred_tblock_sizze_23836\n    #undef chunk_sizze_24218\n}\nFUTHA", "RK_KERNEL_SIZED(simulate_8477zisegred_small_21963_dim1, 1, 1)\nvoid simulate_8477zisegred_small_21963(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_20948, int64_t num_tblocks_21957, int64_t segment_sizze_nonzzero_24282, __global unsigned char *mem_23405, __global unsigned char *mem_23652, __global unsigned char *mem_23665, __global unsigned char *mem_23668, __global unsigned char *mem_23675, __global unsigned char *mem_23678)\n{\n    #define segred_tblock_sizze_21956 (simulate_8477zisegred_small_21963zisegred_tblock_sizze_21956)\n    \n    volatile __local unsigned char *red_arr_i8_mem_24289_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i8_mem_24289_backing_0_offset = 0 + (segred_tblock_sizze_21956 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_21956, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24285;\n    int32_t tblock_sizze_24288;\n    int32_t wave_sizze_24287;\n    int32_t block_id_24286;\n    int32_t global_tid_24284;\n    int64_t phys_tid_21963;\n    __local unsigned char *red_arr_i8_mem_24289;\n    int32_t phys_tblock_id_24291;\n    int32_t iterations_24292;\n    \n    local_tid_24285 = get_local_id(0);\n    tblock_sizze_24288 = get_local_size(0);\n    wave_sizze_24287 = LOCKSTEP_WIDTH;\n    block_id_24286 = get_tblock_id(0);\n    global_tid_24284 = block_id_24286 * tblock_sizze_24288 + local_tid_24285;\n    phys_tid_21963 = sext_i32_i64(global_tid_24284);\n    red_arr_i8_mem_24289 = (__local unsigned char *) red_arr_i8_mem_24289_backing_0;\n    phys_tblock_id_24291 = get_tblock_id(0);\n    iterations_24292 = sdiv_up32(sext_i64_i32(sdiv_up64(m_20948, squot64(segred_tblock_sizz",
                                    "e_21956, segment_sizze_nonzzero_24282))) - phys_tblock_id_24291, sext_i64_i32(num_tblocks_21957));\n    for (int32_t i_24293 = 0; i_24293 < iterations_24292; i_24293++) {\n        int32_t virt_tblock_id_24294;\n        int64_t slice_24295;\n        int64_t gtid_21961;\n        int64_t remnant_24296;\n        int64_t gtid_21962;\n        \n        virt_tblock_id_24294 = phys_tblock_id_24291 + i_24293 * sext_i64_i32(num_tblocks_21957);\n        slice_24295 = m_20948;\n        gtid_21961 = squot64(sext_i32_i64(local_tid_24285), segment_sizze_nonzzero_24282) + sext_i32_i64(virt_tblock_id_24294) * squot64(segred_tblock_sizze_21956, segment_sizze_nonzzero_24282);\n        remnant_24296 = squot64(sext_i32_i64(local_tid_24285), segment_sizze_nonzzero_24282) + sext_i32_i64(virt_tblock_id_24294) * squot64(segred_tblock_sizze_21956, segment_sizze_nonzzero_24282) - gtid_21961;\n        gtid_21962 = srem64(sext_i32_i64(local_tid_24285), num_qubits_15486);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_qubits_15486) && (slt64(gtid_21961, m_20948) && slt64(sext_i32_i64(local_tid_24285), num_qubits_15486 * squot64(segred_tblock_sizze_21956, segment_sizze_nonzzero_24282)))) {\n                // apply map function\n                {\n                    bool index_certs_21968 = 0;\n                    int64_t g_arg3_21970 = add64(num_qubits_15486, gtid_21962);\n                    bool x_21971 = sle64((int64_t) 0, g_arg3_21970);\n                    bool y_21972 = slt64(g_arg3_21970, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                    bool bounds_check_21973 = x_21971 && y_21972;\n                    bool index_certs_21974;\n                    \n                    if (!bounds_check_21973) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 13) == -1) {\n                                global_failure_args[0] = (int64_t) g_arg3_21970;\n                                global_", "failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    bool y_21977 = slt64(gtid_21962, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                    bool index_certs_21979;\n                    \n                    if (!y_21977) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 14) == -1) {\n                                global_failure_args[0] = (int64_t) gtid_21962;\n                                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int64_t defunc_0_f_res_23205 = ((__global int64_t *) mem_23652)[(int64_t) 0];\n                    int64_t eta_p_21967 = ((__global int64_t *) mem_23665)[gtid_21961];\n                    int8_t g_arg3_21975 = ((__global int8_t *) mem_23405)[eta_p_21967 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + g_arg3_21970];\n                    int8_t g_arg2_21980 = ((__global int8_t *) mem_23405)[eta_p_21967 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + gtid_21962];\n                    int8_t g_arg1_21981 = ((__global int8_t *) mem_23405)[defunc_0_f_res_23205 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + g_arg3_21970];\n                    int8_t g_arg0_21982 = ((__global int8_t *) mem_23405)[defunc_0_f_res_23205 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + gtid_21962];\n                    bool cond_21983 = g", "_arg0_21982 == g_arg2_21980;\n                    bool cond_t_res_21984 = g_arg0_21982 == (int8_t) 0;\n                    bool x_21985 = cond_21983 && cond_t_res_21984;\n                    int8_t g_res_21986;\n                    \n                    if (x_21985) {\n                        g_res_21986 = (int8_t) 0;\n                    } else {\n                        bool cond_t_res_21987 = g_arg0_21982 == (int8_t) 1;\n                        bool x_21988 = cond_21983 && cond_t_res_21987;\n                        int8_t g_res_f_res_21989;\n                        \n                        if (x_21988) {\n                            int8_t g_res_f_res_t_res_21990 = sub8(g_arg3_21975, g_arg1_21981);\n                            \n                            g_res_f_res_21989 = g_res_f_res_t_res_21990;\n                        } else {\n                            bool cond_t_res_21991 = g_arg2_21980 == (int8_t) 0;\n                            bool x_21992 = cond_t_res_21987 && cond_t_res_21991;\n                            int8_t g_res_f_res_f_res_21993;\n                            \n                            if (x_21992) {\n                                int8_t zm_lhs_21994 = mul8((int8_t) 2, g_arg1_21981);\n                                int8_t zt_rhs_21995 = sub8(zm_lhs_21994, (int8_t) 1);\n                                int8_t g_res_f_res_f_res_t_res_21996 = mul8(g_arg3_21975, zt_rhs_21995);\n                                \n                                g_res_f_res_f_res_21993 = g_res_f_res_f_res_t_res_21996;\n                            } else {\n                                bool cond_t_res_21997 = g_arg2_21980 == (int8_t) 1;\n                                bool x_21998 = cond_t_res_21984 && cond_t_res_21997;\n                                int8_t g_res_f_res_f_res_f_res_21999;\n                                \n                                if (x_21998) {\n                                    int8_t zm_rhs_22000 = mul8((int8_t) 2, g_arg3_21975);\n                            ",
                                    "        int8_t zt_rhs_22001 = sub8((int8_t) 1, zm_rhs_22000);\n                                    int8_t g_res_f_res_f_res_f_res_t_res_22002 = mul8(g_arg1_21981, zt_rhs_22001);\n                                    \n                                    g_res_f_res_f_res_f_res_21999 = g_res_f_res_f_res_f_res_t_res_22002;\n                                } else {\n                                    g_res_f_res_f_res_f_res_21999 = (int8_t) 0;\n                                }\n                                g_res_f_res_f_res_21993 = g_res_f_res_f_res_f_res_21999;\n                            }\n                            g_res_f_res_21989 = g_res_f_res_f_res_21993;\n                        }\n                        g_res_21986 = g_res_f_res_21989;\n                    }\n                    \n                    int8_t tmp_22003 = g_arg2_21980 ^ g_arg0_21982;\n                    int8_t tmp_22004 = g_arg3_21975 ^ g_arg1_21981;\n                    int8_t mem_23674[(int64_t) 2];\n                    \n                    mem_23674[(int64_t) 0] = tmp_22003;\n                    mem_23674[(int64_t) 1] = tmp_22004;\n                    // write map-out result(s)\n                    {\n                        for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                            ((__global int8_t *) mem_23678)[gtid_21961 * ((int64_t) 2 * num_qubits_15486) + gtid_21962 * (int64_t) 2 + i_0] = mem_23674[i_0];\n                        }\n                    }\n                    // save results to be reduced\n                    {\n                        ((__local int8_t *) red_arr_i8_mem_24289)[sext_i32_i64(local_tid_24285)] = g_res_21986;\n                    }\n                }\n            } else {\n                ((__local int8_t *) red_arr_i8_mem_24289)[sext_i32_i64(local_tid_24285)] = (int8_t) 0;\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((i", "nt64_t) 0, num_qubits_15486)) {\n            // perform segmented scan to imitate reduction\n            {\n                int8_t eta_p_21964;\n                int8_t eta_p_21965;\n                int8_t eta_p_24297;\n                int8_t eta_p_24298;\n                bool ltid_in_bounds_24300 = slt64(sext_i32_i64(local_tid_24285), num_qubits_15486 * squot64(segred_tblock_sizze_21956, segment_sizze_nonzzero_24282));\n                int32_t skip_threads_24301;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_24300) {\n                        eta_p_21965 = ((volatile __local int8_t *) red_arr_i8_mem_24289)[sext_i32_i64(local_tid_24285)];\n                        if ((local_tid_24285 - squot32(local_tid_24285, 32) * 32) == 0) {\n                            eta_p_21964 = eta_p_21965;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_24301 = 1;\n                    while (slt32(skip_threads_24301, 32)) {\n                        bool thread_active_24302 = sle32(skip_threads_24301, local_tid_24285 - squot32(local_tid_24285, 32) * 32) && ltid_in_bounds_24300;\n                        \n                        if (thread_active_24302) {\n                            // read operands\n                            {\n                                eta_p_21964 = ((volatile __local int8_t *) red_arr_i8_mem_24289)[sext_i32_i64(local_tid_24285) - sext_i32_i64(skip_threads_24301)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_24303 = slt64(srem64(sext_i32_i64(local_tid_24285), num_qubits_15486), sext_i32_i64(local_tid_24285) - sext_i32_i64(local_tid_24285 - skip_threads_24301));\n                            \n                            if (thread_active_24302 && inactive_243", "03) {\n                                eta_p_21964 = eta_p_21965;\n                            }\n                            if (thread_active_24302) {\n                                if (!inactive_24303) {\n                                    int8_t defunc_0_op_res_21966 = add8(eta_p_21964, eta_p_21965);\n                                    \n                                    eta_p_21964 = defunc_0_op_res_21966;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_24287, skip_threads_24301)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_24302) {\n                            // write result\n                            {\n                                ((volatile __local int8_t *) red_arr_i8_mem_24289)[sext_i32_i64(local_tid_24285)] = eta_p_21964;\n                                eta_p_21965 = eta_p_21964;\n                            }\n                        }\n                        if (sle32(wave_sizze_24287, skip_threads_24301)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_24301 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_24285 - squot32(local_tid_24285, 32) * 32) == 31 && ltid_in_bounds_24300) {\n                        ((volatile __local int8_t *) red_arr_i8_mem_24289)[sext_i32_i64(squot32(local_tid_24285, 32))] = eta_p_21964;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_24304;\n                    \n                    // read input for in-block scan\n            ",
                                    "        {\n                        if (squot32(local_tid_24285, 32) == 0 && ltid_in_bounds_24300) {\n                            eta_p_24298 = ((volatile __local int8_t *) red_arr_i8_mem_24289)[sext_i32_i64(local_tid_24285)];\n                            if ((local_tid_24285 - squot32(local_tid_24285, 32) * 32) == 0) {\n                                eta_p_24297 = eta_p_24298;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_24304 = 1;\n                        while (slt32(skip_threads_24304, 32)) {\n                            bool thread_active_24305 = sle32(skip_threads_24304, local_tid_24285 - squot32(local_tid_24285, 32) * 32) && (squot32(local_tid_24285, 32) == 0 && ltid_in_bounds_24300);\n                            \n                            if (thread_active_24305) {\n                                // read operands\n                                {\n                                    eta_p_24297 = ((volatile __local int8_t *) red_arr_i8_mem_24289)[sext_i32_i64(local_tid_24285) - sext_i32_i64(skip_threads_24304)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_24306 = slt64(srem64(sext_i32_i64(local_tid_24285 * 32 + 32 - 1), num_qubits_15486), sext_i32_i64(local_tid_24285 * 32 + 32 - 1) - sext_i32_i64((local_tid_24285 - skip_threads_24304) * 32 + 32 - 1));\n                                \n                                if (thread_active_24305 && inactive_24306) {\n                                    eta_p_24297 = eta_p_24298;\n                                }\n                                if (thread_active_24305) {\n                                    if (!inactive_24306) {\n                                        int8_t defunc_0_op_res_24299 = add8(eta_p_24297, eta_p_2", "4298);\n                                        \n                                        eta_p_24297 = defunc_0_op_res_24299;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_24287, skip_threads_24304)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_24305) {\n                                // write result\n                                {\n                                    ((volatile __local int8_t *) red_arr_i8_mem_24289)[sext_i32_i64(local_tid_24285)] = eta_p_24297;\n                                    eta_p_24298 = eta_p_24297;\n                                }\n                            }\n                            if (sle32(wave_sizze_24287, skip_threads_24304)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_24304 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_24307 = squot32(local_tid_24285, 32) == 0 || !ltid_in_bounds_24300;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_24307) {\n                            eta_p_21965 = eta_p_21964;\n                            eta_p_21964 = ((__local int8_t *) red_arr_i8_mem_24289)[sext_i32_i64(squot32(local_tid_24285, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_24308 = slt64(srem64(sext_i32_i64(local_tid_24285), num_qubits_15486), sext_i32_i64(local_tid_24285) - sext_i32_i64(squot32(local_tid_24285, 32) * 32 - 1));\n                        \n                 ", "       if (!no_carry_in_24307) {\n                            if (inactive_24308) {\n                                eta_p_21964 = eta_p_21965;\n                            }\n                        }\n                        if (!no_carry_in_24307) {\n                            if (!inactive_24308) {\n                                int8_t defunc_0_op_res_21966 = add8(eta_p_21964, eta_p_21965);\n                                \n                                eta_p_21964 = defunc_0_op_res_21966;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_24307) {\n                            ((__local int8_t *) red_arr_i8_mem_24289)[sext_i32_i64(local_tid_24285)] = eta_p_21964;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_24285, 32) == 0 && ltid_in_bounds_24300) {\n                        ((__local int8_t *) red_arr_i8_mem_24289)[sext_i32_i64(local_tid_24285)] = eta_p_21965;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_24294) * squot64(segred_tblock_sizze_21956, segment_sizze_nonzzero_24282) + sext_i32_i64(local_tid_24285), m_20948) && slt64(sext_i32_i64(local_tid_24285), squot64(segred_tblock_sizze_21956, segment_sizze_nonzzero_24282))) {\n                int8_t tmp_24309 = ((__local int8_t *) red_arr_i8_mem_24289)[(sext_i32_i64(local_tid_24285) + (int64_t) 1) * segment_sizze_nonzzero_24282 - (int64_t) 1];\n                \n                ((__global int8_t *) mem_23675)[sext_i32_i64(virt_tblock_id_24294) * squot64(segred_tblock_sizze_21956, segment_sizze_nonzzero_24282) ",
                                    "+ sext_i32_i64(local_tid_24285)] = tmp_24309;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_21956\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegred_small_22608_dim1, 1, 1)\nvoid simulate_8477zisegred_small_22608(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t m_21170, int64_t num_tblocks_22601, int64_t segment_sizze_nonzzero_24688, __global unsigned char *mem_23405, __global unsigned char *mem_23475, __global unsigned char *mem_23477, __global unsigned char *mem_23480, __global unsigned char *mem_23482, __global unsigned char *mem_23484)\n{\n    #define segred_tblock_sizze_22600 (simulate_8477zisegred_small_22608zisegred_tblock_sizze_22600)\n    \n    volatile __local unsigned char *red_arr_i8_mem_24695_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i8_mem_24695_backing_0_offset = 0 + (segred_tblock_sizze_22600 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22600, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24691;\n    int32_t tblock_sizze_24694;\n    int32_t wave_sizze_24693;\n    int32_t block_id_24692;\n    int32_t global_tid_24690;\n    int64_t phys_tid_22608;\n    __local unsigned char *red_arr_i8_mem_24695;\n    int32_t phys_tblock_id_24697;\n    int32_t iterations_24698;\n    \n    local_tid_24691 = get_local_id(0);\n    tblock_sizze_24694 = get_local_size(0);\n    wave_sizze_24693 = LOCKSTEP_WIDTH;\n    block_id_24692 = get_tblock_id(0);\n    global_tid_24690 = block_id_24692 * tblock_sizze_24694 + local_tid_24691;\n    phys", "_tid_22608 = sext_i32_i64(global_tid_24690);\n    red_arr_i8_mem_24695 = (__local unsigned char *) red_arr_i8_mem_24695_backing_0;\n    phys_tblock_id_24697 = get_tblock_id(0);\n    iterations_24698 = sdiv_up32(sext_i64_i32(sdiv_up64(m_21170, squot64(segred_tblock_sizze_22600, segment_sizze_nonzzero_24688))) - phys_tblock_id_24697, sext_i64_i32(num_tblocks_22601));\n    for (int32_t i_24699 = 0; i_24699 < iterations_24698; i_24699++) {\n        int32_t virt_tblock_id_24700;\n        int64_t slice_24701;\n        int64_t gtid_22606;\n        int64_t remnant_24702;\n        int64_t gtid_22607;\n        \n        virt_tblock_id_24700 = phys_tblock_id_24697 + i_24699 * sext_i64_i32(num_tblocks_22601);\n        slice_24701 = m_21170;\n        gtid_22606 = squot64(sext_i32_i64(local_tid_24691), segment_sizze_nonzzero_24688) + sext_i32_i64(virt_tblock_id_24700) * squot64(segred_tblock_sizze_22600, segment_sizze_nonzzero_24688);\n        remnant_24702 = squot64(sext_i32_i64(local_tid_24691), segment_sizze_nonzzero_24688) + sext_i32_i64(virt_tblock_id_24700) * squot64(segred_tblock_sizze_22600, segment_sizze_nonzzero_24688) - gtid_22606;\n        gtid_22607 = srem64(sext_i32_i64(local_tid_24691), num_qubits_15486);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_qubits_15486) && (slt64(gtid_22606, m_21170) && slt64(sext_i32_i64(local_tid_24691), num_qubits_15486 * squot64(segred_tblock_sizze_22600, segment_sizze_nonzzero_24688)))) {\n                // apply map function\n                {\n                    bool index_certs_22613 = 0;\n                    int64_t g_arg3_22615 = add64(num_qubits_15486, gtid_22607);\n                    bool x_22616 = sle64((int64_t) 0, g_arg3_22615);\n                    bool y_22617 = slt64(g_arg3_22615, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                    bool bounds_check_22618 = x_22616 && y_22617;\n                    bool index_certs_22619;\n                    \n                  ", "  if (!bounds_check_22618) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 28) == -1) {\n                                global_failure_args[0] = (int64_t) g_arg3_22615;\n                                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    bool y_22622 = slt64(gtid_22607, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                    bool index_certs_22624;\n                    \n                    if (!y_22622) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 29) == -1) {\n                                global_failure_args[0] = (int64_t) gtid_22607;\n                                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int64_t idx_22612 = ((__global int64_t *) mem_23477)[gtid_22606];\n                    int8_t g_arg2_22625 = ((__global int8_t *) mem_23405)[arg_15490 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + gtid_22607];\n                    int8_t g_arg1_22626 = ((__global int8_t *) mem_23405)[idx_22612 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + g_arg3_22615];\n                    int8_t g_arg0_22627 = ((__global int8_t *) mem_23405)[idx_22612 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + gtid_22607];\n                    bool cond_22628 = g_arg0_22627 == g_arg2_22625",
                                    ";\n                    bool cond_t_res_22629 = g_arg0_22627 == (int8_t) 0;\n                    bool x_22630 = cond_22628 && cond_t_res_22629;\n                    int8_t g_res_22631;\n                    \n                    if (x_22630) {\n                        g_res_22631 = (int8_t) 0;\n                    } else {\n                        int8_t g_arg3_22620 = ((__global int8_t *) mem_23405)[arg_15490 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + g_arg3_22615];\n                        bool cond_t_res_22632 = g_arg0_22627 == (int8_t) 1;\n                        bool x_22633 = cond_22628 && cond_t_res_22632;\n                        int8_t g_res_f_res_22634;\n                        \n                        if (x_22633) {\n                            int8_t g_res_f_res_t_res_22635 = sub8(g_arg3_22620, g_arg1_22626);\n                            \n                            g_res_f_res_22634 = g_res_f_res_t_res_22635;\n                        } else {\n                            bool cond_t_res_22636 = g_arg2_22625 == (int8_t) 0;\n                            bool x_22637 = cond_t_res_22632 && cond_t_res_22636;\n                            int8_t g_res_f_res_f_res_22638;\n                            \n                            if (x_22637) {\n                                int8_t zm_lhs_22639 = mul8((int8_t) 2, g_arg1_22626);\n                                int8_t zt_rhs_22640 = sub8(zm_lhs_22639, (int8_t) 1);\n                                int8_t g_res_f_res_f_res_t_res_22641 = mul8(g_arg3_22620, zt_rhs_22640);\n                                \n                                g_res_f_res_f_res_22638 = g_res_f_res_f_res_t_res_22641;\n                            } else {\n                                bool cond_t_res_22642 = g_arg2_22625 == (int8_t) 1;\n                                bool x_22643 = cond_t_res_22629 && cond_t_res_22642;\n                                int8_t g_res_f_res_f_res_f_res_22644;\n                                \n                     ", "           if (x_22643) {\n                                    int8_t zm_rhs_22645 = mul8((int8_t) 2, g_arg3_22620);\n                                    int8_t zt_rhs_22646 = sub8((int8_t) 1, zm_rhs_22645);\n                                    int8_t g_res_f_res_f_res_f_res_t_res_22647 = mul8(g_arg1_22626, zt_rhs_22646);\n                                    \n                                    g_res_f_res_f_res_f_res_22644 = g_res_f_res_f_res_f_res_t_res_22647;\n                                } else {\n                                    g_res_f_res_f_res_f_res_22644 = (int8_t) 0;\n                                }\n                                g_res_f_res_f_res_22638 = g_res_f_res_f_res_f_res_22644;\n                            }\n                            g_res_f_res_22634 = g_res_f_res_f_res_22638;\n                        }\n                        g_res_22631 = g_res_f_res_22634;\n                    }\n                    // write map-out result(s)\n                    {\n                        ((__global int8_t *) mem_23482)[gtid_22606 * num_qubits_15486 + gtid_22607] = g_arg1_22626;\n                        ((__global int8_t *) mem_23484)[gtid_22606 * num_qubits_15486 + gtid_22607] = g_arg0_22627;\n                    }\n                    // save results to be reduced\n                    {\n                        ((__local int8_t *) red_arr_i8_mem_24695)[sext_i32_i64(local_tid_24691)] = g_res_22631;\n                    }\n                }\n            } else {\n                ((__local int8_t *) red_arr_i8_mem_24695)[sext_i32_i64(local_tid_24691)] = (int8_t) 0;\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_qubits_15486)) {\n            // perform segmented scan to imitate reduction\n            {\n                int8_t eta_p_22609;\n                int8_t eta_p_22610;\n                int8_t eta_p_24703;\n          ", "      int8_t eta_p_24704;\n                bool ltid_in_bounds_24706 = slt64(sext_i32_i64(local_tid_24691), num_qubits_15486 * squot64(segred_tblock_sizze_22600, segment_sizze_nonzzero_24688));\n                int32_t skip_threads_24707;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_24706) {\n                        eta_p_22610 = ((volatile __local int8_t *) red_arr_i8_mem_24695)[sext_i32_i64(local_tid_24691)];\n                        if ((local_tid_24691 - squot32(local_tid_24691, 32) * 32) == 0) {\n                            eta_p_22609 = eta_p_22610;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_24707 = 1;\n                    while (slt32(skip_threads_24707, 32)) {\n                        bool thread_active_24708 = sle32(skip_threads_24707, local_tid_24691 - squot32(local_tid_24691, 32) * 32) && ltid_in_bounds_24706;\n                        \n                        if (thread_active_24708) {\n                            // read operands\n                            {\n                                eta_p_22609 = ((volatile __local int8_t *) red_arr_i8_mem_24695)[sext_i32_i64(local_tid_24691) - sext_i32_i64(skip_threads_24707)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_24709 = slt64(srem64(sext_i32_i64(local_tid_24691), num_qubits_15486), sext_i32_i64(local_tid_24691) - sext_i32_i64(local_tid_24691 - skip_threads_24707));\n                            \n                            if (thread_active_24708 && inactive_24709) {\n                                eta_p_22609 = eta_p_22610;\n                            }\n                            if (thread_active_24708) {\n                                if (!inactive_24709) {\n                  ",
                                    "                  int8_t defunc_0_op_res_22611 = add8(eta_p_22609, eta_p_22610);\n                                    \n                                    eta_p_22609 = defunc_0_op_res_22611;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_24693, skip_threads_24707)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_24708) {\n                            // write result\n                            {\n                                ((volatile __local int8_t *) red_arr_i8_mem_24695)[sext_i32_i64(local_tid_24691)] = eta_p_22609;\n                                eta_p_22610 = eta_p_22609;\n                            }\n                        }\n                        if (sle32(wave_sizze_24693, skip_threads_24707)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_24707 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_24691 - squot32(local_tid_24691, 32) * 32) == 31 && ltid_in_bounds_24706) {\n                        ((volatile __local int8_t *) red_arr_i8_mem_24695)[sext_i32_i64(squot32(local_tid_24691, 32))] = eta_p_22609;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_24710;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_24691, 32) == 0 && ltid_in_bounds_24706) {\n                            eta_p_24704 = ((volatile __local int8_t *) red_arr_i8_mem_24695)[sext_i32_i64(local_tid_24691)];", "\n                            if ((local_tid_24691 - squot32(local_tid_24691, 32) * 32) == 0) {\n                                eta_p_24703 = eta_p_24704;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_24710 = 1;\n                        while (slt32(skip_threads_24710, 32)) {\n                            bool thread_active_24711 = sle32(skip_threads_24710, local_tid_24691 - squot32(local_tid_24691, 32) * 32) && (squot32(local_tid_24691, 32) == 0 && ltid_in_bounds_24706);\n                            \n                            if (thread_active_24711) {\n                                // read operands\n                                {\n                                    eta_p_24703 = ((volatile __local int8_t *) red_arr_i8_mem_24695)[sext_i32_i64(local_tid_24691) - sext_i32_i64(skip_threads_24710)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_24712 = slt64(srem64(sext_i32_i64(local_tid_24691 * 32 + 32 - 1), num_qubits_15486), sext_i32_i64(local_tid_24691 * 32 + 32 - 1) - sext_i32_i64((local_tid_24691 - skip_threads_24710) * 32 + 32 - 1));\n                                \n                                if (thread_active_24711 && inactive_24712) {\n                                    eta_p_24703 = eta_p_24704;\n                                }\n                                if (thread_active_24711) {\n                                    if (!inactive_24712) {\n                                        int8_t defunc_0_op_res_24705 = add8(eta_p_24703, eta_p_24704);\n                                        \n                                        eta_p_24703 = defunc_0_op_res_24705;\n                                    }\n                                }\n                          ", "  }\n                            if (sle32(wave_sizze_24693, skip_threads_24710)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_24711) {\n                                // write result\n                                {\n                                    ((volatile __local int8_t *) red_arr_i8_mem_24695)[sext_i32_i64(local_tid_24691)] = eta_p_24703;\n                                    eta_p_24704 = eta_p_24703;\n                                }\n                            }\n                            if (sle32(wave_sizze_24693, skip_threads_24710)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_24710 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_24713 = squot32(local_tid_24691, 32) == 0 || !ltid_in_bounds_24706;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_24713) {\n                            eta_p_22610 = eta_p_22609;\n                            eta_p_22609 = ((__local int8_t *) red_arr_i8_mem_24695)[sext_i32_i64(squot32(local_tid_24691, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_24714 = slt64(srem64(sext_i32_i64(local_tid_24691), num_qubits_15486), sext_i32_i64(local_tid_24691) - sext_i32_i64(squot32(local_tid_24691, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_24713) {\n                            if (inactive_24714) {\n                                eta_p_22609 = eta_p_22610;\n                            }\n                        }\n                        i",
                                    "f (!no_carry_in_24713) {\n                            if (!inactive_24714) {\n                                int8_t defunc_0_op_res_22611 = add8(eta_p_22609, eta_p_22610);\n                                \n                                eta_p_22609 = defunc_0_op_res_22611;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_24713) {\n                            ((__local int8_t *) red_arr_i8_mem_24695)[sext_i32_i64(local_tid_24691)] = eta_p_22609;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_24691, 32) == 0 && ltid_in_bounds_24706) {\n                        ((__local int8_t *) red_arr_i8_mem_24695)[sext_i32_i64(local_tid_24691)] = eta_p_22610;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_24700) * squot64(segred_tblock_sizze_22600, segment_sizze_nonzzero_24688) + sext_i32_i64(local_tid_24691), m_21170) && slt64(sext_i32_i64(local_tid_24691), squot64(segred_tblock_sizze_22600, segment_sizze_nonzzero_24688))) {\n                int8_t tmp_24715 = ((__local int8_t *) red_arr_i8_mem_24695)[(sext_i32_i64(local_tid_24691) + (int64_t) 1) * segment_sizze_nonzzero_24688 - (int64_t) 1];\n                \n                ((__global int8_t *) mem_23480)[sext_i32_i64(virt_tblock_id_24700) * squot64(segred_tblock_sizze_22600, segment_sizze_nonzzero_24688) + sext_i32_i64(local_tid_24691)] = tmp_24715;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tb", "lock_sizze_22600\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegred_small_22739_dim1, 1, 1)\nvoid simulate_8477zisegred_small_22739(__global int *global_failure, int64_t num_qubits_15486, int64_t m_21170, int64_t num_tblocks_22734, int64_t segment_sizze_nonzzero_24821, __global unsigned char *mem_23614, __global unsigned char *mem_23616)\n{\n    #define segred_tblock_sizze_22733 (simulate_8477zisegred_small_22739zisegred_tblock_sizze_22733)\n    \n    volatile __local unsigned char *red_arr_i8_mem_24828_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i8_mem_24828_backing_0_offset = 0 + (segred_tblock_sizze_22733 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22733, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24824;\n    int32_t tblock_sizze_24827;\n    int32_t wave_sizze_24826;\n    int32_t block_id_24825;\n    int32_t global_tid_24823;\n    int64_t phys_tid_22739;\n    __local unsigned char *red_arr_i8_mem_24828;\n    int32_t phys_tblock_id_24830;\n    int32_t iterations_24831;\n    \n    local_tid_24824 = get_local_id(0);\n    tblock_sizze_24827 = get_local_size(0);\n    wave_sizze_24826 = LOCKSTEP_WIDTH;\n    block_id_24825 = get_tblock_id(0);\n    global_tid_24823 = block_id_24825 * tblock_sizze_24827 + local_tid_24824;\n    phys_tid_22739 = sext_i32_i64(global_tid_24823);\n    red_arr_i8_mem_24828 = (__local unsigned char *) red_arr_i8_mem_24828_backing_0;\n    phys_tblock_id_24830 = get_tblock_id(0);\n    iterations_24831 = sdiv_up32(sext_i64_i32(sdiv_up64(num_qubits_15486, squot64(segred_tblock_sizze_22733, segment_sizze_nonzzero_24821))) - phys_tblock_id_24830, sext_i64_i32(num_tblocks_22734));\n    for (int32_t i_24832 = 0; i_24832 < iterations_24831; i_24832++) {\n        int32_t virt_tblock_id_24833;\n        int64_t slice_24834;\n        int64_t gtid_22737;\n        int64_t remnant_24835;\n        int64_t gtid_22738;\n        \n        virt_tblock_id_24833 = phys_tblock_id_24830 + i_24832 * sext_i64_i32(num_tblocks_2273", "4);\n        slice_24834 = num_qubits_15486;\n        gtid_22737 = squot64(sext_i32_i64(local_tid_24824), segment_sizze_nonzzero_24821) + sext_i32_i64(virt_tblock_id_24833) * squot64(segred_tblock_sizze_22733, segment_sizze_nonzzero_24821);\n        remnant_24835 = squot64(sext_i32_i64(local_tid_24824), segment_sizze_nonzzero_24821) + sext_i32_i64(virt_tblock_id_24833) * squot64(segred_tblock_sizze_22733, segment_sizze_nonzzero_24821) - gtid_22737;\n        gtid_22738 = srem64(sext_i32_i64(local_tid_24824), m_21170);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, m_21170) && (slt64(gtid_22737, num_qubits_15486) && slt64(sext_i32_i64(local_tid_24824), m_21170 * squot64(segred_tblock_sizze_22733, segment_sizze_nonzzero_24821)))) {\n                // apply map function\n                {\n                    int8_t x_22744 = ((__global int8_t *) mem_23614)[gtid_22738 + gtid_22737 * m_21170];\n                    \n                    // save results to be reduced\n                    {\n                        ((__local int8_t *) red_arr_i8_mem_24828)[sext_i32_i64(local_tid_24824)] = x_22744;\n                    }\n                }\n            } else {\n                ((__local int8_t *) red_arr_i8_mem_24828)[sext_i32_i64(local_tid_24824)] = (int8_t) 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, m_21170)) {\n            // perform segmented scan to imitate reduction\n            {\n                int8_t eta_p_22740;\n                int8_t eta_p_22741;\n                int8_t eta_p_24836;\n                int8_t eta_p_24837;\n                bool ltid_in_bounds_24839 = slt64(sext_i32_i64(local_tid_24824), m_21170 * squot64(segred_tblock_sizze_22733, segment_sizze_nonzzero_24821));\n                int32_t skip_threads_24840;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_24839) {\n                        eta_p_22741 = ((vol",
                                    "atile __local int8_t *) red_arr_i8_mem_24828)[sext_i32_i64(local_tid_24824)];\n                        if ((local_tid_24824 - squot32(local_tid_24824, 32) * 32) == 0) {\n                            eta_p_22740 = eta_p_22741;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_24840 = 1;\n                    while (slt32(skip_threads_24840, 32)) {\n                        bool thread_active_24841 = sle32(skip_threads_24840, local_tid_24824 - squot32(local_tid_24824, 32) * 32) && ltid_in_bounds_24839;\n                        \n                        if (thread_active_24841) {\n                            // read operands\n                            {\n                                eta_p_22740 = ((volatile __local int8_t *) red_arr_i8_mem_24828)[sext_i32_i64(local_tid_24824) - sext_i32_i64(skip_threads_24840)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_24842 = slt64(srem64(sext_i32_i64(local_tid_24824), m_21170), sext_i32_i64(local_tid_24824) - sext_i32_i64(local_tid_24824 - skip_threads_24840));\n                            \n                            if (thread_active_24841 && inactive_24842) {\n                                eta_p_22740 = eta_p_22741;\n                            }\n                            if (thread_active_24841) {\n                                if (!inactive_24842) {\n                                    int8_t defunc_0_op_res_22742 = eta_p_22740 ^ eta_p_22741;\n                                    \n                                    eta_p_22740 = defunc_0_op_res_22742;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_24826, skip_threads_24840)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n           ", "             }\n                        if (thread_active_24841) {\n                            // write result\n                            {\n                                ((volatile __local int8_t *) red_arr_i8_mem_24828)[sext_i32_i64(local_tid_24824)] = eta_p_22740;\n                                eta_p_22741 = eta_p_22740;\n                            }\n                        }\n                        if (sle32(wave_sizze_24826, skip_threads_24840)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_24840 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_24824 - squot32(local_tid_24824, 32) * 32) == 31 && ltid_in_bounds_24839) {\n                        ((volatile __local int8_t *) red_arr_i8_mem_24828)[sext_i32_i64(squot32(local_tid_24824, 32))] = eta_p_22740;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_24843;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_24824, 32) == 0 && ltid_in_bounds_24839) {\n                            eta_p_24837 = ((volatile __local int8_t *) red_arr_i8_mem_24828)[sext_i32_i64(local_tid_24824)];\n                            if ((local_tid_24824 - squot32(local_tid_24824, 32) * 32) == 0) {\n                                eta_p_24836 = eta_p_24837;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_24843 = 1;\n                        while (slt32(skip_threads_24843", ", 32)) {\n                            bool thread_active_24844 = sle32(skip_threads_24843, local_tid_24824 - squot32(local_tid_24824, 32) * 32) && (squot32(local_tid_24824, 32) == 0 && ltid_in_bounds_24839);\n                            \n                            if (thread_active_24844) {\n                                // read operands\n                                {\n                                    eta_p_24836 = ((volatile __local int8_t *) red_arr_i8_mem_24828)[sext_i32_i64(local_tid_24824) - sext_i32_i64(skip_threads_24843)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_24845 = slt64(srem64(sext_i32_i64(local_tid_24824 * 32 + 32 - 1), m_21170), sext_i32_i64(local_tid_24824 * 32 + 32 - 1) - sext_i32_i64((local_tid_24824 - skip_threads_24843) * 32 + 32 - 1));\n                                \n                                if (thread_active_24844 && inactive_24845) {\n                                    eta_p_24836 = eta_p_24837;\n                                }\n                                if (thread_active_24844) {\n                                    if (!inactive_24845) {\n                                        int8_t defunc_0_op_res_24838 = eta_p_24836 ^ eta_p_24837;\n                                        \n                                        eta_p_24836 = defunc_0_op_res_24838;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_24826, skip_threads_24843)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_24844) {\n                                // write result\n                                {\n                                    ((volatile __local int8_t *) red_arr_i8_mem_24828)[sext_i32_i64(local_tid_24824)] = eta_p_2",
                                    "4836;\n                                    eta_p_24837 = eta_p_24836;\n                                }\n                            }\n                            if (sle32(wave_sizze_24826, skip_threads_24843)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_24843 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_24846 = squot32(local_tid_24824, 32) == 0 || !ltid_in_bounds_24839;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_24846) {\n                            eta_p_22741 = eta_p_22740;\n                            eta_p_22740 = ((__local int8_t *) red_arr_i8_mem_24828)[sext_i32_i64(squot32(local_tid_24824, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_24847 = slt64(srem64(sext_i32_i64(local_tid_24824), m_21170), sext_i32_i64(local_tid_24824) - sext_i32_i64(squot32(local_tid_24824, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_24846) {\n                            if (inactive_24847) {\n                                eta_p_22740 = eta_p_22741;\n                            }\n                        }\n                        if (!no_carry_in_24846) {\n                            if (!inactive_24847) {\n                                int8_t defunc_0_op_res_22742 = eta_p_22740 ^ eta_p_22741;\n                                \n                                eta_p_22740 = defunc_0_op_res_22742;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_", "in_24846) {\n                            ((__local int8_t *) red_arr_i8_mem_24828)[sext_i32_i64(local_tid_24824)] = eta_p_22740;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_24824, 32) == 0 && ltid_in_bounds_24839) {\n                        ((__local int8_t *) red_arr_i8_mem_24828)[sext_i32_i64(local_tid_24824)] = eta_p_22741;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_24833) * squot64(segred_tblock_sizze_22733, segment_sizze_nonzzero_24821) + sext_i32_i64(local_tid_24824), num_qubits_15486) && slt64(sext_i32_i64(local_tid_24824), squot64(segred_tblock_sizze_22733, segment_sizze_nonzzero_24821))) {\n                int8_t tmp_24848 = ((__local int8_t *) red_arr_i8_mem_24828)[(sext_i32_i64(local_tid_24824) + (int64_t) 1) * segment_sizze_nonzzero_24821 - (int64_t) 1];\n                \n                ((__global int8_t *) mem_23616)[sext_i32_i64(virt_tblock_id_24833) * squot64(segred_tblock_sizze_22733, segment_sizze_nonzzero_24821) + sext_i32_i64(local_tid_24824)] = tmp_24848;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_22733\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegred_small_22800_dim1, 1, 1)\nvoid simulate_8477zisegred_small_22800(__global int *global_failure, int64_t num_qubits_15486, int64_t m_21170, int64_t num_tblocks_22795, int64_t segment_sizze_nonzzero_24904, __global unsigned char *mem_23629, __global unsigned char *mem_23631)\n{\n    #define segred_tblock_sizze_22794 (simulate_8477zisegred_small_22800zisegred_tblock_sizze_22794)\n    \n   ", " volatile __local unsigned char *red_arr_i8_mem_24911_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i8_mem_24911_backing_0_offset = 0 + (segred_tblock_sizze_22794 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22794, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24907;\n    int32_t tblock_sizze_24910;\n    int32_t wave_sizze_24909;\n    int32_t block_id_24908;\n    int32_t global_tid_24906;\n    int64_t phys_tid_22800;\n    __local unsigned char *red_arr_i8_mem_24911;\n    int32_t phys_tblock_id_24913;\n    int32_t iterations_24914;\n    \n    local_tid_24907 = get_local_id(0);\n    tblock_sizze_24910 = get_local_size(0);\n    wave_sizze_24909 = LOCKSTEP_WIDTH;\n    block_id_24908 = get_tblock_id(0);\n    global_tid_24906 = block_id_24908 * tblock_sizze_24910 + local_tid_24907;\n    phys_tid_22800 = sext_i32_i64(global_tid_24906);\n    red_arr_i8_mem_24911 = (__local unsigned char *) red_arr_i8_mem_24911_backing_0;\n    phys_tblock_id_24913 = get_tblock_id(0);\n    iterations_24914 = sdiv_up32(sext_i64_i32(sdiv_up64(num_qubits_15486, squot64(segred_tblock_sizze_22794, segment_sizze_nonzzero_24904))) - phys_tblock_id_24913, sext_i64_i32(num_tblocks_22795));\n    for (int32_t i_24915 = 0; i_24915 < iterations_24914; i_24915++) {\n        int32_t virt_tblock_id_24916;\n        int64_t slice_24917;\n        int64_t gtid_22798;\n        int64_t remnant_24918;\n        int64_t gtid_22799;\n        \n        virt_tblock_id_24916 = phys_tblock_id_24913 + i_24915 * sext_i64_i32(num_tblocks_22795);\n        slice_24917 = num_qubits_15486;\n        gtid_22798 = squot64(sext_i32_i64(local_tid_24907), segment_sizze_nonzzero_24904) + sext_i32_i64(virt_tblock_id_24916) * squot64(segred_tblock_sizze_22794, segment_sizze_nonzzero_24904);\n        remnant_24918 = squot64(sext_i32_i64(local_tid_24907), segment_sizze_nonzzero_24904) + sext_i32_i64(virt_tblock_id_24916) * squot64(segred_tblock_sizze_22794, segment_sizze_nonzzero_24904) - gtid_2",
                                    "2798;\n        gtid_22799 = srem64(sext_i32_i64(local_tid_24907), m_21170);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, m_21170) && (slt64(gtid_22798, num_qubits_15486) && slt64(sext_i32_i64(local_tid_24907), m_21170 * squot64(segred_tblock_sizze_22794, segment_sizze_nonzzero_24904)))) {\n                // apply map function\n                {\n                    int8_t x_22805 = ((__global int8_t *) mem_23629)[gtid_22799 + gtid_22798 * m_21170];\n                    \n                    // save results to be reduced\n                    {\n                        ((__local int8_t *) red_arr_i8_mem_24911)[sext_i32_i64(local_tid_24907)] = x_22805;\n                    }\n                }\n            } else {\n                ((__local int8_t *) red_arr_i8_mem_24911)[sext_i32_i64(local_tid_24907)] = (int8_t) 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, m_21170)) {\n            // perform segmented scan to imitate reduction\n            {\n                int8_t eta_p_22801;\n                int8_t eta_p_22802;\n                int8_t eta_p_24919;\n                int8_t eta_p_24920;\n                bool ltid_in_bounds_24922 = slt64(sext_i32_i64(local_tid_24907), m_21170 * squot64(segred_tblock_sizze_22794, segment_sizze_nonzzero_24904));\n                int32_t skip_threads_24923;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_24922) {\n                        eta_p_22802 = ((volatile __local int8_t *) red_arr_i8_mem_24911)[sext_i32_i64(local_tid_24907)];\n                        if ((local_tid_24907 - squot32(local_tid_24907, 32) * 32) == 0) {\n                            eta_p_22801 = eta_p_22802;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_24923 = 1;\n                    while (sl", "t32(skip_threads_24923, 32)) {\n                        bool thread_active_24924 = sle32(skip_threads_24923, local_tid_24907 - squot32(local_tid_24907, 32) * 32) && ltid_in_bounds_24922;\n                        \n                        if (thread_active_24924) {\n                            // read operands\n                            {\n                                eta_p_22801 = ((volatile __local int8_t *) red_arr_i8_mem_24911)[sext_i32_i64(local_tid_24907) - sext_i32_i64(skip_threads_24923)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_24925 = slt64(srem64(sext_i32_i64(local_tid_24907), m_21170), sext_i32_i64(local_tid_24907) - sext_i32_i64(local_tid_24907 - skip_threads_24923));\n                            \n                            if (thread_active_24924 && inactive_24925) {\n                                eta_p_22801 = eta_p_22802;\n                            }\n                            if (thread_active_24924) {\n                                if (!inactive_24925) {\n                                    int8_t defunc_0_op_res_22803 = eta_p_22801 ^ eta_p_22802;\n                                    \n                                    eta_p_22801 = defunc_0_op_res_22803;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_24909, skip_threads_24923)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_24924) {\n                            // write result\n                            {\n                                ((volatile __local int8_t *) red_arr_i8_mem_24911)[sext_i32_i64(local_tid_24907)] = eta_p_22801;\n                                eta_p_22802 = eta_p_22801;\n                            }\n                        }\n                        if (sle32(wave_sizze_24909, skip_thr", "eads_24923)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_24923 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_24907 - squot32(local_tid_24907, 32) * 32) == 31 && ltid_in_bounds_24922) {\n                        ((volatile __local int8_t *) red_arr_i8_mem_24911)[sext_i32_i64(squot32(local_tid_24907, 32))] = eta_p_22801;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_24926;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_24907, 32) == 0 && ltid_in_bounds_24922) {\n                            eta_p_24920 = ((volatile __local int8_t *) red_arr_i8_mem_24911)[sext_i32_i64(local_tid_24907)];\n                            if ((local_tid_24907 - squot32(local_tid_24907, 32) * 32) == 0) {\n                                eta_p_24919 = eta_p_24920;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_24926 = 1;\n                        while (slt32(skip_threads_24926, 32)) {\n                            bool thread_active_24927 = sle32(skip_threads_24926, local_tid_24907 - squot32(local_tid_24907, 32) * 32) && (squot32(local_tid_24907, 32) == 0 && ltid_in_bounds_24922);\n                            \n                            if (thread_active_24927) {\n                                // read operands\n                                {\n                                    eta_p_24919 = ((volatile __local i",
                                    "nt8_t *) red_arr_i8_mem_24911)[sext_i32_i64(local_tid_24907) - sext_i32_i64(skip_threads_24926)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_24928 = slt64(srem64(sext_i32_i64(local_tid_24907 * 32 + 32 - 1), m_21170), sext_i32_i64(local_tid_24907 * 32 + 32 - 1) - sext_i32_i64((local_tid_24907 - skip_threads_24926) * 32 + 32 - 1));\n                                \n                                if (thread_active_24927 && inactive_24928) {\n                                    eta_p_24919 = eta_p_24920;\n                                }\n                                if (thread_active_24927) {\n                                    if (!inactive_24928) {\n                                        int8_t defunc_0_op_res_24921 = eta_p_24919 ^ eta_p_24920;\n                                        \n                                        eta_p_24919 = defunc_0_op_res_24921;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_24909, skip_threads_24926)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_24927) {\n                                // write result\n                                {\n                                    ((volatile __local int8_t *) red_arr_i8_mem_24911)[sext_i32_i64(local_tid_24907)] = eta_p_24919;\n                                    eta_p_24920 = eta_p_24919;\n                                }\n                            }\n                            if (sle32(wave_sizze_24909, skip_threads_24926)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_24926 *= 2;\n                        }\n                    }\n                }\n                barri", "er(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_24929 = squot32(local_tid_24907, 32) == 0 || !ltid_in_bounds_24922;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_24929) {\n                            eta_p_22802 = eta_p_22801;\n                            eta_p_22801 = ((__local int8_t *) red_arr_i8_mem_24911)[sext_i32_i64(squot32(local_tid_24907, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_24930 = slt64(srem64(sext_i32_i64(local_tid_24907), m_21170), sext_i32_i64(local_tid_24907) - sext_i32_i64(squot32(local_tid_24907, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_24929) {\n                            if (inactive_24930) {\n                                eta_p_22801 = eta_p_22802;\n                            }\n                        }\n                        if (!no_carry_in_24929) {\n                            if (!inactive_24930) {\n                                int8_t defunc_0_op_res_22803 = eta_p_22801 ^ eta_p_22802;\n                                \n                                eta_p_22801 = defunc_0_op_res_22803;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_24929) {\n                            ((__local int8_t *) red_arr_i8_mem_24911)[sext_i32_i64(local_tid_24907)] = eta_p_22801;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_24907, 32) == 0 && ltid_in_bounds_24922) {\n                        ((__local int8_t *)", " red_arr_i8_mem_24911)[sext_i32_i64(local_tid_24907)] = eta_p_22802;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_24916) * squot64(segred_tblock_sizze_22794, segment_sizze_nonzzero_24904) + sext_i32_i64(local_tid_24907), num_qubits_15486) && slt64(sext_i32_i64(local_tid_24907), squot64(segred_tblock_sizze_22794, segment_sizze_nonzzero_24904))) {\n                int8_t tmp_24931 = ((__local int8_t *) red_arr_i8_mem_24911)[(sext_i32_i64(local_tid_24907) + (int64_t) 1) * segment_sizze_nonzzero_24904 - (int64_t) 1];\n                \n                ((__global int8_t *) mem_23631)[sext_i32_i64(virt_tblock_id_24916) * squot64(segred_tblock_sizze_22794, segment_sizze_nonzzero_24904) + sext_i32_i64(local_tid_24907)] = tmp_24931;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_22794\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegscan_21661_dim1, 1, 1)\nvoid simulate_8477zisegscan_21661(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_15490, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t num_tblocks_21658, int64_t num_virt_blocks_24070, int64_t num_virt_threads_24071, __global unsigned char *mem_23405, __global unsigned char *mem_23414, __global unsigned char *mem_23652, __global unsigned char *mem_23661, __global unsigned char *mem_23663, __global unsigned char *status_flags_mem_24072, __global unsigned char *aggregates_mem_24074, __global unsigned char *incprefixes_mem_24076, __global unsigned char *global_dynid_mem_24078)\n{\n    #define segscan_tblock_sizze_21656 (simulate_8477zisegscan_21661zisegscan_tblock_sizze_21656)\n    #define chunk_sizze_24069 (s",
                                    "imulate_8477zisegscan_21661zichunk_sizze_24069)\n    \n    volatile __local unsigned char *local_mem_24088_backing_0 = &shared_mem[0];\n    const int64_t local_mem_24088_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_21656), chunk_sizze_24069 * segscan_tblock_sizze_21656 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_21656), chunk_sizze_24069 * segscan_tblock_sizze_21656 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24081;\n    int32_t tblock_sizze_24084;\n    int32_t wave_sizze_24083;\n    int32_t block_id_24082;\n    int32_t global_tid_24080;\n    int64_t phys_tid_21661;\n    int32_t chunk_sizze_32b_24085;\n    int64_t byte_offsets_24086;\n    int64_t warp_byte_offset_24087;\n    __local unsigned char *local_mem_24088;\n    int64_t trans_arr_len_24089;\n    int64_t phys_block_id_24095;\n    int64_t virtloop_bound_24096;\n    \n    local_tid_24081 = get_local_id(0);\n    tblock_sizze_24084 = get_local_size(0);\n    wave_sizze_24083 = LOCKSTEP_WIDTH;\n    block_id_24082 = get_tblock_id(0);\n    global_tid_24080 = block_id_24082 * tblock_sizze_24084 + local_tid_24081;\n    phys_tid_21661 = sext_i32_i64(global_tid_24080);\n    chunk_sizze_32b_24085 = sext_i64_i32(chunk_sizze_24069);\n    byte_offsets_24086 = segscan_tblock_sizze_21656 * (int64_t) 8;\n    warp_byte_offset_24087 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_24088 = (__local unsigned char *) local_mem_24088_backing_0;\n    trans_arr_len_24089 = chunk_sizze_24069 * segscan_tblock_sizze_21656;\n    phys_block_id_24095 = get_tblock_id(0);\n    virtloop_bound_24096 = sdiv_up64(num_virt_blocks_24070 - phys_block_id_24095, num_tblocks_21658);\n    for (", "int64_t virtloop_i_24097 = 0; virtloop_i_24097 < virtloop_bound_24096; virtloop_i_24097++) {\n        int64_t dynamic_id_24098;\n        int64_t block_offset_24099;\n        int64_t sgm_idx_24100;\n        int32_t boundary_24101;\n        int32_t segsizze_compact_24102;\n        int64_t private_mem_24103[chunk_sizze_24069];\n        int64_t thd_offset_24105;\n        int64_t acc_24121;\n        int64_t prefix_24131;\n        bool block_new_sgm_24132;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_24081 == 0) {\n                dynamic_id_24098 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_24078)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_24088)[(int64_t) 0] = dynamic_id_24098;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_24098 == num_virt_blocks_24070 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_24078)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_24098 = ((__local int32_t *) local_mem_24088)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_24099 = dynamic_id_24098 * chunk_sizze_24069 * segscan_tblock_sizze_21656;\n        sgm_idx_24100 = smod64(block_offset_24099, arg_15490);\n        boundary_24101 = sext_i64_i32(smin64(chunk_sizze_24069 * segscan_tblock_sizze_21656, arg_15490 - sgm_idx_24100));\n        segsizze_compact_24102 = sext_i64_i32(smin64(chunk_sizze_24069 * segscan_tblock_sizze_21656, arg_15490));\n        thd_offset_24105 = block_offset_24099 + sext_i32_i64(local_tid_24081);\n        // Load and map\n        {\n            for (int64_t i_24106 = 0; i_24106 < chunk_sizze_24069; i_24106++) {\n                int64_t virt_tid_24107 = thd_", "offset_24105 + i_24106 * segscan_tblock_sizze_21656;\n                int64_t slice_24108 = arg_15490;\n                int64_t gtid_21660 = virt_tid_24107;\n                int64_t remnant_24109 = virt_tid_24107 - gtid_21660;\n                \n                if (slt64(virt_tid_24107, arg_15490)) {\n                    int64_t defunc_0_f_res_23178 = ((__global int64_t *) mem_23652)[(int64_t) 0];\n                    bool cond_20924 = gtid_21660 == defunc_0_f_res_23178;\n                    bool cond_20925 = !cond_20924;\n                    bool lifted_lambda_res_20926;\n                    \n                    if (cond_20925) {\n                        int64_t loopres_23177 = ((__global int64_t *) mem_23414)[(int64_t) 0];\n                        bool y_20928 = slt64(gtid_21660, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                        bool index_certs_20930;\n                        \n                        if (!y_20928) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 5) == -1) {\n                                    global_failure_args[0] = (int64_t) gtid_21660;\n                                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        bool x_20931 = sle64((int64_t) 0, loopres_23177);\n                        bool y_20932 = slt64(loopres_23177, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                        bool bounds_check_20933 = x_20931 && y_20932;\n                        bool index_certs_20934;\n                        \n                        if (!bounds_check_20933) {\n                            {\n                       ",
                                    "         if (atomic_cmpxchg_i32_global(global_failure, -1, 6) == -1) {\n                                    global_failure_args[0] = (int64_t) loopres_23177;\n                                    global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        int8_t zeze_lhs_20935 = ((__global int8_t *) mem_23405)[gtid_21660 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + loopres_23177];\n                        bool lifted_lambda_res_t_res_20936 = zeze_lhs_20935 == (int8_t) 1;\n                        \n                        lifted_lambda_res_20926 = lifted_lambda_res_t_res_20936;\n                    } else {\n                        lifted_lambda_res_20926 = 0;\n                    }\n                    \n                    int64_t defunc_0_f_res_20937 = btoi_bool_i64(lifted_lambda_res_20926);\n                    \n                    ((__global int64_t *) mem_23663)[gtid_21660] = defunc_0_f_res_20937;\n                    private_mem_24103[i_24106] = defunc_0_f_res_20937;\n                } else {\n                    private_mem_24103[i_24106] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_24110 = 0; i_24110 < chunk_sizze_24069; i_24110++) {\n                int64_t sharedIdx_24111 = sext_i32_i64(local_tid_24081) + i_24110 * segscan_tblock_sizze_21656;\n                int64_t tmp_24112 = private_mem_24103[i_24110];\n                \n                ((__local int64_t *) local_mem_24088)[sharedIdx_24111] = tmp_24112;\n            ", "}\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_24113 = 0; i_24113 < chunk_sizze_24069; i_24113++) {\n                int64_t sharedIdx_24114 = sext_i32_i64(local_tid_24081) * chunk_sizze_24069 + i_24113;\n                int64_t tmp_24115 = ((__local int64_t *) local_mem_24088)[sharedIdx_24114];\n                \n                private_mem_24103[i_24113] = tmp_24115;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_24116 = 0; i_24116 < chunk_sizze_24069 - (int64_t) 1; i_24116++) {\n                int64_t eta_p_20920;\n                int64_t eta_p_20921;\n                \n                eta_p_20920 = private_mem_24103[i_24116];\n                eta_p_20921 = private_mem_24103[i_24116 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_20922 = add64(eta_p_20920, eta_p_20921);\n                \n                private_mem_24103[i_24116 + (int64_t) 1] = defunc_0_op_res_20922;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_24117 = private_mem_24103[chunk_sizze_24069 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_24088)[sext_i32_i64(local_tid_24081)] = tmp_24117;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_24118;\n            int64_t eta_p_24119;\n            int64_t eta_p_24122;\n            int64_t eta_p_24123;\n            bool ltid_in_bounds_24125 = slt64(sext_i32_i64(local_tid_24081), num_virt_threads_24071);\n            int32_t skip_threads_24126;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_24125) {\n                    eta_p_24119 = ((volatile __local int64_t *) local_mem_24088)[sext_i32_i64(local_tid_24081)];\n                    if ((local_tid_24081 - squot32(local_tid_24081, 32) * 32) == 0) {\n                        eta_p_241", "18 = eta_p_24119;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_24126 = 1;\n                while (slt32(skip_threads_24126, 32)) {\n                    bool thread_active_24127 = sle32(skip_threads_24126, local_tid_24081 - squot32(local_tid_24081, 32) * 32) && ltid_in_bounds_24125;\n                    \n                    if (thread_active_24127) {\n                        // read operands\n                        {\n                            eta_p_24118 = ((volatile __local int64_t *) local_mem_24088)[sext_i32_i64(local_tid_24081) - sext_i32_i64(skip_threads_24126)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_24127) {\n                            int64_t defunc_0_op_res_24120 = add64(eta_p_24118, eta_p_24119);\n                            \n                            eta_p_24118 = defunc_0_op_res_24120;\n                        }\n                    }\n                    if (sle32(wave_sizze_24083, skip_threads_24126)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_24127) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_24088)[sext_i32_i64(local_tid_24081)] = eta_p_24118;\n                            eta_p_24119 = eta_p_24118;\n                        }\n                    }\n                    if (sle32(wave_sizze_24083, skip_threads_24126)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_24126 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_24081 - squot32(local_tid_24081, 32) * 32) == 31 && ",
                                    "ltid_in_bounds_24125) {\n                    ((volatile __local int64_t *) local_mem_24088)[sext_i32_i64(squot32(local_tid_24081, 32))] = eta_p_24118;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_24128;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_24081, 32) == 0 && ltid_in_bounds_24125) {\n                        eta_p_24123 = ((volatile __local int64_t *) local_mem_24088)[sext_i32_i64(local_tid_24081)];\n                        if ((local_tid_24081 - squot32(local_tid_24081, 32) * 32) == 0) {\n                            eta_p_24122 = eta_p_24123;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_24128 = 1;\n                    while (slt32(skip_threads_24128, 32)) {\n                        bool thread_active_24129 = sle32(skip_threads_24128, local_tid_24081 - squot32(local_tid_24081, 32) * 32) && (squot32(local_tid_24081, 32) == 0 && ltid_in_bounds_24125);\n                        \n                        if (thread_active_24129) {\n                            // read operands\n                            {\n                                eta_p_24122 = ((volatile __local int64_t *) local_mem_24088)[sext_i32_i64(local_tid_24081) - sext_i32_i64(skip_threads_24128)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_24129) {\n                                int64_t defunc_0_op_res_24124 = add64(eta_p_24122, eta_p_24123);\n                                \n                                eta_p_24122 = defunc_0_op_res_24124;\n                            }\n                        }\n", "                        if (sle32(wave_sizze_24083, skip_threads_24128)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_24129) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_24088)[sext_i32_i64(local_tid_24081)] = eta_p_24122;\n                                eta_p_24123 = eta_p_24122;\n                            }\n                        }\n                        if (sle32(wave_sizze_24083, skip_threads_24128)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_24128 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_24130 = squot32(local_tid_24081, 32) == 0 || !ltid_in_bounds_24125;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_24130) {\n                        eta_p_24119 = eta_p_24118;\n                        eta_p_24118 = ((__local int64_t *) local_mem_24088)[sext_i32_i64(squot32(local_tid_24081, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_24130) {\n                        int64_t defunc_0_op_res_24120 = add64(eta_p_24118, eta_p_24119);\n                        \n                        eta_p_24118 = defunc_0_op_res_24120;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_24130) {\n                        ((__local int64_t *) local_mem_24088)[sext_i32_i64(local_tid_24081)] = eta_p_24118;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct va", "lues for first block\n            {\n                if (squot32(local_tid_24081, 32) == 0 && ltid_in_bounds_24125) {\n                    ((__local int64_t *) local_mem_24088)[sext_i32_i64(local_tid_24081)] = eta_p_24119;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_24081 == 0) {\n                acc_24121 = ((__local int64_t *) local_mem_24088)[segscan_tblock_sizze_21656 - (int64_t) 1];\n            } else {\n                acc_24121 = ((__local int64_t *) local_mem_24088)[sext_i32_i64(local_tid_24081) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_24131 = (int64_t) 0;\n        block_new_sgm_24132 = sgm_idx_24100 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_24132 && local_tid_24081 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_24076)[dynamic_id_24098] = acc_24121;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_24072)[dynamic_id_24098] = (int8_t) 2;\n                acc_24121 = (int64_t) 0;\n            }\n            if (!block_new_sgm_24132 && slt32(local_tid_24081, wave_sizze_24083)) {\n                if (local_tid_24081 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_24074)[dynamic_id_24098] = acc_24121;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_24072)[dynamic_id_24098] = (int8_t) 1;\n                    \n                    int8_t tmp_24133 = ((volatile __global int8_t *) status_flags_mem_24072)[dynamic_id_24098 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_24088)[(int64_t) 0] = tmp_24133;\n                }\n                mem_fence_local();\n                \n                int8_t status_24134 = ((__local int8_t *) local_mem_24088)[(int64_t) 0];\n                \n           ",
                                    "     if (status_24134 == (int8_t) 2) {\n                    if (local_tid_24081 == 0) {\n                        prefix_24131 = ((volatile __global int64_t *) incprefixes_mem_24076)[dynamic_id_24098 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_24135 = sext_i64_i32(dynamic_id_24098 - sext_i32_i64(wave_sizze_24083));\n                    \n                    while (slt32(wave_sizze_24083 * -1, readOffset_24135)) {\n                        int32_t read_i_24136 = readOffset_24135 + local_tid_24081;\n                        int64_t aggr_24137 = (int64_t) 0;\n                        int8_t flag_24138 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_24136)) {\n                            flag_24138 = ((volatile __global int8_t *) status_flags_mem_24072)[sext_i32_i64(read_i_24136)];\n                            if (flag_24138 == (int8_t) 2) {\n                                aggr_24137 = ((volatile __global int64_t *) incprefixes_mem_24076)[sext_i32_i64(read_i_24136)];\n                            } else if (flag_24138 == (int8_t) 1) {\n                                aggr_24137 = ((volatile __global int64_t *) aggregates_mem_24074)[sext_i32_i64(read_i_24136)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_24088)[(int64_t) 4 + sext_i32_i64(local_tid_24081)] = aggr_24137;\n                        ((__local int8_t *) local_mem_24088)[sext_i32_i64(local_tid_24081)] = flag_24138;\n                        flag_24138 = ((__local int8_t *) local_mem_24088)[sext_i32_i64(wave_sizze_24083) - (int64_t) 1];\n                        if (slt8(flag_24138, (int8_t) 2)) {\n                            int8_t flg_x_24142;\n                            int8_t flg_y_24143;\n                            int64_t eta_p_24139;\n                            int64_t eta_p_24140;\n                            int32_t skip_threads_24144;\n                            \n     ", "                       // read input for in-block scan\n                            {\n                                flg_y_24143 = ((volatile __local int8_t *) local_mem_24088)[sext_i32_i64(local_tid_24081)];\n                                eta_p_24140 = ((volatile __local int64_t *) local_mem_24088)[(int64_t) 4 + sext_i32_i64(local_tid_24081)];\n                                if ((local_tid_24081 - squot32(local_tid_24081, 32) * 32) == 0) {\n                                    eta_p_24139 = eta_p_24140;\n                                    flg_x_24142 = flg_y_24143;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_24144 = 1;\n                                while (slt32(skip_threads_24144, 32)) {\n                                    if (sle32(skip_threads_24144, local_tid_24081 - squot32(local_tid_24081, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_24142 = ((volatile __local int8_t *) local_mem_24088)[sext_i32_i64(local_tid_24081) - sext_i32_i64(skip_threads_24144)];\n                                            eta_p_24139 = ((volatile __local int64_t *) local_mem_24088)[(int64_t) 4 + (sext_i32_i64(local_tid_24081) - sext_i32_i64(skip_threads_24144))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_24143 == (int8_t) 2 || flg_y_24143 == (int8_t) 0) {\n                                                flg_x_24142 = flg_y_24143;\n                                                eta_p_24139 = eta_p_24140;\n                                            } else {\n                                                int64_t defunc_0_op_res_24141 = add64(eta_p_2413", "9, eta_p_24140);\n                                                \n                                                eta_p_24139 = defunc_0_op_res_24141;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_24088)[sext_i32_i64(local_tid_24081)] = flg_x_24142;\n                                            flg_y_24143 = flg_x_24142;\n                                            ((volatile __local int64_t *) local_mem_24088)[(int64_t) 4 + sext_i32_i64(local_tid_24081)] = eta_p_24139;\n                                            eta_p_24140 = eta_p_24139;\n                                        }\n                                    }\n                                    skip_threads_24144 *= 2;\n                                }\n                            }\n                        }\n                        flag_24138 = ((__local int8_t *) local_mem_24088)[sext_i32_i64(wave_sizze_24083) - (int64_t) 1];\n                        aggr_24137 = ((__local int64_t *) local_mem_24088)[(int64_t) 4 + (sext_i32_i64(wave_sizze_24083) - (int64_t) 1)];\n                        if (flag_24138 == (int8_t) 2) {\n                            readOffset_24135 = wave_sizze_24083 * -1;\n                        } else if (flag_24138 == (int8_t) 1) {\n                            readOffset_24135 -= wave_sizze_24083;\n                        }\n                        if (slt8((int8_t) 0, flag_24138)) {\n                            int64_t eta_p_24145 = aggr_24137;\n                            int64_t eta_p_24146 = prefix_24131;\n                            int64_t defunc_0_op_res_24147 = add64(eta_p_24145, eta_p_24146);\n                            \n                            prefix_24131 = defunc_0_op_res_24147;\n                        }\n                        mem_fence_local();\n                    ",
                                    "}\n                }\n                if (local_tid_24081 == 0) {\n                    if (boundary_24101 == sext_i64_i32(segscan_tblock_sizze_21656 * chunk_sizze_24069)) {\n                        int64_t eta_p_24148 = prefix_24131;\n                        int64_t eta_p_24149 = acc_24121;\n                        int64_t defunc_0_op_res_24150 = add64(eta_p_24148, eta_p_24149);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_24076)[dynamic_id_24098] = defunc_0_op_res_24150;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_24072)[dynamic_id_24098] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_24088)[(int64_t) 4] = prefix_24131;\n                    acc_24121 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_24098 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_24131 = ((__local int64_t *) local_mem_24088)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_24151;\n            int64_t eta_p_24152;\n            int64_t eta_p_24154 = prefix_24131;\n            int64_t eta_p_24155 = acc_24121;\n            \n            if (slt32(local_tid_24081 * chunk_sizze_32b_24085, boundary_24101) && !block_new_sgm_24132) {\n                int64_t defunc_0_op_res_24156 = add64(eta_p_24154, eta_p_24155);\n                \n                eta_p_24151 = defunc_0_op_res_24156;\n            } else {\n                eta_p_24151 = acc_24121;\n            }\n            \n            int32_t stopping_point_24157 = segsizze_compact_24102 - srem32(local_tid_24081 * chunk_sizze_32b_24085 - 1 + segsizze_compact_24102 - boundary_24101, segsizze_compact_24102);\n            \n            for (int64_t i_24158 = 0; i_24158 < chunk_sizze_24069; i_24158++) {\n                if (slt32(sext_i64_i32(i_24158)", ", stopping_point_24157 - 1)) {\n                    eta_p_24152 = private_mem_24103[i_24158];\n                    \n                    int64_t defunc_0_op_res_24153 = add64(eta_p_24151, eta_p_24152);\n                    \n                    private_mem_24103[i_24158] = defunc_0_op_res_24153;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_24159 = 0; i_24159 < chunk_sizze_24069; i_24159++) {\n                int64_t sharedIdx_24160 = sext_i32_i64(local_tid_24081) * chunk_sizze_24069 + i_24159;\n                int64_t tmp_24161 = private_mem_24103[i_24159];\n                \n                ((__local int64_t *) local_mem_24088)[sharedIdx_24160] = tmp_24161;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_24162 = 0; i_24162 < chunk_sizze_24069; i_24162++) {\n                int64_t flat_idx_24163 = thd_offset_24105 + i_24162 * segscan_tblock_sizze_21656;\n                int64_t slice_24164 = arg_15490;\n                int64_t gtid_21660 = flat_idx_24163;\n                int64_t remnant_24165 = flat_idx_24163 - gtid_21660;\n                \n                if (slt64(flat_idx_24163, arg_15490)) {\n                    int64_t tmp_24166 = ((__local int64_t *) local_mem_24088)[flat_idx_24163 - block_offset_24099];\n                    \n                    ((__global int64_t *) mem_23661)[gtid_21660] = tmp_24166;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_21656\n    #undef chunk_sizze_24069\n}\nFUTHARK_KERNEL_SIZED(simulate_8477zisegscan_22103_dim1, 1, 1)\nvoid simulate_8477zisegscan_22103(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t num_qubits_15486, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, int64_t num_tblocks_22100, int64_t num_virt_blocks_244", "92, int64_t num_virt_threads_24493, __global unsigned char *mem_23405, __global unsigned char *mem_23414, __global unsigned char *mem_23467, __global unsigned char *mem_23469, __global unsigned char *status_flags_mem_24494, __global unsigned char *aggregates_mem_24496, __global unsigned char *incprefixes_mem_24498, __global unsigned char *global_dynid_mem_24500)\n{\n    #define segscan_tblock_sizze_22098 (simulate_8477zisegscan_22103zisegscan_tblock_sizze_22098)\n    #define chunk_sizze_24491 (simulate_8477zisegscan_22103zichunk_sizze_24491)\n    \n    volatile __local unsigned char *local_mem_24510_backing_0 = &shared_mem[0];\n    const int64_t local_mem_24510_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22098), chunk_sizze_24491 * segscan_tblock_sizze_22098 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22098), chunk_sizze_24491 * segscan_tblock_sizze_22098 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24503;\n    int32_t tblock_sizze_24506;\n    int32_t wave_sizze_24505;\n    int32_t block_id_24504;\n    int32_t global_tid_24502;\n    int64_t phys_tid_22103;\n    int32_t chunk_sizze_32b_24507;\n    int64_t byte_offsets_24508;\n    int64_t warp_byte_offset_24509;\n    __local unsigned char *local_mem_24510;\n    int64_t trans_arr_len_24511;\n    int64_t phys_block_id_24517;\n    int64_t virtloop_bound_24518;\n    \n    local_tid_24503 = get_local_id(0);\n    tblock_sizze_24506 = get_local_size(0);\n    wave_sizze_24505 = LOCKSTEP_WIDTH;\n    block_id_24504 = get_tblock_id(0);\n    global_tid_24502 = block_id_24504 * tblock_sizze_24506 + local_tid_24503;\n    phys_tid_22103 = sext_i32_i64(global_tid_24502);\n    chunk_sizze_32b_24507 ",
                                    "= sext_i64_i32(chunk_sizze_24491);\n    byte_offsets_24508 = segscan_tblock_sizze_22098 * (int64_t) 8;\n    warp_byte_offset_24509 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_24510 = (__local unsigned char *) local_mem_24510_backing_0;\n    trans_arr_len_24511 = chunk_sizze_24491 * segscan_tblock_sizze_22098;\n    phys_block_id_24517 = get_tblock_id(0);\n    virtloop_bound_24518 = sdiv_up64(num_virt_blocks_24492 - phys_block_id_24517, num_tblocks_22100);\n    for (int64_t virtloop_i_24519 = 0; virtloop_i_24519 < virtloop_bound_24518; virtloop_i_24519++) {\n        int64_t dynamic_id_24520;\n        int64_t block_offset_24521;\n        int64_t sgm_idx_24522;\n        int32_t boundary_24523;\n        int32_t segsizze_compact_24524;\n        int64_t private_mem_24525[chunk_sizze_24491];\n        int64_t thd_offset_24527;\n        int64_t acc_24543;\n        int64_t prefix_24553;\n        bool block_new_sgm_24554;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_24503 == 0) {\n                dynamic_id_24520 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_24500)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_24510)[(int64_t) 0] = dynamic_id_24520;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_24520 == num_virt_blocks_24492 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_24500)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_24520 = ((__local int32_t *) local_mem_24510)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_24521 = dynamic_id_24520 * chunk_sizze_24491 * segscan_tblock_sizze_22098;\n        sgm_idx_24522 = smod64(block_off", "set_24521, num_qubits_15486);\n        boundary_24523 = sext_i64_i32(smin64(chunk_sizze_24491 * segscan_tblock_sizze_22098, num_qubits_15486 - sgm_idx_24522));\n        segsizze_compact_24524 = sext_i64_i32(smin64(chunk_sizze_24491 * segscan_tblock_sizze_22098, num_qubits_15486));\n        thd_offset_24527 = block_offset_24521 + sext_i32_i64(local_tid_24503);\n        // Load and map\n        {\n            for (int64_t i_24528 = 0; i_24528 < chunk_sizze_24491; i_24528++) {\n                int64_t virt_tid_24529 = thd_offset_24527 + i_24528 * segscan_tblock_sizze_22098;\n                int64_t slice_24530 = num_qubits_15486;\n                int64_t gtid_22102 = virt_tid_24529;\n                int64_t remnant_24531 = virt_tid_24529 - gtid_22102;\n                \n                if (slt64(virt_tid_24529, num_qubits_15486)) {\n                    bool y_21154 = slt64(gtid_22102, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);\n                    bool index_certs_21156;\n                    \n                    if (!y_21154) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 18) == -1) {\n                                global_failure_args[0] = (int64_t) gtid_22102;\n                                global_failure_args[1] = (int64_t) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int64_t loopres_23217 = ((__global int64_t *) mem_23414)[(int64_t) 0];\n                    int8_t zeze_lhs_21157 = ((__global int8_t *) mem_23405)[gtid_22102 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 + loopres_23217];\n                    bool lifted_lambda_res_21158 = zeze_lhs_21157 == (int8_t) 1;\n                    int64_t defunc_0_f_res_21159 = btoi_bo", "ol_i64(lifted_lambda_res_21158);\n                    \n                    ((__global int64_t *) mem_23469)[gtid_22102] = defunc_0_f_res_21159;\n                    private_mem_24525[i_24528] = defunc_0_f_res_21159;\n                } else {\n                    private_mem_24525[i_24528] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_24532 = 0; i_24532 < chunk_sizze_24491; i_24532++) {\n                int64_t sharedIdx_24533 = sext_i32_i64(local_tid_24503) + i_24532 * segscan_tblock_sizze_22098;\n                int64_t tmp_24534 = private_mem_24525[i_24532];\n                \n                ((__local int64_t *) local_mem_24510)[sharedIdx_24533] = tmp_24534;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_24535 = 0; i_24535 < chunk_sizze_24491; i_24535++) {\n                int64_t sharedIdx_24536 = sext_i32_i64(local_tid_24503) * chunk_sizze_24491 + i_24535;\n                int64_t tmp_24537 = ((__local int64_t *) local_mem_24510)[sharedIdx_24536];\n                \n                private_mem_24525[i_24535] = tmp_24537;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_24538 = 0; i_24538 < chunk_sizze_24491 - (int64_t) 1; i_24538++) {\n                int64_t eta_p_21149;\n                int64_t eta_p_21150;\n                \n                eta_p_21149 = private_mem_24525[i_24538];\n                eta_p_21150 = private_mem_24525[i_24538 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_21151 = add64(eta_p_21149, eta_p_21150);\n                \n                private_mem_24525[i_24538 + (int64_t) 1] = defunc_0_op_res_21151;\n            }\n        }\n        // Publish results in shared memory\n        {\n            i",
                                    "nt64_t tmp_24539 = private_mem_24525[chunk_sizze_24491 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_24510)[sext_i32_i64(local_tid_24503)] = tmp_24539;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_24540;\n            int64_t eta_p_24541;\n            int64_t eta_p_24544;\n            int64_t eta_p_24545;\n            bool ltid_in_bounds_24547 = slt64(sext_i32_i64(local_tid_24503), num_virt_threads_24493);\n            int32_t skip_threads_24548;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_24547) {\n                    eta_p_24541 = ((volatile __local int64_t *) local_mem_24510)[sext_i32_i64(local_tid_24503)];\n                    if ((local_tid_24503 - squot32(local_tid_24503, 32) * 32) == 0) {\n                        eta_p_24540 = eta_p_24541;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_24548 = 1;\n                while (slt32(skip_threads_24548, 32)) {\n                    bool thread_active_24549 = sle32(skip_threads_24548, local_tid_24503 - squot32(local_tid_24503, 32) * 32) && ltid_in_bounds_24547;\n                    \n                    if (thread_active_24549) {\n                        // read operands\n                        {\n                            eta_p_24540 = ((volatile __local int64_t *) local_mem_24510)[sext_i32_i64(local_tid_24503) - sext_i32_i64(skip_threads_24548)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_24549) {\n                            int64_t defunc_0_op_res_24542 = add64(eta_p_24540, eta_p_24541);\n                            \n                            eta_p_24540 = defunc_0_op_res_24542;\n                        }\n                    }\n                 ", "   if (sle32(wave_sizze_24505, skip_threads_24548)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_24549) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_24510)[sext_i32_i64(local_tid_24503)] = eta_p_24540;\n                            eta_p_24541 = eta_p_24540;\n                        }\n                    }\n                    if (sle32(wave_sizze_24505, skip_threads_24548)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_24548 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_24503 - squot32(local_tid_24503, 32) * 32) == 31 && ltid_in_bounds_24547) {\n                    ((volatile __local int64_t *) local_mem_24510)[sext_i32_i64(squot32(local_tid_24503, 32))] = eta_p_24540;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_24550;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_24503, 32) == 0 && ltid_in_bounds_24547) {\n                        eta_p_24545 = ((volatile __local int64_t *) local_mem_24510)[sext_i32_i64(local_tid_24503)];\n                        if ((local_tid_24503 - squot32(local_tid_24503, 32) * 32) == 0) {\n                            eta_p_24544 = eta_p_24545;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_24550 = 1;\n                    while (slt32(skip_threads_24550, 32)) {\n                        bool thread_acti", "ve_24551 = sle32(skip_threads_24550, local_tid_24503 - squot32(local_tid_24503, 32) * 32) && (squot32(local_tid_24503, 32) == 0 && ltid_in_bounds_24547);\n                        \n                        if (thread_active_24551) {\n                            // read operands\n                            {\n                                eta_p_24544 = ((volatile __local int64_t *) local_mem_24510)[sext_i32_i64(local_tid_24503) - sext_i32_i64(skip_threads_24550)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_24551) {\n                                int64_t defunc_0_op_res_24546 = add64(eta_p_24544, eta_p_24545);\n                                \n                                eta_p_24544 = defunc_0_op_res_24546;\n                            }\n                        }\n                        if (sle32(wave_sizze_24505, skip_threads_24550)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_24551) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_24510)[sext_i32_i64(local_tid_24503)] = eta_p_24544;\n                                eta_p_24545 = eta_p_24544;\n                            }\n                        }\n                        if (sle32(wave_sizze_24505, skip_threads_24550)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_24550 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_24552 = squot32(local_tid_24503, 32) == 0 || !ltid_in_bounds_24547;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!",
                                    "no_carry_in_24552) {\n                        eta_p_24541 = eta_p_24540;\n                        eta_p_24540 = ((__local int64_t *) local_mem_24510)[sext_i32_i64(squot32(local_tid_24503, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_24552) {\n                        int64_t defunc_0_op_res_24542 = add64(eta_p_24540, eta_p_24541);\n                        \n                        eta_p_24540 = defunc_0_op_res_24542;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_24552) {\n                        ((__local int64_t *) local_mem_24510)[sext_i32_i64(local_tid_24503)] = eta_p_24540;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_24503, 32) == 0 && ltid_in_bounds_24547) {\n                    ((__local int64_t *) local_mem_24510)[sext_i32_i64(local_tid_24503)] = eta_p_24541;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_24503 == 0) {\n                acc_24543 = ((__local int64_t *) local_mem_24510)[segscan_tblock_sizze_22098 - (int64_t) 1];\n            } else {\n                acc_24543 = ((__local int64_t *) local_mem_24510)[sext_i32_i64(local_tid_24503) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_24553 = (int64_t) 0;\n        block_new_sgm_24554 = sgm_idx_24522 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_24554 && local_tid_24503 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_24498)[dynamic_id_24520] = acc_24543;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_24494)[dynamic_id", "_24520] = (int8_t) 2;\n                acc_24543 = (int64_t) 0;\n            }\n            if (!block_new_sgm_24554 && slt32(local_tid_24503, wave_sizze_24505)) {\n                if (local_tid_24503 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_24496)[dynamic_id_24520] = acc_24543;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_24494)[dynamic_id_24520] = (int8_t) 1;\n                    \n                    int8_t tmp_24555 = ((volatile __global int8_t *) status_flags_mem_24494)[dynamic_id_24520 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_24510)[(int64_t) 0] = tmp_24555;\n                }\n                mem_fence_local();\n                \n                int8_t status_24556 = ((__local int8_t *) local_mem_24510)[(int64_t) 0];\n                \n                if (status_24556 == (int8_t) 2) {\n                    if (local_tid_24503 == 0) {\n                        prefix_24553 = ((volatile __global int64_t *) incprefixes_mem_24498)[dynamic_id_24520 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_24557 = sext_i64_i32(dynamic_id_24520 - sext_i32_i64(wave_sizze_24505));\n                    \n                    while (slt32(wave_sizze_24505 * -1, readOffset_24557)) {\n                        int32_t read_i_24558 = readOffset_24557 + local_tid_24503;\n                        int64_t aggr_24559 = (int64_t) 0;\n                        int8_t flag_24560 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_24558)) {\n                            flag_24560 = ((volatile __global int8_t *) status_flags_mem_24494)[sext_i32_i64(read_i_24558)];\n                            if (flag_24560 == (int8_t) 2) {\n                                aggr_24559 = ((volatile __global int64_t *) incprefixes_mem_24498)[sext_i32_i64(read_i_24558)];\n                            } else if (f", "lag_24560 == (int8_t) 1) {\n                                aggr_24559 = ((volatile __global int64_t *) aggregates_mem_24496)[sext_i32_i64(read_i_24558)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_24510)[(int64_t) 4 + sext_i32_i64(local_tid_24503)] = aggr_24559;\n                        ((__local int8_t *) local_mem_24510)[sext_i32_i64(local_tid_24503)] = flag_24560;\n                        flag_24560 = ((__local int8_t *) local_mem_24510)[sext_i32_i64(wave_sizze_24505) - (int64_t) 1];\n                        if (slt8(flag_24560, (int8_t) 2)) {\n                            int8_t flg_x_24564;\n                            int8_t flg_y_24565;\n                            int64_t eta_p_24561;\n                            int64_t eta_p_24562;\n                            int32_t skip_threads_24566;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_24565 = ((volatile __local int8_t *) local_mem_24510)[sext_i32_i64(local_tid_24503)];\n                                eta_p_24562 = ((volatile __local int64_t *) local_mem_24510)[(int64_t) 4 + sext_i32_i64(local_tid_24503)];\n                                if ((local_tid_24503 - squot32(local_tid_24503, 32) * 32) == 0) {\n                                    eta_p_24561 = eta_p_24562;\n                                    flg_x_24564 = flg_y_24565;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_24566 = 1;\n                                while (slt32(skip_threads_24566, 32)) {\n                                    if (sle32(skip_threads_24566, local_tid_24503 - squot32(local_tid_24503, 32) * 32)) {\n                                        // read operands\n                                        {\n       ",
                                    "                                     flg_x_24564 = ((volatile __local int8_t *) local_mem_24510)[sext_i32_i64(local_tid_24503) - sext_i32_i64(skip_threads_24566)];\n                                            eta_p_24561 = ((volatile __local int64_t *) local_mem_24510)[(int64_t) 4 + (sext_i32_i64(local_tid_24503) - sext_i32_i64(skip_threads_24566))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_24565 == (int8_t) 2 || flg_y_24565 == (int8_t) 0) {\n                                                flg_x_24564 = flg_y_24565;\n                                                eta_p_24561 = eta_p_24562;\n                                            } else {\n                                                int64_t defunc_0_op_res_24563 = add64(eta_p_24561, eta_p_24562);\n                                                \n                                                eta_p_24561 = defunc_0_op_res_24563;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_24510)[sext_i32_i64(local_tid_24503)] = flg_x_24564;\n                                            flg_y_24565 = flg_x_24564;\n                                            ((volatile __local int64_t *) local_mem_24510)[(int64_t) 4 + sext_i32_i64(local_tid_24503)] = eta_p_24561;\n                                            eta_p_24562 = eta_p_24561;\n                                        }\n                                    }\n                                    skip_threads_24566 *= 2;\n                                }\n                            }\n                        }\n                        flag_24560 = ((__local int8_t *) local_mem_24510)[sext_i32_i64(wave_sizze_245", "05) - (int64_t) 1];\n                        aggr_24559 = ((__local int64_t *) local_mem_24510)[(int64_t) 4 + (sext_i32_i64(wave_sizze_24505) - (int64_t) 1)];\n                        if (flag_24560 == (int8_t) 2) {\n                            readOffset_24557 = wave_sizze_24505 * -1;\n                        } else if (flag_24560 == (int8_t) 1) {\n                            readOffset_24557 -= wave_sizze_24505;\n                        }\n                        if (slt8((int8_t) 0, flag_24560)) {\n                            int64_t eta_p_24567 = aggr_24559;\n                            int64_t eta_p_24568 = prefix_24553;\n                            int64_t defunc_0_op_res_24569 = add64(eta_p_24567, eta_p_24568);\n                            \n                            prefix_24553 = defunc_0_op_res_24569;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_24503 == 0) {\n                    if (boundary_24523 == sext_i64_i32(segscan_tblock_sizze_22098 * chunk_sizze_24491)) {\n                        int64_t eta_p_24570 = prefix_24553;\n                        int64_t eta_p_24571 = acc_24543;\n                        int64_t defunc_0_op_res_24572 = add64(eta_p_24570, eta_p_24571);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_24498)[dynamic_id_24520] = defunc_0_op_res_24572;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_24494)[dynamic_id_24520] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_24510)[(int64_t) 4] = prefix_24553;\n                    acc_24543 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_24520 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_24553 = ((__local int64_t *) local_mem_24510)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n       ", "     }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_24573;\n            int64_t eta_p_24574;\n            int64_t eta_p_24576 = prefix_24553;\n            int64_t eta_p_24577 = acc_24543;\n            \n            if (slt32(local_tid_24503 * chunk_sizze_32b_24507, boundary_24523) && !block_new_sgm_24554) {\n                int64_t defunc_0_op_res_24578 = add64(eta_p_24576, eta_p_24577);\n                \n                eta_p_24573 = defunc_0_op_res_24578;\n            } else {\n                eta_p_24573 = acc_24543;\n            }\n            \n            int32_t stopping_point_24579 = segsizze_compact_24524 - srem32(local_tid_24503 * chunk_sizze_32b_24507 - 1 + segsizze_compact_24524 - boundary_24523, segsizze_compact_24524);\n            \n            for (int64_t i_24580 = 0; i_24580 < chunk_sizze_24491; i_24580++) {\n                if (slt32(sext_i64_i32(i_24580), stopping_point_24579 - 1)) {\n                    eta_p_24574 = private_mem_24525[i_24580];\n                    \n                    int64_t defunc_0_op_res_24575 = add64(eta_p_24573, eta_p_24574);\n                    \n                    private_mem_24525[i_24580] = defunc_0_op_res_24575;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_24581 = 0; i_24581 < chunk_sizze_24491; i_24581++) {\n                int64_t sharedIdx_24582 = sext_i32_i64(local_tid_24503) * chunk_sizze_24491 + i_24581;\n                int64_t tmp_24583 = private_mem_24525[i_24581];\n                \n                ((__local int64_t *) local_mem_24510)[sharedIdx_24582] = tmp_24583;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_24584 = 0; i_24584 < chunk_sizze_24491; i_24584++) {\n                int64_t flat_idx_24585 = thd_offset_24527 + i_24584 * segscan_tblock_sizze_22098;\n                int64_t slice_24586 = num_qubits_15486;\n                int64_t gtid_221", "02 = flat_idx_24585;\n                int64_t remnant_24587 = flat_idx_24585 - gtid_22102;\n                \n                if (slt64(flat_idx_24585, num_qubits_15486)) {\n                    int64_t tmp_24588 = ((__local int64_t *) local_mem_24510)[flat_idx_24585 - block_offset_24521];\n                    \n                    ((__global int64_t *) mem_23467)[gtid_22102] = tmp_24588;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22098\n    #undef chunk_sizze_24491\n}\n", NULL};
// Start of gpu_prototypes.h

// Constants used for transpositions.  In principle these should be configurable.
#define TR_BLOCK_DIM 16
#define TR_TILE_DIM (TR_BLOCK_DIM*2)
#define TR_ELEMS_PER_THREAD 8

// Config stuff included in every GPU backend.
struct gpu_config {
  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_cache;
  size_t default_shared_memory;
  size_t default_registers;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

// The following are dummy sizes that mean the concrete defaults
// will be set during initialisation via hardware-inspection-based
// heuristics.
struct gpu_config gpu_config_initial = {
  0
};

// Must be defined by the user.
static int gpu_macros(struct futhark_context *ctx, char*** names, int64_t** values);

static void gpu_init_log(struct futhark_context *ctx);
struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);
static int gpu_free_all(struct futhark_context *ctx);

// End of gpu_prototypes.h

// Start of backends/cuda.h.

// Forward declarations.
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
// Take care not to override an existing error.
#define CUDA_SUCCEED_OR_RETURN(e) {             \
    char *serror = CUDA_SUCCEED_NONFATAL(e);    \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
      } else {                                  \
        free(serror);                           \
      }                                         \
      return bad;                               \
    }                                           \
  }

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
                                          const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
                                       const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  char* cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  char* program;
  int num_nvrtc_opts;
  char* *nvrtc_opts;

  char* preferred_device;
  int preferred_device_num;

  int unified_memory;

  char* dump_ptx_to;
  char* load_ptx_from;

  struct gpu_config gpu;
};

static void backend_context_config_setup(struct futhark_context_config *cfg) {
  cfg->num_nvrtc_opts = 0;
  cfg->nvrtc_opts = (char**) malloc(sizeof(char*));
  cfg->nvrtc_opts[0] = NULL;

  cfg->program = strconcat(gpu_program);

  cfg->preferred_device_num = 0;
  cfg->preferred_device = strdup("");

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->unified_memory = 2;

  cfg->gpu = gpu_config_initial;
  cfg->gpu.default_block_size = 256;
  cfg->gpu.default_tile_size = 32;
  cfg->gpu.default_reg_tile_size = 2;
  cfg->gpu.default_threshold = 32*1024;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  for (int i = 0; i < cfg->num_nvrtc_opts; i++) {
    free(cfg->nvrtc_opts[i]);
  }
  free(cfg->nvrtc_opts);
  free(cfg->dump_ptx_to);
  free(cfg->load_ptx_from);
  free(cfg->preferred_device);
  free(cfg->program);
}

void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt) {
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = strdup(opt);
  cfg->num_nvrtc_opts++;
  cfg->nvrtc_opts = (char **) realloc(cfg->nvrtc_opts, (cfg->num_nvrtc_opts + 1) * sizeof(char *));
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  free(cfg->preferred_device);
  cfg->preferred_device = strdup(s);
  cfg->preferred_device_num = x;
}

const char* futhark_context_config_get_program(struct futhark_context_config *cfg) {
  return cfg->program;
}

void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s) {
  free(cfg->program);
  cfg->program = strdup(s);
}

void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *path) {
  free(cfg->dump_ptx_to);
  cfg->dump_ptx_to = strdup(path);
}

void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *path) {
  free(cfg->load_ptx_from);
  cfg->load_ptx_from = strdup(path);
}

void futhark_context_config_set_unified_memory(struct futhark_context_config* cfg, int flag) {
  cfg->unified_memory = flag;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  const char *name;
};

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list free_list;
  struct event_list event_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  struct program* program;
  bool program_initialised;
  // Uniform fields above.

  CUdeviceptr global_failure;
  CUdeviceptr global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  int32_t failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;

  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;
  CUstream stream;

  struct free_list gpu_free_list;

  size_t max_thread_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;
  size_t max_registers;
  size_t max_cache;

  size_t lockstep_width;

  struct builtin_kernels* kernels;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static int cuda_device_setup(struct futhark_context *ctx) {
  struct futhark_context_config *cfg = ctx->cfg;
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best = 0, cc_minor_best = 0;
  int cc_major = 0, cc_minor = 0;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (cfg->logging) {
      fprintf(ctx->log, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
              i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (cfg->logging) {
        fprintf(ctx->log, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, cfg->preferred_device) != NULL &&
        num_device_matches++ == cfg->preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (cfg->logging) {
    fprintf(ctx->log, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  static struct {
    int major;
    int minor;
    const char *arch_str;
  } const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" },
    { 8, 6, "compute_80" },
    { 8, 7, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  int num_archs = sizeof(x)/sizeof(x[0]);
  for (int i = 0; i < num_archs; i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static void cuda_nvrtc_mk_build_options(struct futhark_context *ctx, const char *extra_opts[],
                                        char*** opts_out, size_t *n_opts) {
  int arch_set = 0, num_extra_opts;
  struct futhark_context_config *cfg = ctx->cfg;

  char** macro_names;
  int64_t* macro_vals;
  int num_macros = gpu_macros(ctx, &macro_names, &macro_vals);

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t i = 0, n_opts_alloc = 20 + num_macros + num_extra_opts + cfg->num_tuning_params;
  char **opts = (char**) malloc(n_opts_alloc * sizeof(char *));
  if (!arch_set) {
    opts[i++] = strdup("-arch");
    opts[i++] = strdup(cuda_nvrtc_get_arch(ctx->dev));
  }
  opts[i++] = strdup("-default-device");
  if (cfg->debugging) {
    opts[i++] = strdup("-G");
    opts[i++] = strdup("-lineinfo");
  } else {
    opts[i++] = strdup("--disable-warnings");
  }
  opts[i++] = msgprintf("-D%s=%d",
                        "max_thread_block_size",
                        (int)ctx->max_thread_block_size);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_shared_memory",
                        (int)ctx->max_shared_memory);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_registers",
                        (int)ctx->max_registers);

  for (int j = 0; j < num_macros; j++) {
    opts[i++] = msgprintf("-D%s=%zu", macro_names[j], macro_vals[j]);
  }

  for (int j = 0; j < cfg->num_tuning_params; j++) {
    opts[i++] = msgprintf("-D%s=%zu", cfg->tuning_param_vars[j],
                          cfg->tuning_params[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_thread_block_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = strdup(extra_opts[j]);
  }

  opts[i++] = msgprintf("-DTR_BLOCK_DIM=%d", TR_BLOCK_DIM);
  opts[i++] = msgprintf("-DTR_TILE_DIM=%d", TR_TILE_DIM);
  opts[i++] = msgprintf("-DTR_ELEMS_PER_THREAD=%d", TR_ELEMS_PER_THREAD);

  free(macro_names);
  free(macro_vals);

  *n_opts = i;
  *opts_out = opts;
}

static char* cuda_nvrtc_build(const char *src, const char *opts[], size_t n_opts,
                              char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_load_ptx_from_cache(struct futhark_context_config *cfg,
                                     const char *src,
                                     const char *opts[], size_t n_opts,
                                     struct cache_hash *h, const char *cache_fname,
                                     char **ptx) {
  if (cfg->logging) {
    fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
  }
  cache_hash_init(h);
  for (size_t i = 0; i < n_opts; i++) {
    cache_hash(h, opts[i], strlen(opts[i]));
  }
  cache_hash(h, src, strlen(src));
  size_t ptxsize;
  errno = 0;
  if (cache_restore(cache_fname, h, (unsigned char**)ptx, &ptxsize) != 0) {
    if (cfg->logging) {
      fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
    }
  }
}

static void cuda_size_setup(struct futhark_context *ctx)
{
  struct futhark_context_config *cfg = ctx->cfg;
  if (cfg->gpu.default_block_size > ctx->max_thread_block_size) {
    if (cfg->gpu.default_block_size_changed) {
      fprintf(stderr,
              "Note: Device limits default block size to %zu (down from %zu).\n",
              ctx->max_thread_block_size, cfg->gpu.default_block_size);
    }
    cfg->gpu.default_block_size = ctx->max_thread_block_size;
  }
  if (cfg->gpu.default_grid_size > ctx->max_grid_size) {
    if (cfg->gpu.default_grid_size_changed) {
      fprintf(stderr,
              "Note: Device limits default grid size to %zu (down from %zu).\n",
              ctx->max_grid_size, cfg->gpu.default_grid_size);
    }
    cfg->gpu.default_grid_size = ctx->max_grid_size;
  }
  if (cfg->gpu.default_tile_size > ctx->max_tile_size) {
    if (cfg->gpu.default_tile_size_changed) {
      fprintf(stderr,
              "Note: Device limits default tile size to %zu (down from %zu).\n",
              ctx->max_tile_size, cfg->gpu.default_tile_size);
    }
    cfg->gpu.default_tile_size = ctx->max_tile_size;
  }

  if (!cfg->gpu.default_grid_size_changed) {
    cfg->gpu.default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / cfg->gpu.default_block_size;
  }

  for (int i = 0; i < cfg->num_tuning_params; i++) {
    const char *size_class = cfg->tuning_param_classes[i];
    int64_t *size_value = &cfg->tuning_params[i];
    const char* size_name = cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "thread_block_size") == size_class) {
      max_value = ctx->max_thread_block_size;
      default_value = cfg->gpu.default_block_size;
    } else if (strstr(size_class, "grid_size") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = cfg->gpu.default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = cfg->gpu.default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = cfg->gpu.default_reg_tile_size;
    } else if (strstr(size_class, "shared_memory") == size_class) {
      max_value = ctx->max_shared_memory;
      default_value = ctx->max_shared_memory;
    } else if (strstr(size_class, "cache") == size_class) {
      max_value = ctx->max_cache;
      default_value = ctx->max_cache;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = cfg->gpu.default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct futhark_context *ctx,
                               const char *src,
                               const char *extra_opts[],
                               const char* cache_fname) {
  char *ptx = NULL;
  struct futhark_context_config *cfg = ctx->cfg;

  if (cfg->load_ptx_from) {
    ptx = slurp_file(cfg->load_ptx_from, NULL);
  }

  char **opts;
  size_t n_opts;
  cuda_nvrtc_mk_build_options(ctx, extra_opts, &opts, &n_opts);

  if (cfg->logging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  struct cache_hash h;
  int loaded_ptx_from_cache = 0;
  if (cache_fname != NULL) {
    cuda_load_ptx_from_cache(cfg, src, (const char**)opts, n_opts, &h, cache_fname, &ptx);

    if (ptx != NULL) {
      if (cfg->logging) {
        fprintf(stderr, "Restored PTX from cache; now loading module...\n");
      }
      if (cuModuleLoadData(&ctx->module, ptx) == CUDA_SUCCESS) {
        if (cfg->logging) {
          fprintf(stderr, "Success!\n");
        }
        loaded_ptx_from_cache = 1;
      } else {
        if (cfg->logging) {
          fprintf(stderr, "Failed!\n");
        }
        free(ptx);
        ptx = NULL;
      }
    }
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(src, (const char**)opts, n_opts, &ptx);
    if (problem != NULL) {
      return problem;
    }
  }

  if (cfg->dump_ptx_to != NULL) {
    dump_file(cfg->dump_ptx_to, ptx, strlen(ptx));
  }

  if (!loaded_ptx_from_cache) {
    CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));
  }

  if (cache_fname != NULL && !loaded_ptx_from_cache) {
    if (cfg->logging) {
      fprintf(stderr, "Caching PTX in %s...\n", cache_fname);
    }
    errno = 0;
    if (cache_store(cache_fname, &h, (const unsigned char*)ptx, strlen(ptx)) != 0) {
      fprintf(stderr, "Failed to cache PTX: %s\n", strerror(errno));
    }
  }

  for (size_t i = 0; i < n_opts; i++) {
    free((char *)opts[i]);
  }
  free(opts);
  free(ptx);

  return NULL;
}

struct cuda_event {
  cudaEvent_t start;
  cudaEvent_t end;
};

static struct cuda_event* cuda_event_new(struct futhark_context* ctx) {
  if (ctx->profiling && !ctx->profiling_paused) {
    struct cuda_event* e = malloc(sizeof(struct cuda_event));
    cudaEventCreate(&e->start);
    cudaEventCreate(&e->end);
    return e;
  } else {
    return NULL;
  }
}

static int cuda_event_report(struct str_builder* sb, struct cuda_event* e) {
  float ms;
  CUresult err;
  if ((err = cuEventElapsedTime(&ms, e->start, e->end)) != CUDA_SUCCESS) {
    return err;
  }

  // CUDA provides milisecond resolution, but we want microseconds.
  str_builder(sb, ",\"duration\":%f", ms*1000);

  if ((err = cuEventDestroy(e->start)) != CUDA_SUCCESS) {
    return 1;
  }

  if ((err = cuEventDestroy(e->end)) != CUDA_SUCCESS) {
    return 1;
  }

  free(e);

  return 0;
}

int futhark_context_sync(struct futhark_context* ctx) {
  CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cu_ctx));
  CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
  if (ctx->failure_is_an_option) {
    // Check for any delayed error.
    int32_t failure_idx;
    CUDA_SUCCEED_OR_RETURN(
                           cuMemcpyDtoH(&failure_idx,
                                        ctx->global_failure,
                                        sizeof(int32_t)));
    ctx->failure_is_an_option = 0;

    if (failure_idx >= 0) {
      // We have to clear global_failure so that the next entry point
      // is not considered a failure from the start.
      int32_t no_failure = -1;
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyHtoD(ctx->global_failure,
                                          &no_failure,
                                          sizeof(int32_t)));

      int64_t args[max_failure_args+1];
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyDtoH(&args,
                                          ctx->global_failure_args,
                                          sizeof(args)));

      ctx->error = get_failure_msg(failure_idx, args);

      return FUTHARK_PROGRAM_ERROR;
    }
  }

  CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cu_ctx));
  return 0;
}

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);

int backend_context_setup(struct futhark_context* ctx) {
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;
  ctx->kernels = NULL;

  CUDA_SUCCEED_FATAL(cuInit(0));
  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->gpu_free_list);

  if (ctx->cfg->unified_memory == 2) {
    ctx->cfg->unified_memory = device_query(ctx->dev, MANAGED_MEMORY);
  }

  if (ctx->cfg->logging) {
    if (ctx->cfg->unified_memory) {
      fprintf(ctx->log, "Using managed memory\n");
    } else {
      fprintf(ctx->log, "Using unmanaged memory\n");
    }
  }

  ctx->max_thread_block_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_thread_block_size);
  ctx->max_threshold = 1U<<31; // No limit.
  ctx->max_bespoke = 1U<<31; // No limit.

  if (ctx->cfg->gpu.default_registers != 0) {
    ctx->max_registers = ctx->cfg->gpu.default_registers;
  } else {
    ctx->max_registers = device_query(ctx->dev, MAX_REGISTERS_PER_BLOCK);
  }

  if (ctx->cfg->gpu.default_shared_memory != 0) {
    ctx->max_shared_memory = ctx->cfg->gpu.default_shared_memory;
  } else {
    // MAX_SHARED_MEMORY_PER_BLOCK gives bogus numbers (48KiB); probably
    // for backwards compatibility.  Add _OPTIN and you seem to get the
    // right number.
    ctx->max_shared_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK_OPTIN);
#if CUDART_VERSION >= 12000
    ctx->max_shared_memory -= device_query(ctx->dev, RESERVED_SHARED_MEMORY_PER_BLOCK);
#endif
  }

  if (ctx->cfg->gpu.default_cache != 0) {
    ctx->max_cache = ctx->cfg->gpu.default_cache;
  } else {
    ctx->max_cache = device_query(ctx->dev, L2_CACHE_SIZE);
  }

  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);
  CUDA_SUCCEED_FATAL(cuStreamCreate(&ctx->stream, CU_STREAM_DEFAULT));
  cuda_size_setup(ctx);

  gpu_init_log(ctx);

  ctx->error = cuda_module_setup(ctx,
                                 ctx->cfg->program,
                                 (const char**)ctx->cfg->nvrtc_opts,
                                 ctx->cfg->cache_fname);

  if (ctx->error != NULL) {
    futhark_panic(1, "During CUDA initialisation:\n%s\n", ctx->error);
  }

  int32_t no_error = -1;
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
  CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error, sizeof(no_error)));
  // The +1 is to avoid zero-byte allocations.
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t)*(max_failure_args+1)));

  if ((ctx->kernels = init_builtin_kernels(ctx)) == NULL) {
    return 1;
  }

  return 0;
}

void backend_context_teardown(struct futhark_context* ctx) {
  if (ctx->kernels != NULL) {
    free_builtin_kernels(ctx, ctx->kernels);
    cuMemFree(ctx->global_failure);
    cuMemFree(ctx->global_failure_args);
    CUDA_SUCCEED_FATAL(gpu_free_all(ctx));
    CUDA_SUCCEED_FATAL(cuStreamDestroy(ctx->stream));
    CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
    CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
  }
  free_list_destroy(&ctx->gpu_free_list);
}

// GPU ABSTRACTION LAYER

// Types.

typedef CUfunction gpu_kernel;
typedef CUdeviceptr gpu_mem;

static void gpu_create_kernel(struct futhark_context *ctx,
                              gpu_kernel* kernel,
                              const char* name) {
  if (ctx->debugging) {
    fprintf(ctx->log, "Creating kernel %s.\n", name);
  }
  CUDA_SUCCEED_FATAL(cuModuleGetFunction(kernel, ctx->module, name));
  // Unless the below is set, the kernel is limited to 48KiB of memory.
  CUDA_SUCCEED_FATAL(cuFuncSetAttribute(*kernel,
                                        cudaFuncAttributeMaxDynamicSharedMemorySize,
                                        ctx->max_shared_memory));
}

static void gpu_free_kernel(struct futhark_context *ctx,
                            gpu_kernel kernel) {
  (void)ctx;
  (void)kernel;
}

static int gpu_scalar_to_device(struct futhark_context* ctx,
                                gpu_mem dst, size_t offset, size_t size,
                                void *src) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(dst + offset, src, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_scalar_from_device(struct futhark_context* ctx,
                                  void *dst,
                                  gpu_mem src, size_t offset, size_t size) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_from_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(dst, src + offset, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_memcpy(struct futhark_context* ctx,
                      gpu_mem dst, int64_t dst_offset,
                      gpu_mem src, int64_t src_offset,
                      int64_t nbytes) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_dev_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyAsync(dst+dst_offset, src+src_offset, nbytes, ctx->stream));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_host2gpu(struct futhark_context* ctx, bool sync,
                           gpu_mem dst, int64_t dst_offset,
                           const unsigned char* src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_host_to_dev",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoD(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoDAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_gpu2host(struct futhark_context* ctx, bool sync,
                           unsigned char* dst, int64_t dst_offset,
                           gpu_mem src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_dev_to_host",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoH(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoHAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
    if (sync &&
        ctx->failure_is_an_option &&
        futhark_context_sync(ctx) != 0) {
      return 1;
    }
  }
  return FUTHARK_SUCCESS;
}

static int gpu_launch_kernel(struct futhark_context* ctx,
                             gpu_kernel kernel, const char *name,
                             const int32_t grid[3],
                             const int32_t block[3],
                             unsigned int shared_mem_bytes,
                             int num_args,
                             void* args[num_args],
                             size_t args_sizes[num_args]) {
  (void) args_sizes;

  if (shared_mem_bytes > ctx->max_shared_memory) {
    set_error(ctx, msgprintf("Kernel %s with %d bytes of memory exceeds device limit of %d\n",
                             name, shared_mem_bytes, (int)ctx->max_shared_memory));
    return 1;
  }

  int64_t time_start = 0, time_end = 0;
  if (ctx->debugging) {
    time_start = get_wall_time();
  }

  struct cuda_event *event = cuda_event_new(ctx);

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    add_event(ctx,
              name,
              msgprintf("Kernel %s with\n"
                        "  grid=(%d,%d,%d)\n"
                        "  block=(%d,%d,%d)\n"
                        "  shared memory=%d",
                        name,
                        grid[0], grid[1], grid[2],
                        block[0], block[1], block[2],
                        shared_mem_bytes),
              event,
              (event_report_fn)cuda_event_report);
  }

  CUDA_SUCCEED_OR_RETURN
    (cuLaunchKernel(kernel,
                    grid[0], grid[1], grid[2],
                    block[0], block[1], block[2],
                    shared_mem_bytes, ctx->stream,
                    args, NULL));

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }

  if (ctx->debugging) {
    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
    time_end = get_wall_time();
    long int time_diff = time_end - time_start;
    fprintf(ctx->log, "  runtime: %ldus\n", time_diff);
  }
  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return FUTHARK_SUCCESS;
}

static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out) {
  CUresult res;
  if (ctx->cfg->unified_memory) {
    res = cuMemAllocManaged(mem_out, size, CU_MEM_ATTACH_GLOBAL);
  } else {
    res = cuMemAlloc(mem_out, size);
  }

  if (res == CUDA_ERROR_OUT_OF_MEMORY) {
    return FUTHARK_OUT_OF_MEMORY;
  }

  CUDA_SUCCEED_OR_RETURN(res);
  return FUTHARK_SUCCESS;
}

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem) {
  (void)ctx;
  CUDA_SUCCEED_OR_RETURN(cuMemFree(mem));
  return FUTHARK_SUCCESS;
}

// End of backends/cuda.h.

// Start of gpu.h

// Generic functions that use our tiny GPU abstraction layer.  The
// entire context must be defined before this header is included.  In
// particular we expect the following functions to be available:

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem);
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out);
int gpu_launch_kernel(struct futhark_context* ctx,
                      gpu_kernel kernel, const char *name,
                      const int32_t grid[3],
                      const int32_t block[3],
                      unsigned int shared_mem_bytes,
                      int num_args,
                      void* args[num_args],
                      size_t args_sizes[num_args]);
int gpu_memcpy(struct futhark_context* ctx,
               gpu_mem dst, int64_t dst_offset,
               gpu_mem src, int64_t src_offset,
               int64_t nbytes);
int gpu_scalar_from_device(struct futhark_context* ctx,
                           void *dst,
                           gpu_mem src, size_t offset, size_t size);
int gpu_scalar_to_device(struct futhark_context* ctx,
                         gpu_mem dst, size_t offset, size_t size,
                         void *src);
void gpu_create_kernel(struct futhark_context *ctx,
                       gpu_kernel* kernel,
                       const char* name);

static void gpu_init_log(struct futhark_context *ctx) {
  if (ctx->cfg->logging) {
    fprintf(ctx->log, "Default block size: %ld\n", (long)ctx->cfg->gpu.default_block_size);
    fprintf(ctx->log, "Default grid size: %ld\n", (long)ctx->cfg->gpu.default_grid_size);
    fprintf(ctx->log, "Default tile size: %ld\n", (long)ctx->cfg->gpu.default_tile_size);
    fprintf(ctx->log, "Default register tile size: %ld\n", (long)ctx->cfg->gpu.default_reg_tile_size);
    fprintf(ctx->log, "Default cache: %ld\n", (long)ctx->cfg->gpu.default_cache);
    fprintf(ctx->log, "Default registers: %ld\n", (long)ctx->cfg->gpu.default_registers);
    fprintf(ctx->log, "Default threshold: %ld\n", (long)ctx->cfg->gpu.default_threshold);
    fprintf(ctx->log, "Max thread block size: %ld\n", (long)ctx->max_thread_block_size);
    fprintf(ctx->log, "Max grid size: %ld\n", (long)ctx->max_grid_size);
    fprintf(ctx->log, "Max tile size: %ld\n", (long)ctx->max_tile_size);
    fprintf(ctx->log, "Max threshold: %ld\n", (long)ctx->max_threshold);
    fprintf(ctx->log, "Max shared memory: %ld\n", (long)ctx->max_shared_memory);
    fprintf(ctx->log, "Max registers: %ld\n", (long)ctx->max_registers);
    fprintf(ctx->log, "Max cache: %ld\n", (long)ctx->max_cache);
    fprintf(ctx->log, "Lockstep width: %ld\n", (long)ctx->lockstep_width);
  }
}

// Generic GPU command line options.

void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_block_size = size;
  cfg->gpu.default_block_size_changed = 1;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  futhark_context_config_set_default_thread_block_size(cfg, size);
}

void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int num) {
  cfg->gpu.default_grid_size = num;
  cfg->gpu.default_grid_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  futhark_context_config_set_default_grid_size(cfg, num);
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_tile_size = size;
  cfg->gpu.default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_reg_tile_size = size;
}

void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_cache = size;
}

void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_registers = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_thread_block_size") == 0 ||
      strcmp(param_name, "default_group_size") == 0) {
    cfg->gpu.default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_grid_size") == 0 ||
      strcmp(param_name, "default_num_groups") == 0) {
    cfg->gpu.default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->gpu.default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->gpu.default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->gpu.default_reg_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_cache") == 0) {
    cfg->gpu.default_cache = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_shared_memory") == 0) {
    cfg->gpu.default_shared_memory = new_value;
    return 0;
  }

  return 1;
}

// End of GPU command line optiopns.

// Max number of thead blocks we allow along the second or third
// dimension for transpositions.
#define MAX_TR_THREAD_BLOCKS 65535

struct builtin_kernels {
  // We have a lot of ways to transpose arrays.
  gpu_kernel map_transpose_1b;
  gpu_kernel map_transpose_1b_low_height;
  gpu_kernel map_transpose_1b_low_width;
  gpu_kernel map_transpose_1b_small;
  gpu_kernel map_transpose_1b_large;
  gpu_kernel map_transpose_2b;
  gpu_kernel map_transpose_2b_low_height;
  gpu_kernel map_transpose_2b_low_width;
  gpu_kernel map_transpose_2b_small;
  gpu_kernel map_transpose_2b_large;
  gpu_kernel map_transpose_4b;
  gpu_kernel map_transpose_4b_low_height;
  gpu_kernel map_transpose_4b_low_width;
  gpu_kernel map_transpose_4b_small;
  gpu_kernel map_transpose_4b_large;
  gpu_kernel map_transpose_8b;
  gpu_kernel map_transpose_8b_low_height;
  gpu_kernel map_transpose_8b_low_width;
  gpu_kernel map_transpose_8b_small;
  gpu_kernel map_transpose_8b_large;

  // And a few ways of copying.
  gpu_kernel lmad_copy_1b;
  gpu_kernel lmad_copy_2b;
  gpu_kernel lmad_copy_4b;
  gpu_kernel lmad_copy_8b;
};

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx) {
  struct builtin_kernels *kernels = malloc(sizeof(struct builtin_kernels));
  gpu_create_kernel(ctx, &kernels->map_transpose_1b, "map_transpose_1b");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_large, "map_transpose_1b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_height, "map_transpose_1b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_width, "map_transpose_1b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_small, "map_transpose_1b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_2b, "map_transpose_2b");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_large, "map_transpose_2b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_height, "map_transpose_2b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_width, "map_transpose_2b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_small, "map_transpose_2b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_4b, "map_transpose_4b");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_large, "map_transpose_4b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_height, "map_transpose_4b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_width, "map_transpose_4b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_small, "map_transpose_4b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_8b, "map_transpose_8b");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_large, "map_transpose_8b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_height, "map_transpose_8b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_width, "map_transpose_8b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_small, "map_transpose_8b_small");

  gpu_create_kernel(ctx, &kernels->lmad_copy_1b, "lmad_copy_1b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_2b, "lmad_copy_2b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_4b, "lmad_copy_4b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_8b, "lmad_copy_8b");

  return kernels;
}

void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels) {
  gpu_free_kernel(ctx, kernels->map_transpose_1b);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_2b);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_4b);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_8b);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_small);

  gpu_free_kernel(ctx, kernels->lmad_copy_1b);
  gpu_free_kernel(ctx, kernels->lmad_copy_2b);
  gpu_free_kernel(ctx, kernels->lmad_copy_4b);
  gpu_free_kernel(ctx, kernels->lmad_copy_8b);

  free(kernels);
}

static int gpu_alloc(struct futhark_context *ctx, FILE *log,
                     size_t min_size, const char *tag,
                     gpu_mem *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  gpu_mem* memptr;
  if (free_list_find(&ctx->gpu_free_list, min_size, tag, size_out, (fl_mem*)&memptr) == 0) {
    // Successfully found a free block.  Is it big enough?
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      *mem_out = *memptr;
      free(memptr);
      return FUTHARK_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }
      int error = gpu_free_actual(ctx, *memptr);
      free(memptr);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    }
  }

  *size_out = min_size;

  // We have to allocate a new block from the driver.  If the
  // allocation does not succeed, then we might be in an out-of-memory
  // situation.  We now start freeing things from the free list until
  // we think we have freed enough that the allocation will succeed.
  // Since we don't know how far the allocation is from fitting, we
  // have to check after every deallocation.  This might be pretty
  // expensive.  Let's hope that this case is hit rarely.

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  int error = gpu_alloc_actual(ctx, min_size, mem_out);

  while (error == FUTHARK_OUT_OF_MEMORY) {
    if (ctx->cfg->debugging) {
      fprintf(log, "Out of GPU memory: releasing entry from the free list...\n");
    }
    gpu_mem* memptr;
    if (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
      gpu_mem mem = *memptr;
      free(memptr);
      error = gpu_free_actual(ctx, mem);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    } else {
      break;
    }
    error = gpu_alloc_actual(ctx, min_size, mem_out);
  }

  return error;
}

static int gpu_free(struct futhark_context *ctx,
                    gpu_mem mem, size_t size, const char *tag) {
  gpu_mem* memptr = malloc(sizeof(gpu_mem));
  *memptr = mem;
  free_list_insert(&ctx->gpu_free_list, size, (fl_mem)memptr, tag);
  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx) {
  free_list_pack(&ctx->gpu_free_list);
  gpu_mem* memptr;
  while (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
    gpu_mem mem = *memptr;
    free(memptr);
    int error = gpu_free_actual(ctx, mem);
    if (error != FUTHARK_SUCCESS) {
      return error;
    }
  }

  return FUTHARK_SUCCESS;
}

static int gpu_map_transpose(struct futhark_context* ctx,
                             gpu_kernel kernel_default,
                             gpu_kernel kernel_low_height,
                             gpu_kernel kernel_low_width,
                             gpu_kernel kernel_small,
                             gpu_kernel kernel_large,
                             const char *name, size_t elem_size,
                             gpu_mem dst, int64_t dst_offset,
                             gpu_mem src, int64_t src_offset,
                             int64_t k, int64_t n, int64_t m) {
  int64_t mulx = TR_BLOCK_DIM / n;
  int64_t muly = TR_BLOCK_DIM / m;
  int32_t mulx32 = mulx;
  int32_t muly32 = muly;
  int32_t k32 = k;
  int32_t n32 = n;
  int32_t m32 = m;

  gpu_kernel kernel = kernel_default;
  int32_t grid[3];
  int32_t block[3];

  void* args[11];
  size_t args_sizes[11] = {
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t)
  };

  args[0] = &dst;
  args[1] = &dst_offset;
  args[2] = &src;
  args[3] = &src_offset;
  args[7] = &mulx;
  args[8] = &muly;

  if (dst_offset + k * n * m <= 2147483647L &&
      src_offset + k * n * m <= 2147483647L) {
    if (m <= TR_BLOCK_DIM/2 && n <= TR_BLOCK_DIM/2) {
      if (ctx->logging) { fprintf(ctx->log, "Using small kernel\n"); }
      kernel = kernel_small;
      grid[0] = ((k * n * m) + (TR_BLOCK_DIM*TR_BLOCK_DIM) - 1) / (TR_BLOCK_DIM*TR_BLOCK_DIM);
      grid[1] = 1;
      grid[2] = 1;
      block[0] = TR_BLOCK_DIM*TR_BLOCK_DIM;
      block[1] = 1;
      block[2] = 1;
    } else if (m <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < n) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-width kernel\n"); }
      kernel = kernel_low_width;
      int64_t x_elems = m;
      int64_t y_elems = (n + muly - 1) / muly;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else if (n <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < m) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-height kernel\n"); }
      kernel = kernel_low_height;
      int64_t x_elems = (m + mulx - 1) / mulx;
      int64_t y_elems = n;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else {
      if (ctx->logging) { fprintf(ctx->log, "Using default kernel\n"); }
      kernel = kernel_default;
      grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[2] = k;
      block[0] = TR_TILE_DIM;
      block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
      block[2] = 1;
    }
    args[4] = &k32;
    args[5] = &m32;
    args[6] = &n32;
    args[7] = &mulx32;
    args[8] = &muly32;
  } else {
    if (ctx->logging) { fprintf(ctx->log, "Using large kernel\n"); }
    kernel = kernel_large;
    grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[2] = k;
    block[0] = TR_TILE_DIM;
    block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
    block[2] = 1;
    args[4] = &k;
    args[5] = &m;
    args[6] = &n;
    args[7] = &mulx;
    args[8] = &muly;
    args_sizes[4] = sizeof(int64_t);
    args_sizes[5] = sizeof(int64_t);
    args_sizes[6] = sizeof(int64_t);
    args_sizes[7] = sizeof(int64_t);
    args_sizes[8] = sizeof(int64_t);
  }

  // Cap the number of thead blocks we launch and figure out how many
  // repeats we need alongside each dimension.
  int32_t repeat_1 = grid[1] / MAX_TR_THREAD_BLOCKS;
  int32_t repeat_2 = grid[2] / MAX_TR_THREAD_BLOCKS;
  grid[1] = repeat_1 > 0 ? MAX_TR_THREAD_BLOCKS : grid[1];
  grid[2] = repeat_2 > 0 ? MAX_TR_THREAD_BLOCKS : grid[2];
  args[9] = &repeat_1;
  args[10] = &repeat_2;
  args_sizes[9] = sizeof(repeat_1);
  args_sizes[10] = sizeof(repeat_2);

  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return gpu_launch_kernel(ctx, kernel, name, grid, block,
                           TR_TILE_DIM*(TR_TILE_DIM+1)*elem_size,
                           sizeof(args)/sizeof(args[0]), args, args_sizes);
}

#define GEN_MAP_TRANSPOSE_GPU2GPU(NAME, ELEM_TYPE)                      \
  static int map_transpose_gpu2gpu_##NAME                               \
  (struct futhark_context* ctx,                                         \
   gpu_mem dst, int64_t dst_offset,                                     \
   gpu_mem src, int64_t src_offset,                                     \
   int64_t k, int64_t m, int64_t n)                                     \
  {                                                                     \
    return                                                              \
      gpu_map_transpose                                                 \
      (ctx,                                                             \
       ctx->kernels->map_transpose_##NAME,                              \
       ctx->kernels->map_transpose_##NAME##_low_height,                 \
       ctx->kernels->map_transpose_##NAME##_low_width,                  \
       ctx->kernels->map_transpose_##NAME##_small,                      \
       ctx->kernels->map_transpose_##NAME##_large,                      \
       "map_transpose_" #NAME, sizeof(ELEM_TYPE),                       \
       dst, dst_offset, src, src_offset,                                \
       k, n, m);                                                        \
  }

static int gpu_lmad_copy(struct futhark_context* ctx,
                         gpu_kernel kernel, int r,
                         gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                         gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                         int64_t shape[r]) {
  if (r > 8) {
    set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n"));
    return 1;
  }

  int64_t n = 1;
  for (int i = 0; i < r; i++) { n *= shape[i]; }

  void* args[6+(8*3)];
  size_t args_sizes[6+(8*3)];

  args[0] = &dst;
  args_sizes[0] = sizeof(gpu_mem);
  args[1] = &dst_offset;
  args_sizes[1] = sizeof(dst_offset);
  args[2] = &src;
  args_sizes[2] = sizeof(gpu_mem);
  args[3] = &src_offset;
  args_sizes[3] = sizeof(src_offset);
  args[4] = &n;
  args_sizes[4] = sizeof(n);
  args[5] = &r;
  args_sizes[5] = sizeof(r);

  int64_t zero = 0;

  for (int i = 0; i < 8; i++) {
    args_sizes[6+i*3] = sizeof(int64_t);
    args_sizes[6+i*3+1] = sizeof(int64_t);
    args_sizes[6+i*3+2] = sizeof(int64_t);
    if (i < r) {
      args[6+i*3] = &shape[i];
      args[6+i*3+1] = &dst_strides[i];
      args[6+i*3+2] = &src_strides[i];
    } else {
      args[6+i*3] = &zero;
      args[6+i*3+1] = &zero;
      args[6+i*3+2] = &zero;
    }
  }
  const size_t w = 256; // XXX: hardcoded thread block size.

  return gpu_launch_kernel(ctx, kernel, "copy_lmad_dev_to_dev",
                           (const int32_t[3]) {(n+w-1)/w,1,1},
                           (const int32_t[3]) {w,1,1},
                           0, 6+(8*3), args, args_sizes);
}

#define GEN_LMAD_COPY_ELEMENTS_GPU2GPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return gpu_lmad_copy(ctx, ctx->kernels->lmad_copy_##NAME, r,        \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \

#define GEN_LMAD_COPY_GPU2GPU(NAME, ELEM_TYPE)                          \
  static int lmad_copy_gpu2gpu_##NAME                                   \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "GPU to GPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return FUTHARK_SUCCESS; }                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                       r, dst_strides, src_strides, shape)) {           \
      log_transpose(ctx, k, n, m);                                      \
      return map_transpose_gpu2gpu_##NAME                               \
        (ctx, dst, dst_offset, src, src_offset, k, n, m);               \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}        \
      return gpu_memcpy(ctx,                                            \
                        dst, dst_offset*sizeof(ELEM_TYPE),              \
                        src, src_offset*sizeof(ELEM_TYPE),              \
                        size * sizeof(ELEM_TYPE));                      \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}     \
      return lmad_copy_elements_gpu2gpu_##NAME                          \
        (ctx, r,                                                        \
         dst, dst_offset, dst_strides,                                  \
         src, src_offset, src_strides,                                  \
         shape);                                                        \
    }                                                                   \
  }

static int
lmad_copy_elements_host2gpu(struct futhark_context *ctx, size_t elem_size,
                            int r,
                            gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                            unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                            int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from host to GPU.\n"));
  return 1;
}

static int
lmad_copy_elements_gpu2host (struct futhark_context *ctx, size_t elem_size,
                             int r,
                             unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                             gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                             int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from GPU to host.\n"));
  return 1;
}

#define GEN_LMAD_COPY_ELEMENTS_HOSTGPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return (ctx, ctx->kernels->lmad_copy_##NAME, r,                     \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \


static int lmad_copy_host2gpu(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                              unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_host2gpu(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_host2gpu
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

static int lmad_copy_gpu2host(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                              gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_gpu2host(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_gpu2host
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

GEN_MAP_TRANSPOSE_GPU2GPU(1b, uint8_t)
GEN_MAP_TRANSPOSE_GPU2GPU(2b, uint16_t)
GEN_MAP_TRANSPOSE_GPU2GPU(4b, uint32_t)
GEN_MAP_TRANSPOSE_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_GPU2GPU(8b, uint64_t)

// End of gpu.h

static int gpu_macros(struct futhark_context *ctx, char ***names_out, int64_t **values_out)
{
    int num_macros = 100;
    char **names = malloc(num_macros * sizeof(char *));
    int64_t *values = malloc(num_macros * sizeof(int64_t));
    
    {
        names[0] = "simulate_8477zisegmap_22980_dim1";
        values[0] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22982;
    }
    {
        names[1] = "simulate_8477zisegmap_22980zisegmap_tblock_sizze_22983";
        values[1] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22982;
    }
    {
        names[2] = "simulate_8477zisegmap_22960_dim1";
        values[2] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22924;
    }
    {
        names[3] = "simulate_8477zisegmap_22960zisegmap_tblock_sizze_22955";
        values[3] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22924;
    }
    {
        names[4] = "simulate_8477zigpuseq_25059_dim1";
        values[4] = (int64_t) 1;
    }
    {
        names[5] = "simulate_8477zisegmap_22914_dim1";
        values[5] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22916;
    }
    {
        names[6] = "simulate_8477zisegmap_22914zisegmap_tblock_sizze_22917";
        values[6] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22916;
    }
    {
        names[7] = "simulate_8477zisegmap_22900_dim1";
        values[7] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22870;
    }
    {
        names[8] = "simulate_8477zisegmap_22900zisegmap_tblock_sizze_22895";
        values[8] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22870;
    }
    {
        names[9] = "simulate_8477zigpuseq_25025_dim1";
        values[9] = (int64_t) 1;
    }
    {
        names[10] = "simulate_8477zisegmap_22860_dim1";
        values[10] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22862;
    }
    {
        names[11] = "simulate_8477zisegmap_22860zisegmap_tblock_sizze_22863";
        values[11] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22862;
    }
    {
        names[12] = "simulate_8477zisegmap_22847_dim1";
        values[12] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22818;
    }
    {
        names[13] = "simulate_8477zisegmap_22847zisegmap_tblock_sizze_22842";
        values[13] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22818;
    }
    {
        names[14] = "simulate_8477zigpuseq_24991_dim1";
        values[14] = (int64_t) 1;
    }
    {
        names[15] = "simulate_8477zisegmap_22808_dim1";
        values[15] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22810;
    }
    {
        names[16] = "simulate_8477zisegmap_22808zisegmap_tblock_sizze_22811";
        values[16] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22810;
    }
    {
        names[17] = "simulate_8477zisegred_large_22800_dim1";
        values[17] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22777;
    }
    {
        names[18] = "simulate_8477zisegred_large_22800zisegred_tblock_sizze_22794";
        values[18] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22777;
    }
    {
        names[19] = "simulate_8477zisegred_large_22800zichunk_sizze_24903";
        values[19] = (int64_t) 1;
    }
    {
        names[20] = "simulate_8477zisegred_small_22800_dim1";
        values[20] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22777;
    }
    {
        names[21] = "simulate_8477zisegred_small_22800zisegred_tblock_sizze_22794";
        values[21] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22777;
    }
    {
        names[22] = "simulate_8477zisegmap_22767_dim1";
        values[22] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22751;
    }
    {
        names[23] = "simulate_8477zisegmap_22767zisegmap_tblock_sizze_22763";
        values[23] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22751;
    }
    {
        names[24] = "simulate_8477zisegred_large_22739_dim1";
        values[24] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22716;
    }
    {
        names[25] = "simulate_8477zisegred_large_22739zisegred_tblock_sizze_22733";
        values[25] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22716;
    }
    {
        names[26] = "simulate_8477zisegred_large_22739zichunk_sizze_24820";
        values[26] = (int64_t) 1;
    }
    {
        names[27] = "simulate_8477zisegred_small_22739_dim1";
        values[27] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22716;
    }
    {
        names[28] = "simulate_8477zisegred_small_22739zisegred_tblock_sizze_22733";
        values[28] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22716;
    }
    {
        names[29] = "simulate_8477zisegmap_22706_dim1";
        values[29] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22690;
    }
    {
        names[30] = "simulate_8477zisegmap_22706zisegmap_tblock_sizze_22702";
        values[30] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22690;
    }
    {
        names[31] = "simulate_8477zigpuseq_24803_dim1";
        values[31] = (int64_t) 1;
    }
    {
        names[32] = "simulate_8477zisegred_nonseg_22676_dim1";
        values[32] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22506;
    }
    {
        names[33] = "simulate_8477zisegred_nonseg_22676zisegred_tblock_sizze_22670";
        values[33] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22506;
    }
    {
        names[34] = "simulate_8477zisegred_nonseg_22676zichunk_sizze_24769";
        values[34] = (int64_t) 1;
    }
    {
        names[35] = "simulate_8477zisegmap_22653_dim1";
        values[35] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22336;
    }
    {
        names[36] = "simulate_8477zisegmap_22653zisegmap_tblock_sizze_22649";
        values[36] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22336;
    }
    {
        names[37] = "simulate_8477zisegred_large_22608_dim1";
        values[37] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22357;
    }
    {
        names[38] = "simulate_8477zisegred_large_22608zisegred_tblock_sizze_22600";
        values[38] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22357;
    }
    {
        names[39] = "simulate_8477zisegred_large_22608zichunk_sizze_24687";
        values[39] = (int64_t) 1;
    }
    {
        names[40] = "simulate_8477zisegred_small_22608_dim1";
        values[40] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22357;
    }
    {
        names[41] = "simulate_8477zisegred_small_22608zisegred_tblock_sizze_22600";
        values[41] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22357;
    }
    {
        names[42] = "simulate_8477zisegmap_22591_dim1";
        values[42] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22409;
    }
    {
        names[43] = "simulate_8477zisegmap_22591zisegmap_tblock_sizze_22585";
        values[43] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22409;
    }
    {
        names[44] = "simulate_8477zisegmap_22528_dim1";
        values[44] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22204;
    }
    {
        names[45] = "simulate_8477zisegmap_22528zisegmap_tblock_sizze_22521";
        values[45] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22204;
    }
    {
        names[46] = "simulate_8477zigpuseq_24656_dim1";
        values[46] = (int64_t) 1;
    }
    {
        names[47] = "simulate_8477zisegred_nonseg_22135_dim1";
        values[47] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22115;
    }
    {
        names[48] = "simulate_8477zisegred_nonseg_22135zisegred_tblock_sizze_22127";
        values[48] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22115;
    }
    {
        names[49] = "simulate_8477zisegred_nonseg_22135zichunk_sizze_24619";
        values[49] = (int64_t) 1;
    }
    {
        names[50] = "simulate_8477zigpuseq_24609_dim1";
        values[50] = (int64_t) 1;
    }
    {
        names[51] = "simulate_8477zisegmap_22105_dim1";
        values[51] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22107;
    }
    {
        names[52] = "simulate_8477zisegmap_22105zisegmap_tblock_sizze_22108";
        values[52] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22107;
    }
    {
        names[53] = "simulate_8477zisegscan_22103_dim1";
        values[53] = *ctx->tuning_params.simulate_8477zisegscan_tblock_sizze_22097;
    }
    {
        names[54] = "simulate_8477zisegscan_22103zisegscan_tblock_sizze_22098";
        values[54] = *ctx->tuning_params.simulate_8477zisegscan_tblock_sizze_22097;
    }
    {
        names[55] = "simulate_8477zisegscan_22103zichunk_sizze_24491";
        values[55] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[56] = "simulate_8477zisegmap_22089_dim1";
        values[56] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22091;
    }
    {
        names[57] = "simulate_8477zisegmap_22089zisegmap_tblock_sizze_22092";
        values[57] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22091;
    }
    {
        names[58] = "simulate_8477zisegmap_22081_dim1";
        values[58] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22083;
    }
    {
        names[59] = "simulate_8477zisegmap_22081zisegmap_tblock_sizze_22084";
        values[59] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22083;
    }
    {
        names[60] = "simulate_8477zisegmap_22073_dim1";
        values[60] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22075;
    }
    {
        names[61] = "simulate_8477zisegmap_22073zisegmap_tblock_sizze_22076";
        values[61] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22075;
    }
    {
        names[62] = "simulate_8477zisegmap_22065_dim1";
        values[62] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22049;
    }
    {
        names[63] = "simulate_8477zisegmap_22065zisegmap_tblock_sizze_22061";
        values[63] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22049;
    }
    {
        names[64] = "simulate_8477zisegmap_22039_dim1";
        values[64] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22041;
    }
    {
        names[65] = "simulate_8477zisegmap_22039zisegmap_tblock_sizze_22042";
        values[65] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22041;
    }
    {
        names[66] = "simulate_8477zisegmap_22011_dim1";
        values[66] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21856;
    }
    {
        names[67] = "simulate_8477zisegmap_22011zisegmap_tblock_sizze_22007";
        values[67] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21856;
    }
    {
        names[68] = "simulate_8477zisegred_large_21963_dim1";
        values[68] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21877;
    }
    {
        names[69] = "simulate_8477zisegred_large_21963zisegred_tblock_sizze_21956";
        values[69] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21877;
    }
    {
        names[70] = "simulate_8477zisegred_large_21963zichunk_sizze_24281";
        values[70] = (int64_t) 1;
    }
    {
        names[71] = "simulate_8477zisegred_small_21963_dim1";
        values[71] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21877;
    }
    {
        names[72] = "simulate_8477zisegred_small_21963zisegred_tblock_sizze_21956";
        values[72] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21877;
    }
    {
        names[73] = "simulate_8477zisegmap_21948_dim1";
        values[73] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21932;
    }
    {
        names[74] = "simulate_8477zisegmap_21948zisegmap_tblock_sizze_21943";
        values[74] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21932;
    }
    {
        names[75] = "simulate_8477zisegmap_21774_dim1";
        values[75] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21698;
    }
    {
        names[76] = "simulate_8477zisegmap_21774zisegmap_tblock_sizze_21768";
        values[76] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21698;
    }
    {
        names[77] = "simulate_8477zisegred_nonseg_23843_dim1";
        values[77] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_23835;
    }
    {
        names[78] = "simulate_8477zisegred_nonseg_23843zisegred_num_tblocks_23834";
        values[78] = *ctx->tuning_params.simulate_8477zisegred_num_tblocks_23833;
    }
    {
        names[79] = "simulate_8477zisegred_nonseg_23843zisegred_tblock_sizze_23836";
        values[79] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_23835;
    }
    {
        names[80] = "simulate_8477zisegred_nonseg_23843zichunk_sizze_24218";
        values[80] = (int64_t) 1;
    }
    {
        names[81] = "simulate_8477zisegmap_21663_dim1";
        values[81] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21665;
    }
    {
        names[82] = "simulate_8477zisegmap_21663zisegmap_tblock_sizze_21666";
        values[82] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21665;
    }
    {
        names[83] = "simulate_8477zisegmap_21689_dim1";
        values[83] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21673;
    }
    {
        names[84] = "simulate_8477zisegmap_21689zisegmap_tblock_sizze_21684";
        values[84] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21673;
    }
    {
        names[85] = "simulate_8477zisegscan_21661_dim1";
        values[85] = *ctx->tuning_params.simulate_8477zisegscan_tblock_sizze_21655;
    }
    {
        names[86] = "simulate_8477zisegscan_21661zisegscan_tblock_sizze_21656";
        values[86] = *ctx->tuning_params.simulate_8477zisegscan_tblock_sizze_21655;
    }
    {
        names[87] = "simulate_8477zisegscan_21661zichunk_sizze_24069";
        values[87] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[88] = "simulate_8477zigpuseq_24059_dim1";
        values[88] = (int64_t) 1;
    }
    {
        names[89] = "simulate_8477zigpuseq_24049_dim1";
        values[89] = (int64_t) 1;
    }
    {
        names[90] = "simulate_8477zisegred_nonseg_21653_dim1";
        values[90] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21644;
    }
    {
        names[91] = "simulate_8477zisegred_nonseg_21653zisegred_tblock_sizze_21645";
        values[91] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21644;
    }
    {
        names[92] = "simulate_8477zisegred_nonseg_21653zichunk_sizze_23994";
        values[92] = (int64_t) 1;
    }
    {
        names[93] = "simulate_8477zigpuseq_23988_dim1";
        values[93] = (int64_t) 1;
    }
    {
        names[94] = "simulate_8477zigpuseq_23981_dim1";
        values[94] = (int64_t) 1;
    }
    {
        names[95] = "simulate_8477zisegmap_21631_dim1";
        values[95] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21568;
    }
    {
        names[96] = "simulate_8477zisegmap_21631zisegmap_tblock_sizze_21626";
        values[96] = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21568;
    }
    {
        names[97] = "simulate_8477zisegred_nonseg_21553_dim1";
        values[97] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21545;
    }
    {
        names[98] = "simulate_8477zisegred_nonseg_21553zisegred_tblock_sizze_21546";
        values[98] = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21545;
    }
    {
        names[99] = "simulate_8477zisegred_nonseg_21553zichunk_sizze_23890";
        values[99] = (int64_t) 1;
    }
    *names_out = names;
    *values_out = values;
    return num_macros;
}
static char *get_failure_msg(int failure_idx, int64_t args[])
{
    (void) args;
    switch (failure_idx) {
        
      case 0:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:102:23-35\n   #1  definitions.fut:102:39-52\n", args[0], args[1]);
            break;
        }
        
      case 1:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:102:23-32\n   #1  definitions.fut:102:39-52\n", args[0], args[1]);
            break;
        }
        
      case 2:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:137:43-53\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n", args[0], args[1]);
            break;
        }
        
      case 3:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:43-52\n   #1  definitions.fut:25:92-98\n   #2  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 4:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:26:43-52\n   #1  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 5:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:106:53-62\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n", args[0], args[1]);
            break;
        }
        
      case 6:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:106:53-65\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n", args[0], args[1]);
            break;
        }
        
      case 7:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-82\n   #1  definitions.fut:25:92-98\n   #2  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 8:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-82\n   #1  definitions.fut:25:92-98\n   #2  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 9:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:26:18-27\n   #1  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 10:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-89\n   #1  definitions.fut:25:92-98\n   #2  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 11:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:60-72\n   #1  definitions.fut:25:92-98\n   #2  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 12:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-82\n   #1  definitions.fut:25:92-98\n   #2  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 13:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-89\n   #1  definitions.fut:25:92-98\n   #2  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 14:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:60-72\n   #1  definitions.fut:25:92-98\n   #2  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 15:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:73-89\n   #1  definitions.fut:25:92-98\n   #2  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 16:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:25:60-72\n   #1  definitions.fut:25:92-98\n   #2  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 17:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:26:18-27\n   #1  definitions.fut:89:58-109:37\n", args[0], args[1]);
            break;
        }
        
      case 18:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:137:43-50\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n", args[0], args[1]);
            break;
        }
        
      case 19:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:145:31-40\n   #1  definitions.fut:148:27-33\n", args[0], args[1]);
            break;
        }
        
      case 20:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:150:64-73\n", args[0], args[1]);
            break;
        }
        
      case 21:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:147:31-51\n   #1  definitions.fut:148:27-33\n", args[0], args[1]);
            break;
        }
        
      case 22:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:146:31-47\n   #1  definitions.fut:148:27-33\n", args[0], args[1]);
            break;
        }
        
      case 23:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:145:31-40\n   #1  definitions.fut:148:27-33\n", args[0], args[1]);
            break;
        }
        
      case 24:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:150:64-73\n", args[0], args[1]);
            break;
        }
        
      case 25:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:147:31-51\n   #1  definitions.fut:148:27-33\n", args[0], args[1]);
            break;
        }
        
      case 26:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:146:31-47\n   #1  definitions.fut:148:27-33\n", args[0], args[1]);
            break;
        }
        
      case 27:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:145:31-40\n   #1  definitions.fut:148:27-33\n", args[0], args[1]);
            break;
        }
        
      case 28:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:147:31-51\n   #1  definitions.fut:148:27-33\n", args[0], args[1]);
            break;
        }
        
      case 29:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:146:31-47\n   #1  definitions.fut:148:27-33\n", args[0], args[1]);
            break;
        }
        
      case 30:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:147:31-51\n   #1  definitions.fut:148:27-33\n", args[0], args[1]);
            break;
        }
        
      case 31:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:146:31-47\n   #1  definitions.fut:148:27-33\n", args[0], args[1]);
            break;
        }
        
      case 32:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:150:64-73\n", args[0], args[1]);
            break;
        }
        
      case 33:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:69:22-38\n   #1  definitions.fut:72:10-18\n   #2  main.fut:7:78-19:39\n", args[0], args[1]);
            break;
        }
        
      case 34:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:68:22-34\n   #1  definitions.fut:72:10-18\n   #2  main.fut:7:78-19:39\n", args[0], args[1]);
            break;
        }
        
      case 35:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:67:21-30\n   #1  definitions.fut:72:10-18\n   #2  main.fut:7:78-19:39\n", args[0], args[1]);
            break;
        }
        
      case 36:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:83:22-38\n   #1  definitions.fut:85:10-18\n   #2  main.fut:7:78-21:36\n", args[0], args[1]);
            break;
        }
        
      case 37:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:82:22-34\n   #1  definitions.fut:85:10-18\n   #2  main.fut:7:78-21:36\n", args[0], args[1]);
            break;
        }
        
      case 38:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:81:21-30\n   #1  definitions.fut:85:10-18\n   #2  main.fut:7:78-21:36\n", args[0], args[1]);
            break;
        }
        
      case 39:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:55:22-34\n   #1  definitions.fut:58:10-18\n   #2  main.fut:7:78-23:42\n", args[0], args[1]);
            break;
        }
        
      case 40:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:54:22-34\n   #1  definitions.fut:58:10-18\n   #2  main.fut:7:78-23:42\n", args[0], args[1]);
            break;
        }
        
      case 41:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:53:22-38\n   #1  definitions.fut:58:10-18\n   #2  main.fut:7:78-23:42\n", args[0], args[1]);
            break;
        }
        
      case 42:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:52:22-38\n   #1  definitions.fut:58:10-18\n   #2  main.fut:7:78-23:42\n", args[0], args[1]);
            break;
        }
        
      case 43:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  definitions.fut:52:22-31\n   #1  definitions.fut:58:10-18\n   #2  main.fut:7:78-23:42\n", args[0], args[1]);
            break;
        }
    }
    return strdup("Unknown error.  This is a compiler bug.");
}
struct program {
    int dummy;
    gpu_kernel builtinzhiota_i64ziiota_i64_24189;
    gpu_kernel builtinzhreplicate_i32zireplicate_23898;
    gpu_kernel builtinzhreplicate_i8zireplicate_23960;
    gpu_kernel simulate_8477zigpuseq_23981;
    gpu_kernel simulate_8477zigpuseq_23988;
    gpu_kernel simulate_8477zigpuseq_24049;
    gpu_kernel simulate_8477zigpuseq_24059;
    gpu_kernel simulate_8477zigpuseq_24609;
    gpu_kernel simulate_8477zigpuseq_24656;
    gpu_kernel simulate_8477zigpuseq_24803;
    gpu_kernel simulate_8477zigpuseq_24991;
    gpu_kernel simulate_8477zigpuseq_25025;
    gpu_kernel simulate_8477zigpuseq_25059;
    gpu_kernel simulate_8477zireplicate_24363;
    gpu_kernel simulate_8477zireplicate_24383;
    gpu_kernel simulate_8477zireplicate_24403;
    gpu_kernel simulate_8477zisegmap_21631;
    gpu_kernel simulate_8477zisegmap_21663;
    gpu_kernel simulate_8477zisegmap_21689;
    gpu_kernel simulate_8477zisegmap_21774;
    gpu_kernel simulate_8477zisegmap_21948;
    gpu_kernel simulate_8477zisegmap_22011;
    gpu_kernel simulate_8477zisegmap_22039;
    gpu_kernel simulate_8477zisegmap_22065;
    gpu_kernel simulate_8477zisegmap_22073;
    gpu_kernel simulate_8477zisegmap_22081;
    gpu_kernel simulate_8477zisegmap_22089;
    gpu_kernel simulate_8477zisegmap_22105;
    gpu_kernel simulate_8477zisegmap_22528;
    gpu_kernel simulate_8477zisegmap_22591;
    gpu_kernel simulate_8477zisegmap_22653;
    gpu_kernel simulate_8477zisegmap_22706;
    gpu_kernel simulate_8477zisegmap_22767;
    gpu_kernel simulate_8477zisegmap_22808;
    gpu_kernel simulate_8477zisegmap_22847;
    gpu_kernel simulate_8477zisegmap_22860;
    gpu_kernel simulate_8477zisegmap_22900;
    gpu_kernel simulate_8477zisegmap_22914;
    gpu_kernel simulate_8477zisegmap_22960;
    gpu_kernel simulate_8477zisegmap_22980;
    gpu_kernel simulate_8477zisegred_large_21963;
    gpu_kernel simulate_8477zisegred_large_22608;
    gpu_kernel simulate_8477zisegred_large_22739;
    gpu_kernel simulate_8477zisegred_large_22800;
    gpu_kernel simulate_8477zisegred_nonseg_21553;
    gpu_kernel simulate_8477zisegred_nonseg_21653;
    gpu_kernel simulate_8477zisegred_nonseg_22135;
    gpu_kernel simulate_8477zisegred_nonseg_22676;
    gpu_kernel simulate_8477zisegred_nonseg_23843;
    gpu_kernel simulate_8477zisegred_small_21963;
    gpu_kernel simulate_8477zisegred_small_22608;
    gpu_kernel simulate_8477zisegred_small_22739;
    gpu_kernel simulate_8477zisegred_small_22800;
    gpu_kernel simulate_8477zisegscan_21661;
    gpu_kernel simulate_8477zisegscan_22103;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    gpu_create_kernel(ctx, &ctx->program->builtinzhiota_i64ziiota_i64_24189, "builtinzhiota_i64ziiota_i64_24189");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_23898, "builtinzhreplicate_i32zireplicate_23898");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i8zireplicate_23960, "builtinzhreplicate_i8zireplicate_23960");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zigpuseq_23981, "simulate_8477zigpuseq_23981");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zigpuseq_23988, "simulate_8477zigpuseq_23988");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zigpuseq_24049, "simulate_8477zigpuseq_24049");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zigpuseq_24059, "simulate_8477zigpuseq_24059");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zigpuseq_24609, "simulate_8477zigpuseq_24609");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zigpuseq_24656, "simulate_8477zigpuseq_24656");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zigpuseq_24803, "simulate_8477zigpuseq_24803");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zigpuseq_24991, "simulate_8477zigpuseq_24991");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zigpuseq_25025, "simulate_8477zigpuseq_25025");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zigpuseq_25059, "simulate_8477zigpuseq_25059");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zireplicate_24363, "simulate_8477zireplicate_24363");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zireplicate_24383, "simulate_8477zireplicate_24383");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zireplicate_24403, "simulate_8477zireplicate_24403");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_21631, "simulate_8477zisegmap_21631");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_21663, "simulate_8477zisegmap_21663");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_21689, "simulate_8477zisegmap_21689");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_21774, "simulate_8477zisegmap_21774");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_21948, "simulate_8477zisegmap_21948");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22011, "simulate_8477zisegmap_22011");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22039, "simulate_8477zisegmap_22039");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22065, "simulate_8477zisegmap_22065");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22073, "simulate_8477zisegmap_22073");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22081, "simulate_8477zisegmap_22081");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22089, "simulate_8477zisegmap_22089");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22105, "simulate_8477zisegmap_22105");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22528, "simulate_8477zisegmap_22528");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22591, "simulate_8477zisegmap_22591");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22653, "simulate_8477zisegmap_22653");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22706, "simulate_8477zisegmap_22706");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22767, "simulate_8477zisegmap_22767");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22808, "simulate_8477zisegmap_22808");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22847, "simulate_8477zisegmap_22847");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22860, "simulate_8477zisegmap_22860");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22900, "simulate_8477zisegmap_22900");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22914, "simulate_8477zisegmap_22914");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22960, "simulate_8477zisegmap_22960");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegmap_22980, "simulate_8477zisegmap_22980");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_large_21963, "simulate_8477zisegred_large_21963");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_large_22608, "simulate_8477zisegred_large_22608");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_large_22739, "simulate_8477zisegred_large_22739");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_large_22800, "simulate_8477zisegred_large_22800");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_nonseg_21553, "simulate_8477zisegred_nonseg_21553");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_nonseg_21653, "simulate_8477zisegred_nonseg_21653");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_nonseg_22135, "simulate_8477zisegred_nonseg_22135");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_nonseg_22676, "simulate_8477zisegred_nonseg_22676");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_nonseg_23843, "simulate_8477zisegred_nonseg_23843");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_small_21963, "simulate_8477zisegred_small_21963");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_small_22608, "simulate_8477zisegred_small_22608");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_small_22739, "simulate_8477zisegred_small_22739");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegred_small_22800, "simulate_8477zisegred_small_22800");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegscan_21661, "simulate_8477zisegscan_21661");
    gpu_create_kernel(ctx, &ctx->program->simulate_8477zisegscan_22103, "simulate_8477zisegscan_22103");
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    gpu_free_kernel(ctx, ctx->program->builtinzhiota_i64ziiota_i64_24189);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_23898);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_23960);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zigpuseq_23981);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zigpuseq_23988);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zigpuseq_24049);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zigpuseq_24059);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zigpuseq_24609);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zigpuseq_24656);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zigpuseq_24803);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zigpuseq_24991);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zigpuseq_25025);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zigpuseq_25059);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zireplicate_24363);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zireplicate_24383);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zireplicate_24403);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_21631);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_21663);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_21689);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_21774);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_21948);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22011);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22039);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22065);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22073);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22081);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22089);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22105);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22528);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22591);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22653);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22706);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22767);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22808);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22847);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22860);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22900);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22914);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22960);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegmap_22980);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_large_21963);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_large_22608);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_large_22739);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_large_22800);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_nonseg_21553);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_nonseg_21653);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_nonseg_22135);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_nonseg_22676);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_nonseg_23843);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_small_21963);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_small_22608);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_small_22739);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegred_small_22800);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegscan_21661);
    gpu_free_kernel(ctx, ctx->program->simulate_8477zisegscan_22103);
    free(ctx->program);
}
static void set_tuning_params(struct futhark_context *ctx)
{
    (void) ctx;
    ctx->tuning_params.builtinzhiota_i64zitblock_sizze_24193 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_23902 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_23964 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_21667 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_21675 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_21700 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22043 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22077 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22085 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22093 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22109 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22206 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22812 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22820 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22864 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22872 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22918 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22926 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22984 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21568 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21665 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21673 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21698 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21856 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21932 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22041 = &ctx->cfg->tuning_params[25];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22049 = &ctx->cfg->tuning_params[26];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22075 = &ctx->cfg->tuning_params[27];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22083 = &ctx->cfg->tuning_params[28];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22091 = &ctx->cfg->tuning_params[29];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22107 = &ctx->cfg->tuning_params[30];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22204 = &ctx->cfg->tuning_params[31];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22336 = &ctx->cfg->tuning_params[32];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22409 = &ctx->cfg->tuning_params[33];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22690 = &ctx->cfg->tuning_params[34];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22751 = &ctx->cfg->tuning_params[35];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22810 = &ctx->cfg->tuning_params[36];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22818 = &ctx->cfg->tuning_params[37];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22862 = &ctx->cfg->tuning_params[38];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22870 = &ctx->cfg->tuning_params[39];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22916 = &ctx->cfg->tuning_params[40];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22924 = &ctx->cfg->tuning_params[41];
    ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22982 = &ctx->cfg->tuning_params[42];
    ctx->tuning_params.simulate_8477zisegred_num_tblocks_21547 = &ctx->cfg->tuning_params[43];
    ctx->tuning_params.simulate_8477zisegred_num_tblocks_21646 = &ctx->cfg->tuning_params[44];
    ctx->tuning_params.simulate_8477zisegred_num_tblocks_21879 = &ctx->cfg->tuning_params[45];
    ctx->tuning_params.simulate_8477zisegred_num_tblocks_22117 = &ctx->cfg->tuning_params[46];
    ctx->tuning_params.simulate_8477zisegred_num_tblocks_22359 = &ctx->cfg->tuning_params[47];
    ctx->tuning_params.simulate_8477zisegred_num_tblocks_22508 = &ctx->cfg->tuning_params[48];
    ctx->tuning_params.simulate_8477zisegred_num_tblocks_22718 = &ctx->cfg->tuning_params[49];
    ctx->tuning_params.simulate_8477zisegred_num_tblocks_22779 = &ctx->cfg->tuning_params[50];
    ctx->tuning_params.simulate_8477zisegred_num_tblocks_23833 = &ctx->cfg->tuning_params[51];
    ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21545 = &ctx->cfg->tuning_params[52];
    ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21644 = &ctx->cfg->tuning_params[53];
    ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21877 = &ctx->cfg->tuning_params[54];
    ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22115 = &ctx->cfg->tuning_params[55];
    ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22357 = &ctx->cfg->tuning_params[56];
    ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22506 = &ctx->cfg->tuning_params[57];
    ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22716 = &ctx->cfg->tuning_params[58];
    ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22777 = &ctx->cfg->tuning_params[59];
    ctx->tuning_params.simulate_8477zisegred_tblock_sizze_23835 = &ctx->cfg->tuning_params[60];
    ctx->tuning_params.simulate_8477zisegscan_num_tblocks_21657 = &ctx->cfg->tuning_params[61];
    ctx->tuning_params.simulate_8477zisegscan_num_tblocks_22099 = &ctx->cfg->tuning_params[62];
    ctx->tuning_params.simulate_8477zisegscan_tblock_sizze_21655 = &ctx->cfg->tuning_params[63];
    ctx->tuning_params.simulate_8477zisegscan_tblock_sizze_22097 = &ctx->cfg->tuning_params[64];
    ctx->tuning_params.simulate_8477zisuff_outer_par_0 = &ctx->cfg->tuning_params[65];
    ctx->tuning_params.simulate_8477zisuff_outer_par_2 = &ctx->cfg->tuning_params[66];
    ctx->tuning_params.simulate_8477zisuff_outer_par_3 = &ctx->cfg->tuning_params[67];
    ctx->tuning_params.simulate_8477zisuff_outer_par_4 = &ctx->cfg->tuning_params[68];
    ctx->tuning_params.simulate_8477zisuff_outer_screma_1 = &ctx->cfg->tuning_params[69];
    ctx->tuning_params.simulate_8477zitblock_sizze_24367 = &ctx->cfg->tuning_params[70];
    ctx->tuning_params.simulate_8477zitblock_sizze_24387 = &ctx->cfg->tuning_params[71];
    ctx->tuning_params.simulate_8477zitblock_sizze_24407 = &ctx->cfg->tuning_params[72];
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            (void) gpu_free(ctx, block->mem, block->size, desc);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device);
    (void) gpu_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_device + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_device = new_usage;
        if (new_usage > ctx->peak_mem_usage_device) {
            ctx->peak_mem_usage_device = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default);
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_default + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_default = new_usage;
        if (new_usage > ctx->peak_mem_usage_default) {
            ctx->peak_mem_usage_default = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder_char(&builder, '{');
    str_builder_str(&builder, "\"memory\":{");
    str_builder(&builder, "\"space 'device'\": %lld", (long long) ctx->peak_mem_usage_device);
    str_builder_char(&builder, ',');
    str_builder(&builder, "\"default space\": %lld", (long long) ctx->peak_mem_usage_default);
    str_builder_str(&builder, "},\"events\":[");
    if (report_events_in_list(&ctx->event_list, &builder) != 0) {
        free(builder.str);
        return NULL;
    } else {
        str_builder_str(&builder, "]}");
        return builder.str;
    }
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        gpu_free_all(ctx);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f) {
  if (ctx->logging) {
    fprintf(ctx->log, "Event: %s\n%s\n", name, description);
  }
  add_event_to_list(&ctx->event_list, name, description, data, f);
}

char *futhark_context_get_error(struct futhark_context *ctx) {
  char *error = ctx->error;
  ctx->error = NULL;
  return error;
}

void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}

void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = flag;
}

void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag) {
    cfg->logging = flag;
}

void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f) {
  cfg->cache_fname = strdup(f);
}

int futhark_get_tuning_param_count(void) {
  return num_tuning_params;
}

const char *futhark_get_tuning_param_name(int i) {
  return tuning_param_names[i];
}

const char *futhark_get_tuning_param_class(int i) {
    return tuning_param_classes[i];
}

void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f){
  ctx->log = f;
}

void futhark_context_pause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 1;
}

void futhark_context_unpause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 0;
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->cache_fname);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  ctx->program_initialised = false;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  event_list_init(&ctx->event_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->detail_memory = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  set_tuning_params(ctx);
  if (backend_context_setup(ctx) == 0) {
    setup_program(ctx);
    init_constants(ctx);
    ctx->program_initialised = true;
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  if (ctx->program_initialised) {
    free_constants(ctx);
    teardown_program(ctx);
  }
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  event_list_free(&ctx->event_list);
  free(ctx->constants);
  free(ctx->error);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

// Start of copy.h

// Cache-oblivious map-transpose function.
#define GEN_MAP_TRANSPOSE(NAME, ELEM_TYPE)                              \
  static void map_transpose_##NAME                                      \
  (ELEM_TYPE* dst, ELEM_TYPE* src,                                      \
   int64_t k, int64_t m, int64_t n,                                     \
   int64_t cb, int64_t ce, int64_t rb, int64_t re)                      \
  {                                                                     \
  int32_t r = re - rb;                                                  \
  int32_t c = ce - cb;                                                  \
  if (k == 1) {                                                         \
    if (r <= 64 && c <= 64) {                                           \
      for (int64_t j = 0; j < c; j++) {                                 \
        for (int64_t i = 0; i < r; i++) {                               \
          dst[(j + cb) * n + (i + rb)] = src[(i + rb) * m + (j + cb)];  \
        }                                                               \
      }                                                                 \
    } else if (c <= r) {                                                \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb, rb + r/2);    \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb + r/2, re);    \
    } else {                                                            \
      map_transpose_##NAME(dst, src, k, m, n, cb, cb + c/2, rb, re);    \
      map_transpose_##NAME(dst, src, k, m, n, cb + c/2, ce, rb, re);    \
    }                                                                   \
  } else {                                                              \
  for (int64_t i = 0; i < k; i++) {                                     \
    map_transpose_##NAME(dst + i * m * n, src + i * m * n, 1, m, n, cb, ce, rb, re); \
  }\
} \
}

// Straightforward LMAD copy function.
#define GEN_LMAD_COPY_ELEMENTS(NAME, ELEM_TYPE)                         \
  static void lmad_copy_elements_##NAME(int r,                          \
                                        ELEM_TYPE* dst, int64_t dst_strides[r], \
                                        ELEM_TYPE *src, int64_t src_strides[r], \
                                        int64_t shape[r]) {             \
    if (r == 1) {                                                       \
      for (int i = 0; i < shape[0]; i++) {                              \
        dst[i*dst_strides[0]] = src[i*src_strides[0]];                  \
      }                                                                 \
    } else if (r > 1) {                                                 \
      for (int i = 0; i < shape[0]; i++) {                              \
        lmad_copy_elements_##NAME(r-1,                                  \
                                  dst+i*dst_strides[0], dst_strides+1,  \
                                  src+i*src_strides[0], src_strides+1,  \
                                  shape+1);                             \
      }                                                                 \
    }                                                                   \
  }                                                                     \

// Check whether this LMAD can be seen as a transposed 2D array.  This
// is done by checking every possible splitting point.
static bool lmad_is_tr(int64_t *n_out, int64_t *m_out,
                       int r,
                       const int64_t strides[r],
                       const int64_t shape[r]) {
  for (int i = 1; i < r; i++) {
    int n = 1, m = 1;
    bool ok = true;
    int64_t expected = 1;
    // Check strides before 'i'.
    for (int j = i-1; j >= 0; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      n *= shape[j];
    }
    // Check strides after 'i'.
    for (int j = r-1; j >= i; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      m *= shape[j];
    }
    if (ok) {
      *n_out = n;
      *m_out = m;
      return true;
    }
  }
  return false;
}

// This function determines whether the a 'dst' LMAD is row-major and
// 'src' LMAD is column-major.  Both LMADs are for arrays of the same
// shape.  Both LMADs are allowed to have additional dimensions "on
// top".  Essentially, this function determines whether a copy from
// 'src' to 'dst' is a "map(transpose)" that we know how to implement
// efficiently.  The LMADs can have arbitrary rank, and the main
// challenge here is checking whether the src LMAD actually
// corresponds to a 2D column-major layout by morally collapsing
// dimensions.  There is a lot of looping here, but the actual trip
// count is going to be very low in practice.
//
// Returns true if this is indeed a map(transpose), and writes the
// number of arrays, and moral array size to appropriate output
// parameters.
static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]) {
  int64_t rowmajor_strides[r];
  rowmajor_strides[r-1] = 1;

  for (int i = r-2; i >= 0; i--) {
    rowmajor_strides[i] = rowmajor_strides[i+1] * shape[i+1];
  }

  // map_r will be the number of mapped dimensions on top.
  int map_r = 0;
  int64_t num_arrays = 1;
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != rowmajor_strides[i] ||
        src_strides[i] != rowmajor_strides[i]) {
      break;
    } else {
      num_arrays *= shape[i];
      map_r++;
    }
  }

  *num_arrays_out = num_arrays;

  if (r==map_r) {
    return false;
  }

  if (memcmp(&rowmajor_strides[map_r],
             &dst_strides[map_r],
             sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(n_out, m_out, r-map_r, src_strides+map_r, shape+map_r);
  } else if (memcmp(&rowmajor_strides[map_r],
                    &src_strides[map_r],
                    sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(m_out, n_out, r-map_r, dst_strides+map_r, shape+map_r);
  }
  return false;
}

// Check if the strides correspond to row-major strides of *any*
// permutation of the shape.  This is done by recursive search with
// backtracking.  This is worst-case exponential, but hopefully the
// arrays we encounter do not have that many dimensions.
static bool lmad_contiguous_search(int checked, int64_t expected,
                                   int r,
                                   int64_t strides[r], int64_t shape[r], bool used[r]) {
  for (int i = 0; i < r; i++) {
    for (int j = 0; j < r; j++) {
      if (!used[j] && strides[j] == expected && strides[j] >= 0) {
        used[j] = true;
        if (checked+1 == r ||
            lmad_contiguous_search(checked+1, expected * shape[j], r, strides, shape, used)) {
          return true;
        }
        used[j] = false;
      }
    }
  }
  return false;
}

// Does this LMAD correspond to an array with positive strides and no
// holes?
static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]) {
  bool used[r];
  for (int i = 0; i < r; i++) {
    used[i] = false;
  }
  return lmad_contiguous_search(0, 1, r, strides, shape, used);
}

// Does this copy correspond to something that could be done with a
// memcpy()-like operation?  I.e. do the LMADs actually represent the
// same in-memory layout and are they contiguous?
static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]) {
  if (!lmad_contiguous(r, dst_strides, shape)) {
    return false;
  }
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != src_strides[i] && shape[i] != 1) {
      return false;
    }
  }
  return true;
}


static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]) {
  if (ctx->logging) {
    fprintf(ctx->log, "\n# Copy %s\n", kind);
    fprintf(ctx->log, "Shape: ");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, "[%ld]", (long int)shape[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Dst offset: %ld\n", (long int)dst_offset);
    fprintf(ctx->log, "Dst strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)dst_strides[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Src offset: %ld\n", (long int)src_offset);
    fprintf(ctx->log, "Src strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)src_strides[i]); }
    fprintf(ctx->log, "\n");
  }
}

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t n, int64_t m) {
  if (ctx->logging) {
    fprintf(ctx->log, "## Transpose\n");
    fprintf(ctx->log, "Arrays     : %ld\n", (long int)k);
    fprintf(ctx->log, "X elements : %ld\n", (long int)m);
    fprintf(ctx->log, "Y elements : %ld\n", (long int)n);
    fprintf(ctx->log, "\n");
  }
}

#define GEN_LMAD_COPY(NAME, ELEM_TYPE)                                  \
  static void lmad_copy_##NAME                                          \
  (struct futhark_context *ctx, int r,                                  \
   ELEM_TYPE* dst, int64_t dst_offset, int64_t dst_strides[r],          \
   ELEM_TYPE *src, int64_t src_offset, int64_t src_strides[r],          \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "CPU to CPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return; }                                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      map_transpose_##NAME                                              \
        (dst+dst_offset, src+src_offset, k, n, m, 0, n, 0, m);          \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}          \
      memcpy(dst+dst_offset, src+src_offset, size*sizeof(*dst));        \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}       \
      lmad_copy_elements_##NAME                                         \
        (r,                                                             \
         dst+dst_offset, dst_strides,                                   \
         src+src_offset, src_strides, shape);                           \
    }                                                                   \
  }

GEN_MAP_TRANSPOSE(1b, uint8_t)
GEN_MAP_TRANSPOSE(2b, uint16_t)
GEN_MAP_TRANSPOSE(4b, uint32_t)
GEN_MAP_TRANSPOSE(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS(8b, uint64_t)

GEN_LMAD_COPY(1b, uint8_t)
GEN_LMAD_COPY(2b, uint16_t)
GEN_LMAD_COPY(4b, uint32_t)
GEN_LMAD_COPY(8b, uint64_t)

// End of copy.h

#define FUTHARK_FUN_ATTR static

FUTHARK_FUN_ATTR int futrts_builtinzhiota_i64(struct futhark_context *ctx, struct memblock_device mem_24184, int64_t n_24185, int64_t x_24186, int64_t s_24187);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_23893, int64_t num_elems_23894, int32_t val_23895);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_23955, int64_t num_elems_23956, int8_t val_23957);
FUTHARK_FUN_ATTR int futrts_entry_main(struct futhark_context *ctx, struct memblock_device *mem_out_p_25091, int64_t *out_prim_out_25092, struct memblock_device gates_mem_23398, struct memblock_device cQ_mem_23399, struct memblock_device tQ_mem_23400, int64_t n_15648, int32_t seed_15649, int64_t num_qubits_15650);
FUTHARK_FUN_ATTR int futrts_entry_simple(struct futhark_context *ctx, struct memblock_device *mem_out_p_25093, int64_t *out_prim_out_25094, struct memblock_device gates_mem_23398, struct memblock_device cQ_mem_23399, struct memblock_device tQ_mem_23400, int64_t n_15664, int64_t num_qubits_15665);
FUTHARK_FUN_ATTR int futrts_entry_simulate(struct futhark_context *ctx, struct memblock_device *mem_out_p_25095, struct memblock_device *mem_out_p_25096, int64_t *out_prim_out_25097, int64_t *out_prim_out_25098, struct memblock_device gates_mem_23398, struct memblock_device cQ_mem_23399, struct memblock_device tQ_mem_23400, int64_t n_15621, int32_t seed_15622, int64_t num_qubits_15623);
FUTHARK_FUN_ATTR int futrts_simulate_8477(struct futhark_context *ctx, struct memblock_device *mem_out_p_25099, struct memblock_device *mem_out_p_25100, int64_t *out_prim_out_25101, int64_t *out_prim_out_25102, struct memblock_device gates_mem_23398, struct memblock_device cQ_mem_23399, struct memblock_device tQ_mem_23400, int64_t n_15484, int32_t seed_15485, int64_t num_qubits_15486);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define counters_mem_23891 (ctx->constants->counters_mem_23891)
    #define counters_mem_23995 (ctx->constants->counters_mem_23995)
    #define counters_mem_24219 (ctx->constants->counters_mem_24219)
    #define counters_mem_24316 (ctx->constants->counters_mem_24316)
    #define counters_mem_24620 (ctx->constants->counters_mem_24620)
    #define counters_mem_24722 (ctx->constants->counters_mem_24722)
    #define counters_mem_24770 (ctx->constants->counters_mem_24770)
    #define counters_mem_24855 (ctx->constants->counters_mem_24855)
    #define counters_mem_24938 (ctx->constants->counters_mem_24938)
    #define global_dynid_mem_24078 (ctx->constants->global_dynid_mem_24078)
    #define global_dynid_mem_24500 (ctx->constants->global_dynid_mem_24500)
    counters_mem_23891.references = NULL;
    counters_mem_23995.references = NULL;
    counters_mem_24219.references = NULL;
    counters_mem_24316.references = NULL;
    counters_mem_24620.references = NULL;
    counters_mem_24722.references = NULL;
    counters_mem_24770.references = NULL;
    counters_mem_24855.references = NULL;
    counters_mem_24938.references = NULL;
    global_dynid_mem_24078.references = NULL;
    global_dynid_mem_24500.references = NULL;
    if (memblock_alloc_device(ctx, &counters_mem_23891, (int64_t) 80, "counters_mem_23891")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_23891, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_23995, (int64_t) 80, "counters_mem_23995")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_23995, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_24078, (int64_t) 4, "global_dynid_mem_24078")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_24078, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_24219, (int64_t) 80, "counters_mem_24219")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_24219, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_24316, (int64_t) 81920, "counters_mem_24316")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_24316, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_24500, (int64_t) 4, "global_dynid_mem_24500")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_24500, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_24620, (int64_t) 80, "counters_mem_24620")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_24620, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_24722, (int64_t) 81920, "counters_mem_24722")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_24722, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_24770, (int64_t) 80, "counters_mem_24770")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_24770, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_24855, (int64_t) 81920, "counters_mem_24855")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_24855, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_24938, (int64_t) 81920, "counters_mem_24938")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_24938, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    #undef counters_mem_23891
    #undef counters_mem_23995
    #undef counters_mem_24219
    #undef counters_mem_24316
    #undef counters_mem_24620
    #undef counters_mem_24722
    #undef counters_mem_24770
    #undef counters_mem_24855
    #undef counters_mem_24938
    #undef global_dynid_mem_24078
    #undef global_dynid_mem_24500
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_23891, "ctx->constants->counters_mem_23891") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_23995, "ctx->constants->counters_mem_23995") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_24219, "ctx->constants->counters_mem_24219") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_24316, "ctx->constants->counters_mem_24316") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_24620, "ctx->constants->counters_mem_24620") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_24722, "ctx->constants->counters_mem_24722") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_24770, "ctx->constants->counters_mem_24770") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_24855, "ctx->constants->counters_mem_24855") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_24938, "ctx->constants->counters_mem_24938") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_24078, "ctx->constants->global_dynid_mem_24078") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_24500, "ctx->constants->global_dynid_mem_24500") != 0)
        return 1;
    return 0;
}
static int gpu_kernel_builtinzhiota_i64ziiota_i64_24189(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhiota_i64ziiota_i64_24189, "builtin#iota_i64.iota_i64_24189", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i32zireplicate_23898(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_23898, "builtin#replicate_i32.replicate_23898", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i8zireplicate_23960(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int8_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_23960, "builtin#replicate_i8.replicate_23960", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_nonseg_21553(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_nonseg_21553, "simulate_8477.segred_nonseg_21553", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_21631(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_21631, "simulate_8477.segmap_21631", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zigpuseq_23981(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zigpuseq_23981, "simulate_8477.gpuseq_23981", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zigpuseq_23988(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zigpuseq_23988, "simulate_8477.gpuseq_23988", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_nonseg_21653(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_nonseg_21653, "simulate_8477.segred_nonseg_21653", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zigpuseq_24049(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, bool arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zigpuseq_24049, "simulate_8477.gpuseq_24049", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zigpuseq_24059(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int8_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zigpuseq_24059, "simulate_8477.gpuseq_24059", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegscan_21661(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[17] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[17] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegscan_21661, "simulate_8477.segscan_21661", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 17, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_21689(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_21689, "simulate_8477.segmap_21689", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_21663(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_21663, "simulate_8477.segmap_21663", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_nonseg_23843(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_nonseg_23843, "simulate_8477.segred_nonseg_23843", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_21774(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int32_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[19] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15};
        size_t args_sizes[19] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_21774, "simulate_8477.segmap_21774", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 19, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_21948(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_21948, "simulate_8477.segmap_21948", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_small_21963(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_small_21963, "simulate_8477.segred_small_21963", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_large_21963(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[19] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15};
        size_t args_sizes[19] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_large_21963, "simulate_8477.segred_large_21963", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 19, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22011(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22011, "simulate_8477.segmap_22011", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zireplicate_24363(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[7] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zireplicate_24363, "simulate_8477.replicate_24363", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zireplicate_24383(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[7] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zireplicate_24383, "simulate_8477.replicate_24383", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zireplicate_24403(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zireplicate_24403, "simulate_8477.replicate_24403", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22039(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, int32_t arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22039, "simulate_8477.segmap_22039", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22065(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22065, "simulate_8477.segmap_22065", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22073(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22073, "simulate_8477.segmap_22073", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22081(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int8_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22081, "simulate_8477.segmap_22081", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22089(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22089, "simulate_8477.segmap_22089", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegscan_22103(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[16] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[16] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegscan_22103, "simulate_8477.segscan_22103", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 16, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22105(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22105, "simulate_8477.segmap_22105", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zigpuseq_24609(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zigpuseq_24609, "simulate_8477.gpuseq_24609", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_nonseg_22135(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16, gpu_mem arg17)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[21] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16, &arg17};
        size_t args_sizes[21] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16), sizeof(arg17)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_nonseg_22135, "simulate_8477.segred_nonseg_22135", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 21, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zigpuseq_24656(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zigpuseq_24656, "simulate_8477.gpuseq_24656", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22528(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[16] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[16] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22528, "simulate_8477.segmap_22528", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 16, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22591(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22591, "simulate_8477.segmap_22591", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_small_22608(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_small_22608, "simulate_8477.segred_small_22608", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_large_22608(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[20] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16};
        size_t args_sizes[20] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_large_22608, "simulate_8477.segred_large_22608", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 20, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22653(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22653, "simulate_8477.segmap_22653", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_nonseg_22676(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_nonseg_22676, "simulate_8477.segred_nonseg_22676", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zigpuseq_24803(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zigpuseq_24803, "simulate_8477.gpuseq_24803", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22706(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22706, "simulate_8477.segmap_22706", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_small_22739(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_small_22739, "simulate_8477.segred_small_22739", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_large_22739(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_large_22739, "simulate_8477.segred_large_22739", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22767(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22767, "simulate_8477.segmap_22767", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_small_22800(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_small_22800, "simulate_8477.segred_small_22800", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegred_large_22800(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegred_large_22800, "simulate_8477.segred_large_22800", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22808(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int32_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22808, "simulate_8477.segmap_22808", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zigpuseq_24991(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zigpuseq_24991, "simulate_8477.gpuseq_24991", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22847(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22847, "simulate_8477.segmap_22847", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22860(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22860, "simulate_8477.segmap_22860", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zigpuseq_25025(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zigpuseq_25025, "simulate_8477.gpuseq_25025", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22900(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22900, "simulate_8477.segmap_22900", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22914(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22914, "simulate_8477.segmap_22914", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zigpuseq_25059(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zigpuseq_25059, "simulate_8477.gpuseq_25059", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22960(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22960, "simulate_8477.segmap_22960", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_simulate_8477zisegmap_22980(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->simulate_8477zisegmap_22980, "simulate_8477.segmap_22980", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
struct futhark_i8_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i8_1d *futhark_new_i8_1d(struct futhark_context *ctx, const int8_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i8_1d *bad = NULL;
    struct futhark_i8_1d *arr = (struct futhark_i8_1d *) malloc(sizeof(struct futhark_i8_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 1, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 1);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i8_1d *futhark_new_raw_i8_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i8_1d *bad = NULL;
    struct futhark_i8_1d *arr = (struct futhark_i8_1d *) malloc(sizeof(struct futhark_i8_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr, int8_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 1);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i8_1d(struct futhark_context *ctx, int8_t *out, struct futhark_i8_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 1 * (i0 * 1), 1);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i8_1d(struct futhark_context *ctx, struct futhark_i8_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_i8_2d {
    struct memblock_device mem;
    int64_t shape[2];
};
struct futhark_i8_2d *futhark_new_i8_2d(struct futhark_context *ctx, const int8_t *data, int64_t dim0, int64_t dim1)
{
    int err = 0;
    struct futhark_i8_2d *bad = NULL;
    struct futhark_i8_2d *arr = (struct futhark_i8_2d *) malloc(sizeof(struct futhark_i8_2d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * dim1 * 1, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) (dim0 * dim1) * 1);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i8_2d *futhark_new_raw_i8_2d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0, int64_t dim1)
{
    int err = 0;
    struct futhark_i8_2d *bad = NULL;
    struct futhark_i8_2d *arr = (struct futhark_i8_2d *) malloc(sizeof(struct futhark_i8_2d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i8_2d(struct futhark_context *ctx, struct futhark_i8_2d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i8_2d(struct futhark_context *ctx, struct futhark_i8_2d *arr, int8_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) (arr->shape[0] * arr->shape[1]) * 1);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i8_2d(struct futhark_context *ctx, int8_t *out, struct futhark_i8_2d *arr, int64_t i0, int64_t i1)
{
    int err = 0;
    
    if ((i0 >= 0 && i0 < arr->shape[0]) && (i1 >= 0 && i1 < arr->shape[1])) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 1 * (i0 * arr->shape[1] + i1 * 1), 1);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i8_2d(struct futhark_context *ctx, struct futhark_i8_2d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i8_2d(struct futhark_context *ctx, struct futhark_i8_2d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_i64_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 8 * (i0 * 1), 8);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->shape;
}

FUTHARK_FUN_ATTR int futrts_builtinzhiota_i64(struct futhark_context *ctx, struct memblock_device mem_24184, int64_t n_24185, int64_t x_24186, int64_t s_24187)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_23891 = ctx->constants->counters_mem_23891;
    struct memblock_device counters_mem_23995 = ctx->constants->counters_mem_23995;
    struct memblock_device counters_mem_24219 = ctx->constants->counters_mem_24219;
    struct memblock_device counters_mem_24316 = ctx->constants->counters_mem_24316;
    struct memblock_device counters_mem_24620 = ctx->constants->counters_mem_24620;
    struct memblock_device counters_mem_24722 = ctx->constants->counters_mem_24722;
    struct memblock_device counters_mem_24770 = ctx->constants->counters_mem_24770;
    struct memblock_device counters_mem_24855 = ctx->constants->counters_mem_24855;
    struct memblock_device counters_mem_24938 = ctx->constants->counters_mem_24938;
    struct memblock_device global_dynid_mem_24078 = ctx->constants->global_dynid_mem_24078;
    struct memblock_device global_dynid_mem_24500 = ctx->constants->global_dynid_mem_24500;
    int64_t tblock_sizze_24193;
    
    tblock_sizze_24193 = *ctx->tuning_params.builtinzhiota_i64zitblock_sizze_24193;
    
    int64_t virt_num_tblocks_24194 = sdiv_up64(n_24185, tblock_sizze_24193);
    int64_t num_tblocks_24195 = smin64(virt_num_tblocks_24194, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhiota_i64ziiota_i64_24189(ctx, num_tblocks_24195, 1, 1, tblock_sizze_24193, 1, 1, (int64_t) 0, n_24185, x_24186, s_24187, virt_num_tblocks_24194, num_tblocks_24195, mem_24184.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_23893, int64_t num_elems_23894, int32_t val_23895)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_23891 = ctx->constants->counters_mem_23891;
    struct memblock_device counters_mem_23995 = ctx->constants->counters_mem_23995;
    struct memblock_device counters_mem_24219 = ctx->constants->counters_mem_24219;
    struct memblock_device counters_mem_24316 = ctx->constants->counters_mem_24316;
    struct memblock_device counters_mem_24620 = ctx->constants->counters_mem_24620;
    struct memblock_device counters_mem_24722 = ctx->constants->counters_mem_24722;
    struct memblock_device counters_mem_24770 = ctx->constants->counters_mem_24770;
    struct memblock_device counters_mem_24855 = ctx->constants->counters_mem_24855;
    struct memblock_device counters_mem_24938 = ctx->constants->counters_mem_24938;
    struct memblock_device global_dynid_mem_24078 = ctx->constants->global_dynid_mem_24078;
    struct memblock_device global_dynid_mem_24500 = ctx->constants->global_dynid_mem_24500;
    int64_t replicate_n_23897 = num_elems_23894;
    int64_t tblock_sizze_23902;
    
    tblock_sizze_23902 = *ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_23902;
    
    int64_t virt_num_tblocks_23903 = sdiv_up64(replicate_n_23897, tblock_sizze_23902);
    int64_t num_tblocks_23904 = smin64(virt_num_tblocks_23903, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i32zireplicate_23898(ctx, num_tblocks_23904, 1, 1, tblock_sizze_23902, 1, 1, (int64_t) 0, num_elems_23894, val_23895, replicate_n_23897, virt_num_tblocks_23903, num_tblocks_23904, mem_23893.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_23955, int64_t num_elems_23956, int8_t val_23957)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_23891 = ctx->constants->counters_mem_23891;
    struct memblock_device counters_mem_23995 = ctx->constants->counters_mem_23995;
    struct memblock_device counters_mem_24219 = ctx->constants->counters_mem_24219;
    struct memblock_device counters_mem_24316 = ctx->constants->counters_mem_24316;
    struct memblock_device counters_mem_24620 = ctx->constants->counters_mem_24620;
    struct memblock_device counters_mem_24722 = ctx->constants->counters_mem_24722;
    struct memblock_device counters_mem_24770 = ctx->constants->counters_mem_24770;
    struct memblock_device counters_mem_24855 = ctx->constants->counters_mem_24855;
    struct memblock_device counters_mem_24938 = ctx->constants->counters_mem_24938;
    struct memblock_device global_dynid_mem_24078 = ctx->constants->global_dynid_mem_24078;
    struct memblock_device global_dynid_mem_24500 = ctx->constants->global_dynid_mem_24500;
    int64_t replicate_n_23959 = num_elems_23956;
    int64_t tblock_sizze_23964;
    
    tblock_sizze_23964 = *ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_23964;
    
    int64_t virt_num_tblocks_23965 = sdiv_up64(replicate_n_23959, tblock_sizze_23964);
    int64_t num_tblocks_23966 = smin64(virt_num_tblocks_23965, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i8zireplicate_23960(ctx, num_tblocks_23966, 1, 1, tblock_sizze_23964, 1, 1, (int64_t) 0, num_elems_23956, val_23957, replicate_n_23959, virt_num_tblocks_23965, num_tblocks_23966, mem_23955.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_main(struct futhark_context *ctx, struct memblock_device *mem_out_p_25091, int64_t *out_prim_out_25092, struct memblock_device gates_mem_23398, struct memblock_device cQ_mem_23399, struct memblock_device tQ_mem_23400, int64_t n_15648, int32_t seed_15649, int64_t num_qubits_15650)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device ext_mem_23401;
    
    ext_mem_23401.references = NULL;
    
    struct memblock_device ext_mem_23402;
    
    ext_mem_23402.references = NULL;
    
    struct memblock_device mem_out_23885;
    
    mem_out_23885.references = NULL;
    
    struct memblock_device counters_mem_23891 = ctx->constants->counters_mem_23891;
    struct memblock_device counters_mem_23995 = ctx->constants->counters_mem_23995;
    struct memblock_device counters_mem_24219 = ctx->constants->counters_mem_24219;
    struct memblock_device counters_mem_24316 = ctx->constants->counters_mem_24316;
    struct memblock_device counters_mem_24620 = ctx->constants->counters_mem_24620;
    struct memblock_device counters_mem_24722 = ctx->constants->counters_mem_24722;
    struct memblock_device counters_mem_24770 = ctx->constants->counters_mem_24770;
    struct memblock_device counters_mem_24855 = ctx->constants->counters_mem_24855;
    struct memblock_device counters_mem_24938 = ctx->constants->counters_mem_24938;
    struct memblock_device global_dynid_mem_24078 = ctx->constants->global_dynid_mem_24078;
    struct memblock_device global_dynid_mem_24500 = ctx->constants->global_dynid_mem_24500;
    int64_t prim_out_23886;
    int64_t measurements_15715;
    int64_t measurements_15716;
    
    if (futrts_simulate_8477(ctx, &ext_mem_23402, &ext_mem_23401, &measurements_15715, &measurements_15716, gates_mem_23398, cQ_mem_23399, tQ_mem_23400, n_15648, seed_15649, num_qubits_15650) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_set_device(ctx, &mem_out_23885, &ext_mem_23401, "ext_mem_23401") != 0)
        return 1;
    prim_out_23886 = measurements_15716;
    if (memblock_set_device(ctx, &*mem_out_p_25091, &mem_out_23885, "mem_out_23885") != 0)
        return 1;
    *out_prim_out_25092 = prim_out_23886;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &ext_mem_23401, "ext_mem_23401") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23402, "ext_mem_23402") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_23885, "mem_out_23885") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_simple(struct futhark_context *ctx, struct memblock_device *mem_out_p_25093, int64_t *out_prim_out_25094, struct memblock_device gates_mem_23398, struct memblock_device cQ_mem_23399, struct memblock_device tQ_mem_23400, int64_t n_15664, int64_t num_qubits_15665)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device ext_mem_23401;
    
    ext_mem_23401.references = NULL;
    
    struct memblock_device ext_mem_23402;
    
    ext_mem_23402.references = NULL;
    
    struct memblock_device mem_out_23885;
    
    mem_out_23885.references = NULL;
    
    struct memblock_device counters_mem_23891 = ctx->constants->counters_mem_23891;
    struct memblock_device counters_mem_23995 = ctx->constants->counters_mem_23995;
    struct memblock_device counters_mem_24219 = ctx->constants->counters_mem_24219;
    struct memblock_device counters_mem_24316 = ctx->constants->counters_mem_24316;
    struct memblock_device counters_mem_24620 = ctx->constants->counters_mem_24620;
    struct memblock_device counters_mem_24722 = ctx->constants->counters_mem_24722;
    struct memblock_device counters_mem_24770 = ctx->constants->counters_mem_24770;
    struct memblock_device counters_mem_24855 = ctx->constants->counters_mem_24855;
    struct memblock_device counters_mem_24938 = ctx->constants->counters_mem_24938;
    struct memblock_device global_dynid_mem_24078 = ctx->constants->global_dynid_mem_24078;
    struct memblock_device global_dynid_mem_24500 = ctx->constants->global_dynid_mem_24500;
    int64_t prim_out_23886;
    int64_t measurements_16015;
    int64_t measurements_16016;
    
    if (futrts_simulate_8477(ctx, &ext_mem_23402, &ext_mem_23401, &measurements_16015, &measurements_16016, gates_mem_23398, cQ_mem_23399, tQ_mem_23400, n_15664, 2026, num_qubits_15665) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_set_device(ctx, &mem_out_23885, &ext_mem_23401, "ext_mem_23401") != 0)
        return 1;
    prim_out_23886 = measurements_16016;
    if (memblock_set_device(ctx, &*mem_out_p_25093, &mem_out_23885, "mem_out_23885") != 0)
        return 1;
    *out_prim_out_25094 = prim_out_23886;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &ext_mem_23401, "ext_mem_23401") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23402, "ext_mem_23402") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_23885, "mem_out_23885") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_simulate(struct futhark_context *ctx, struct memblock_device *mem_out_p_25095, struct memblock_device *mem_out_p_25096, int64_t *out_prim_out_25097, int64_t *out_prim_out_25098, struct memblock_device gates_mem_23398, struct memblock_device cQ_mem_23399, struct memblock_device tQ_mem_23400, int64_t n_15621, int32_t seed_15622, int64_t num_qubits_15623)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device ext_mem_23401;
    
    ext_mem_23401.references = NULL;
    
    struct memblock_device ext_mem_23402;
    
    ext_mem_23402.references = NULL;
    
    struct memblock_device mem_out_23886;
    
    mem_out_23886.references = NULL;
    
    struct memblock_device mem_out_23885;
    
    mem_out_23885.references = NULL;
    
    struct memblock_device counters_mem_23891 = ctx->constants->counters_mem_23891;
    struct memblock_device counters_mem_23995 = ctx->constants->counters_mem_23995;
    struct memblock_device counters_mem_24219 = ctx->constants->counters_mem_24219;
    struct memblock_device counters_mem_24316 = ctx->constants->counters_mem_24316;
    struct memblock_device counters_mem_24620 = ctx->constants->counters_mem_24620;
    struct memblock_device counters_mem_24722 = ctx->constants->counters_mem_24722;
    struct memblock_device counters_mem_24770 = ctx->constants->counters_mem_24770;
    struct memblock_device counters_mem_24855 = ctx->constants->counters_mem_24855;
    struct memblock_device counters_mem_24938 = ctx->constants->counters_mem_24938;
    struct memblock_device global_dynid_mem_24078 = ctx->constants->global_dynid_mem_24078;
    struct memblock_device global_dynid_mem_24500 = ctx->constants->global_dynid_mem_24500;
    int64_t prim_out_23887;
    int64_t prim_out_23888;
    int64_t entry_result_15627;
    int64_t entry_result_15628;
    
    if (futrts_simulate_8477(ctx, &ext_mem_23402, &ext_mem_23401, &entry_result_15627, &entry_result_15628, gates_mem_23398, cQ_mem_23399, tQ_mem_23400, n_15621, seed_15622, num_qubits_15623) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_set_device(ctx, &mem_out_23885, &ext_mem_23402, "ext_mem_23402") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_23886, &ext_mem_23401, "ext_mem_23401") != 0)
        return 1;
    prim_out_23887 = entry_result_15627;
    prim_out_23888 = entry_result_15628;
    if (memblock_set_device(ctx, &*mem_out_p_25095, &mem_out_23885, "mem_out_23885") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_25096, &mem_out_23886, "mem_out_23886") != 0)
        return 1;
    *out_prim_out_25097 = prim_out_23887;
    *out_prim_out_25098 = prim_out_23888;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &ext_mem_23401, "ext_mem_23401") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23402, "ext_mem_23402") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_23886, "mem_out_23886") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_23885, "mem_out_23885") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_simulate_8477(struct futhark_context *ctx, struct memblock_device *mem_out_p_25099, struct memblock_device *mem_out_p_25100, int64_t *out_prim_out_25101, int64_t *out_prim_out_25102, struct memblock_device gates_mem_23398, struct memblock_device cQ_mem_23399, struct memblock_device tQ_mem_23400, int64_t n_15484, int32_t seed_15485, int64_t num_qubits_15486)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_23430;
    
    mem_23430.references = NULL;
    
    struct memblock_device mem_23423;
    
    mem_23423.references = NULL;
    
    struct memblock_device mem_23422;
    
    mem_23422.references = NULL;
    
    struct memblock_device mem_23421;
    
    mem_23421.references = NULL;
    
    struct memblock_device mem_23420;
    
    mem_23420.references = NULL;
    
    struct memblock_device mem_23419;
    
    mem_23419.references = NULL;
    
    struct memblock_device mem_23418;
    
    mem_23418.references = NULL;
    
    struct memblock_device mem_23417;
    
    mem_23417.references = NULL;
    
    struct memblock_device mem_23416;
    
    mem_23416.references = NULL;
    
    struct memblock_device mem_23415;
    
    mem_23415.references = NULL;
    
    struct memblock_device mem_23443;
    
    mem_23443.references = NULL;
    
    struct memblock_device mem_23436;
    
    mem_23436.references = NULL;
    
    struct memblock_device mem_23435;
    
    mem_23435.references = NULL;
    
    struct memblock_device mem_23434;
    
    mem_23434.references = NULL;
    
    struct memblock_device mem_23433;
    
    mem_23433.references = NULL;
    
    struct memblock_device mem_23432;
    
    mem_23432.references = NULL;
    
    struct memblock_device mem_23456;
    
    mem_23456.references = NULL;
    
    struct memblock_device mem_23449;
    
    mem_23449.references = NULL;
    
    struct memblock_device mem_23448;
    
    mem_23448.references = NULL;
    
    struct memblock_device mem_23447;
    
    mem_23447.references = NULL;
    
    struct memblock_device mem_23446;
    
    mem_23446.references = NULL;
    
    struct memblock_device mem_23445;
    
    mem_23445.references = NULL;
    
    struct memblock_device segred_tmp_mem_24936;
    
    segred_tmp_mem_24936.references = NULL;
    
    struct memblock_device mem_23631;
    
    mem_23631.references = NULL;
    
    struct memblock_device mem_23629;
    
    mem_23629.references = NULL;
    
    struct memblock_device mem_23633;
    
    mem_23633.references = NULL;
    
    struct memblock_device ext_mem_23634;
    
    ext_mem_23634.references = NULL;
    
    struct memblock_device segred_tmp_mem_24853;
    
    segred_tmp_mem_24853.references = NULL;
    
    struct memblock_device mem_23616;
    
    mem_23616.references = NULL;
    
    struct memblock_device mem_23614;
    
    mem_23614.references = NULL;
    
    struct memblock_device mem_23618;
    
    mem_23618.references = NULL;
    
    struct memblock_device ext_mem_23619;
    
    ext_mem_23619.references = NULL;
    
    struct memblock_device segred_tmp_mem_24772;
    
    segred_tmp_mem_24772.references = NULL;
    
    struct memblock_device mem_23541;
    
    mem_23541.references = NULL;
    
    struct memblock_device segred_tmp_mem_24720;
    
    segred_tmp_mem_24720.references = NULL;
    
    struct memblock_device mem_23484;
    
    mem_23484.references = NULL;
    
    struct memblock_device mem_23482;
    
    mem_23482.references = NULL;
    
    struct memblock_device mem_23480;
    
    mem_23480.references = NULL;
    
    struct memblock_device mem_23486;
    
    mem_23486.references = NULL;
    
    struct memblock_device mem_23477;
    
    mem_23477.references = NULL;
    
    struct memblock_device mem_23475;
    
    mem_23475.references = NULL;
    
    struct memblock_device mem_23532;
    
    mem_23532.references = NULL;
    
    struct memblock_device mem_23522;
    
    mem_23522.references = NULL;
    
    struct memblock_device mem_23512;
    
    mem_23512.references = NULL;
    
    struct memblock_device mem_23496;
    
    mem_23496.references = NULL;
    
    struct memblock_device ext_mem_23535;
    
    ext_mem_23535.references = NULL;
    
    struct memblock_device ext_mem_23538;
    
    ext_mem_23538.references = NULL;
    
    struct memblock_device ext_mem_23539;
    
    ext_mem_23539.references = NULL;
    
    struct memblock_device segred_tmp_mem_24622;
    
    segred_tmp_mem_24622.references = NULL;
    
    struct memblock_device color_23823;
    
    color_23823.references = NULL;
    
    struct memblock_device color_23822;
    
    color_23822.references = NULL;
    
    struct memblock_device mem_23596;
    
    mem_23596.references = NULL;
    
    struct memblock_device mem_23582;
    
    mem_23582.references = NULL;
    
    struct memblock_device mem_23568;
    
    mem_23568.references = NULL;
    
    struct memblock_device mem_23552;
    
    mem_23552.references = NULL;
    
    struct memblock_device ext_mem_23600;
    
    ext_mem_23600.references = NULL;
    
    struct memblock_device ext_mem_23603;
    
    ext_mem_23603.references = NULL;
    
    struct memblock_device mem_23473;
    
    mem_23473.references = NULL;
    
    struct memblock_device mem_23471;
    
    mem_23471.references = NULL;
    
    struct memblock_device incprefixes_mem_24498;
    
    incprefixes_mem_24498.references = NULL;
    
    struct memblock_device aggregates_mem_24496;
    
    aggregates_mem_24496.references = NULL;
    
    struct memblock_device status_flags_mem_24494;
    
    status_flags_mem_24494.references = NULL;
    
    struct memblock_device mem_23469;
    
    mem_23469.references = NULL;
    
    struct memblock_device mem_23467;
    
    mem_23467.references = NULL;
    
    struct memblock_device mem_23751;
    
    mem_23751.references = NULL;
    
    struct memblock_device mem_23691;
    
    mem_23691.references = NULL;
    
    struct memblock_device mem_23686;
    
    mem_23686.references = NULL;
    
    struct memblock_device mem_23689;
    
    mem_23689.references = NULL;
    
    struct memblock_device segred_tmp_mem_24314;
    
    segred_tmp_mem_24314.references = NULL;
    
    struct memblock_device mem_23678;
    
    mem_23678.references = NULL;
    
    struct memblock_device mem_23675;
    
    mem_23675.references = NULL;
    
    struct memblock_device mem_23680;
    
    mem_23680.references = NULL;
    
    struct memblock_device mem_23668;
    
    mem_23668.references = NULL;
    
    struct memblock_device mem_23694;
    
    mem_23694.references = NULL;
    
    struct memblock_device segred_tmp_mem_24221;
    
    segred_tmp_mem_24221.references = NULL;
    
    struct memblock_device mem_23858;
    
    mem_23858.references = NULL;
    
    struct memblock_device color_23821;
    
    color_23821.references = NULL;
    
    struct memblock_device mem_23744;
    
    mem_23744.references = NULL;
    
    struct memblock_device mem_23734;
    
    mem_23734.references = NULL;
    
    struct memblock_device ext_mem_23747;
    
    ext_mem_23747.references = NULL;
    
    struct memblock_device ext_mem_23748;
    
    ext_mem_23748.references = NULL;
    
    struct memblock_device mem_23665;
    
    mem_23665.references = NULL;
    
    struct memblock_device mem_23651;
    
    mem_23651.references = NULL;
    
    struct memblock_device incprefixes_mem_24076;
    
    incprefixes_mem_24076.references = NULL;
    
    struct memblock_device aggregates_mem_24074;
    
    aggregates_mem_24074.references = NULL;
    
    struct memblock_device status_flags_mem_24072;
    
    status_flags_mem_24072.references = NULL;
    
    struct memblock_device mem_23663;
    
    mem_23663.references = NULL;
    
    struct memblock_device mem_23661;
    
    mem_23661.references = NULL;
    
    struct memblock_device mem_23657;
    
    mem_23657.references = NULL;
    
    struct memblock_device mem_23656;
    
    mem_23656.references = NULL;
    
    struct memblock_device mem_23655;
    
    mem_23655.references = NULL;
    
    struct memblock_device mem_23654;
    
    mem_23654.references = NULL;
    
    struct memblock_device mem_23653;
    
    mem_23653.references = NULL;
    
    struct memblock_device mem_23652;
    
    mem_23652.references = NULL;
    
    struct memblock_device mem_23463;
    
    mem_23463.references = NULL;
    
    struct memblock_device segred_tmp_mem_23999;
    
    segred_tmp_mem_23999.references = NULL;
    
    struct memblock_device segred_tmp_mem_23997;
    
    segred_tmp_mem_23997.references = NULL;
    
    struct memblock_device mem_23462;
    
    mem_23462.references = NULL;
    
    struct memblock_device mem_23461;
    
    mem_23461.references = NULL;
    
    struct memblock_device mem_23459;
    
    mem_23459.references = NULL;
    
    struct memblock_device mem_23458;
    
    mem_23458.references = NULL;
    
    struct memblock_device mem_23414;
    
    mem_23414.references = NULL;
    
    struct memblock_device mem_23406;
    
    mem_23406.references = NULL;
    
    struct memblock_device mem_23405;
    
    mem_23405.references = NULL;
    
    struct memblock_device segred_tmp_mem_23913;
    
    segred_tmp_mem_23913.references = NULL;
    
    struct memblock_device mem_23402;
    
    mem_23402.references = NULL;
    
    struct memblock_device mem_out_23886;
    
    mem_out_23886.references = NULL;
    
    struct memblock_device mem_out_23885;
    
    mem_out_23885.references = NULL;
    
    struct memblock_device counters_mem_23891 = ctx->constants->counters_mem_23891;
    struct memblock_device counters_mem_23995 = ctx->constants->counters_mem_23995;
    struct memblock_device counters_mem_24219 = ctx->constants->counters_mem_24219;
    struct memblock_device counters_mem_24316 = ctx->constants->counters_mem_24316;
    struct memblock_device counters_mem_24620 = ctx->constants->counters_mem_24620;
    struct memblock_device counters_mem_24722 = ctx->constants->counters_mem_24722;
    struct memblock_device counters_mem_24770 = ctx->constants->counters_mem_24770;
    struct memblock_device counters_mem_24855 = ctx->constants->counters_mem_24855;
    struct memblock_device counters_mem_24938 = ctx->constants->counters_mem_24938;
    struct memblock_device global_dynid_mem_24078 = ctx->constants->global_dynid_mem_24078;
    struct memblock_device global_dynid_mem_24500 = ctx->constants->global_dynid_mem_24500;
    int64_t prim_out_23887;
    int64_t prim_out_23888;
    int64_t arg_15490 = mul64((int64_t) 2, num_qubits_15486);
    int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 = add64((int64_t) 1, arg_15490);
    int64_t segred_tblock_sizze_21546;
    
    segred_tblock_sizze_21546 = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21545;
    
    int64_t num_tblocks_21548;
    int64_t max_num_tblocks_23889;
    
    max_num_tblocks_23889 = *ctx->tuning_params.simulate_8477zisegred_num_tblocks_21547;
    num_tblocks_21548 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(n_15484, segred_tblock_sizze_21546), max_num_tblocks_23889)));
    if (memblock_alloc_device(ctx, &mem_23402, (int64_t) 8, "mem_23402")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegRed");
    
    int64_t chunk_sizze_23890 = (int64_t) 1;
    
    if (memblock_alloc_device(ctx, &segred_tmp_mem_23913, (int64_t) 8 * num_tblocks_21548, "segred_tmp_mem_23913")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t num_threads_23915 = num_tblocks_21548 * segred_tblock_sizze_21546;
    
    {
        err = gpu_kernel_simulate_8477zisegred_nonseg_21553(ctx, num_tblocks_21548, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21545, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_21546 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_21546, (int64_t) 8), (int64_t) 8)), n_15484, num_tblocks_21548, num_threads_23915, gates_mem_23398.mem, mem_23402.mem, counters_mem_23891.mem, segred_tmp_mem_23913.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t read_res_25103;
    
    if ((err = gpu_scalar_from_device(ctx, &read_res_25103, mem_23402.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
        goto cleanup;
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t defunc_0_f_res_21542 = read_res_25103;
    
    if (memblock_unref_device(ctx, &mem_23402, "mem_23402") != 0)
        return 1;
    
    bool bounds_invalid_upwards_17575 = slt64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, (int64_t) 0);
    bool valid_17576 = !bounds_invalid_upwards_17575;
    bool range_valid_c_17577;
    
    if (!valid_17576) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  /prelude/array.fut:249:28-34\n   #2  definitions.fut:34:27-41:35\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t nest_sizze_21625 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;
    int64_t segmap_tblock_sizze_21626;
    
    segmap_tblock_sizze_21626 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21568;
    
    int64_t segmap_usable_groups_21627 = sdiv_up64(nest_sizze_21625, segmap_tblock_sizze_21626);
    
    if (memblock_alloc_device(ctx, &mem_23405, nest_sizze_21625, "mem_23405")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_23944 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, segmap_tblock_sizze_21626));
    
    {
        err = gpu_kernel_simulate_8477zisegmap_21631(ctx, segmap_usable_groups_21627, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21568, 1, 1, (int64_t) 0, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, mem_23405.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int32_t unsign_arg0_17607 = 5460 ^ seed_15485;
    int32_t unsign_arg0_16239 = mul32(48271, unsign_arg0_17607);
    int32_t unsign_arg0_17613 = umod32(unsign_arg0_16239, 2147483647);
    
    if (memblock_alloc_device(ctx, &mem_23406, defunc_0_f_res_21542, "mem_23406")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i8(ctx, mem_23406, defunc_0_f_res_21542, (int8_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_15526 = slt64((int64_t) 0, n_15484);
    int64_t map_arg1_17132 = sub64(arg_15490, (int64_t) 1);
    int64_t distance_upwards_exclusive_17134 = sub64(map_arg1_17132, num_qubits_15486);
    int64_t distance_17135 = add64((int64_t) 1, distance_upwards_exclusive_17134);
    
    if (memblock_alloc_device(ctx, &mem_23414, (int64_t) 8, "mem_23414")) {
        err = 1;
        goto cleanup;
    }
    
    bool simulate_res_15532;
    int64_t simulate_res_15534;
    int32_t simulate_res_15535;
    int32_t simulate_res_15537;
    bool loop_while_15538;
    int64_t i_15540;
    int32_t rng_15541;
    int32_t measurement_count_15543;
    
    loop_while_15538 = loop_cond_15526;
    i_15540 = (int64_t) 0;
    rng_15541 = unsign_arg0_17613;
    measurement_count_15543 = 0;
    while (loop_while_15538) {
        bool x_15544 = sle64((int64_t) 0, i_15540);
        bool y_15545 = slt64(i_15540, n_15484);
        bool bounds_check_15546 = x_15544 && y_15545;
        bool index_certs_15547;
        
        if (!bounds_check_15546) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) i_15540, "] out of bounds for array of shape [", (long long) n_15484, "].", "-> #0  main.fut:9:37-52\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t read_res_25104;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_25104, gates_mem_23398.mem, i_15540 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_15548 = read_res_25104;
        bool cond_15554 = loopres_15548 == (int64_t) 0;
        
        {
            err = gpu_kernel_simulate_8477zigpuseq_23981(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, i_15540, cQ_mem_23399.mem, mem_23414.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        
        int64_t measurement_count_21335 = sext_i32_i64(measurement_count_15543);
        int64_t loopres_15556;
        int32_t loopres_15557;
        int32_t loopres_15559;
        
        if (cond_15554) {
            bool bounds_invalid_upwards_20845 = slt64(map_arg1_17132, num_qubits_15486);
            bool valid_20846 = !bounds_invalid_upwards_20845;
            bool range_valid_c_20847;
            
            if (!valid_20846) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) num_qubits_15486, "...", (long long) map_arg1_17132, " is invalid.", "-> #0  definitions.fut:102:39-52\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t segred_tblock_sizze_21645;
            
            segred_tblock_sizze_21645 = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21644;
            
            int64_t num_tblocks_21647;
            int64_t max_num_tblocks_23987;
            
            max_num_tblocks_23987 = *ctx->tuning_params.simulate_8477zisegred_num_tblocks_21646;
            num_tblocks_21647 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(distance_17135, segred_tblock_sizze_21645), max_num_tblocks_23987)));
            
            bool bounds_invalid_upwards_20886 = slt64(num_qubits_15486, (int64_t) 0);
            bool valid_20887 = !bounds_invalid_upwards_20886;
            bool bounds_invalid_upwards_20890 = slt64(arg_15490, (int64_t) 0);
            bool valid_20891 = !bounds_invalid_upwards_20890;
            bool cond_20897 = num_qubits_15486 == (int64_t) 0;
            int64_t tmp_20899 = sub64(num_qubits_15486, (int64_t) 1);
            bool x_20900 = sle64((int64_t) 0, tmp_20899);
            bool y_20901 = slt64(tmp_20899, num_qubits_15486);
            bool bounds_check_20902 = x_20900 && y_20901;
            bool protect_assert_disj_20903 = cond_20897 || bounds_check_20902;
            bool cond_20906 = arg_15490 == (int64_t) 0;
            bool x_20908 = sle64((int64_t) 0, map_arg1_17132);
            bool y_20909 = slt64(map_arg1_17132, arg_15490);
            bool bounds_check_20910 = x_20908 && y_20909;
            bool protect_assert_disj_20911 = cond_20906 || bounds_check_20910;
            bool x_21336 = sle64((int64_t) 0, measurement_count_21335);
            bool y_21337 = slt64(measurement_count_21335, defunc_0_f_res_21542);
            bool bounds_check_21338 = x_21336 && y_21337;
            bool index_certs_21339;
            
            if (!bounds_check_21338) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) measurement_count_21335, "] out of bounds for array of shape [", (long long) defunc_0_f_res_21542, "].", "-> #0  main.fut:15:20-71\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_23458, (int64_t) 1, "mem_23458")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_23459, (int64_t) 0, "mem_23459")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_simulate_8477zigpuseq_23988(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, mem_23414.mem, mem_23458.mem, mem_23459.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            
            bool index_certs_20852 = 0;
            
            if (memblock_unref_device(ctx, &mem_23459, "mem_23459") != 0)
                return 1;
            if (memblock_alloc_device(ctx, &mem_23461, (int64_t) 8, "mem_23461")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_23462, (int64_t) 1, "mem_23462")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegRed");
            
            int64_t chunk_sizze_23994 = (int64_t) 1;
            
            if (memblock_alloc_device(ctx, &segred_tmp_mem_23997, (int64_t) 8 * num_tblocks_21647, "segred_tmp_mem_23997")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &segred_tmp_mem_23999, num_tblocks_21647, "segred_tmp_mem_23999")) {
                err = 1;
                goto cleanup;
            }
            
            int64_t num_threads_24001 = num_tblocks_21647 * segred_tblock_sizze_21645;
            
            {
                err = gpu_kernel_simulate_8477zisegred_nonseg_21653(ctx, num_tblocks_21647, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21644, 1, 1, 8 + (segred_tblock_sizze_21645 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_21645, (int64_t) 8), (int64_t) 8)) + ((int64_t) 8 * segred_tblock_sizze_21645 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_21645, (int64_t) 8), (int64_t) 8)), num_qubits_15486, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, distance_17135, num_tblocks_21647, num_threads_24001, mem_23405.mem, mem_23414.mem, mem_23461.mem, mem_23462.mem, counters_mem_23995.mem, segred_tmp_mem_23997.mem, segred_tmp_mem_23999.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            
            int8_t read_res_25105;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_25105, mem_23462.mem, (int64_t) 0 * sizeof(int8_t), sizeof(int8_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int8_t defunc_0_f_res_20854 = read_res_25105;
            
            if (memblock_unref_device(ctx, &mem_23462, "mem_23462") != 0)
                return 1;
            
            bool cond_20883 = defunc_0_f_res_20854 == (int8_t) 1;
            bool protect_assert_disj_20884 = valid_17576 || cond_20883;
            bool range_valid_c_20885;
            
            if (!protect_assert_disj_20884) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  definitions.fut:133:47-59\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool protect_assert_disj_20888 = cond_20883 || valid_20887;
            bool range_valid_c_20889;
            
            if (!protect_assert_disj_20888) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) num_qubits_15486, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  definitions.fut:137:61-67\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool loop_not_taken_20892 = !cond_20883;
            bool protect_assert_disj_20893 = valid_20891 || loop_not_taken_20892;
            bool range_valid_c_20894;
            
            if (!protect_assert_disj_20893) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) arg_15490, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  definitions.fut:106:73-84\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool protect_assert_disj_20904 = cond_20883 || protect_assert_disj_20903;
            bool index_certs_20905;
            
            if (!protect_assert_disj_20904) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_20899, "] out of bounds for array of shape [", (long long) num_qubits_15486, "].", "-> #0  /prelude/soacs.fut:257:33-47\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool protect_assert_disj_20912 = loop_not_taken_20892 || protect_assert_disj_20911;
            bool index_certs_20913;
            
            if (!protect_assert_disj_20912) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) map_arg1_17132, "] out of bounds for array of shape [", (long long) arg_15490, "].", "-> #0  /prelude/soacs.fut:257:33-47\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool y_20979 = slt64(arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);
            bool protect_assert_disj_23383 = loop_not_taken_20892 || y_20979;
            bool index_certs_20980;
            
            if (!protect_assert_disj_23383) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) arg_15490, "] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, "].", "-> #0  definitions.fut:26:18-36\n   #1  definitions.fut:89:58-109:37\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool x_21194 = sle64((int64_t) 0, arg_15490);
            bool bounds_check_21196 = y_20979 && x_21194;
            bool protect_assert_disj_23774 = cond_20883 || bounds_check_21196;
            bool index_certs_21197;
            
            if (!protect_assert_disj_23774) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) arg_15490, "] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, "].", "-> #0  definitions.fut:147:31-44\n   #1  definitions.fut:148:27-33\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool index_certs_21198;
            
            if (!protect_assert_disj_23774) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) arg_15490, "] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, "].", "-> #0  definitions.fut:150:35-48\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool protect_assert_disj_23770 = valid_17576 || loop_not_taken_20892;
            bool range_valid_c_21094;
            
            if (!protect_assert_disj_23770) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  definitions.fut:114:45-57\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool x_20898 = !cond_20897;
            bool x_20907 = !cond_20906;
            int64_t segscan_tblock_sizze_22098;
            
            segscan_tblock_sizze_22098 = *ctx->tuning_params.simulate_8477zisegscan_tblock_sizze_22097;
            
            int64_t num_tblocks_22100;
            int64_t max_num_tblocks_24046;
            
            max_num_tblocks_24046 = *ctx->tuning_params.simulate_8477zisegscan_num_tblocks_22099;
            num_tblocks_22100 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(num_qubits_15486, segscan_tblock_sizze_22098), max_num_tblocks_24046)));
            
            int64_t segscan_tblock_sizze_21656;
            
            segscan_tblock_sizze_21656 = *ctx->tuning_params.simulate_8477zisegscan_tblock_sizze_21655;
            
            int64_t num_tblocks_21658;
            int64_t max_num_tblocks_24047;
            
            max_num_tblocks_24047 = *ctx->tuning_params.simulate_8477zisegscan_num_tblocks_21657;
            num_tblocks_21658 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_15490, segscan_tblock_sizze_21656), max_num_tblocks_24047)));
            
            int64_t tmp_21334 = add64((int64_t) 1, i_15540);
            int32_t tmp_21341 = add32(1, measurement_count_15543);
            int64_t segmap_tblock_sizze_22092;
            
            segmap_tblock_sizze_22092 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22091;
            
            int64_t num_tblocks_22094;
            int64_t max_num_tblocks_24048;
            
            max_num_tblocks_24048 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22093;
            num_tblocks_22094 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, segmap_tblock_sizze_22092), max_num_tblocks_24048)));
            if (memblock_alloc_device(ctx, &mem_23463, (int64_t) 0, "mem_23463")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_simulate_8477zigpuseq_24049(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, cond_20883, mem_23414.mem, mem_23458.mem, mem_23463.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (memblock_unref_device(ctx, &mem_23458, "mem_23458") != 0)
                return 1;
            
            int32_t unsign_arg0_21114 = mul32(48271, rng_15541);
            int32_t unsign_arg0_21115 = umod32(unsign_arg0_21114, 2147483647);
            bool zgze_res_21116 = ule32(2147483646, unsign_arg0_21115);
            bool x_23384;
            int32_t x_23385;
            int32_t x_23386;
            bool loop_while_21120;
            int32_t rng_21121;
            int32_t x_21122;
            
            loop_while_21120 = zgze_res_21116;
            rng_21121 = unsign_arg0_21115;
            x_21122 = unsign_arg0_21115;
            while (loop_while_21120) {
                int32_t unsign_arg0_21123 = mul32(48271, rng_21121);
                int32_t unsign_arg0_21124 = umod32(unsign_arg0_21123, 2147483647);
                bool zgze_res_21125 = ule32(2147483646, unsign_arg0_21124);
                bool loop_while_tmp_24055 = zgze_res_21125;
                int32_t rng_tmp_24056 = unsign_arg0_21124;
                int32_t x_tmp_24057 = unsign_arg0_21124;
                
                loop_while_21120 = loop_while_tmp_24055;
                rng_21121 = rng_tmp_24056;
                x_21122 = x_tmp_24057;
            }
            x_23384 = loop_while_21120;
            x_23385 = rng_21121;
            x_23386 = x_21122;
            
            int32_t unsign_arg0_21126 = umod32(x_23386, 2);
            int8_t u64_res_21127 = zext_i32_i8(unsign_arg0_21126);
            int32_t Measurement_res_20914;
            
            if (cond_20883) {
                Measurement_res_20914 = x_23385;
            } else {
                Measurement_res_20914 = rng_15541;
            }
            
            bool index_certs_20896;
            
            if (loop_not_taken_20892) {
                bool x_23396 = 0;
                
                index_certs_20896 = x_23396;
            } else {
                index_certs_20896 = 0;
            }
            if (memblock_unref_device(ctx, &mem_23463, "mem_23463") != 0)
                return 1;
            
            int64_t bytes_23466 = (int64_t) 8 * num_qubits_15486;
            int64_t segmap_tblock_sizze_22108;
            
            segmap_tblock_sizze_22108 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22107;
            
            int64_t num_tblocks_22110;
            int64_t max_num_tblocks_24058;
            
            max_num_tblocks_24058 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22109;
            num_tblocks_22110 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(num_qubits_15486, segmap_tblock_sizze_22108), max_num_tblocks_24058)));
            
            int64_t segmap_tblock_sizze_22585;
            
            segmap_tblock_sizze_22585 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22409;
            
            int64_t segred_tblock_sizze_22600;
            
            segred_tblock_sizze_22600 = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22357;
            
            int64_t segmap_tblock_sizze_22649;
            
            segmap_tblock_sizze_22649 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22336;
            
            int64_t segmap_tblock_sizze_22521;
            
            segmap_tblock_sizze_22521 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22204;
            
            int64_t segred_tblock_sizze_22670;
            
            segred_tblock_sizze_22670 = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22506;
            
            int64_t segred_tblock_sizze_22127;
            
            segred_tblock_sizze_22127 = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22115;
            
            int64_t binop_x_23489 = smax64((int64_t) 0, arg_15490);
            int64_t binop_y_23492 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 * binop_x_23489;
            int64_t binop_y_23493 = smax64((int64_t) 0, binop_y_23492);
            int64_t binop_y_23494 = binop_x_23489 + binop_y_23493;
            int64_t bytes_23495 = (int64_t) 1 + binop_y_23494;
            int64_t binop_x_23517 = smax64((int64_t) 0, tmp_20899);
            int64_t binop_y_23647 = smax64((int64_t) 0, num_qubits_15486);
            int64_t binop_y_23648 = binop_x_23517 + binop_y_23647;
            int64_t binop_y_23649 = (int64_t) 1 + binop_y_23648;
            int64_t bytes_23650 = (int64_t) 8 * binop_y_23649;
            int64_t bytes_23660 = (int64_t) 16 * num_qubits_15486;
            
            if (cond_20883) {
                bool range_valid_c_20973;
                
                if (!valid_20887) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) num_qubits_15486, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  definitions.fut:25:92-98\n   #2  definitions.fut:89:58-109:37\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23652, (int64_t) 8, "mem_23652")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23653, (int64_t) 0, "mem_23653")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23654, (int64_t) 0, "mem_23654")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23655, (int64_t) 1, "mem_23655")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23656, (int64_t) 8, "mem_23656")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23657, (int64_t) 8, "mem_23657")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_simulate_8477zigpuseq_24059(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, num_qubits_15486, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, u64_res_21127, measurement_count_21335, mem_23405.mem, mem_23406.mem, mem_23414.mem, mem_23461.mem, mem_23652.mem, mem_23653.mem, mem_23654.mem, mem_23655.mem, mem_23656.mem, mem_23657.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
                if (memblock_alloc_device(ctx, &mem_23661, bytes_23660, "mem_23661")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23663, bytes_23660, "mem_23663")) {
                    err = 1;
                    goto cleanup;
                }
                if (slt64((int64_t) 0, arg_15490)) {
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegScan");
                    
                    int64_t shared_memory_24065;
                    
                    shared_memory_24065 = ctx->max_shared_memory;
                    
                    int64_t thread_block_sizze_24066;
                    
                    thread_block_sizze_24066 = ctx->max_thread_block_size;
                    
                    int64_t registers_24067;
                    
                    registers_24067 = ctx->max_registers;
                    
                    int64_t thread_block_sizze_24068;
                    
                    thread_block_sizze_24068 = ctx->max_thread_block_size;
                    
                    int64_t chunk_sizze_24069 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_24065, thread_block_sizze_24066), (int64_t) 8), squot64(squot64(registers_24067, thread_block_sizze_24068) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
                    int64_t num_virt_blocks_24070 = sdiv_up64(arg_15490, segscan_tblock_sizze_21656 * chunk_sizze_24069);
                    int64_t num_virt_threads_24071 = num_virt_blocks_24070 * segscan_tblock_sizze_21656;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_24069, '\n');
                    if (memblock_alloc_device(ctx, &status_flags_mem_24072, num_virt_blocks_24070, "status_flags_mem_24072")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_24072, num_virt_blocks_24070, (int8_t) 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &aggregates_mem_24074, (int64_t) 8 * num_virt_blocks_24070, "aggregates_mem_24074")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &incprefixes_mem_24076, (int64_t) 8 * num_virt_blocks_24070, "incprefixes_mem_24076")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_simulate_8477zisegscan_21661(ctx, num_tblocks_21658, 1, 1, *ctx->tuning_params.simulate_8477zisegscan_tblock_sizze_21655, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_21656), chunk_sizze_24069 * segscan_tblock_sizze_21656 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_21656), chunk_sizze_24069 * segscan_tblock_sizze_21656 * (int64_t) 8), (int64_t) 8), (int64_t) 8), arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, num_tblocks_21658, num_virt_blocks_24070, num_virt_threads_24071, mem_23405.mem, mem_23414.mem, mem_23652.mem, mem_23661.mem, mem_23663.mem, status_flags_mem_24072.mem, aggregates_mem_24074.mem, incprefixes_mem_24076.mem, global_dynid_mem_24078.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                }
                
                int64_t m_f_res_20946;
                
                if (x_20907) {
                    int64_t read_res_25106;
                    
                    if ((err = gpu_scalar_from_device(ctx, &read_res_25106, mem_23661.mem, map_arg1_17132 * sizeof(int64_t), sizeof(int64_t))) != 0)
                        goto cleanup;
                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t x_20947 = read_res_25106;
                    
                    m_f_res_20946 = x_20947;
                } else {
                    m_f_res_20946 = (int64_t) 0;
                }
                
                int64_t m_20948;
                
                if (cond_20906) {
                    m_20948 = (int64_t) 0;
                } else {
                    m_20948 = m_f_res_20946;
                }
                
                int64_t m_20949 = sub64(m_20948, (int64_t) 1);
                bool i_p_m_t_s_leq_w_20950 = slt64(m_20949, arg_15490);
                bool zzero_leq_i_p_m_t_s_20951 = sle64((int64_t) 0, m_20949);
                bool y_20952 = i_p_m_t_s_leq_w_20950 && zzero_leq_i_p_m_t_s_20951;
                bool i_lte_j_20953 = sle64((int64_t) 0, m_20948);
                bool forwards_ok_20954 = y_20952 && i_lte_j_20953;
                bool eq_x_zz_20955 = (int64_t) 0 == m_f_res_20946;
                bool p_and_eq_x_y_20956 = x_20907 && eq_x_zz_20955;
                bool empty_slice_20957 = cond_20906 || p_and_eq_x_y_20956;
                bool ok_or_empty_20958 = forwards_ok_20954 || empty_slice_20957;
                bool index_certs_20959;
                
                if (!ok_or_empty_20958) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_20948, "] out of bounds for array of shape [", (long long) arg_15490, "].", "-> #0  /prelude/soacs.fut:258:29-35\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                
                int64_t bytes_23664 = (int64_t) 8 * m_20948;
                int64_t segmap_tblock_sizze_21666;
                
                segmap_tblock_sizze_21666 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21665;
                
                int64_t num_tblocks_21668;
                int64_t max_num_tblocks_24167;
                
                max_num_tblocks_24167 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_21667;
                num_tblocks_21668 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_15490, segmap_tblock_sizze_21666), max_num_tblocks_24167)));
                
                int64_t segmap_tblock_sizze_21684;
                
                segmap_tblock_sizze_21684 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21673;
                
                int64_t num_tblocks_21685;
                int64_t max_num_tblocks_24168;
                
                max_num_tblocks_24168 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_21675;
                num_tblocks_21685 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(num_qubits_15486, segmap_tblock_sizze_21684), max_num_tblocks_24168)));
                if (memblock_alloc_device(ctx, &mem_23651, bytes_23650, "mem_23651")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24169 = sext_i64_i32(sdiv_up64(num_qubits_15486, segmap_tblock_sizze_21684));
                
                {
                    err = gpu_kernel_simulate_8477zisegmap_21689(ctx, num_tblocks_21685, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21673, 1, 1, (int64_t) 0, num_qubits_15486, num_tblocks_21685, virt_num_tblocks_24169, mem_23651.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                
                int64_t segmap_tblock_sizze_21943;
                
                segmap_tblock_sizze_21943 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21932;
                
                int64_t segred_tblock_sizze_21956;
                
                segred_tblock_sizze_21956 = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21877;
                
                int64_t segmap_tblock_sizze_22007;
                
                segmap_tblock_sizze_22007 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21856;
                
                int64_t segmap_tblock_sizze_21768;
                
                segmap_tblock_sizze_21768 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21698;
                
                int64_t segmap_tblock_sizze_22042;
                
                segmap_tblock_sizze_22042 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22041;
                
                int64_t segmap_tblock_sizze_22061;
                
                segmap_tblock_sizze_22061 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22049;
                
                int64_t segmap_usable_groups_22062 = sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, segmap_tblock_sizze_22061);
                int64_t segmap_tblock_sizze_22076;
                
                segmap_tblock_sizze_22076 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22075;
                
                int64_t num_tblocks_22078;
                int64_t max_num_tblocks_24182;
                
                max_num_tblocks_24182 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22077;
                num_tblocks_22078 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, segmap_tblock_sizze_22076), max_num_tblocks_24182)));
                
                int64_t segmap_tblock_sizze_22084;
                
                segmap_tblock_sizze_22084 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22083;
                
                int64_t num_tblocks_22086;
                int64_t max_num_tblocks_24183;
                
                max_num_tblocks_24183 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22085;
                num_tblocks_22086 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, segmap_tblock_sizze_22084), max_num_tblocks_24183)));
                if (memblock_alloc_device(ctx, &mem_23665, bytes_23664, "mem_23665")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhiota_i64(ctx, mem_23665, m_20948, (int64_t) 0, (int64_t) 1) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24201 = sext_i64_i32(sdiv_up64(arg_15490, segmap_tblock_sizze_21666));
                
                {
                    err = gpu_kernel_simulate_8477zisegmap_21663(ctx, num_tblocks_21668, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21665, 1, 1, (int64_t) 0, arg_15490, m_20948, num_tblocks_21668, virt_num_tblocks_24201, mem_23661.mem, mem_23663.mem, mem_23665.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23661, "mem_23661") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23663, "mem_23663") != 0)
                    return 1;
                
                int64_t dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20972 = mul64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_20948);
                bool index_certs_20978 = 0;
                
                if (memblock_unref_device(ctx, &mem_23653, "mem_23653") != 0)
                    return 1;
                
                bool index_certs_20981 = 0;
                
                if (memblock_unref_device(ctx, &mem_23654, "mem_23654") != 0)
                    return 1;
                
                bool suff_outer_par_21694;
                
                suff_outer_par_21694 = *ctx->tuning_params.simulate_8477zisuff_outer_par_0 <= m_20948;
                if (ctx->logging)
                    fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "simulate_8477.suff_outer_par_0", (long) m_20948, suff_outer_par_21694 ? "true" : "false");
                
                int64_t nest_sizze_21955 = num_qubits_15486 * m_20948;
                int64_t num_tblocks_21957;
                int64_t max_num_tblocks_24214;
                
                max_num_tblocks_24214 = *ctx->tuning_params.simulate_8477zisegred_num_tblocks_21879;
                num_tblocks_21957 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_21955, segred_tblock_sizze_21956), max_num_tblocks_24214)));
                
                int64_t num_tblocks_21769;
                int64_t max_num_tblocks_24215;
                
                max_num_tblocks_24215 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_21700;
                num_tblocks_21769 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_20948, segmap_tblock_sizze_21768), max_num_tblocks_24215)));
                
                int64_t ext_23746;
                int64_t shared_memory_capacity_24216;
                
                shared_memory_capacity_24216 = ctx->max_shared_memory;
                if (suff_outer_par_21694) {
                    ext_23746 = (int64_t) 1;
                } else {
                    ext_23746 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;
                }
                
                int64_t ext_23745;
                int64_t shared_memory_capacity_24217;
                
                shared_memory_capacity_24217 = ctx->max_shared_memory;
                if (suff_outer_par_21694) {
                    ext_23745 = m_20948;
                } else {
                    ext_23745 = (int64_t) 1;
                }
                
                int64_t bytes_23677 = (int64_t) 2 * nest_sizze_21955;
                int64_t binop_x_23687 = (int64_t) 8 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;
                int64_t bytes_23688 = m_20948 * binop_x_23687;
                int64_t binop_x_23726 = smax64((int64_t) 0, m_20949);
                int64_t binop_y_23729 = m_20948 * binop_x_23489;
                int64_t binop_y_23730 = smax64((int64_t) 0, binop_y_23729);
                int64_t binop_y_23731 = binop_x_23726 + binop_y_23730;
                int64_t binop_y_23732 = (int64_t) 1 + binop_y_23731;
                int64_t bytes_23733 = (int64_t) 8 * binop_y_23732;
                int64_t num_threads_23824 = segmap_tblock_sizze_21768 * num_tblocks_21769;
                int64_t total_sizze_23825 = arg_15490 * num_threads_23824;
                int64_t segred_num_tblocks_23834;
                
                segred_num_tblocks_23834 = *ctx->tuning_params.simulate_8477zisegred_num_tblocks_23833;
                
                int64_t segred_tblock_sizze_23836;
                
                segred_tblock_sizze_23836 = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_23835;
                
                int64_t ctx_23865 = (int64_t) 2 * num_threads_23824;
                int64_t shared_memory_capacity_24424;
                
                shared_memory_capacity_24424 = ctx->max_shared_memory;
                if (suff_outer_par_21694 && (sle64(sdiv_up64((int64_t) 8 * segred_tblock_sizze_23836, (int64_t) 8) * (int64_t) 8 + (int64_t) 8, shared_memory_capacity_24424) && sle64((int64_t) 0, shared_memory_capacity_24424))) {
                    if (memblock_alloc_device(ctx, &mem_23734, bytes_23733, "mem_23734")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23744, binop_y_23732, "mem_23744")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &color_23821, total_sizze_23825, "color_23821")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23858, (int64_t) 8, "mem_23858")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_24218 = (int64_t) 1;
                    
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_24221, (int64_t) 8 * segred_num_tblocks_23834, "segred_tmp_mem_24221")) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t num_threads_24223 = segred_num_tblocks_23834 * segred_tblock_sizze_23836;
                    
                    {
                        err = gpu_kernel_simulate_8477zisegred_nonseg_23843(ctx, segred_num_tblocks_23834, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_23835, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_23836 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_23836, (int64_t) 8), (int64_t) 8)), num_qubits_15486, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_20948, num_threads_24223, mem_23665.mem, mem_23858.mem, counters_mem_24219.mem, segred_tmp_mem_24221.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    
                    int64_t read_res_25107;
                    
                    if ((err = gpu_scalar_from_device(ctx, &read_res_25107, mem_23858.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
                        goto cleanup;
                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t max_per_thread_23830 = read_res_25107;
                    
                    if (memblock_unref_device(ctx, &mem_23858, "mem_23858") != 0)
                        return 1;
                    
                    int64_t sizze_sum_23854 = num_threads_23824 * max_per_thread_23830;
                    
                    if (memblock_alloc_device(ctx, &mem_23694, sizze_sum_23854, "mem_23694")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_24252 = sext_i64_i32(sdiv_up64(m_20948, segmap_tblock_sizze_21768));
                    
                    {
                        err = gpu_kernel_simulate_8477zisegmap_21774(ctx, num_tblocks_21769, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21698, 1, 1, (int64_t) 0, num_qubits_15486, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_20948, num_tblocks_21769, num_threads_23824, ctx_23865, virt_num_tblocks_24252, mem_23405.mem, mem_23652.mem, mem_23655.mem, mem_23665.mem, mem_23694.mem, mem_23734.mem, mem_23744.mem, color_23821.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23694, "mem_23694") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &color_23821, "color_23821") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23748, &mem_23734, "mem_23734") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23747, &mem_23744, "mem_23744") != 0)
                        return 1;
                } else {
                    int64_t segmap_usable_groups_21944 = sdiv_up64(m_20948, segmap_tblock_sizze_21943);
                    
                    if (memblock_alloc_device(ctx, &mem_23668, (int64_t) 0, "mem_23668")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23680, m_20948, "mem_23680")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_24272 = sext_i64_i32(sdiv_up64(m_20948, segmap_tblock_sizze_21943));
                    
                    {
                        err = gpu_kernel_simulate_8477zisegmap_21948(ctx, segmap_usable_groups_21944, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21932, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_20948, mem_23665.mem, mem_23668.mem, mem_23680.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_alloc_device(ctx, &mem_23675, m_20948, "mem_23675")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23678, bytes_23677, "mem_23678")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_24281 = (int64_t) 1;
                    
                    if (slt64(num_qubits_15486 * (int64_t) 2, segred_tblock_sizze_21956 * chunk_sizze_24281)) {
                        int64_t segment_sizze_nonzzero_24282 = smax64((int64_t) 1, num_qubits_15486);
                        int64_t num_threads_24283 = segred_tblock_sizze_21956 * segred_tblock_sizze_21956;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-small");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) m_20948, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_qubits_15486, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_21956, segment_sizze_nonzzero_24282), '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(m_20948, squot64(segred_tblock_sizze_21956, segment_sizze_nonzzero_24282))), '\n');
                        {
                            err = gpu_kernel_simulate_8477zisegred_small_21963(ctx, num_tblocks_21957, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21877, 1, 1, segred_tblock_sizze_21956 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_21956, (int64_t) 8), (int64_t) 8), num_qubits_15486, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_20948, num_tblocks_21957, segment_sizze_nonzzero_24282, mem_23405.mem, mem_23652.mem, mem_23665.mem, mem_23668.mem, mem_23675.mem, mem_23678.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                    } else {
                        int64_t blocks_per_segment_24310 = sdiv_up64(num_tblocks_21957, smax64((int64_t) 1, m_20948));
                        int64_t q_24311 = sdiv_up64(num_qubits_15486, segred_tblock_sizze_21956 * blocks_per_segment_24310 * chunk_sizze_24281);
                        int64_t num_virtblocks_24312 = blocks_per_segment_24310 * m_20948;
                        int64_t threads_per_segment_24313 = blocks_per_segment_24310 * segred_tblock_sizze_21956;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-large");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) m_20948, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_qubits_15486, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_24312, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_21957, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_21956, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_24311, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_24310, '\n');
                        if (memblock_alloc_device(ctx, &segred_tmp_mem_24314, num_virtblocks_24312, "segred_tmp_mem_24314")) {
                            err = 1;
                            goto cleanup;
                        }
                        {
                            err = gpu_kernel_simulate_8477zisegred_large_21963(ctx, num_tblocks_21957, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_21877, 1, 1, 8 + (segred_tblock_sizze_21956 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_21956, (int64_t) 8), (int64_t) 8)), num_qubits_15486, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_20948, num_tblocks_21957, blocks_per_segment_24310, q_24311, num_virtblocks_24312, threads_per_segment_24313, mem_23405.mem, mem_23652.mem, mem_23665.mem, mem_23668.mem, mem_23675.mem, mem_23678.mem, segred_tmp_mem_24314.mem, counters_mem_24316.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23668, "mem_23668") != 0)
                        return 1;
                    
                    int64_t segmap_usable_groups_22008 = sdiv_up64(m_20948, segmap_tblock_sizze_22007);
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_24353 = sext_i64_i32(sdiv_up64(m_20948, segmap_tblock_sizze_22007));
                    
                    {
                        err = gpu_kernel_simulate_8477zisegmap_22011(ctx, segmap_usable_groups_22008, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_21856, 1, 1, (int64_t) 0, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_20948, mem_23405.mem, mem_23655.mem, mem_23665.mem, mem_23675.mem, mem_23680.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23675, "mem_23675") != 0)
                        return 1;
                    if (memblock_alloc_device(ctx, &mem_23689, bytes_23688, "mem_23689")) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t replicate_n_24362 = arg_15490 * m_20948;
                    int64_t tblock_sizze_24367;
                    
                    tblock_sizze_24367 = *ctx->tuning_params.simulate_8477zitblock_sizze_24367;
                    
                    int64_t virt_num_tblocks_24368 = sdiv_up64(replicate_n_24362, tblock_sizze_24367);
                    int64_t num_tblocks_24369 = smin64(virt_num_tblocks_24368, (int64_t) 1048576);
                    
                    {
                        err = gpu_kernel_simulate_8477zireplicate_24363(ctx, num_tblocks_24369, 1, 1, tblock_sizze_24367, 1, 1, (int64_t) 0, arg_15490, m_20948, replicate_n_24362, virt_num_tblocks_24368, num_tblocks_24369, mem_23665.mem, mem_23689.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    
                    int64_t replicate_n_24382 = m_20948;
                    int64_t tblock_sizze_24387;
                    
                    tblock_sizze_24387 = *ctx->tuning_params.simulate_8477zitblock_sizze_24387;
                    
                    int64_t virt_num_tblocks_24388 = sdiv_up64(replicate_n_24382, tblock_sizze_24387);
                    int64_t num_tblocks_24389 = smin64(virt_num_tblocks_24388, (int64_t) 1048576);
                    
                    {
                        err = gpu_kernel_simulate_8477zireplicate_24383(ctx, num_tblocks_24389, 1, 1, tblock_sizze_24387, 1, 1, (int64_t) 0, arg_15490, m_20948, replicate_n_24382, virt_num_tblocks_24388, num_tblocks_24389, mem_23665.mem, mem_23689.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23686, m_20948, "mem_23686")) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t replicate_n_24402 = m_20948;
                    int64_t tblock_sizze_24407;
                    
                    tblock_sizze_24407 = *ctx->tuning_params.simulate_8477zitblock_sizze_24407;
                    
                    int64_t virt_num_tblocks_24408 = sdiv_up64(replicate_n_24402, tblock_sizze_24407);
                    int64_t num_tblocks_24409 = smin64(virt_num_tblocks_24408, (int64_t) 1048576);
                    
                    {
                        err = gpu_kernel_simulate_8477zireplicate_24403(ctx, num_tblocks_24409, 1, 1, tblock_sizze_24407, 1, 1, (int64_t) 0, m_20948, replicate_n_24402, virt_num_tblocks_24408, num_tblocks_24409, mem_23680.mem, mem_23686.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (memblock_unref_device(ctx, &mem_23680, "mem_23680") != 0)
                        return 1;
                    
                    int64_t tmp_offs_24422 = (int64_t) 0;
                    
                    if (!(m_20948 * tmp_offs_24422 == (int64_t) 0)) {
                        if ((err = lmad_copy_gpu2gpu_8b(ctx, 2, mem_23689.mem, m_20948 * tmp_offs_24422, (int64_t []) {m_20948, (int64_t) 1}, mem_23689.mem, (int64_t) 0, (int64_t []) {m_20948, (int64_t) 1}, (int64_t []) {arg_15490, m_20948})) != 0)
                            goto cleanup;
                    }
                    tmp_offs_24422 += arg_15490;
                    if (!(m_20948 * tmp_offs_24422 == m_20948 * arg_15490)) {
                        if ((err = lmad_copy_gpu2gpu_8b(ctx, 2, mem_23689.mem, m_20948 * tmp_offs_24422, (int64_t []) {m_20948, (int64_t) 1}, mem_23689.mem, m_20948 * arg_15490, (int64_t []) {m_20948, (int64_t) 1}, (int64_t []) {(int64_t) 1, m_20948})) != 0)
                            goto cleanup;
                    }
                    tmp_offs_24422 += (int64_t) 1;
                    if (memblock_alloc_device(ctx, &mem_23691, dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20972, "mem_23691")) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t tmp_offs_24423 = (int64_t) 0;
                    
                    if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_23691.mem, tmp_offs_24423, (int64_t []) {dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, (int64_t) 1}, mem_23678.mem, (int64_t) 0, (int64_t []) {arg_15490, (int64_t) 1}, (int64_t []) {m_20948, arg_15490})) != 0)
                        goto cleanup;
                    tmp_offs_24423 += arg_15490;
                    if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_23691.mem, tmp_offs_24423, (int64_t []) {dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, (int64_t) 1}, mem_23686.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, m_20948}, (int64_t []) {m_20948, (int64_t) 1})) != 0)
                        goto cleanup;
                    tmp_offs_24423 += (int64_t) 1;
                    if (memblock_unref_device(ctx, &mem_23678, "mem_23678") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &mem_23686, "mem_23686") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23748, &mem_23689, "mem_23689") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23747, &mem_23691, "mem_23691") != 0)
                        return 1;
                }
                if (memblock_unref_device(ctx, &mem_23655, "mem_23655") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23665, "mem_23665") != 0)
                    return 1;
                
                int64_t num_tblocks_22044;
                int64_t max_num_tblocks_24425;
                
                max_num_tblocks_24425 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22043;
                num_tblocks_22044 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20972, segmap_tblock_sizze_22042), max_num_tblocks_24425)));
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24426 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20972, segmap_tblock_sizze_22042));
                
                {
                    err = gpu_kernel_simulate_8477zisegmap_22039(ctx, num_tblocks_22044, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22041, 1, 1, (int64_t) 0, num_qubits_15486, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_20948, dzlz7bUZLztZRz20Udz2084Uz2089Uz20UZLZLzpZRz20UZLZLztZRz20Unz20U2ZRz20U1ZRz7dUzg_20972, num_tblocks_22044, ext_23745, ext_23746, virt_num_tblocks_24426, mem_23405.mem, mem_23651.mem, ext_mem_23747.mem, ext_mem_23748.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23651, "mem_23651") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &ext_mem_23747, "ext_mem_23747") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &ext_mem_23748, "ext_mem_23748") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_23751, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, "mem_23751")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24439 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, segmap_tblock_sizze_22061));
                
                {
                    err = gpu_kernel_simulate_8477zisegmap_22065(ctx, segmap_usable_groups_22062, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22049, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, mem_23405.mem, mem_23652.mem, mem_23751.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24448 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, segmap_tblock_sizze_22076));
                
                {
                    err = gpu_kernel_simulate_8477zisegmap_22073(ctx, num_tblocks_22078, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22075, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, num_tblocks_22078, virt_num_tblocks_24448, mem_23405.mem, mem_23656.mem, mem_23751.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23656, "mem_23656") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23751, "mem_23751") != 0)
                    return 1;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24461 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, segmap_tblock_sizze_22084));
                
                {
                    err = gpu_kernel_simulate_8477zisegmap_22081(ctx, num_tblocks_22086, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22083, 1, 1, (int64_t) 0, num_qubits_15486, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, u64_res_21127, num_tblocks_22086, virt_num_tblocks_24461, mem_23405.mem, mem_23652.mem, mem_23657.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23652, "mem_23652") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23657, "mem_23657") != 0)
                    return 1;
            } else {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24474 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, segmap_tblock_sizze_22092));
                
                {
                    err = gpu_kernel_simulate_8477zisegmap_22089(ctx, num_tblocks_22094, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22091, 1, 1, (int64_t) 0, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, num_tblocks_22094, virt_num_tblocks_24474, mem_23405.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_alloc_device(ctx, &mem_23467, bytes_23466, "mem_23467")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23469, bytes_23466, "mem_23469")) {
                    err = 1;
                    goto cleanup;
                }
                if (slt64((int64_t) 0, num_qubits_15486)) {
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegScan");
                    
                    int64_t shared_memory_24487;
                    
                    shared_memory_24487 = ctx->max_shared_memory;
                    
                    int64_t thread_block_sizze_24488;
                    
                    thread_block_sizze_24488 = ctx->max_thread_block_size;
                    
                    int64_t registers_24489;
                    
                    registers_24489 = ctx->max_registers;
                    
                    int64_t thread_block_sizze_24490;
                    
                    thread_block_sizze_24490 = ctx->max_thread_block_size;
                    
                    int64_t chunk_sizze_24491 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_24487, thread_block_sizze_24488), (int64_t) 8), squot64(squot64(registers_24489, thread_block_sizze_24490) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
                    int64_t num_virt_blocks_24492 = sdiv_up64(num_qubits_15486, segscan_tblock_sizze_22098 * chunk_sizze_24491);
                    int64_t num_virt_threads_24493 = num_virt_blocks_24492 * segscan_tblock_sizze_22098;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_24491, '\n');
                    if (memblock_alloc_device(ctx, &status_flags_mem_24494, num_virt_blocks_24492, "status_flags_mem_24494")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_24494, num_virt_blocks_24492, (int8_t) 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &aggregates_mem_24496, (int64_t) 8 * num_virt_blocks_24492, "aggregates_mem_24496")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &incprefixes_mem_24498, (int64_t) 8 * num_virt_blocks_24492, "incprefixes_mem_24498")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_simulate_8477zisegscan_22103(ctx, num_tblocks_22100, 1, 1, *ctx->tuning_params.simulate_8477zisegscan_tblock_sizze_22097, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22098), chunk_sizze_24491 * segscan_tblock_sizze_22098 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22098), chunk_sizze_24491 * segscan_tblock_sizze_22098 * (int64_t) 8), (int64_t) 8), (int64_t) 8), num_qubits_15486, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, num_tblocks_22100, num_virt_blocks_24492, num_virt_threads_24493, mem_23405.mem, mem_23414.mem, mem_23467.mem, mem_23469.mem, status_flags_mem_24494.mem, aggregates_mem_24496.mem, incprefixes_mem_24498.mem, global_dynid_mem_24500.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                }
                
                int64_t m_f_res_21168;
                
                if (x_20898) {
                    int64_t read_res_25108;
                    
                    if ((err = gpu_scalar_from_device(ctx, &read_res_25108, mem_23467.mem, tmp_20899 * sizeof(int64_t), sizeof(int64_t))) != 0)
                        goto cleanup;
                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t x_21169 = read_res_25108;
                    
                    m_f_res_21168 = x_21169;
                } else {
                    m_f_res_21168 = (int64_t) 0;
                }
                
                int64_t m_21170;
                
                if (cond_20897) {
                    m_21170 = (int64_t) 0;
                } else {
                    m_21170 = m_f_res_21168;
                }
                
                int64_t m_21171 = sub64(m_21170, (int64_t) 1);
                bool i_p_m_t_s_leq_w_21172 = slt64(m_21171, num_qubits_15486);
                bool zzero_leq_i_p_m_t_s_21173 = sle64((int64_t) 0, m_21171);
                bool y_21174 = i_p_m_t_s_leq_w_21172 && zzero_leq_i_p_m_t_s_21173;
                bool i_lte_j_21175 = sle64((int64_t) 0, m_21170);
                bool forwards_ok_21176 = y_21174 && i_lte_j_21175;
                bool eq_x_zz_21177 = (int64_t) 0 == m_f_res_21168;
                bool p_and_eq_x_y_21178 = x_20898 && eq_x_zz_21177;
                bool empty_slice_21179 = cond_20897 || p_and_eq_x_y_21178;
                bool ok_or_empty_21180 = forwards_ok_21176 || empty_slice_21179;
                bool index_certs_21181;
                
                if (!ok_or_empty_21180) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_21170, "] out of bounds for array of shape [", (long long) num_qubits_15486, "].", "-> #0  /prelude/soacs.fut:258:29-35\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                
                int64_t bytes_23470 = (int64_t) 8 * m_21170;
                bool range_valid_c_21314;
                
                if (!valid_20891) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) arg_15490, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  definitions.fut:162:47-58\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                
                int64_t conc_tmp_21320 = num_qubits_15486 + num_qubits_15486;
                int64_t conc_tmp_21322 = (int64_t) 1 + conc_tmp_21320;
                bool dim_match_21323 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491 == conc_tmp_21322;
                bool empty_or_match_cert_21324;
                
                if (!dim_match_21323) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Value of (desugared) shape [", (long long) conc_tmp_21322, "] cannot match shape of type `[", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, "]i8`.", "-> #0  definitions.fut:163:22-76\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23471, bytes_23470, "mem_23471")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhiota_i64(ctx, mem_23471, m_21170, (int64_t) 0, (int64_t) 1) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24589 = sext_i64_i32(sdiv_up64(num_qubits_15486, segmap_tblock_sizze_22108));
                
                {
                    err = gpu_kernel_simulate_8477zisegmap_22105(ctx, num_tblocks_22110, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22107, 1, 1, (int64_t) 0, num_qubits_15486, m_21170, num_tblocks_22110, virt_num_tblocks_24589, mem_23467.mem, mem_23469.mem, mem_23471.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23467, "mem_23467") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23469, "mem_23469") != 0)
                    return 1;
                
                bool suff_outer_screma_22113;
                
                suff_outer_screma_22113 = *ctx->tuning_params.simulate_8477zisuff_outer_screma_1 <= m_21170;
                if (ctx->logging)
                    fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "simulate_8477.suff_outer_screma_1", (long) m_21170, suff_outer_screma_22113 ? "true" : "false");
                
                bool suff_outer_par_22516;
                
                suff_outer_par_22516 = *ctx->tuning_params.simulate_8477zisuff_outer_par_2 <= m_21170;
                if (ctx->logging)
                    fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "simulate_8477.suff_outer_par_2", (long) m_21170, suff_outer_par_22516 ? "true" : "false");
                
                int64_t nest_sizze_22599 = num_qubits_15486 * m_21170;
                int64_t num_tblocks_22601;
                int64_t max_num_tblocks_24602;
                
                max_num_tblocks_24602 = *ctx->tuning_params.simulate_8477zisegred_num_tblocks_22359;
                num_tblocks_22601 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_22599, segred_tblock_sizze_22600), max_num_tblocks_24602)));
                
                int64_t num_tblocks_22522;
                int64_t max_num_tblocks_24603;
                
                max_num_tblocks_24603 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22206;
                num_tblocks_22522 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_21170, segmap_tblock_sizze_22521), max_num_tblocks_24603)));
                
                int64_t num_tblocks_22671;
                int64_t max_num_tblocks_24604;
                
                max_num_tblocks_24604 = *ctx->tuning_params.simulate_8477zisegred_num_tblocks_22508;
                num_tblocks_22671 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_21170, segred_tblock_sizze_22670), max_num_tblocks_24604)));
                
                int64_t num_tblocks_22128;
                int64_t max_num_tblocks_24605;
                
                max_num_tblocks_24605 = *ctx->tuning_params.simulate_8477zisegred_num_tblocks_22117;
                num_tblocks_22128 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_21170, segred_tblock_sizze_22127), max_num_tblocks_24605)));
                
                bool suff_outer_par_22686;
                
                suff_outer_par_22686 = *ctx->tuning_params.simulate_8477zisuff_outer_par_3 <= num_qubits_15486;
                if (ctx->logging)
                    fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "simulate_8477.suff_outer_par_3", (long) num_qubits_15486, suff_outer_par_22686 ? "true" : "false");
                
                int64_t segred_tblock_sizze_22733;
                
                segred_tblock_sizze_22733 = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22716;
                
                int64_t num_tblocks_22734;
                int64_t max_num_tblocks_24606;
                
                max_num_tblocks_24606 = *ctx->tuning_params.simulate_8477zisegred_num_tblocks_22718;
                num_tblocks_22734 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_22599, segred_tblock_sizze_22733), max_num_tblocks_24606)));
                
                int64_t segmap_tblock_sizze_22702;
                
                segmap_tblock_sizze_22702 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22690;
                
                bool suff_outer_par_22747;
                
                suff_outer_par_22747 = *ctx->tuning_params.simulate_8477zisuff_outer_par_4 <= num_qubits_15486;
                if (ctx->logging)
                    fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "simulate_8477.suff_outer_par_4", (long) num_qubits_15486, suff_outer_par_22747 ? "true" : "false");
                
                int64_t segred_tblock_sizze_22794;
                
                segred_tblock_sizze_22794 = *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22777;
                
                int64_t num_tblocks_22795;
                int64_t max_num_tblocks_24607;
                
                max_num_tblocks_24607 = *ctx->tuning_params.simulate_8477zisegred_num_tblocks_22779;
                num_tblocks_22795 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_22599, segred_tblock_sizze_22794), max_num_tblocks_24607)));
                
                int64_t segmap_tblock_sizze_22763;
                
                segmap_tblock_sizze_22763 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22751;
                
                int64_t segmap_tblock_sizze_22811;
                
                segmap_tblock_sizze_22811 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22810;
                
                int64_t num_tblocks_22813;
                int64_t max_num_tblocks_24608;
                
                max_num_tblocks_24608 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22812;
                num_tblocks_22813 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, segmap_tblock_sizze_22811), max_num_tblocks_24608)));
                if (memblock_alloc_device(ctx, &mem_23473, (int64_t) 1, "mem_23473")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_simulate_8477zigpuseq_24609(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, mem_23405.mem, mem_23473.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                
                int64_t ext_23537;
                int64_t shared_memory_capacity_24615;
                
                shared_memory_capacity_24615 = ctx->max_shared_memory;
                if (suff_outer_par_22516) {
                    ext_23537 = (int64_t) 1;
                } else {
                    ext_23537 = num_qubits_15486;
                }
                
                int64_t ext_23536;
                int64_t shared_memory_capacity_24616;
                
                shared_memory_capacity_24616 = ctx->max_shared_memory;
                if (suff_outer_par_22516) {
                    ext_23536 = m_21170;
                } else {
                    ext_23536 = (int64_t) 1;
                }
                
                int64_t binop_x_23515 = smax64((int64_t) 0, m_21171);
                int64_t binop_y_23518 = m_21170 * binop_x_23517;
                int64_t binop_y_23519 = smax64((int64_t) 0, binop_y_23518);
                int64_t binop_y_23520 = binop_x_23515 + binop_y_23519;
                int64_t bytes_23521 = (int64_t) 1 + binop_y_23520;
                int64_t ext_23602;
                int64_t shared_memory_capacity_24617;
                
                shared_memory_capacity_24617 = ctx->max_shared_memory;
                if (suff_outer_screma_22113) {
                    ext_23602 = (int64_t) 1;
                } else {
                    ext_23602 = ext_23537;
                }
                
                int64_t ext_23601;
                int64_t shared_memory_capacity_24618;
                
                shared_memory_capacity_24618 = ctx->max_shared_memory;
                if (suff_outer_screma_22113) {
                    ext_23601 = m_21170;
                } else {
                    ext_23601 = ext_23536;
                }
                
                int64_t num_threads_23870 = segred_tblock_sizze_22127 * num_tblocks_22128;
                int64_t total_sizze_23871 = num_qubits_15486 * num_threads_23870;
                int64_t total_sizze_23872 = num_qubits_15486 * num_threads_23870;
                int64_t shared_memory_capacity_24809;
                
                shared_memory_capacity_24809 = ctx->max_shared_memory;
                if (suff_outer_screma_22113 && (sle64(sdiv_up64(segred_tblock_sizze_22127, (int64_t) 8) * (int64_t) 8 + (int64_t) 8, shared_memory_capacity_24809) && sle64((int64_t) 0, shared_memory_capacity_24809))) {
                    if (memblock_alloc_device(ctx, &mem_23552, bytes_23495, "mem_23552")) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_23552.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491}, mem_23405.mem, (int64_t) 0, (int64_t []) {dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, (int64_t) 1}, (int64_t []) {dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491})) != 0)
                        goto cleanup;
                    if (memblock_alloc_device(ctx, &mem_23568, (int64_t) 1, "mem_23568")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23582, bytes_23521, "mem_23582")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23596, bytes_23521, "mem_23596")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &color_23822, total_sizze_23871, "color_23822")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &color_23823, total_sizze_23872, "color_23823")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_24619 = (int64_t) 1;
                    
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_24622, num_tblocks_22128, "segred_tmp_mem_24622")) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t num_threads_24624 = num_tblocks_22128 * segred_tblock_sizze_22127;
                    
                    {
                        err = gpu_kernel_simulate_8477zisegred_nonseg_22135(ctx, num_tblocks_22128, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22115, 1, 1, 8 + (segred_tblock_sizze_22127 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22127, (int64_t) 8), (int64_t) 8)), num_qubits_15486, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_21170, num_tblocks_22128, num_threads_23870, num_threads_24624, mem_23405.mem, mem_23471.mem, mem_23473.mem, mem_23552.mem, mem_23568.mem, mem_23582.mem, mem_23596.mem, color_23822.mem, color_23823.mem, counters_mem_24620.mem, segred_tmp_mem_24622.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23552, "mem_23552") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &color_23822, "color_23822") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &color_23823, "color_23823") != 0)
                        return 1;
                    {
                        err = gpu_kernel_simulate_8477zigpuseq_24656(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, measurement_count_21335, mem_23406.mem, mem_23568.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (memblock_unref_device(ctx, &mem_23568, "mem_23568") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23603, &mem_23582, "mem_23582") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23600, &mem_23596, "mem_23596") != 0)
                        return 1;
                } else {
                    int64_t shared_memory_capacity_24768;
                    
                    shared_memory_capacity_24768 = ctx->max_shared_memory;
                    if (suff_outer_par_22516 && sle64((int64_t) 0, shared_memory_capacity_24768)) {
                        if (memblock_alloc_device(ctx, &mem_23496, bytes_23495, "mem_23496")) {
                            err = 1;
                            goto cleanup;
                        }
                        if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_23496.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491}, mem_23405.mem, (int64_t) 0, (int64_t []) {dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, (int64_t) 1}, (int64_t []) {dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491})) != 0)
                            goto cleanup;
                        if (memblock_alloc_device(ctx, &mem_23512, m_21170, "mem_23512")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23522, bytes_23521, "mem_23522")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23532, bytes_23521, "mem_23532")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t virt_num_tblocks_24662 = sext_i64_i32(sdiv_up64(m_21170, segmap_tblock_sizze_22521));
                        
                        {
                            err = gpu_kernel_simulate_8477zisegmap_22528(ctx, num_tblocks_22522, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22204, 1, 1, (int64_t) 0, num_qubits_15486, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_21170, num_tblocks_22522, virt_num_tblocks_24662, mem_23405.mem, mem_23471.mem, mem_23473.mem, mem_23496.mem, mem_23512.mem, mem_23522.mem, mem_23532.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_unref_device(ctx, &mem_23496, "mem_23496") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_23539, &mem_23512, "mem_23512") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_23538, &mem_23522, "mem_23522") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_23535, &mem_23532, "mem_23532") != 0)
                            return 1;
                    } else {
                        int64_t segmap_usable_groups_22586 = sdiv_up64(m_21170, segmap_tblock_sizze_22585);
                        
                        if (memblock_alloc_device(ctx, &mem_23475, (int64_t) 0, "mem_23475")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23477, bytes_23470, "mem_23477")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23486, m_21170, "mem_23486")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t virt_num_tblocks_24678 = sext_i64_i32(sdiv_up64(m_21170, segmap_tblock_sizze_22585));
                        
                        {
                            err = gpu_kernel_simulate_8477zisegmap_22591(ctx, segmap_usable_groups_22586, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22409, 1, 1, (int64_t) 0, num_qubits_15486, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_21170, mem_23471.mem, mem_23475.mem, mem_23477.mem, mem_23486.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_alloc_device(ctx, &mem_23480, m_21170, "mem_23480")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23482, nest_sizze_22599, "mem_23482")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23484, nest_sizze_22599, "mem_23484")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegRed");
                        
                        int64_t chunk_sizze_24687 = (int64_t) 1;
                        
                        if (slt64(num_qubits_15486 * (int64_t) 2, segred_tblock_sizze_22600 * chunk_sizze_24687)) {
                            int64_t segment_sizze_nonzzero_24688 = smax64((int64_t) 1, num_qubits_15486);
                            int64_t num_threads_24689 = segred_tblock_sizze_22600 * segred_tblock_sizze_22600;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-small");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) m_21170, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_qubits_15486, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_22600, segment_sizze_nonzzero_24688), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(m_21170, squot64(segred_tblock_sizze_22600, segment_sizze_nonzzero_24688))), '\n');
                            {
                                err = gpu_kernel_simulate_8477zisegred_small_22608(ctx, num_tblocks_22601, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22357, 1, 1, segred_tblock_sizze_22600 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22600, (int64_t) 8), (int64_t) 8), num_qubits_15486, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_21170, num_tblocks_22601, segment_sizze_nonzzero_24688, mem_23405.mem, mem_23475.mem, mem_23477.mem, mem_23480.mem, mem_23482.mem, mem_23484.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                            ctx->failure_is_an_option = 1;
                        } else {
                            int64_t blocks_per_segment_24716 = sdiv_up64(num_tblocks_22601, smax64((int64_t) 1, m_21170));
                            int64_t q_24717 = sdiv_up64(num_qubits_15486, segred_tblock_sizze_22600 * blocks_per_segment_24716 * chunk_sizze_24687);
                            int64_t num_virtblocks_24718 = blocks_per_segment_24716 * m_21170;
                            int64_t threads_per_segment_24719 = blocks_per_segment_24716 * segred_tblock_sizze_22600;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-large");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) m_21170, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_qubits_15486, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_24718, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_22601, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_22600, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_24717, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_24716, '\n');
                            if (memblock_alloc_device(ctx, &segred_tmp_mem_24720, num_virtblocks_24718, "segred_tmp_mem_24720")) {
                                err = 1;
                                goto cleanup;
                            }
                            {
                                err = gpu_kernel_simulate_8477zisegred_large_22608(ctx, num_tblocks_22601, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22357, 1, 1, 8 + (segred_tblock_sizze_22600 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22600, (int64_t) 8), (int64_t) 8)), num_qubits_15486, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_21170, num_tblocks_22601, blocks_per_segment_24716, q_24717, num_virtblocks_24718, threads_per_segment_24719, mem_23405.mem, mem_23475.mem, mem_23477.mem, mem_23480.mem, mem_23482.mem, mem_23484.mem, segred_tmp_mem_24720.mem, counters_mem_24722.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                            ctx->failure_is_an_option = 1;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_unref_device(ctx, &mem_23475, "mem_23475") != 0)
                            return 1;
                        
                        int64_t segmap_usable_groups_22650 = sdiv_up64(m_21170, segmap_tblock_sizze_22649);
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t virt_num_tblocks_24759 = sext_i64_i32(sdiv_up64(m_21170, segmap_tblock_sizze_22649));
                        
                        {
                            err = gpu_kernel_simulate_8477zisegmap_22653(ctx, segmap_usable_groups_22650, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22336, 1, 1, (int64_t) 0, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, m_21170, mem_23405.mem, mem_23473.mem, mem_23477.mem, mem_23480.mem, mem_23486.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_unref_device(ctx, &mem_23477, "mem_23477") != 0)
                            return 1;
                        if (memblock_unref_device(ctx, &mem_23480, "mem_23480") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_23539, &mem_23486, "mem_23486") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_23538, &mem_23484, "mem_23484") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_23535, &mem_23482, "mem_23482") != 0)
                            return 1;
                    }
                    if (memblock_alloc_device(ctx, &mem_23541, (int64_t) 1, "mem_23541")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_24769 = (int64_t) 1;
                    
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_24772, num_tblocks_22671, "segred_tmp_mem_24772")) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t num_threads_24774 = num_tblocks_22671 * segred_tblock_sizze_22670;
                    
                    {
                        err = gpu_kernel_simulate_8477zisegred_nonseg_22676(ctx, num_tblocks_22671, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22506, 1, 1, 8 + (segred_tblock_sizze_22670 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22670, (int64_t) 8), (int64_t) 8)), m_21170, num_tblocks_22671, num_threads_24774, ext_mem_23539.mem, mem_23541.mem, counters_mem_24770.mem, segred_tmp_mem_24772.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &ext_mem_23539, "ext_mem_23539") != 0)
                        return 1;
                    {
                        err = gpu_kernel_simulate_8477zigpuseq_24803(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, measurement_count_21335, mem_23406.mem, mem_23541.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (memblock_unref_device(ctx, &mem_23541, "mem_23541") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23603, &ext_mem_23538, "ext_mem_23538") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23600, &ext_mem_23535, "ext_mem_23535") != 0)
                        return 1;
                }
                if (memblock_unref_device(ctx, &mem_23471, "mem_23471") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23473, "mem_23473") != 0)
                    return 1;
                
                int64_t shared_memory_capacity_24892;
                
                shared_memory_capacity_24892 = ctx->max_shared_memory;
                if (suff_outer_par_22686 && sle64((int64_t) 0, shared_memory_capacity_24892)) {
                    int64_t segmap_usable_groups_22703 = sdiv_up64(num_qubits_15486, segmap_tblock_sizze_22702);
                    
                    if (memblock_alloc_device(ctx, &mem_23618, num_qubits_15486, "mem_23618")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_24810 = sext_i64_i32(sdiv_up64(num_qubits_15486, segmap_tblock_sizze_22702));
                    
                    {
                        err = gpu_kernel_simulate_8477zisegmap_22706(ctx, segmap_usable_groups_22703, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22690, 1, 1, (int64_t) 0, num_qubits_15486, m_21170, ext_23601, ext_23602, ext_mem_23603.mem, mem_23618.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_23619, &mem_23618, "mem_23618") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &mem_23614, bytes_23521, "mem_23614")) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_23614.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, m_21170}, ext_mem_23603.mem, (int64_t) 0, (int64_t []) {ext_23602, ext_23601}, (int64_t []) {m_21170, num_qubits_15486})) != 0)
                        goto cleanup;
                    if (memblock_alloc_device(ctx, &mem_23616, num_qubits_15486, "mem_23616")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_24820 = (int64_t) 1;
                    
                    if (slt64(m_21170 * (int64_t) 2, segred_tblock_sizze_22733 * chunk_sizze_24820)) {
                        int64_t segment_sizze_nonzzero_24821 = smax64((int64_t) 1, m_21170);
                        int64_t num_threads_24822 = segred_tblock_sizze_22733 * segred_tblock_sizze_22733;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-small");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) num_qubits_15486, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) m_21170, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_22733, segment_sizze_nonzzero_24821), '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(num_qubits_15486, squot64(segred_tblock_sizze_22733, segment_sizze_nonzzero_24821))), '\n');
                        {
                            err = gpu_kernel_simulate_8477zisegred_small_22739(ctx, num_tblocks_22734, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22716, 1, 1, segred_tblock_sizze_22733 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22733, (int64_t) 8), (int64_t) 8), num_qubits_15486, m_21170, num_tblocks_22734, segment_sizze_nonzzero_24821, mem_23614.mem, mem_23616.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                    } else {
                        int64_t blocks_per_segment_24849 = sdiv_up64(num_tblocks_22734, smax64((int64_t) 1, num_qubits_15486));
                        int64_t q_24850 = sdiv_up64(m_21170, segred_tblock_sizze_22733 * blocks_per_segment_24849 * chunk_sizze_24820);
                        int64_t num_virtblocks_24851 = blocks_per_segment_24849 * num_qubits_15486;
                        int64_t threads_per_segment_24852 = blocks_per_segment_24849 * segred_tblock_sizze_22733;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-large");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) num_qubits_15486, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) m_21170, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_24851, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_22734, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_22733, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_24850, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_24849, '\n');
                        if (memblock_alloc_device(ctx, &segred_tmp_mem_24853, num_virtblocks_24851, "segred_tmp_mem_24853")) {
                            err = 1;
                            goto cleanup;
                        }
                        {
                            err = gpu_kernel_simulate_8477zisegred_large_22739(ctx, num_tblocks_22734, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22716, 1, 1, 8 + (segred_tblock_sizze_22733 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22733, (int64_t) 8), (int64_t) 8)), num_qubits_15486, m_21170, num_tblocks_22734, blocks_per_segment_24849, q_24850, num_virtblocks_24851, threads_per_segment_24852, mem_23614.mem, mem_23616.mem, segred_tmp_mem_24853.mem, counters_mem_24855.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23614, "mem_23614") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23619, &mem_23616, "mem_23616") != 0)
                        return 1;
                }
                if (memblock_unref_device(ctx, &ext_mem_23603, "ext_mem_23603") != 0)
                    return 1;
                
                int64_t shared_memory_capacity_24975;
                
                shared_memory_capacity_24975 = ctx->max_shared_memory;
                if (suff_outer_par_22747 && sle64((int64_t) 0, shared_memory_capacity_24975)) {
                    int64_t segmap_usable_groups_22764 = sdiv_up64(num_qubits_15486, segmap_tblock_sizze_22763);
                    
                    if (memblock_alloc_device(ctx, &mem_23633, num_qubits_15486, "mem_23633")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_24893 = sext_i64_i32(sdiv_up64(num_qubits_15486, segmap_tblock_sizze_22763));
                    
                    {
                        err = gpu_kernel_simulate_8477zisegmap_22767(ctx, segmap_usable_groups_22764, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22751, 1, 1, (int64_t) 0, num_qubits_15486, m_21170, ext_23601, ext_23602, ext_mem_23600.mem, mem_23633.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_23634, &mem_23633, "mem_23633") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &mem_23629, bytes_23521, "mem_23629")) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_23629.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, m_21170}, ext_mem_23600.mem, (int64_t) 0, (int64_t []) {ext_23602, ext_23601}, (int64_t []) {m_21170, num_qubits_15486})) != 0)
                        goto cleanup;
                    if (memblock_alloc_device(ctx, &mem_23631, num_qubits_15486, "mem_23631")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_24903 = (int64_t) 1;
                    
                    if (slt64(m_21170 * (int64_t) 2, segred_tblock_sizze_22794 * chunk_sizze_24903)) {
                        int64_t segment_sizze_nonzzero_24904 = smax64((int64_t) 1, m_21170);
                        int64_t num_threads_24905 = segred_tblock_sizze_22794 * segred_tblock_sizze_22794;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-small");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) num_qubits_15486, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) m_21170, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_22794, segment_sizze_nonzzero_24904), '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(num_qubits_15486, squot64(segred_tblock_sizze_22794, segment_sizze_nonzzero_24904))), '\n');
                        {
                            err = gpu_kernel_simulate_8477zisegred_small_22800(ctx, num_tblocks_22795, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22777, 1, 1, segred_tblock_sizze_22794 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22794, (int64_t) 8), (int64_t) 8), num_qubits_15486, m_21170, num_tblocks_22795, segment_sizze_nonzzero_24904, mem_23629.mem, mem_23631.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                    } else {
                        int64_t blocks_per_segment_24932 = sdiv_up64(num_tblocks_22795, smax64((int64_t) 1, num_qubits_15486));
                        int64_t q_24933 = sdiv_up64(m_21170, segred_tblock_sizze_22794 * blocks_per_segment_24932 * chunk_sizze_24903);
                        int64_t num_virtblocks_24934 = blocks_per_segment_24932 * num_qubits_15486;
                        int64_t threads_per_segment_24935 = blocks_per_segment_24932 * segred_tblock_sizze_22794;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-large");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) num_qubits_15486, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) m_21170, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_24934, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_22795, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_22794, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_24933, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_24932, '\n');
                        if (memblock_alloc_device(ctx, &segred_tmp_mem_24936, num_virtblocks_24934, "segred_tmp_mem_24936")) {
                            err = 1;
                            goto cleanup;
                        }
                        {
                            err = gpu_kernel_simulate_8477zisegred_large_22800(ctx, num_tblocks_22795, 1, 1, *ctx->tuning_params.simulate_8477zisegred_tblock_sizze_22777, 1, 1, 8 + (segred_tblock_sizze_22794 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_22794, (int64_t) 8), (int64_t) 8)), num_qubits_15486, m_21170, num_tblocks_22795, blocks_per_segment_24932, q_24933, num_virtblocks_24934, threads_per_segment_24935, mem_23629.mem, mem_23631.mem, segred_tmp_mem_24936.mem, counters_mem_24938.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23629, "mem_23629") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_23634, &mem_23631, "mem_23631") != 0)
                        return 1;
                }
                if (memblock_unref_device(ctx, &ext_mem_23600, "ext_mem_23600") != 0)
                    return 1;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24976 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, segmap_tblock_sizze_22811));
                
                {
                    err = gpu_kernel_simulate_8477zisegmap_22808(ctx, num_tblocks_22813, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22810, 1, 1, (int64_t) 0, num_qubits_15486, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, conc_tmp_21320, measurement_count_21335, num_tblocks_22813, virt_num_tblocks_24976, mem_23405.mem, mem_23406.mem, ext_mem_23619.mem, ext_mem_23634.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &ext_mem_23619, "ext_mem_23619") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &ext_mem_23634, "ext_mem_23634") != 0)
                    return 1;
            }
            if (memblock_unref_device(ctx, &mem_23461, "mem_23461") != 0)
                return 1;
            loopres_15556 = tmp_21334;
            loopres_15557 = Measurement_res_20914;
            loopres_15559 = tmp_21341;
        } else {
            bool cond_15577 = loopres_15548 == (int64_t) 1;
            int64_t dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255 = mul64((int64_t) 6, num_qubits_15486);
            int64_t loopres_f_res_15579;
            
            if (cond_15577) {
                bool bounds_invalid_upwards_21349 = slt64(arg_15490, (int64_t) 0);
                bool valid_21350 = !bounds_invalid_upwards_21349;
                bool range_valid_c_21351;
                
                if (!valid_21350) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) arg_15490, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  definitions.fut:64:61-69\n   #2  main.fut:7:78-19:39\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                
                bool y_21363 = slt64(arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);
                bool index_certs_21364;
                
                if (!y_21363) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) arg_15490, "] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, "].", "-> #0  definitions.fut:67:21-35\n   #1  definitions.fut:72:10-18\n   #2  main.fut:7:78-19:39\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                
                int64_t segmap_tblock_sizze_22842;
                
                segmap_tblock_sizze_22842 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22818;
                
                int64_t num_tblocks_22843;
                int64_t max_num_tblocks_24989;
                
                max_num_tblocks_24989 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22820;
                num_tblocks_22843 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_15490, segmap_tblock_sizze_22842), max_num_tblocks_24989)));
                
                int64_t segmap_tblock_sizze_22863;
                
                segmap_tblock_sizze_22863 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22862;
                
                int64_t num_tblocks_22865;
                int64_t max_num_tblocks_24990;
                
                max_num_tblocks_24990 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22864;
                num_tblocks_22865 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255, segmap_tblock_sizze_22863), max_num_tblocks_24990)));
                
                int64_t tmp_21399 = add64((int64_t) 1, i_15540);
                
                if (memblock_alloc_device(ctx, &mem_23445, (int64_t) 24, "mem_23445")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23446, (int64_t) 8, "mem_23446")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23447, (int64_t) 24, "mem_23447")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23448, (int64_t) 0, "mem_23448")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_23449, (int64_t) 0, "mem_23449")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_simulate_8477zigpuseq_24991(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, num_qubits_15486, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, mem_23414.mem, mem_23445.mem, mem_23446.mem, mem_23447.mem, mem_23448.mem, mem_23449.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
                if (memblock_unref_device(ctx, &mem_23445, "mem_23445") != 0)
                    return 1;
                
                bool index_certs_21358 = 0;
                
                if (memblock_unref_device(ctx, &mem_23448, "mem_23448") != 0)
                    return 1;
                
                bool index_certs_21362 = 0;
                
                if (memblock_unref_device(ctx, &mem_23449, "mem_23449") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_23456, dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255, "mem_23456")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_24997 = sext_i64_i32(sdiv_up64(arg_15490, segmap_tblock_sizze_22842));
                
                {
                    err = gpu_kernel_simulate_8477zisegmap_22847(ctx, num_tblocks_22843, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22818, 1, 1, (int64_t) 0, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, num_tblocks_22843, virt_num_tblocks_24997, mem_23405.mem, mem_23414.mem, mem_23446.mem, mem_23456.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23446, "mem_23446") != 0)
                    return 1;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_25010 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255, segmap_tblock_sizze_22863));
                
                {
                    err = gpu_kernel_simulate_8477zisegmap_22860(ctx, num_tblocks_22865, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22862, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255, num_tblocks_22865, virt_num_tblocks_25010, mem_23405.mem, mem_23447.mem, mem_23456.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_23447, "mem_23447") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_23456, "mem_23456") != 0)
                    return 1;
                loopres_f_res_15579 = tmp_21399;
            } else {
                bool cond_15587 = loopres_15548 == (int64_t) 2;
                int64_t dzlz7bUZLztZRz20Utmpz20U2z7dUzg_16359 = mul64((int64_t) 4, num_qubits_15486);
                int64_t loopres_f_res_f_res_15589;
                
                if (cond_15587) {
                    bool bounds_invalid_upwards_21407 = slt64(arg_15490, (int64_t) 0);
                    bool valid_21408 = !bounds_invalid_upwards_21407;
                    bool range_valid_c_21409;
                    
                    if (!valid_21408) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) arg_15490, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  definitions.fut:78:53-61\n   #2  main.fut:7:78-21:36\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    bool y_21421 = slt64(arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);
                    bool index_certs_21422;
                    
                    if (!y_21421) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) arg_15490, "] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, "].", "-> #0  definitions.fut:81:21-35\n   #1  definitions.fut:85:10-18\n   #2  main.fut:7:78-21:36\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    int64_t segmap_tblock_sizze_22895;
                    
                    segmap_tblock_sizze_22895 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22870;
                    
                    int64_t num_tblocks_22896;
                    int64_t max_num_tblocks_25023;
                    
                    max_num_tblocks_25023 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22872;
                    num_tblocks_22896 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_15490, segmap_tblock_sizze_22895), max_num_tblocks_25023)));
                    
                    int64_t segmap_tblock_sizze_22917;
                    
                    segmap_tblock_sizze_22917 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22916;
                    
                    int64_t num_tblocks_22919;
                    int64_t max_num_tblocks_25024;
                    
                    max_num_tblocks_25024 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22918;
                    num_tblocks_22919 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20Utmpz20U2z7dUzg_16359, segmap_tblock_sizze_22917), max_num_tblocks_25024)));
                    
                    int64_t tmp_21461 = add64((int64_t) 1, i_15540);
                    
                    if (memblock_alloc_device(ctx, &mem_23432, (int64_t) 16, "mem_23432")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23433, (int64_t) 8, "mem_23433")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23434, (int64_t) 16, "mem_23434")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23435, (int64_t) 0, "mem_23435")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_23436, (int64_t) 0, "mem_23436")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_simulate_8477zigpuseq_25025(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, num_qubits_15486, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, mem_23414.mem, mem_23432.mem, mem_23433.mem, mem_23434.mem, mem_23435.mem, mem_23436.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (memblock_unref_device(ctx, &mem_23432, "mem_23432") != 0)
                        return 1;
                    
                    bool index_certs_21416 = 0;
                    
                    if (memblock_unref_device(ctx, &mem_23435, "mem_23435") != 0)
                        return 1;
                    
                    bool index_certs_21420 = 0;
                    
                    if (memblock_unref_device(ctx, &mem_23436, "mem_23436") != 0)
                        return 1;
                    if (memblock_alloc_device(ctx, &mem_23443, dzlz7bUZLztZRz20Utmpz20U2z7dUzg_16359, "mem_23443")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_25031 = sext_i64_i32(sdiv_up64(arg_15490, segmap_tblock_sizze_22895));
                    
                    {
                        err = gpu_kernel_simulate_8477zisegmap_22900(ctx, num_tblocks_22896, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22870, 1, 1, (int64_t) 0, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, num_tblocks_22896, virt_num_tblocks_25031, mem_23405.mem, mem_23414.mem, mem_23433.mem, mem_23443.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23433, "mem_23433") != 0)
                        return 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_25044 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Utmpz20U2z7dUzg_16359, segmap_tblock_sizze_22917));
                    
                    {
                        err = gpu_kernel_simulate_8477zisegmap_22914(ctx, num_tblocks_22919, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22916, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, dzlz7bUZLztZRz20Utmpz20U2z7dUzg_16359, num_tblocks_22919, virt_num_tblocks_25044, mem_23405.mem, mem_23434.mem, mem_23443.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_23434, "mem_23434") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &mem_23443, "mem_23443") != 0)
                        return 1;
                    loopres_f_res_f_res_15589 = tmp_21461;
                } else {
                    bool cond_15597 = loopres_15548 == (int64_t) 3;
                    int64_t loopres_f_res_f_res_f_res_15599;
                    
                    if (cond_15597) {
                        bool bounds_invalid_upwards_21469 = slt64(arg_15490, (int64_t) 0);
                        bool valid_21470 = !bounds_invalid_upwards_21469;
                        bool range_valid_c_21471;
                        
                        if (!valid_21470) {
                            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) arg_15490, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  definitions.fut:48:10-18\n   #2  main.fut:7:78-23:42\n"));
                            err = FUTHARK_PROGRAM_ERROR;
                            goto cleanup;
                        }
                        
                        bool y_21475 = slt64(arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491);
                        bool index_certs_21476;
                        
                        if (!y_21475) {
                            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) arg_15490, "] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, "].", "-> #0  definitions.fut:56:21-35\n   #1  definitions.fut:58:10-18\n   #2  main.fut:7:78-23:42\n"));
                            err = FUTHARK_PROGRAM_ERROR;
                            goto cleanup;
                        }
                        
                        int64_t segmap_tblock_sizze_22955;
                        
                        segmap_tblock_sizze_22955 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22924;
                        
                        int64_t num_tblocks_22956;
                        int64_t max_num_tblocks_25057;
                        
                        max_num_tblocks_25057 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22926;
                        num_tblocks_22956 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_15490, segmap_tblock_sizze_22955), max_num_tblocks_25057)));
                        
                        int64_t segmap_tblock_sizze_22983;
                        
                        segmap_tblock_sizze_22983 = *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22982;
                        
                        int64_t num_tblocks_22985;
                        int64_t max_num_tblocks_25058;
                        
                        max_num_tblocks_25058 = *ctx->tuning_params.simulate_8477zisegmap_num_tblocks_22984;
                        num_tblocks_22985 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255, segmap_tblock_sizze_22983), max_num_tblocks_25058)));
                        
                        int64_t tmp_21541 = add64((int64_t) 1, i_15540);
                        
                        if (memblock_alloc_device(ctx, &mem_23415, (int64_t) 24, "mem_23415")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23416, (int64_t) 8, "mem_23416")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23417, (int64_t) 8, "mem_23417")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23418, (int64_t) 24, "mem_23418")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23419, (int64_t) 0, "mem_23419")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23420, (int64_t) 0, "mem_23420")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23421, (int64_t) 8, "mem_23421")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23422, (int64_t) 0, "mem_23422")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_23423, (int64_t) 0, "mem_23423")) {
                            err = 1;
                            goto cleanup;
                        }
                        {
                            err = gpu_kernel_simulate_8477zigpuseq_25059(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, num_qubits_15486, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, i_15540, tQ_mem_23400.mem, mem_23414.mem, mem_23415.mem, mem_23416.mem, mem_23417.mem, mem_23418.mem, mem_23419.mem, mem_23420.mem, mem_23421.mem, mem_23422.mem, mem_23423.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                        if (memblock_unref_device(ctx, &mem_23415, "mem_23415") != 0)
                            return 1;
                        
                        bool index_certs_21480 = 0;
                        
                        if (memblock_unref_device(ctx, &mem_23419, "mem_23419") != 0)
                            return 1;
                        
                        bool index_certs_21484 = 0;
                        
                        if (memblock_unref_device(ctx, &mem_23420, "mem_23420") != 0)
                            return 1;
                        
                        bool index_certs_21489 = 0;
                        
                        if (memblock_unref_device(ctx, &mem_23422, "mem_23422") != 0)
                            return 1;
                        
                        bool index_certs_21493 = 0;
                        
                        if (memblock_unref_device(ctx, &mem_23423, "mem_23423") != 0)
                            return 1;
                        if (memblock_alloc_device(ctx, &mem_23430, dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255, "mem_23430")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t virt_num_tblocks_25065 = sext_i64_i32(sdiv_up64(arg_15490, segmap_tblock_sizze_22955));
                        
                        {
                            err = gpu_kernel_simulate_8477zisegmap_22960(ctx, num_tblocks_22956, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22924, 1, 1, (int64_t) 0, arg_15490, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, num_tblocks_22956, virt_num_tblocks_25065, mem_23405.mem, mem_23414.mem, mem_23416.mem, mem_23417.mem, mem_23421.mem, mem_23430.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        ctx->failure_is_an_option = 1;
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_unref_device(ctx, &mem_23416, "mem_23416") != 0)
                            return 1;
                        if (memblock_unref_device(ctx, &mem_23417, "mem_23417") != 0)
                            return 1;
                        if (memblock_unref_device(ctx, &mem_23421, "mem_23421") != 0)
                            return 1;
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t virt_num_tblocks_25078 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255, segmap_tblock_sizze_22983));
                        
                        {
                            err = gpu_kernel_simulate_8477zisegmap_22980(ctx, num_tblocks_22985, 1, 1, *ctx->tuning_params.simulate_8477zisegmap_tblock_sizze_22982, 1, 1, (int64_t) 0, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491, dzlz7bUZLztZRz20Utmpz20U3z7dUzg_16255, num_tblocks_22985, virt_num_tblocks_25078, mem_23405.mem, mem_23418.mem, mem_23430.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_unref_device(ctx, &mem_23418, "mem_23418") != 0)
                            return 1;
                        if (memblock_unref_device(ctx, &mem_23430, "mem_23430") != 0)
                            return 1;
                        loopres_f_res_f_res_f_res_15599 = tmp_21541;
                    } else {
                        int64_t tmp_15607 = add64((int64_t) 1, i_15540);
                        
                        loopres_f_res_f_res_f_res_15599 = tmp_15607;
                    }
                    loopres_f_res_f_res_15589 = loopres_f_res_f_res_f_res_15599;
                }
                loopres_f_res_15579 = loopres_f_res_f_res_15589;
            }
            loopres_15556 = loopres_f_res_15579;
            loopres_15557 = rng_15541;
            loopres_15559 = measurement_count_15543;
        }
        
        bool loop_cond_15614 = slt64(loopres_15556, n_15484);
        bool loop_while_tmp_23975 = loop_cond_15614;
        int64_t i_tmp_23977 = loopres_15556;
        int32_t rng_tmp_23978 = loopres_15557;
        int32_t measurement_count_tmp_23980 = loopres_15559;
        
        loop_while_15538 = loop_while_tmp_23975;
        i_15540 = i_tmp_23977;
        rng_15541 = rng_tmp_23978;
        measurement_count_15543 = measurement_count_tmp_23980;
    }
    simulate_res_15532 = loop_while_15538;
    simulate_res_15534 = i_15540;
    simulate_res_15535 = rng_15541;
    simulate_res_15537 = measurement_count_15543;
    if (memblock_unref_device(ctx, &mem_23414, "mem_23414") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_23885, &mem_23405, "mem_23405") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_23886, &mem_23406, "mem_23406") != 0)
        return 1;
    prim_out_23887 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20Unum_qubitsZRz20U1z7dUzg_15491;
    prim_out_23888 = defunc_0_f_res_21542;
    if (memblock_set_device(ctx, &*mem_out_p_25099, &mem_out_23885, "mem_out_23885") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_25100, &mem_out_23886, "mem_out_23886") != 0)
        return 1;
    *out_prim_out_25101 = prim_out_23887;
    *out_prim_out_25102 = prim_out_23888;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_23430, "mem_23430") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23423, "mem_23423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23422, "mem_23422") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23421, "mem_23421") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23420, "mem_23420") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23419, "mem_23419") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23418, "mem_23418") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23417, "mem_23417") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23416, "mem_23416") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23415, "mem_23415") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23443, "mem_23443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23436, "mem_23436") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23435, "mem_23435") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23434, "mem_23434") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23433, "mem_23433") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23432, "mem_23432") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23456, "mem_23456") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23449, "mem_23449") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23448, "mem_23448") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23447, "mem_23447") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23446, "mem_23446") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23445, "mem_23445") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_24936, "segred_tmp_mem_24936") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23631, "mem_23631") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23629, "mem_23629") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23633, "mem_23633") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23634, "ext_mem_23634") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_24853, "segred_tmp_mem_24853") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23616, "mem_23616") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23614, "mem_23614") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23618, "mem_23618") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23619, "ext_mem_23619") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_24772, "segred_tmp_mem_24772") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23541, "mem_23541") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_24720, "segred_tmp_mem_24720") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23484, "mem_23484") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23482, "mem_23482") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23480, "mem_23480") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23486, "mem_23486") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23477, "mem_23477") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23475, "mem_23475") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23532, "mem_23532") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23522, "mem_23522") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23512, "mem_23512") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23496, "mem_23496") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23535, "ext_mem_23535") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23538, "ext_mem_23538") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23539, "ext_mem_23539") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_24622, "segred_tmp_mem_24622") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_23823, "color_23823") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_23822, "color_23822") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23596, "mem_23596") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23582, "mem_23582") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23568, "mem_23568") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23552, "mem_23552") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23600, "ext_mem_23600") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23603, "ext_mem_23603") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23473, "mem_23473") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23471, "mem_23471") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_24498, "incprefixes_mem_24498") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_24496, "aggregates_mem_24496") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_24494, "status_flags_mem_24494") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23469, "mem_23469") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23467, "mem_23467") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23751, "mem_23751") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23691, "mem_23691") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23686, "mem_23686") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23689, "mem_23689") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_24314, "segred_tmp_mem_24314") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23678, "mem_23678") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23675, "mem_23675") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23680, "mem_23680") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23668, "mem_23668") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23694, "mem_23694") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_24221, "segred_tmp_mem_24221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23858, "mem_23858") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_23821, "color_23821") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23744, "mem_23744") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23734, "mem_23734") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23747, "ext_mem_23747") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_23748, "ext_mem_23748") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23665, "mem_23665") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23651, "mem_23651") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_24076, "incprefixes_mem_24076") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_24074, "aggregates_mem_24074") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_24072, "status_flags_mem_24072") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23663, "mem_23663") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23661, "mem_23661") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23657, "mem_23657") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23656, "mem_23656") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23655, "mem_23655") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23654, "mem_23654") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23653, "mem_23653") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23652, "mem_23652") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23463, "mem_23463") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23999, "segred_tmp_mem_23999") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23997, "segred_tmp_mem_23997") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23462, "mem_23462") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23461, "mem_23461") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23459, "mem_23459") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23458, "mem_23458") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23414, "mem_23414") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23406, "mem_23406") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23405, "mem_23405") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23913, "segred_tmp_mem_23913") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_23402, "mem_23402") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_23886, "mem_out_23886") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_23885, "mem_out_23885") != 0)
            return 1;
    }
    return err;
}

int futhark_entry_main(struct futhark_context *ctx, struct futhark_i8_1d **out0, const int32_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i64_1d *in4)
{
    int64_t n_15648 = (int64_t) 0;
    int32_t seed_15649 = 0;
    int64_t num_qubits_15650 = (int64_t) 0;
    int64_t prim_out_23886 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_23885;
    
    mem_out_23885.references = NULL;
    
    struct memblock_device tQ_mem_23400;
    
    tQ_mem_23400.references = NULL;
    
    struct memblock_device cQ_mem_23399;
    
    cQ_mem_23399.references = NULL;
    
    struct memblock_device gates_mem_23398;
    
    gates_mem_23398.references = NULL;
    seed_15649 = in0;
    num_qubits_15650 = in1;
    gates_mem_23398 = in2->mem;
    n_15648 = in2->shape[0];
    cQ_mem_23399 = in3->mem;
    n_15648 = in3->shape[0];
    tQ_mem_23400 = in4->mem;
    n_15648 = in4->shape[0];
    if (!(n_15648 == in2->shape[0] && (n_15648 == in3->shape[0] && n_15648 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_main(ctx, &mem_out_23885, &prim_out_23886, gates_mem_23398, cQ_mem_23399, tQ_mem_23400, n_15648, seed_15649, num_qubits_15650);
        if (ret == 0) {
            struct memblock_device counters_mem_23891 = ctx->constants->counters_mem_23891;
            struct memblock_device counters_mem_23995 = ctx->constants->counters_mem_23995;
            struct memblock_device counters_mem_24219 = ctx->constants->counters_mem_24219;
            struct memblock_device counters_mem_24316 = ctx->constants->counters_mem_24316;
            struct memblock_device counters_mem_24620 = ctx->constants->counters_mem_24620;
            struct memblock_device counters_mem_24722 = ctx->constants->counters_mem_24722;
            struct memblock_device counters_mem_24770 = ctx->constants->counters_mem_24770;
            struct memblock_device counters_mem_24855 = ctx->constants->counters_mem_24855;
            struct memblock_device counters_mem_24938 = ctx->constants->counters_mem_24938;
            struct memblock_device global_dynid_mem_24078 = ctx->constants->global_dynid_mem_24078;
            struct memblock_device global_dynid_mem_24500 = ctx->constants->global_dynid_mem_24500;
            
            assert((*out0 = (struct futhark_i8_1d *) malloc(sizeof(struct futhark_i8_1d))) != NULL);
            (*out0)->mem = mem_out_23885;
            (*out0)->shape[0] = prim_out_23886;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_simple(struct futhark_context *ctx, struct futhark_i8_1d **out0, const int64_t in0, const struct futhark_i64_1d *in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3)
{
    int64_t n_15664 = (int64_t) 0;
    int64_t num_qubits_15665 = (int64_t) 0;
    int64_t prim_out_23886 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_23885;
    
    mem_out_23885.references = NULL;
    
    struct memblock_device tQ_mem_23400;
    
    tQ_mem_23400.references = NULL;
    
    struct memblock_device cQ_mem_23399;
    
    cQ_mem_23399.references = NULL;
    
    struct memblock_device gates_mem_23398;
    
    gates_mem_23398.references = NULL;
    num_qubits_15665 = in0;
    gates_mem_23398 = in1->mem;
    n_15664 = in1->shape[0];
    cQ_mem_23399 = in2->mem;
    n_15664 = in2->shape[0];
    tQ_mem_23400 = in3->mem;
    n_15664 = in3->shape[0];
    if (!(n_15664 == in1->shape[0] && (n_15664 == in2->shape[0] && n_15664 == in3->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_simple(ctx, &mem_out_23885, &prim_out_23886, gates_mem_23398, cQ_mem_23399, tQ_mem_23400, n_15664, num_qubits_15665);
        if (ret == 0) {
            struct memblock_device counters_mem_23891 = ctx->constants->counters_mem_23891;
            struct memblock_device counters_mem_23995 = ctx->constants->counters_mem_23995;
            struct memblock_device counters_mem_24219 = ctx->constants->counters_mem_24219;
            struct memblock_device counters_mem_24316 = ctx->constants->counters_mem_24316;
            struct memblock_device counters_mem_24620 = ctx->constants->counters_mem_24620;
            struct memblock_device counters_mem_24722 = ctx->constants->counters_mem_24722;
            struct memblock_device counters_mem_24770 = ctx->constants->counters_mem_24770;
            struct memblock_device counters_mem_24855 = ctx->constants->counters_mem_24855;
            struct memblock_device counters_mem_24938 = ctx->constants->counters_mem_24938;
            struct memblock_device global_dynid_mem_24078 = ctx->constants->global_dynid_mem_24078;
            struct memblock_device global_dynid_mem_24500 = ctx->constants->global_dynid_mem_24500;
            
            assert((*out0 = (struct futhark_i8_1d *) malloc(sizeof(struct futhark_i8_1d))) != NULL);
            (*out0)->mem = mem_out_23885;
            (*out0)->shape[0] = prim_out_23886;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_simulate(struct futhark_context *ctx, struct futhark_i8_2d **out0, struct futhark_i8_1d **out1, const int32_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i64_1d *in4)
{
    int64_t n_15621 = (int64_t) 0;
    int32_t seed_15622 = 0;
    int64_t num_qubits_15623 = (int64_t) 0;
    int64_t prim_out_23887 = (int64_t) 0;
    int64_t prim_out_23888 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_23886;
    
    mem_out_23886.references = NULL;
    
    struct memblock_device mem_out_23885;
    
    mem_out_23885.references = NULL;
    
    struct memblock_device tQ_mem_23400;
    
    tQ_mem_23400.references = NULL;
    
    struct memblock_device cQ_mem_23399;
    
    cQ_mem_23399.references = NULL;
    
    struct memblock_device gates_mem_23398;
    
    gates_mem_23398.references = NULL;
    seed_15622 = in0;
    num_qubits_15623 = in1;
    gates_mem_23398 = in2->mem;
    n_15621 = in2->shape[0];
    cQ_mem_23399 = in3->mem;
    n_15621 = in3->shape[0];
    tQ_mem_23400 = in4->mem;
    n_15621 = in4->shape[0];
    if (!(n_15621 == in2->shape[0] && (n_15621 == in3->shape[0] && n_15621 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_simulate(ctx, &mem_out_23885, &mem_out_23886, &prim_out_23887, &prim_out_23888, gates_mem_23398, cQ_mem_23399, tQ_mem_23400, n_15621, seed_15622, num_qubits_15623);
        if (ret == 0) {
            struct memblock_device counters_mem_23891 = ctx->constants->counters_mem_23891;
            struct memblock_device counters_mem_23995 = ctx->constants->counters_mem_23995;
            struct memblock_device counters_mem_24219 = ctx->constants->counters_mem_24219;
            struct memblock_device counters_mem_24316 = ctx->constants->counters_mem_24316;
            struct memblock_device counters_mem_24620 = ctx->constants->counters_mem_24620;
            struct memblock_device counters_mem_24722 = ctx->constants->counters_mem_24722;
            struct memblock_device counters_mem_24770 = ctx->constants->counters_mem_24770;
            struct memblock_device counters_mem_24855 = ctx->constants->counters_mem_24855;
            struct memblock_device counters_mem_24938 = ctx->constants->counters_mem_24938;
            struct memblock_device global_dynid_mem_24078 = ctx->constants->global_dynid_mem_24078;
            struct memblock_device global_dynid_mem_24500 = ctx->constants->global_dynid_mem_24500;
            
            assert((*out0 = (struct futhark_i8_2d *) malloc(sizeof(struct futhark_i8_2d))) != NULL);
            (*out0)->mem = mem_out_23885;
            (*out0)->shape[0] = prim_out_23887;
            (*out0)->shape[1] = prim_out_23887;
            assert((*out1 = (struct futhark_i8_1d *) malloc(sizeof(struct futhark_i8_1d))) != NULL);
            (*out1)->mem = mem_out_23886;
            (*out1)->shape[0] = prim_out_23888;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
